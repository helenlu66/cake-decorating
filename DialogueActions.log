18:04:21,622 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:21,623 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,389 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,390 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,427 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,427 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,463 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,463 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,496 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,496 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,529 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,530 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,562 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,562 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,595 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,596 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,629 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,629 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,660 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:04:22,669 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:04:22,702 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f35ba84c810>
18:04:22,702 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f35ba61c170> server_hostname='api.openai.com' timeout=5.0
18:04:22,708 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f35ba82a050>
18:04:22,709 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:04:22,709 httpcore.http11 DEBUG send_request_headers.complete
18:04:22,709 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:04:22,710 httpcore.http11 DEBUG send_request_body.complete
18:04:22,710 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:04:23,243 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:04:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8a1b342bd8f027ad464bf3499661f716'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_vwJq7f_YtnDfo7kT3LQIpt8PoYRZ42x8IjNJ.tINvU-1701903863-0-Aas5pB/11cVRQt3Cxrc1MGAavRRZILVLQQM2yTrM6F7cUcfsBbudyQBtPUzh3QXYG7S1N3sDO65Yj92PGArdkfU=; path=/; expires=Wed, 06-Dec-23 23:34:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=36Qo1ZYu6gQdOCDfqnA4zeNaIqH3vP3YtsEoftUbH2g-1701903863241-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182ae5eceb6ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:04:23,245 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:04:23,245 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:04:23,767 httpcore.http11 DEBUG receive_response_body.complete
18:04:23,767 httpcore.http11 DEBUG response_closed.started
18:04:23,767 httpcore.http11 DEBUG response_closed.complete
18:04:23,768 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:10,562 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:10,563 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,328 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,329 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,368 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,369 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,403 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,403 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,436 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,436 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,469 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,469 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,501 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,501 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,534 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,535 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,565 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,566 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,596 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:06:11,605 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:06:11,633 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c92add0>
18:06:11,633 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986cb33c80> server_hostname='api.openai.com' timeout=5.0
18:06:11,640 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c935750>
18:06:11,641 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:11,641 httpcore.http11 DEBUG send_request_headers.complete
18:06:11,641 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:11,642 httpcore.http11 DEBUG send_request_body.complete
18:06:11,642 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:12,87 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:12 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'359'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'86b27ebb4df5bb027061a47a4a23a408'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7OBsIGWLKw429wzNfubpBG1w1xPo9p_pn0f6xrLiTKI-1701903972-0-AVz57idx+VRHj3//Be5Xro1KpS6xo5GySIXgt2QxBI0pxs3Yd76f6BKTVjgjrPPIl1JxN1dYCyI003RVuZbX+ZA=; path=/; expires=Wed, 06-Dec-23 23:36:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=51BY5i2lwp6sgvCs2Vq.kLOMPs.7fiKtpCi1Sm45j2Y-1701903972084-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182d8ecc8b4cef-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:12,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:06:12,89 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:12,439 httpcore.http11 DEBUG receive_response_body.complete
18:06:12,439 httpcore.http11 DEBUG response_closed.started
18:06:12,439 httpcore.http11 DEBUG response_closed.complete
18:06:12,440 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:12,514 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:06:26,287 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:06:26,289 httpcore.connection DEBUG close.started
18:06:26,289 httpcore.connection DEBUG close.complete
18:06:26,289 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:06:26,292 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c934e10>
18:06:26,292 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986cb33c80> server_hostname='api.openai.com' timeout=5.0
18:06:26,298 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986cc14c10>
18:06:26,298 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:26,299 httpcore.http11 DEBUG send_request_headers.complete
18:06:26,299 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:26,334 httpcore.http11 DEBUG send_request_body.complete
18:06:26,334 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:28,964 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:28 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'1'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1893'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5bec98e9862a580d6efccd0d023504a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182dea5eef3ba6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:28,965 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:06:28,965 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:28,965 httpcore.http11 DEBUG receive_response_body.complete
18:06:28,965 httpcore.http11 DEBUG response_closed.started
18:06:28,965 httpcore.http11 DEBUG response_closed.complete
18:06:28,966 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:06:28,966 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 2 column 1 (char 1)
18:06:28,975 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\n\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:06:28,983 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:06:28,985 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c755090>
18:06:28,985 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986cb33bf0> server_hostname='api.openai.com' timeout=None
18:06:28,993 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c7550d0>
18:06:28,993 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:28,994 httpcore.http11 DEBUG send_request_headers.complete
18:06:28,994 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:28,994 httpcore.http11 DEBUG send_request_body.complete
18:06:28,994 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:29,388 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'242'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f2f42517cf15248f3ff1bb96beab6a74'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uc5orlaxhb0ZcteprbJs2Xa4CDOyG13cBf8Me1.Rq_0-1701903989-0-AWNKkThf4sgC84DSHjlRsOPq/618IxHhsyu0HQWfFxqcBP2Gjj1N9Lotkd4HyBNAwscdrSR2yBEz+eLB98OJudg=; path=/; expires=Wed, 06-Dec-23 23:36:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=duNqR8Wjcid7Omebc9tIirrXdOjFRpKA2suM7guSmc8-1701903989386-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182dfb3c264d14-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:29,390 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:06:29,390 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:29,390 httpcore.http11 DEBUG receive_response_body.complete
18:06:29,390 httpcore.http11 DEBUG response_closed.started
18:06:29,391 httpcore.http11 DEBUG response_closed.complete
18:06:29,391 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:06:29,400 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\n\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:06:29,408 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:06:29,410 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c778610>
18:06:29,410 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986ca00290> server_hostname='api.openai.com' timeout=None
18:06:29,416 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c76e290>
18:06:29,416 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:29,417 httpcore.http11 DEBUG send_request_headers.complete
18:06:29,417 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:29,417 httpcore.http11 DEBUG send_request_body.complete
18:06:29,417 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:30,585 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1065'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9207908209e01a3602f1fea617be88b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aG4uNt6aPcJ8f5jiDGhP3NjLfnUgCYLh7t7Qnrg2jlI-1701903990-0-AbT4R5pGqX91gzP+zpmAUPxOunDK2SZ2J7NOgnRgNQmEq5d2xDvzBnf8xxA1S4Z6WDztsLrTv6B7CC8FR6VhlzE=; path=/; expires=Wed, 06-Dec-23 23:36:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=HGBGp4DM4fSOnAr6j9OrbTutJmgN.vDcFD7qj2NM0yM-1701903990583-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182dfddb863b69-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:30,587 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:06:30,587 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:30,587 httpcore.http11 DEBUG receive_response_body.complete
18:06:30,588 httpcore.http11 DEBUG response_closed.started
18:06:30,588 httpcore.http11 DEBUG response_closed.complete
18:06:30,588 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:06:30,591 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Ok, let's start with the first candle. Can you tell me where you would like me to place it? Please be as specific as possible so I can help you accurately place the candles.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:06:30,593 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:30,593 httpcore.http11 DEBUG send_request_headers.complete
18:06:30,593 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:30,593 httpcore.http11 DEBUG send_request_body.complete
18:06:30,594 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:31,300 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'591'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e475a4697f85a0c0194679c8836f47a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182e053d1c3ba6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:31,301 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:06:31,301 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:32,910 httpcore.http11 DEBUG receive_response_body.complete
18:06:32,911 httpcore.http11 DEBUG response_closed.started
18:06:32,911 httpcore.http11 DEBUG response_closed.complete
18:06:32,911 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:32,978 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:14:23,343 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:23,345 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,108 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,109 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,143 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,144 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,177 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,178 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,209 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,209 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,241 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,241 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,270 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,271 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,301 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,301 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,331 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,332 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,361 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:14:24,370 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:14:24,400 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603364c50>
18:14:24,400 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa603563c80> server_hostname='api.openai.com' timeout=5.0
18:14:24,405 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603395f50>
18:14:24,405 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:24,405 httpcore.http11 DEBUG send_request_headers.complete
18:14:24,406 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:24,406 httpcore.http11 DEBUG send_request_body.complete
18:14:24,406 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:24,885 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:24 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'26605efdef44faeb5fa397dab600436d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.5_fPErG5K9yT9CzSLuLk4xxrEUHDSPB8HlHAJbSn3s-1701904464-0-AUwZLBAqvU8hvqGFBloYcA/QvYrRDYCiuK9HELpp1xr8kyM+NnOgu27PcE9hjH2sF2XpwPfJiHKanB5K9FsgnVQ=; path=/; expires=Wed, 06-Dec-23 23:44:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RrcE_r3qRBeJA9XO3QDWwJXkPumpU5oUi8W0SM8uHak-1701904464882-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8318399688244d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:24,887 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:14:24,887 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:25,387 httpcore.http11 DEBUG receive_response_body.complete
18:14:25,387 httpcore.http11 DEBUG response_closed.started
18:14:25,387 httpcore.http11 DEBUG response_closed.complete
18:14:25,387 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:14:25,453 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:14:39,676 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:14:39,679 httpcore.connection DEBUG close.started
18:14:39,679 httpcore.connection DEBUG close.complete
18:14:39,679 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:14:39,682 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603364d90>
18:14:39,682 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa603563c80> server_hostname='api.openai.com' timeout=5.0
18:14:39,691 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603364bd0>
18:14:39,691 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:39,691 httpcore.http11 DEBUG send_request_headers.complete
18:14:39,691 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:39,712 httpcore.http11 DEBUG send_request_body.complete
18:14:39,712 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:40,830 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:40 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'463'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f119909bbf016b463e69a8b85f8f7499'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'831839f61ffa4cfc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:40,831 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:14:40,831 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:40,831 httpcore.http11 DEBUG receive_response_body.complete
18:14:40,832 httpcore.http11 DEBUG response_closed.started
18:14:40,832 httpcore.http11 DEBUG response_closed.complete
18:14:40,832 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:14:40,832 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:14:40,842 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nHi, put it to the left.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:14:40,849 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:14:40,852 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa6031876d0>
18:14:40,852 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa603563bf0> server_hostname='api.openai.com' timeout=None
18:14:40,856 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603185350>
18:14:40,856 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:40,857 httpcore.http11 DEBUG send_request_headers.complete
18:14:40,857 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:40,857 httpcore.http11 DEBUG send_request_body.complete
18:14:40,857 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:41,203 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'248'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9f8f58dd013b12c3fb666bc2ce803985'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.puo5hr42Xfy6VXBM2_hu.ajlEasEBr.VZAeHhhdlfk-1701904481-0-AZ5atlemN9efs9P73MdzgjDVfL4fiDIr+iuYSc6oSycd2iIevVRCTmWaougAT7VH3SCIiFSBwdJfg1kQo8HPgok=; path=/; expires=Wed, 06-Dec-23 23:44:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fzLBxL33cqWWyrCo5LxWD3e5yXHVNlNdPtYWLHZWdKg-1701904481201-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'831839fd5a643b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:41,204 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:14:41,205 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:41,205 httpcore.http11 DEBUG receive_response_body.complete
18:14:41,205 httpcore.http11 DEBUG response_closed.started
18:14:41,205 httpcore.http11 DEBUG response_closed.complete
18:14:41,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:14:41,217 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 20 in the x direction and 20 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (20, 20). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 20 in the x direction and 20 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (20, 20). You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nHi, put it to the left.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:14:41,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:14:41,226 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa6031a8ad0>
18:14:41,226 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa60342c680> server_hostname='api.openai.com' timeout=None
18:14:41,233 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa60319e650>
18:14:41,233 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:41,233 httpcore.http11 DEBUG send_request_headers.complete
18:14:41,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:41,233 httpcore.http11 DEBUG send_request_body.complete
18:14:41,233 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:41,841 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'511'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'bfef72e3ebef5a20041562e23339b414'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.gLcC.aGbDun4o4tCJNM1Nw9_M9d2J3Lr6ohlWLIWNY-1701904481-0-AfSLW8aiQLGs033TGofP75MYjpOKsDiAAb25q2mvxbJU7t1Mh3QfTKR1AIY0SNeoQNk6jSaIZ7Xw8jb8onC02pE=; path=/; expires=Wed, 06-Dec-23 23:44:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=N0n1QIYAmak4GdVuITmDa9uCgDJuv.oVsCGfsEqwf0Q-1701904481838-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'831839ffbcdb3bab-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:41,842 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:14:41,842 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:41,842 httpcore.http11 DEBUG receive_response_body.complete
18:14:41,843 httpcore.http11 DEBUG response_closed.started
18:14:41,843 httpcore.http11 DEBUG response_closed.complete
18:14:41,843 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:14:41,846 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:14:41,848 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:41,848 httpcore.http11 DEBUG send_request_headers.complete
18:14:41,848 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:41,849 httpcore.http11 DEBUG send_request_body.complete
18:14:41,849 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:42,282 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a01e73ae8692ff7669545c8f6d6d2ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83183a038aee4cfc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:42,283 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:14:42,284 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:42,546 httpcore.http11 DEBUG receive_response_body.complete
18:14:42,546 httpcore.http11 DEBUG response_closed.started
18:14:42,546 httpcore.http11 DEBUG response_closed.complete
18:14:42,547 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:14:42,614 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:37:39,803 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:39,805 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,587 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,587 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,627 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,628 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,663 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,664 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,696 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,697 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,730 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,731 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,763 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,764 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,796 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,796 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,827 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,828 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,858 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:37:40,867 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:40,898 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980ea1910>
18:37:40,898 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980dbfc80> server_hostname='api.openai.com' timeout=5.0
18:37:40,904 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980bc1650>
18:37:40,905 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:40,905 httpcore.http11 DEBUG send_request_headers.complete
18:37:40,905 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:40,906 httpcore.http11 DEBUG send_request_body.complete
18:37:40,906 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:41,340 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:41 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'604426a3dd0bf52bfb7bf8720d30b357'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=de6QToKOzo_TOprGGzP4kqrM4aDhqYNAQShJBa2ekGY-1701905861-0-AW7P/Y78OT1+BpbixU52xxnQl2904QjHRIvGvM8Do11SnvDHIk01CLz6ckixBiLJcC74Q7ShbyWcwhE9SA8dAlo=; path=/; expires=Thu, 07-Dec-23 00:07:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=atZXLIi7KvMZ4QIH45s2rsC_OD3On6OmUfS1z8lUQsU-1701905861338-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185baea9da4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:41,342 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:37:41,342 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:41,804 httpcore.http11 DEBUG receive_response_body.complete
18:37:41,804 httpcore.http11 DEBUG response_closed.started
18:37:41,804 httpcore.http11 DEBUG response_closed.complete
18:37:41,804 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:37:41,872 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:37:56,194 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:37:56,196 httpcore.connection DEBUG close.started
18:37:56,196 httpcore.connection DEBUG close.complete
18:37:56,196 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:56,199 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980bc0dd0>
18:37:56,199 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980dbfc80> server_hostname='api.openai.com' timeout=5.0
18:37:56,204 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980bc1650>
18:37:56,204 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:56,204 httpcore.http11 DEBUG send_request_headers.complete
18:37:56,205 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:56,238 httpcore.http11 DEBUG send_request_body.complete
18:37:56,238 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:57,347 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'304b683735aad1698e99e070bc91657e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c0e4c4c3b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:57,348 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:37:57,348 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:57,348 httpcore.http11 DEBUG receive_response_body.complete
18:37:57,348 httpcore.http11 DEBUG response_closed.started
18:37:57,349 httpcore.http11 DEBUG response_closed.complete
18:37:57,349 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:37:57,349 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:37:57,359 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nWhat? What the hell?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:57,366 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:57,373 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f29809e1310>
18:37:57,373 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980dbfbf0> server_hostname='api.openai.com' timeout=None
18:37:57,383 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f29809e36d0>
18:37:57,383 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:57,383 httpcore.http11 DEBUG send_request_headers.complete
18:37:57,383 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:57,383 httpcore.http11 DEBUG send_request_body.complete
18:37:57,384 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:57,750 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'283'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0fe0f87f58127da520805ba11a341f02'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tkIpVU8zlHVgog7ySbANVP48LRNh1ZluWPznK0zxESM-1701905877-0-ASNPR2sFTnIrf9qf2ByHDdZgl5ibgtRO/DVScrwmhYpeK6rZSZTfkbK2fpTcZvVrePEKQconE6kPD/zU1MC8thY=; path=/; expires=Thu, 07-Dec-23 00:07:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LgIa1EKKFXm04ANCyoYfIri1oGws56qPbS76CvFRCN0-1701905877747-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c15afe54cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:57,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:57,751 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:57,752 httpcore.http11 DEBUG receive_response_body.complete
18:37:57,752 httpcore.http11 DEBUG response_closed.started
18:37:57,752 httpcore.http11 DEBUG response_closed.complete
18:37:57,752 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:57,762 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nWhat? What the hell?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:57,769 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:57,771 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980a04590>
18:37:57,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980c88290> server_hostname='api.openai.com' timeout=None
18:37:57,781 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f29809fa050>
18:37:57,781 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:57,782 httpcore.http11 DEBUG send_request_headers.complete
18:37:57,782 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:57,783 httpcore.http11 DEBUG send_request_body.complete
18:37:57,783 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:58,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'923'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dbdb68d56db24ee3169a697f331e243f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ofgQFnumf_P1RqpMbtybZU5_e7FY1Ccj8nWibhFtJkc-1701905878-0-Afy/8PaqwnU4rzj0KppX0Rdp7dW0nza7hqQrPmPsWCGIGKvNdPqZR8Z6qzvJafd3p5y3ZIF6dMaT6M9FYxn+MOw=; path=/; expires=Thu, 07-Dec-23 00:07:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=tZb85p34uxKEet0sTPLGoGvUvbtL.enYL.LCK.gSax4-1701905878853-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c1829004ce4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:58,857 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:58,857 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:58,858 httpcore.http11 DEBUG receive_response_body.complete
18:37:58,858 httpcore.http11 DEBUG response_closed.started
18:37:58,858 httpcore.http11 DEBUG response_closed.complete
18:37:58,858 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:58,861 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I apologize for the confusion. I'm an assistant robot here to help you place the candles on the cake. Could you please tell me where you would like me to place the first candle?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:37:58,863 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:58,863 httpcore.http11 DEBUG send_request_headers.complete
18:37:58,863 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:58,864 httpcore.http11 DEBUG send_request_body.complete
18:37:58,864 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:59,558 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'563'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd32feb71cc070df82be98a9b0fcb6c5c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c1eeb4b3b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:59,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:37:59,559 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:00,919 httpcore.http11 DEBUG receive_response_body.complete
18:38:00,919 httpcore.http11 DEBUG response_closed.started
18:38:00,919 httpcore.http11 DEBUG response_closed.complete
18:38:00,920 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:38:00,990 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
16:55:11,373 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:11,374 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,151 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,152 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,192 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,193 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,228 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,229 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,262 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,263 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,298 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,298 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,332 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,332 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,367 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,367 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,401 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,401 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,436 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
16:55:12,445 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:55:12,476 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ade90>
16:55:12,476 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb2afd10> server_hostname='api.openai.com' timeout=5.0
16:55:12,481 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ae990>
16:55:12,482 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:12,482 httpcore.http11 DEBUG send_request_headers.complete
16:55:12,482 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:12,482 httpcore.http11 DEBUG send_request_body.complete
16:55:12,482 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:13,319 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:13 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'686'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1c8ff1093f8090a98d62e8cd557fc279'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4zYLpK4yTUQ0n0kaSrsah29EYn2ZRZrBnMB0lQok4BQ-1702072513-1-AbE5Lw1tjGBcR1wV449SOIelknkIgqMtqV73ZGs6HLfh8hYsiYbC/7kwhuWde/p+OFDOJJygNGFym6qLP/1s0ms=; path=/; expires=Fri, 08-Dec-23 22:25:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=MlOgY.svFauQZRJUJFtVu1FA6nZ3.aLWSFNdT1VM8x0-1702072513316-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840530e9f3031-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:13,321 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
16:55:13,321 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:13,714 httpcore.http11 DEBUG receive_response_body.complete
16:55:13,714 httpcore.http11 DEBUG response_closed.started
16:55:13,714 httpcore.http11 DEBUG response_closed.complete
16:55:13,715 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
16:55:13,785 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
16:55:29,394 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
16:55:29,398 httpcore.connection DEBUG close.started
16:55:29,398 httpcore.connection DEBUG close.complete
16:55:29,399 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:55:29,401 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ae990>
16:55:29,401 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb2afd10> server_hostname='api.openai.com' timeout=5.0
16:55:29,407 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ade90>
16:55:29,407 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:29,408 httpcore.http11 DEBUG send_request_headers.complete
16:55:29,408 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:29,437 httpcore.http11 DEBUG send_request_body.complete
16:55:29,437 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:30,392 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'437'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e5629beaede2321395038eb80c11384b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840bccbf03010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:30,393 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
16:55:30,393 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:30,393 httpcore.http11 DEBUG receive_response_body.complete
16:55:30,393 httpcore.http11 DEBUG response_closed.started
16:55:30,393 httpcore.http11 DEBUG response_closed.complete
16:55:30,394 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
16:55:30,394 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
16:55:30,402 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:55:30,409 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:55:30,412 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0d1e50>
16:55:30,412 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb2afc80> server_hostname='api.openai.com' timeout=None
16:55:30,420 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0d1e90>
16:55:30,420 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:30,421 httpcore.http11 DEBUG send_request_headers.complete
16:55:30,421 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:30,421 httpcore.http11 DEBUG send_request_body.complete
16:55:30,421 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:30,770 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'186'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5269eee3b54f3a98592582eef1560f4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=v3.Kb7jblhUJRA1BN_uhHrQvvXW6dluGTmtW8K_b..o-1702072530-1-ASArlEnPeikY1DISWext0GMx4JILrJz5p7bk/tVYcXDaZGjVTOJihU/eoUAJ3/3vG+N6o/XiZWMB0a/oR83SbMs=; path=/; expires=Fri, 08-Dec-23 22:25:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=VOhwumN2dYGtyYK4S5LP05AfgKDyemM5C6pZiEt7BqM-1702072530768-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840c32fce3b94-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:30,772 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:55:30,772 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:30,772 httpcore.http11 DEBUG receive_response_body.complete
16:55:30,773 httpcore.http11 DEBUG response_closed.started
16:55:30,773 httpcore.http11 DEBUG response_closed.complete
16:55:30,773 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:55:30,783 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:55:30,790 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:55:30,792 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0e52d0>
16:55:30,792 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb378710> server_hostname='api.openai.com' timeout=None
16:55:30,800 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdc468510>
16:55:30,800 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:30,800 httpcore.http11 DEBUG send_request_headers.complete
16:55:30,801 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:30,801 httpcore.http11 DEBUG send_request_body.complete
16:55:30,801 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:31,450 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'531'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7efefc471661137d4f864c61148267ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ew5pdzQq0nfh8fpyLkNAOpjDgXXrFCyFZr1oTrzxCrQ-1702072531-1-AUXExlmI8OdCM2BViZUCm7t6Y6Y7xUYMcY66dk2zo6aMyBEuOpTXbn7hNfI6GVWD6tZ+Un/PjkQAA4cj5DNm+WQ=; path=/; expires=Fri, 08-Dec-23 22:25:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=XhS5ZcvpMGOkKOM.GPRroqOZwEZhwvIYBJqHUJ13m7w-1702072531447-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840c58b114cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:31,451 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:55:31,451 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:31,452 httpcore.http11 DEBUG receive_response_body.complete
16:55:31,452 httpcore.http11 DEBUG response_closed.started
16:55:31,452 httpcore.http11 DEBUG response_closed.complete
16:55:31,452 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:55:31,458 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:31,461 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:35,164 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:35,167 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:35,169 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:38,870 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:38,873 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:38,875 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:42,576 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:42,579 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:42,581 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:46,282 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:46,285 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:46,288 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:58:16,994 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:16,995 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,777 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,779 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,819 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,820 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,855 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,856 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,889 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,890 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,925 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,925 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,958 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,959 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,994 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,994 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:18,29 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:18,29 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:18,65 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
16:58:18,75 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:58:18,105 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345828c10>
16:58:18,105 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0345a2bd10> server_hostname='api.openai.com' timeout=5.0
16:58:18,113 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345b18910>
16:58:18,113 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:18,114 httpcore.http11 DEBUG send_request_headers.complete
16:58:18,114 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:18,115 httpcore.http11 DEBUG send_request_body.complete
16:58:18,115 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:18,591 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:18 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'393'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b399c5855eee82464de261ac5ab6d325'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=oLEvUg0.bIurRQ7aq8DlLv77vlvw0flsXM4OVlp7yuU-1702072698-1-ASpUvYKeIJ3XIpgej0NYiDs0VlcE6ymfC2I05gaJ4RcaxnMQtrrxXjmwOjUqNrvJv2/en2ApcY0kA7IoW9Q9lTA=; path=/; expires=Fri, 08-Dec-23 22:28:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=nqwjw0Zf2JL21eKZD9M5gjdel.0bPqjDQ64r0idKm1Y-1702072698588-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832844db3a4f4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:18,593 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
16:58:18,594 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:19,280 httpcore.http11 DEBUG receive_response_body.complete
16:58:19,280 httpcore.http11 DEBUG response_closed.started
16:58:19,280 httpcore.http11 DEBUG response_closed.complete
16:58:19,281 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
16:58:19,351 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
16:58:35,45 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
16:58:35,48 httpcore.connection DEBUG close.started
16:58:35,48 httpcore.connection DEBUG close.complete
16:58:35,48 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:58:35,50 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345af5a50>
16:58:35,50 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0345a2bd10> server_hostname='api.openai.com' timeout=5.0
16:58:35,55 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f034582a210>
16:58:35,55 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:35,56 httpcore.http11 DEBUG send_request_headers.complete
16:58:35,56 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:35,90 httpcore.http11 DEBUG send_request_body.complete
16:58:35,90 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:36,101 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:36 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'438'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'26e6de7c22dd2b79bd55d37543beba4e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832845451d004cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:36,102 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
16:58:36,102 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:36,103 httpcore.http11 DEBUG receive_response_body.complete
16:58:36,103 httpcore.http11 DEBUG response_closed.started
16:58:36,103 httpcore.http11 DEBUG response_closed.complete
16:58:36,103 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
16:58:36,103 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
16:58:36,112 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:58:36,117 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:58:36,119 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345650d90>
16:58:36,120 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0345a2bc80> server_hostname='api.openai.com' timeout=None
16:58:36,125 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f03456511d0>
16:58:36,125 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:36,125 httpcore.http11 DEBUG send_request_headers.complete
16:58:36,125 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:36,126 httpcore.http11 DEBUG send_request_body.complete
16:58:36,126 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:36,338 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a7d3c852bea74ac1142eff1fee56aab3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5ky0R..GYuMBz6_cK0.cFzL.cxh1GQ55GSPfLD9XnFQ-1702072716-1-ATE6JAyZyD0415ecWJbHiPocs0tCnmW4De6MCqZB8WMoybShM2RSqVjdxPZueb4kNoWrbLQxYNcWB8SpXB8IA5Y=; path=/; expires=Fri, 08-Dec-23 22:28:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=AS6y5vKL0QVgfEWrVmApqgusuR4EaZs2_Un_DUMKscM-1702072716335-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328454bc8274cfa-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:36,339 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:58:36,339 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:36,340 httpcore.http11 DEBUG receive_response_body.complete
16:58:36,340 httpcore.http11 DEBUG response_closed.started
16:58:36,340 httpcore.http11 DEBUG response_closed.complete
16:58:36,340 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:58:36,351 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:58:36,358 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:58:36,361 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f034565fd50>
16:58:36,361 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f03458f8710> server_hostname='api.openai.com' timeout=None
16:58:36,366 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345666250>
16:58:36,366 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:36,367 httpcore.http11 DEBUG send_request_headers.complete
16:58:36,367 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:36,367 httpcore.http11 DEBUG send_request_body.complete
16:58:36,367 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:36,854 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b77a3bf21164697821d25da9fc1d331e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xoo35dNVIb4Yi4KzEVHWIddfcPLnpSkwfVIrdXtp2Wc-1702072716-1-Ab/te3M34njoDiKAhJb78KhjQ8NdVVFZV2v1D0heYRj78mW8w2ZwoZkdEXzASekxYWAAEZOMElubohd3/3cMuF0=; path=/; expires=Fri, 08-Dec-23 22:28:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=u_OW2rULnHVUHx5C6jTo.3Ghj5DJsl0LgmlKhQwjkjg-1702072716850-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328454d4ae23068-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:36,855 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:58:36,855 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:36,855 httpcore.http11 DEBUG receive_response_body.complete
16:58:36,856 httpcore.http11 DEBUG response_closed.started
16:58:36,856 httpcore.http11 DEBUG response_closed.complete
16:58:36,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:58:36,860 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:58:36,863 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:58:40,566 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:58:40,568 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:58:40,571 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:58:44,272 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:58:44,274 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:58:44,276 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:59:44,209 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:44,211 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:44,994 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:44,996 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,32 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,32 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,67 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,67 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,100 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,100 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,133 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,134 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,165 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,166 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,198 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,198 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,230 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,231 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,263 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
16:59:45,272 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:59:45,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e28606d0>
16:59:45,301 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
16:59:45,308 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571e90>
16:59:45,308 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:59:45,308 httpcore.http11 DEBUG send_request_headers.complete
16:59:45,309 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:59:45,309 httpcore.http11 DEBUG send_request_body.complete
16:59:45,309 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:59:45,761 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:59:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'378'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'62871b462068aeb8478f769924f1ef08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=l9pnjJ10wrk6VJdpc0EQmWAdUckzhr7AF74lC7T705g-1702072785-1-AbPqxEcXVeqY39XHmJh4tgzmb4yU2TYDKpBgNG2bU9QczKn84f2qy8dGMG6CSiNo2jwGTRetv6lgn5WBxOjUG50=; path=/; expires=Fri, 08-Dec-23 22:29:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=YyGTkFLiueEaI15vagqpOObSiZlgSLA5smuzvNluYyw-1702072785758-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832846fc2b654cd6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:59:45,763 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
16:59:45,763 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:59:46,546 httpcore.http11 DEBUG receive_response_body.complete
16:59:46,547 httpcore.http11 DEBUG response_closed.started
16:59:46,547 httpcore.http11 DEBUG response_closed.complete
16:59:46,547 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
16:59:46,619 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:00:02,343 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:00:02,346 httpcore.connection DEBUG close.started
17:00:02,346 httpcore.connection DEBUG close.complete
17:00:02,346 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:00:02,348 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571e90>
17:00:02,348 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:00:02,353 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571710>
17:00:02,353 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:02,354 httpcore.http11 DEBUG send_request_headers.complete
17:00:02,354 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:02,364 httpcore.http11 DEBUG send_request_body.complete
17:00:02,364 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:03,258 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:03 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'483'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8ea4d98b2ed1727b9dbd6d7c177be133'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284766bd2a304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:03,259 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:00:03,259 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:03,260 httpcore.http11 DEBUG receive_response_body.complete
17:00:03,260 httpcore.http11 DEBUG response_closed.started
17:00:03,260 httpcore.http11 DEBUG response_closed.complete
17:00:03,260 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:00:03,261 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:00:03,270 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:03,277 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:03,279 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595650>
17:00:03,279 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:00:03,288 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595d10>
17:00:03,289 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:03,289 httpcore.http11 DEBUG send_request_headers.complete
17:00:03,289 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:03,289 httpcore.http11 DEBUG send_request_body.complete
17:00:03,290 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:03,514 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a8de8edd4a2574d8937a8f009b32b191'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2dz_LzaTTVdrO2zXC.prMPCK6viwTrMNUMj2ADy9UTo-1702072803-1-AaQw5kOM9KFasftiwjul3Tz4HGu62YK13LUlFNTsSiI40J6TPdXtnIiNuF6BiblW/ByglPyIfCOGdCcb/IBSSqM=; path=/; expires=Fri, 08-Dec-23 22:30:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Mkh7vJhMOqAMnnvy68CFViiMYWDHn3oFx0EdiEpBIJs-1702072803511-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328476c8a184ce9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:03,515 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:03,515 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:03,516 httpcore.http11 DEBUG receive_response_body.complete
17:00:03,516 httpcore.http11 DEBUG response_closed.started
17:00:03,516 httpcore.http11 DEBUG response_closed.complete
17:00:03,517 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:03,527 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:03,534 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:03,536 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25a8cd0>
17:00:03,536 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2838710> server_hostname='api.openai.com' timeout=None
17:00:03,547 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25a8d10>
17:00:03,547 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:03,548 httpcore.http11 DEBUG send_request_headers.complete
17:00:03,548 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:03,548 httpcore.http11 DEBUG send_request_body.complete
17:00:03,548 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:04,42 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'391'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9b8825da9b8ffc65e55f2e2b2f24f507'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PjJpiPCfUI7cP3H3Q8HpHAYxX2Cnk_orHSSUnXG5oZA-1702072804-1-AUkjFLCFY0WsM0vrgsBXl0M3sx/zBEL1UABda9FWN8VBBEKAr9+PLBMW0x/zbfQBcn7cdZs2iAtcg4FDOajeIMg=; path=/; expires=Fri, 08-Dec-23 22:30:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pAJ0Xfv.a6DaPyD6qYyEKb4EMXstPa9CxtrXnuwja3U-1702072804039-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328476e2b4e4ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:04,44 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:04,44 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:04,45 httpcore.http11 DEBUG receive_response_body.complete
17:00:04,45 httpcore.http11 DEBUG response_closed.started
17:00:04,45 httpcore.http11 DEBUG response_closed.complete
17:00:04,45 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:04,51 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:04,54 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:07,757 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:07,761 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:07,763 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:11,465 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:11,467 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:11,470 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:15,171 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:15,174 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:15,177 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:18,878 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:18,881 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:18,884 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:22,585 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:22,587 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:22,590 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:26,291 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:26,294 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:26,297 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:29,998 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:30,2 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:30,5 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:33,706 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:33,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:00:33,709 httpcore.connection DEBUG close.started
17:00:33,709 httpcore.connection DEBUG close.complete
17:00:33,709 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:00:33,738 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571710>
17:00:33,738 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:00:33,747 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2594c90>
17:00:33,747 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:33,747 httpcore.http11 DEBUG send_request_headers.complete
17:00:33,747 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:33,747 httpcore.http11 DEBUG send_request_body.complete
17:00:33,747 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:34,434 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:34 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'576'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9d0b9798f5ad1e8260f041a86e9c7e18'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328482ae9c84d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:34,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:00:34,435 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:34,705 httpcore.http11 DEBUG receive_response_body.complete
17:00:34,705 httpcore.http11 DEBUG response_closed.started
17:00:34,705 httpcore.http11 DEBUG response_closed.complete
17:00:34,706 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:00:34,775 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:00:47,498 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:00:47,499 httpcore.connection DEBUG close.started
17:00:47,499 httpcore.connection DEBUG close.complete
17:00:47,499 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:00:47,515 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b1090>
17:00:47,515 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:00:47,521 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b0510>
17:00:47,521 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:47,522 httpcore.http11 DEBUG send_request_headers.complete
17:00:47,522 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:47,553 httpcore.http11 DEBUG send_request_body.complete
17:00:47,554 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:48,439 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'382'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1fc2b7602aad4ca93c849b17173ffb50'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832848810e0e3074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:48,440 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:00:48,440 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:48,441 httpcore.http11 DEBUG receive_response_body.complete
17:00:48,441 httpcore.http11 DEBUG response_closed.started
17:00:48,441 httpcore.http11 DEBUG response_closed.complete
17:00:48,441 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:00:48,441 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:00:48,449 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:48,451 httpcore.connection DEBUG close.started
17:00:48,452 httpcore.connection DEBUG close.complete
17:00:48,452 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:48,454 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595d10>
17:00:48,454 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:00:48,459 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595710>
17:00:48,459 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:48,459 httpcore.http11 DEBUG send_request_headers.complete
17:00:48,459 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:48,460 httpcore.http11 DEBUG send_request_body.complete
17:00:48,460 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:48,672 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'98'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'51384e70329e3d88c964aaeabb875f68'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284886dbb74cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:48,673 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:48,673 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:48,674 httpcore.http11 DEBUG receive_response_body.complete
17:00:48,674 httpcore.http11 DEBUG response_closed.started
17:00:48,674 httpcore.http11 DEBUG response_closed.complete
17:00:48,674 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:48,684 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:48,691 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:48,693 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c6610>
17:00:48,693 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773e30> server_hostname='api.openai.com' timeout=None
17:00:48,699 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c6410>
17:00:48,699 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:48,699 httpcore.http11 DEBUG send_request_headers.complete
17:00:48,699 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:48,700 httpcore.http11 DEBUG send_request_body.complete
17:00:48,700 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:48,945 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'133'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3e3859be5d4ec909f33068e030fd479c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=agydFVpaIi0uRPHsRxUQRk3raHVyGUDWdK93ce33IuA-1702072848-1-ATKSAAUV1EmL/QbEPiz6oBVOSwToRCc6eCtDYDrSQZc0nQCPNd6Z84h2jApl8PFyr9X3pvhrZcA1SHVL9VozSvc=; path=/; expires=Fri, 08-Dec-23 22:30:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=D64X7tNyLEpH1ev9iA1XxE2rblqGvtTZ9Vfsy1DwtHk-1702072848942-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832848885d374d06-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:48,946 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:48,947 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:48,947 httpcore.http11 DEBUG receive_response_body.complete
17:00:48,947 httpcore.http11 DEBUG response_closed.started
17:00:48,947 httpcore.http11 DEBUG response_closed.complete
17:00:48,948 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:48,951 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:48,954 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:52,655 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:52,657 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:52,660 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:56,361 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:56,364 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:56,366 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:00,67 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:00,68 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:01:00,70 httpcore.connection DEBUG close.started
17:01:00,70 httpcore.connection DEBUG close.complete
17:01:00,70 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:01:00,73 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cc650>
17:01:00,73 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:01:00,81 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cccd0>
17:01:00,81 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:00,82 httpcore.http11 DEBUG send_request_headers.complete
17:01:00,82 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:00,82 httpcore.http11 DEBUG send_request_body.complete
17:01:00,82 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:00,820 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'500'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1c7254255dbe193e67d5efa3a15e55cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832848cf8fb94cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:00,820 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:01:00,821 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:01,161 httpcore.http11 DEBUG receive_response_body.complete
17:01:01,162 httpcore.http11 DEBUG response_closed.started
17:01:01,162 httpcore.http11 DEBUG response_closed.complete
17:01:01,162 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:01:01,230 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:01:14,521 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:01:14,524 httpcore.connection DEBUG close.started
17:01:14,524 httpcore.connection DEBUG close.complete
17:01:14,524 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:01:14,527 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c6f90>
17:01:14,527 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:01:14,534 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c7090>
17:01:14,534 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:14,534 httpcore.http11 DEBUG send_request_headers.complete
17:01:14,535 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:14,564 httpcore.http11 DEBUG send_request_body.complete
17:01:14,564 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:15,448 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:15 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'434'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'46476bc6e3794aa8f299099c8f91b153'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284929d8cf3b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:15,449 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:01:15,450 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:15,450 httpcore.http11 DEBUG receive_response_body.complete
17:01:15,450 httpcore.http11 DEBUG response_closed.started
17:01:15,450 httpcore.http11 DEBUG response_closed.complete
17:01:15,450 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:01:15,451 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:01:15,457 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:01:15,458 httpcore.connection DEBUG close.started
17:01:15,458 httpcore.connection DEBUG close.complete
17:01:15,459 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:01:15,461 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b3950>
17:01:15,461 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:01:15,468 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b1e90>
17:01:15,468 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:15,468 httpcore.http11 DEBUG send_request_headers.complete
17:01:15,469 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:15,469 httpcore.http11 DEBUG send_request_body.complete
17:01:15,469 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:15,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'300'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd53d3064a6086635bb2238a7ab6f8e84'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328492fad654d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:15,856 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:01:15,856 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:15,857 httpcore.http11 DEBUG receive_response_body.complete
17:01:15,857 httpcore.http11 DEBUG response_closed.started
17:01:15,857 httpcore.http11 DEBUG response_closed.complete
17:01:15,857 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:01:15,867 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:01:15,868 httpcore.connection DEBUG close.started
17:01:15,869 httpcore.connection DEBUG close.complete
17:01:15,869 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:01:15,872 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2573950>
17:01:15,872 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2838710> server_hostname='api.openai.com' timeout=None
17:01:15,878 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2573f90>
17:01:15,878 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:15,878 httpcore.http11 DEBUG send_request_headers.complete
17:01:15,878 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:15,878 httpcore.http11 DEBUG send_request_body.complete
17:01:15,878 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:16,406 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'413'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'048dfa6c6cf4bd8bf777de3725d7b011'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284932398a4d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:16,406 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:01:16,407 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:16,407 httpcore.http11 DEBUG receive_response_body.complete
17:01:16,407 httpcore.http11 DEBUG response_closed.started
17:01:16,407 httpcore.http11 DEBUG response_closed.complete
17:01:16,407 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:01:16,412 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:16,414 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:20,115 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:20,118 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:20,120 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:23,821 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:23,823 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:23,826 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:27,527 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:27,530 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:27,537 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:31,238 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:31,241 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:31,243 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:34,944 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:34,946 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:34,949 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:38,650 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:38,652 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:38,673 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:42,373 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:42,376 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:42,379 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:46,80 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:46,83 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:46,85 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:49,786 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:49,789 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:49,791 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:53,492 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:53,495 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:53,497 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:57,198 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:57,200 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:57,202 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:00,903 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:00,904 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:02:00,906 httpcore.connection DEBUG close.started
17:02:00,906 httpcore.connection DEBUG close.complete
17:02:00,906 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:02:00,935 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c60d0>
17:02:00,936 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:02:00,946 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c5d10>
17:02:00,946 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:00,946 httpcore.http11 DEBUG send_request_headers.complete
17:02:00,947 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:00,947 httpcore.http11 DEBUG send_request_body.complete
17:02:00,947 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:01,364 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f4569221506058a12bcd2392a8d12130'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284a4be8c43071-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:01,365 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:02:01,365 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:01,645 httpcore.http11 DEBUG receive_response_body.complete
17:02:01,646 httpcore.http11 DEBUG response_closed.started
17:02:01,646 httpcore.http11 DEBUG response_closed.complete
17:02:01,646 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:02:01,714 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:02:14,403 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:02:14,404 httpcore.connection DEBUG close.started
17:02:14,405 httpcore.connection DEBUG close.complete
17:02:14,405 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:02:14,407 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cc810>
17:02:14,407 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:02:14,412 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cc610>
17:02:14,413 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:14,413 httpcore.http11 DEBUG send_request_headers.complete
17:02:14,413 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:14,443 httpcore.http11 DEBUG send_request_body.complete
17:02:14,443 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:15,702 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:15 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f6658bb19dc7371d1798ca045351f907'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284aa01b9c3008-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:15,702 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:02:15,702 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:15,703 httpcore.http11 DEBUG receive_response_body.complete
17:02:15,703 httpcore.http11 DEBUG response_closed.started
17:02:15,703 httpcore.http11 DEBUG response_closed.complete
17:02:15,703 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:02:15,703 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:02:15,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:02:15,708 httpcore.connection DEBUG close.started
17:02:15,708 httpcore.connection DEBUG close.complete
17:02:15,708 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:02:15,711 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25d5690>
17:02:15,711 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:02:15,719 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25d4f90>
17:02:15,720 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:15,720 httpcore.http11 DEBUG send_request_headers.complete
17:02:15,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:15,721 httpcore.http11 DEBUG send_request_body.complete
17:02:15,721 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:15,912 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'101'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ecd4c53851c8e5f03a906e43943af6a1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284aa84df63b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:15,912 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:02:15,913 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:15,913 httpcore.http11 DEBUG receive_response_body.complete
17:02:15,913 httpcore.http11 DEBUG response_closed.started
17:02:15,913 httpcore.http11 DEBUG response_closed.complete
17:02:15,913 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:02:15,920 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:02:15,921 httpcore.connection DEBUG close.started
17:02:15,921 httpcore.connection DEBUG close.complete
17:02:15,921 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:02:15,923 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b39d0>
17:02:15,923 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773e30> server_hostname='api.openai.com' timeout=None
17:02:15,929 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b2510>
17:02:15,929 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:15,929 httpcore.http11 DEBUG send_request_headers.complete
17:02:15,929 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:15,930 httpcore.http11 DEBUG send_request_body.complete
17:02:15,930 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:16,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cbb47112dc4dd6256e4e950421e1d60f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284aa98af23b8e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:16,127 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:02:16,127 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:16,127 httpcore.http11 DEBUG receive_response_body.complete
17:02:16,127 httpcore.http11 DEBUG response_closed.started
17:02:16,127 httpcore.http11 DEBUG response_closed.complete
17:02:16,128 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:02:16,131 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:02:16,133 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:19,834 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:19,838 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:02:19,840 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:23,541 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:23,544 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:02:23,547 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:27,247 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:27,248 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:02:27,249 httpcore.connection DEBUG close.started
17:02:27,249 httpcore.connection DEBUG close.complete
17:02:27,249 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:02:27,251 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b2050>
17:02:27,252 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:02:27,257 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b2110>
17:02:27,257 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:27,257 httpcore.http11 DEBUG send_request_headers.complete
17:02:27,258 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:27,258 httpcore.http11 DEBUG send_request_body.complete
17:02:27,258 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:27,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'449'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8020f093ad53e6afde755c8df2d0ce49'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284af059c54ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:27,821 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:02:27,821 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:28,244 httpcore.http11 DEBUG receive_response_body.complete
17:02:28,244 httpcore.http11 DEBUG response_closed.started
17:02:28,245 httpcore.http11 DEBUG response_closed.complete
17:02:28,245 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:02:28,312 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:42:51,316 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:51,319 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,138 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,140 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,182 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,183 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,231 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,232 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,273 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,274 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,322 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,323 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,363 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,364 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,412 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,413 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,454 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,455 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:55,612 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:42:55,636 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:42:55,654 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa2599a90>
17:42:55,655 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:42:55,662 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f771d0>
17:42:55,663 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:55,665 httpcore.http11 DEBUG send_request_headers.complete
17:42:55,666 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:55,667 httpcore.http11 DEBUG send_request_body.complete
17:42:55,667 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:56,304 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:42:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'503'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c4d9faf20af794464e44451784fb0114'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hcwEV4YeN53KbWYeynAhXHuSFyXCbSQVuPontRzJ_NM-1702075376-1-AfOFqF6fo0n7K3qqZ38C6NfpT53ZKfAeDydv33JWcmMuT1ClxobG/9COVLHrOMoKCFuKrPYRK+Ks8wr7y5a7w8M=; path=/; expires=Fri, 08-Dec-23 23:12:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=T9HzWSHYRM2Zw_iE1fw6u9y3OCaj4C24TmT2_4HvyTY-1702075376299-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288639edc74cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:56,314 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:42:56,315 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:57,137 httpcore.http11 DEBUG receive_response_body.complete
17:42:57,138 httpcore.http11 DEBUG response_closed.started
17:42:57,139 httpcore.http11 DEBUG response_closed.complete
17:42:57,140 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:42:57,211 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:43:13,3 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:43:13,13 httpcore.connection DEBUG close.started
17:43:13,14 httpcore.connection DEBUG close.complete
17:43:13,14 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:43:13,16 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f771d0>
17:43:13,16 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:43:13,22 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f77410>
17:43:13,22 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:13,23 httpcore.http11 DEBUG send_request_headers.complete
17:43:13,24 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:13,55 httpcore.http11 DEBUG send_request_body.complete
17:43:13,55 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:14,45 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:43:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'457'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ad0c7cf71d3797488592eb246f7aaa1a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832886a66d653035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:14,49 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:43:14,50 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:14,51 httpcore.http11 DEBUG receive_response_body.complete
17:43:14,51 httpcore.http11 DEBUG response_closed.started
17:43:14,52 httpcore.http11 DEBUG response_closed.complete
17:43:14,52 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:43:14,53 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:43:14,88 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:43:14,100 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:43:14,103 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcb150>
17:43:14,103 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9eb0> server_hostname='api.openai.com' timeout=None
17:43:14,117 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcb010>
17:43:14,118 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:14,119 httpcore.http11 DEBUG send_request_headers.complete
17:43:14,120 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:14,121 httpcore.http11 DEBUG send_request_body.complete
17:43:14,121 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:14,364 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:43:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9f2bdf70efce46b39ba7be1dc470a5f2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3Kt38mmV2MuKJo21sBRk1W31dKpT3u2kJ2RsGCr9UuI-1702075394-1-AUGGDfbt80RYKPv3zeGi6k4JnRTSKI+2rOo83x0ml+Rt2uJHtWSmVRPTsmuZBgiyz/sow+g2jBGHZyzGGdhfKjM=; path=/; expires=Fri, 08-Dec-23 23:13:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BC8AiFYMeFeCmUhVHL85Yr01uzaVA_5S5L5chC56I70-1702075394360-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832886ad49394d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:14,373 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:43:14,374 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:14,374 httpcore.http11 DEBUG receive_response_body.complete
17:43:14,375 httpcore.http11 DEBUG response_closed.started
17:43:14,375 httpcore.http11 DEBUG response_closed.complete
17:43:14,375 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:43:14,408 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:43:14,419 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:43:14,422 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0ddf990>
17:43:14,422 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ffa7b0> server_hostname='api.openai.com' timeout=None
17:43:14,428 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0ddf790>
17:43:14,429 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:14,430 httpcore.http11 DEBUG send_request_headers.complete
17:43:14,430 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:14,431 httpcore.http11 DEBUG send_request_body.complete
17:43:14,431 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:14,993 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:43:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'478'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fc6c609dd563d1d9609c7a78c6adcb59'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4NITqCPlM1B4VMqRzNquqEdORArm1rtIbj09Pe6YaHQ-1702075394-1-AcSTYurJ0y9qrTkyb//2jYffZszQ4sN4ovdh6m638bbPcXxYQ1g6CpI1vpgHeBXFvkRFrH5wcDhLBiL9DFPC1oA=; path=/; expires=Fri, 08-Dec-23 23:13:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IYdOLrWclqHvzdZQmjiBCY9RCmnq9Ox6r5sdOMG.M64-1702075394989-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832886af39923045-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:15,0 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:43:15,1 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:15,3 httpcore.http11 DEBUG receive_response_body.complete
17:43:15,4 httpcore.http11 DEBUG response_closed.started
17:43:15,5 httpcore.http11 DEBUG response_closed.complete
17:43:15,5 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:43:15,22 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:15,27 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:22,234 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:22,245 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:22,248 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:27,450 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:27,468 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:27,472 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:32,675 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:32,693 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:32,698 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:37,901 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:37,921 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:37,926 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:45,129 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:45,151 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:45,155 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:50,358 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:50,377 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:50,380 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:55,582 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:55,602 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:55,606 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:00,809 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:00,829 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:44:00,833 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:06,36 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:06,44 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:06,48 httpcore.connection DEBUG close.started
17:44:06,49 httpcore.connection DEBUG close.complete
17:44:06,49 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:06,79 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f77410>
17:44:06,80 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:06,87 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0ddbed0>
17:44:06,88 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:06,89 httpcore.http11 DEBUG send_request_headers.complete
17:44:06,90 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:06,91 httpcore.http11 DEBUG send_request_body.complete
17:44:06,91 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:07,173 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'956'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'57c361ac2d2baaf42a3e80df39159ba6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832887f21cc04d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:07,178 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:07,179 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:07,482 httpcore.http11 DEBUG receive_response_body.complete
17:44:07,483 httpcore.http11 DEBUG response_closed.started
17:44:07,484 httpcore.http11 DEBUG response_closed.complete
17:44:07,485 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:07,552 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:44:20,292 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:44:20,298 httpcore.connection DEBUG close.started
17:44:20,298 httpcore.connection DEBUG close.complete
17:44:20,299 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:20,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09a50>
17:44:20,302 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:20,309 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09ad0>
17:44:20,309 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:20,310 httpcore.http11 DEBUG send_request_headers.complete
17:44:20,310 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:20,347 httpcore.http11 DEBUG send_request_body.complete
17:44:20,348 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:21,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'389'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c96069710dbb00f5fb7f88bb03cb2b77'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328884afe934cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:21,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:44:21,460 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:21,461 httpcore.http11 DEBUG receive_response_body.complete
17:44:21,461 httpcore.http11 DEBUG response_closed.started
17:44:21,462 httpcore.http11 DEBUG response_closed.complete
17:44:21,462 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:44:21,463 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:44:21,496 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:21,500 httpcore.connection DEBUG close.started
17:44:21,501 httpcore.connection DEBUG close.complete
17:44:21,501 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:21,504 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dca1d0>
17:44:21,504 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9eb0> server_hostname='api.openai.com' timeout=None
17:44:21,509 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcb110>
17:44:21,510 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:21,511 httpcore.http11 DEBUG send_request_headers.complete
17:44:21,511 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:21,512 httpcore.http11 DEBUG send_request_body.complete
17:44:21,512 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:21,705 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fb643bb5c44ed7c6e942a67ba414a70f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888527f5f4cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:21,712 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:21,713 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:21,715 httpcore.http11 DEBUG receive_response_body.complete
17:44:21,716 httpcore.http11 DEBUG response_closed.started
17:44:21,716 httpcore.http11 DEBUG response_closed.complete
17:44:21,717 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:21,752 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:21,767 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:21,770 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09e50>
17:44:21,771 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:44:21,777 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09050>
17:44:21,777 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:21,778 httpcore.http11 DEBUG send_request_headers.complete
17:44:21,778 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:21,779 httpcore.http11 DEBUG send_request_body.complete
17:44:21,779 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:21,994 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8af60fac07d0d6e94e9ca8bdb3e58fdc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Wp_iVMatOZMSFDkPdpMQt_hy17v_wIK.dyzDzdNXN4c-1702075461-1-AcwPH6cdh/ZGIQcavKJgJm3Pm6bqYSh4dv13grlgXpT8LSHGU1ZyKlE3qOF0dfpuCxP4ZT/aWThSAxkPvQvYPg4=; path=/; expires=Fri, 08-Dec-23 23:14:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=QltwJ6RX5me7d1gAx1ZEmXTSD2j.p5H7bXtMBKbGViM-1702075461989-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888541ff94ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:22,4 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:22,5 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:22,6 httpcore.http11 DEBUG receive_response_body.complete
17:44:22,6 httpcore.http11 DEBUG response_closed.started
17:44:22,7 httpcore.http11 DEBUG response_closed.complete
17:44:22,7 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:22,22 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:44:22,27 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:27,231 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:27,236 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:27,241 httpcore.connection DEBUG close.started
17:44:27,241 httpcore.connection DEBUG close.complete
17:44:27,242 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:27,244 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e08cd0>
17:44:27,245 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:27,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0b490>
17:44:27,251 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:27,253 httpcore.http11 DEBUG send_request_headers.complete
17:44:27,253 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:27,254 httpcore.http11 DEBUG send_request_body.complete
17:44:27,254 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:27,664 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'339'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'557c902f8ceba2f99e4df00384ff57c4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888765d374d17-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:27,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:27,671 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:27,853 httpcore.http11 DEBUG receive_response_body.complete
17:44:27,854 httpcore.http11 DEBUG response_closed.started
17:44:27,855 httpcore.http11 DEBUG response_closed.complete
17:44:27,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:27,928 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:44:40,661 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:44:40,669 httpcore.connection DEBUG close.started
17:44:40,670 httpcore.connection DEBUG close.complete
17:44:40,671 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:40,674 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e11850>
17:44:40,674 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:40,682 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e118d0>
17:44:40,683 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:40,685 httpcore.http11 DEBUG send_request_headers.complete
17:44:40,686 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:40,718 httpcore.http11 DEBUG send_request_body.complete
17:44:40,718 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:41,628 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:41 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'72d1af114600a180239e224359e9e870'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888ca4b5a4ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:41,633 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:44:41,634 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:41,635 httpcore.http11 DEBUG receive_response_body.complete
17:44:41,635 httpcore.http11 DEBUG response_closed.started
17:44:41,635 httpcore.http11 DEBUG response_closed.complete
17:44:41,636 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:44:41,636 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:44:41,666 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:41,669 httpcore.connection DEBUG close.started
17:44:41,670 httpcore.connection DEBUG close.complete
17:44:41,670 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:41,672 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ca10>
17:44:41,673 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:44:41,680 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ca90>
17:44:41,681 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:41,682 httpcore.http11 DEBUG send_request_headers.complete
17:44:41,682 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:41,683 httpcore.http11 DEBUG send_request_body.complete
17:44:41,683 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:41,884 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'174f7159ade3952c06b9f4739ffac3f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888d08b2c4cdb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:41,890 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:41,891 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:41,892 httpcore.http11 DEBUG receive_response_body.complete
17:44:41,892 httpcore.http11 DEBUG response_closed.started
17:44:41,893 httpcore.http11 DEBUG response_closed.complete
17:44:41,893 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:41,910 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:44:41,915 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:47,117 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:47,123 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:47,128 httpcore.connection DEBUG close.started
17:44:47,129 httpcore.connection DEBUG close.complete
17:44:47,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:47,131 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e117d0>
17:44:47,131 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:47,141 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e126d0>
17:44:47,142 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:47,144 httpcore.http11 DEBUG send_request_headers.complete
17:44:47,144 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:47,145 httpcore.http11 DEBUG send_request_body.complete
17:44:47,146 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:47,586 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:47 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'371'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0b52604eb0551e7ecffc578365b1f9dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888f2a8596ac9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:47,590 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:47,591 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:47,780 httpcore.http11 DEBUG receive_response_body.complete
17:44:47,781 httpcore.http11 DEBUG response_closed.started
17:44:47,782 httpcore.http11 DEBUG response_closed.complete
17:44:47,783 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:47,849 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:00,393 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:00,397 httpcore.connection DEBUG close.started
17:45:00,397 httpcore.connection DEBUG close.complete
17:45:00,397 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:00,400 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0a650>
17:45:00,400 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:00,407 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0a4d0>
17:45:00,408 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:00,409 httpcore.http11 DEBUG send_request_headers.complete
17:45:00,409 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:00,447 httpcore.http11 DEBUG send_request_body.complete
17:45:00,447 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:01,430 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:01 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd5ddffa97fde7c58351c4f71a7377efb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889458a984d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:01,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:01,435 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:01,436 httpcore.http11 DEBUG receive_response_body.complete
17:45:01,437 httpcore.http11 DEBUG response_closed.started
17:45:01,437 httpcore.http11 DEBUG response_closed.complete
17:45:01,438 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:01,439 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:01,469 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\ndown\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:01,472 httpcore.connection DEBUG close.started
17:45:01,472 httpcore.connection DEBUG close.complete
17:45:01,473 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:01,475 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0b050>
17:45:01,475 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:45:01,481 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09b50>
17:45:01,481 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:01,482 httpcore.http11 DEBUG send_request_headers.complete
17:45:01,483 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:01,483 httpcore.http11 DEBUG send_request_body.complete
17:45:01,484 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:01,762 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'134'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b9c73caec8e0e791549baa62c9b5280b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328894c4ff43010-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:01,768 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:01,769 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:01,770 httpcore.http11 DEBUG receive_response_body.complete
17:45:01,771 httpcore.http11 DEBUG response_closed.started
17:45:01,771 httpcore.http11 DEBUG response_closed.complete
17:45:01,772 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:01,790 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:01,794 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:06,995 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:07,2 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:07,10 httpcore.connection DEBUG close.started
17:45:07,10 httpcore.connection DEBUG close.complete
17:45:07,11 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:07,42 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0ba50>
17:45:07,43 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:07,50 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0a950>
17:45:07,51 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:07,52 httpcore.http11 DEBUG send_request_headers.complete
17:45:07,53 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:07,54 httpcore.http11 DEBUG send_request_body.complete
17:45:07,54 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:07,484 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'351'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'db9c5552fc7aee2bca1847df98796cd1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328896f1ad74cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:07,489 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:07,490 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:07,752 httpcore.http11 DEBUG receive_response_body.complete
17:45:07,753 httpcore.http11 DEBUG response_closed.started
17:45:07,754 httpcore.http11 DEBUG response_closed.complete
17:45:07,755 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:07,820 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:20,463 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:20,468 httpcore.connection DEBUG close.started
17:45:20,469 httpcore.connection DEBUG close.complete
17:45:20,469 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:20,472 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1e9d0>
17:45:20,472 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:20,478 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ea90>
17:45:20,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:20,479 httpcore.http11 DEBUG send_request_headers.complete
17:45:20,480 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:20,516 httpcore.http11 DEBUG send_request_body.complete
17:45:20,517 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:21,728 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'644'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'acfafac8b0c92ef392f24a50f5faeb55'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889c30bc24cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:21,732 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:21,733 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:21,734 httpcore.http11 DEBUG receive_response_body.complete
17:45:21,735 httpcore.http11 DEBUG response_closed.started
17:45:21,735 httpcore.http11 DEBUG response_closed.complete
17:45:21,736 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:21,737 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:21,765 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nforward.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:21,769 httpcore.connection DEBUG close.started
17:45:21,769 httpcore.connection DEBUG close.complete
17:45:21,769 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:21,772 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e19b90>
17:45:21,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:45:21,779 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e19c10>
17:45:21,780 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:21,781 httpcore.http11 DEBUG send_request_headers.complete
17:45:21,781 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:21,782 httpcore.http11 DEBUG send_request_body.complete
17:45:21,782 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:21,979 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'051529ebf99663b80ec99b5432bd273f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889cb2c714cd6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:21,983 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:21,984 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:21,986 httpcore.http11 DEBUG receive_response_body.complete
17:45:21,986 httpcore.http11 DEBUG response_closed.started
17:45:21,987 httpcore.http11 DEBUG response_closed.complete
17:45:21,987 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:22,5 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:22,9 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:27,212 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:27,218 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:27,224 httpcore.connection DEBUG close.started
17:45:27,224 httpcore.connection DEBUG close.complete
17:45:27,224 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:27,227 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ebd0>
17:45:27,227 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:27,233 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1f850>
17:45:27,234 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:27,235 httpcore.http11 DEBUG send_request_headers.complete
17:45:27,235 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:27,236 httpcore.http11 DEBUG send_request_body.complete
17:45:27,236 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:27,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'478'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'de3cead6a00db61ee829722dce0d9382'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889ed3ff04d08-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:27,859 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:27,861 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:28,140 httpcore.http11 DEBUG receive_response_body.complete
17:45:28,141 httpcore.http11 DEBUG response_closed.started
17:45:28,142 httpcore.http11 DEBUG response_closed.complete
17:45:28,143 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:28,209 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:40,894 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:40,898 httpcore.connection DEBUG close.started
17:45:40,899 httpcore.connection DEBUG close.complete
17:45:40,899 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:40,901 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f68910>
17:45:40,902 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:40,908 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f68710>
17:45:40,909 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:40,911 httpcore.http11 DEBUG send_request_headers.complete
17:45:40,912 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:40,950 httpcore.http11 DEBUG send_request_body.complete
17:45:40,951 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:41,846 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:41 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'387'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8f93cdb2836f72aa5d1e79a0adcdc8f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288a42bef74cde-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:41,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:41,852 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:41,854 httpcore.http11 DEBUG receive_response_body.complete
17:45:41,855 httpcore.http11 DEBUG response_closed.started
17:45:41,855 httpcore.http11 DEBUG response_closed.complete
17:45:41,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:41,857 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:41,884 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:41,887 httpcore.connection DEBUG close.started
17:45:41,888 httpcore.connection DEBUG close.complete
17:45:41,888 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:41,890 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09750>
17:45:41,891 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:45:41,895 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0ba50>
17:45:41,896 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:41,897 httpcore.http11 DEBUG send_request_headers.complete
17:45:41,897 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:41,897 httpcore.http11 DEBUG send_request_body.complete
17:45:41,898 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:42,103 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'741106a7e8fefa1071eba29ce1648572'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288a48df5c3b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:42,110 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:42,110 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:42,111 httpcore.http11 DEBUG receive_response_body.complete
17:45:42,112 httpcore.http11 DEBUG response_closed.started
17:45:42,112 httpcore.http11 DEBUG response_closed.complete
17:45:42,112 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:42,128 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:42,131 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:47,333 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:47,348 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:47,351 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:52,554 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:52,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:52,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:57,781 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:57,789 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:57,794 httpcore.connection DEBUG close.started
17:45:57,794 httpcore.connection DEBUG close.complete
17:45:57,795 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:57,797 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0bb90>
17:45:57,798 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:57,806 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09810>
17:45:57,807 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:57,809 httpcore.http11 DEBUG send_request_headers.complete
17:45:57,810 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:57,811 httpcore.http11 DEBUG send_request_body.complete
17:45:57,811 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:58,255 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1c6496de4c649c1c16fbc9adaae4a679'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288aac5f794cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:58,260 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:58,261 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:58,632 httpcore.http11 DEBUG receive_response_body.complete
17:45:58,633 httpcore.http11 DEBUG response_closed.started
17:45:58,634 httpcore.http11 DEBUG response_closed.complete
17:45:58,635 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:58,703 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:46:12,270 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:46:12,275 httpcore.connection DEBUG close.started
17:46:12,275 httpcore.connection DEBUG close.complete
17:46:12,275 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:46:12,305 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e19d50>
17:46:12,306 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:46:12,312 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1a310>
17:46:12,313 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:12,315 httpcore.http11 DEBUG send_request_headers.complete
17:46:12,315 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:12,347 httpcore.http11 DEBUG send_request_body.complete
17:46:12,348 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:13,483 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:13 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'39'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'416'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c2b570e392ed39fe920ab4a4212f31c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b06fcea3010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:13,487 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:46:13,488 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:13,489 httpcore.http11 DEBUG receive_response_body.complete
17:46:13,490 httpcore.http11 DEBUG response_closed.started
17:46:13,490 httpcore.http11 DEBUG response_closed.complete
17:46:13,491 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:46:13,491 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:46:13,522 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nI don't know, do you have suggestions?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:13,527 httpcore.connection DEBUG close.started
17:46:13,528 httpcore.connection DEBUG close.complete
17:46:13,529 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:13,533 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcaf50>
17:46:13,534 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9eb0> server_hostname='api.openai.com' timeout=None
17:46:13,539 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dca1d0>
17:46:13,539 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:13,540 httpcore.http11 DEBUG send_request_headers.complete
17:46:13,541 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:13,541 httpcore.http11 DEBUG send_request_body.complete
17:46:13,541 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:14,360 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'723'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd153d7a4faee8abf407ec6dbb4bf9807'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b0eaa1f4d04-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:14,369 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:14,370 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:14,370 httpcore.http11 DEBUG receive_response_body.complete
17:46:14,371 httpcore.http11 DEBUG response_closed.started
17:46:14,371 httpcore.http11 DEBUG response_closed.complete
17:46:14,371 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:14,405 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nI don't know, do you have suggestions?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:14,419 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:14,422 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1b2d0>
17:46:14,423 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ffa330> server_hostname='api.openai.com' timeout=None
17:46:14,430 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ab50>
17:46:14,430 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:14,431 httpcore.http11 DEBUG send_request_headers.complete
17:46:14,432 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:14,432 httpcore.http11 DEBUG send_request_body.complete
17:46:14,433 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:15,564 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1037'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1811757b03dbea470d826b8dbc8c7ff2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YMuLF_lv.L3t46b8rx2n6_f4ad4eUvKoklDoBLCWiTo-1702075575-1-ASK49isOOMTWcfj7tzqPFtQ7qTjRWu1qXRUiR3oqX77Q/o9D/ZAjkDRKEu0cUQ1bgpLoYTfK8pdat63J5Gv+7Uc=; path=/; expires=Fri, 08-Dec-23 23:16:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=FrWjeQm.9SpF2yEIu0hyHl.sP3scNoo2LGq0Gm5498k-1702075575559-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b143c3a3ba0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:15,571 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:15,572 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:15,573 httpcore.http11 DEBUG receive_response_body.complete
17:46:15,574 httpcore.http11 DEBUG response_closed.started
17:46:15,574 httpcore.http11 DEBUG response_closed.complete
17:46:15,575 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:15,582 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'I suggest placing the second candle directly across from the first candle. That way, the candles will be evenly spaced around the cake. Shall I go ahead and place the second candle there?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:46:15,586 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:15,587 httpcore.http11 DEBUG send_request_headers.complete
17:46:15,588 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:15,588 httpcore.http11 DEBUG send_request_body.complete
17:46:15,589 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:16,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'465'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9a07111c011108c35350f35374f20433'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b1b6a653010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:16,131 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:46:16,132 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:17,896 httpcore.http11 DEBUG receive_response_body.complete
17:46:17,897 httpcore.http11 DEBUG response_closed.started
17:46:17,898 httpcore.http11 DEBUG response_closed.complete
17:46:17,898 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:46:17,971 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:58:04,276 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:04,280 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,118 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,119 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,163 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,164 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,212 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,213 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,254 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,255 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,302 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,303 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,343 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,344 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,392 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,393 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,433 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,434 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:45,731 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:45,734 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,569 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,570 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,612 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,613 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,660 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,661 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,703 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,704 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,751 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,752 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,793 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,794 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,841 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,842 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,882 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,883 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:48,190 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:58:48,210 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:58:48,241 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d3190>
17:58:48,241 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
17:58:48,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d3690>
17:58:48,253 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:58:48,256 httpcore.http11 DEBUG send_request_headers.complete
17:58:48,256 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:58:48,257 httpcore.http11 DEBUG send_request_body.complete
17:58:48,258 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:58:48,722 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:58:48 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ac569a87614adb6fb1f6f2ecb763610b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6CntS1cxn46BYQ6TxeHy2uH5.71dbNbSBXuwlyT3TnQ-1702076328-1-Ace9EsaQUzXzYwiA/qt428W+V29XaW4XcdsnxyeTAnW2zGGe701zYZcaUxRSy1IWEhDHwQJXPaxmsGhxXzWKVbY=; path=/; expires=Fri, 08-Dec-23 23:28:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=FUK2NY5e7HqqJ.RiJF5e8K2PXnDF8BMZzpTXKPHcGjE-1702076328717-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289d7b9a3a4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:58:48,732 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:58:48,733 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:58:49,549 httpcore.http11 DEBUG receive_response_body.complete
17:58:49,550 httpcore.http11 DEBUG response_closed.started
17:58:49,551 httpcore.http11 DEBUG response_closed.complete
17:58:49,552 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:58:49,639 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:59:03,208 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:59:03,222 httpcore.connection DEBUG close.started
17:59:03,223 httpcore.connection DEBUG close.complete
17:59:03,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:59:03,225 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d3690>
17:59:03,226 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
17:59:03,231 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d38d0>
17:59:03,232 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:59:03,233 httpcore.http11 DEBUG send_request_headers.complete
17:59:03,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:59:03,271 httpcore.http11 DEBUG send_request_body.complete
17:59:03,272 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:59:04,160 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:59:04 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'10be7de730dbeef26d67bd4316620be7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289dd939664d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:59:04,163 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:59:04,164 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:59:04,166 httpcore.http11 DEBUG receive_response_body.complete
17:59:04,167 httpcore.http11 DEBUG response_closed.started
17:59:04,168 httpcore.http11 DEBUG response_closed.complete
17:59:04,168 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:59:04,170 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:59:04,206 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:59:04,219 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:59:04,222 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf28287d0>
17:59:04,222 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859fd0> server_hostname='api.openai.com' timeout=None
17:59:04,230 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2828750>
17:59:04,231 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:59:04,232 httpcore.http11 DEBUG send_request_headers.complete
17:59:04,232 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:59:04,233 httpcore.http11 DEBUG send_request_body.complete
17:59:04,233 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:59:04,470 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:59:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b2528ca6c8ce5584683f9f6166ee64d8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mZ8gxZBR2DcChR4F.pLZ1CtzRM5smSRnIZBxtQBoMSQ-1702076344-1-ASFLYminXObAdcconYf2zyKHdtigVIsKNcKkNkLAzvE8/UYftJvxkb2VblsiU29MIsE4vkbYbTQ3YcrN9RLk2gY=; path=/; expires=Fri, 08-Dec-23 23:29:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=62HD2qCHMXW7UH8_9wEEgmueG8SJ2l_MYcPvkgEygWI-1702076344466-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289ddf78084ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:59:04,476 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:59:04,477 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:59:04,478 httpcore.http11 DEBUG receive_response_body.complete
17:59:04,478 httpcore.http11 DEBUG response_closed.started
17:59:04,479 httpcore.http11 DEBUG response_closed.complete
17:59:04,479 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:59:04,513 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:59:04,524 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:59:04,527 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2837710>
17:59:04,527 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf285a7b0> server_hostname='api.openai.com' timeout=None
17:59:04,536 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2834350>
17:59:04,536 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:59:04,537 httpcore.http11 DEBUG send_request_headers.complete
17:59:04,537 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:59:04,538 httpcore.http11 DEBUG send_request_body.complete
17:59:04,539 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:59:05,75 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:59:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'414'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0c7c552e9bc3c9ba3ac42d62b9062e32'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JsNp_.Nm6azw8J.iO0xmqu7B9L4GWs3v5Q8aNuRg5uo-1702076345-1-AUW1pz97OwBIrOot5YEgKQNpMO5IF7lEPhvQ27Mm7fwF4ZyzeOkmuWqnVkkCmFTQdfR2clV3UBKM/DKAUXe/B9U=; path=/; expires=Fri, 08-Dec-23 23:29:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=CYbqbW3mFK3XsRGj4QdsECRGC2RLVk0nPrwHDuRes3Y-1702076345070-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289de15c0a3b8e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:59:05,82 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:59:05,83 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:59:05,83 httpcore.http11 DEBUG receive_response_body.complete
17:59:05,84 httpcore.http11 DEBUG response_closed.started
17:59:05,84 httpcore.http11 DEBUG response_closed.complete
17:59:05,84 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:59:05,101 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:05,106 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:12,314 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:12,330 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:12,333 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:17,538 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:17,558 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:17,562 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:22,764 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:22,783 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:22,786 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:27,988 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:28,4 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:28,8 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:35,210 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:35,228 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:35,232 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:40,435 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:40,452 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:40,456 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:45,659 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:45,683 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:45,687 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:50,889 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:50,907 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:50,911 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:56,114 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:56,132 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:56,135 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:01,338 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:01,344 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:00:01,351 httpcore.connection DEBUG close.started
18:00:01,351 httpcore.connection DEBUG close.complete
18:00:01,351 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:01,383 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2894e50>
18:00:01,383 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:01,390 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2648090>
18:00:01,391 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:01,393 httpcore.http11 DEBUG send_request_headers.complete
18:00:01,394 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:01,395 httpcore.http11 DEBUG send_request_body.complete
18:00:01,395 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:02,3 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:02 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'492'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3344db0081bb6388243b45fef530d60'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f44bc654d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:02,8 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:00:02,9 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:02,203 httpcore.http11 DEBUG receive_response_body.complete
18:00:02,204 httpcore.http11 DEBUG response_closed.started
18:00:02,205 httpcore.http11 DEBUG response_closed.complete
18:00:02,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:00:02,271 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:00:09,815 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:00:09,819 httpcore.connection DEBUG close.started
18:00:09,820 httpcore.connection DEBUG close.complete
18:00:09,820 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:09,823 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265dd50>
18:00:09,823 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:09,831 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265ddd0>
18:00:09,831 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:09,833 httpcore.http11 DEBUG send_request_headers.complete
18:00:09,833 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:09,902 httpcore.http11 DEBUG send_request_body.complete
18:00:09,903 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:10,960 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:10 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'67f5c93b689dc1a082cc488ededc6538'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f797eb43bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:10,965 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:00:10,966 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:10,968 httpcore.http11 DEBUG receive_response_body.complete
18:00:10,968 httpcore.http11 DEBUG response_closed.started
18:00:10,969 httpcore.http11 DEBUG response_closed.complete
18:00:10,969 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:00:10,970 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:00:11,3 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMove forward.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:11,6 httpcore.connection DEBUG close.started
18:00:11,6 httpcore.connection DEBUG close.complete
18:00:11,7 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:00:11,9 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2822fd0>
18:00:11,10 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859fd0> server_hostname='api.openai.com' timeout=None
18:00:11,16 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2823f10>
18:00:11,16 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:11,17 httpcore.http11 DEBUG send_request_headers.complete
18:00:11,18 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:11,18 httpcore.http11 DEBUG send_request_body.complete
18:00:11,19 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:11,269 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'676b94a77ac4d2a5f09ce57e1eef6445'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f80daa44d0d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:11,275 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:11,277 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:11,279 httpcore.http11 DEBUG receive_response_body.complete
18:00:11,279 httpcore.http11 DEBUG response_closed.started
18:00:11,280 httpcore.http11 DEBUG response_closed.complete
18:00:11,280 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:11,288 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or to the left, right, up or down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:00:11,292 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:11,293 httpcore.http11 DEBUG send_request_headers.complete
18:00:11,294 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:11,294 httpcore.http11 DEBUG send_request_body.complete
18:00:11,294 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:12,58 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:12 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'691'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1531eaf516916d0a32f192ab023c7db4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f829dcb3bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:12,62 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:00:12,63 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:12,989 httpcore.http11 DEBUG receive_response_body.complete
18:00:12,990 httpcore.http11 DEBUG response_closed.started
18:00:12,990 httpcore.http11 DEBUG response_closed.complete
18:00:12,991 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:00:13,58 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:00:27,289 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:00:27,294 httpcore.connection DEBUG close.started
18:00:27,295 httpcore.connection DEBUG close.complete
18:00:27,296 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:27,298 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265f250>
18:00:27,298 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:27,303 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265e850>
18:00:27,304 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:27,305 httpcore.http11 DEBUG send_request_headers.complete
18:00:27,305 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:27,337 httpcore.http11 DEBUG send_request_body.complete
18:00:27,337 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:28,153 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:28 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'70ca47bce3b16a6bb9ceaacbc27f2b5b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289fe6a8604d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:28,158 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:00:28,159 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:28,159 httpcore.http11 DEBUG receive_response_body.complete
18:00:28,160 httpcore.http11 DEBUG response_closed.started
18:00:28,160 httpcore.http11 DEBUG response_closed.complete
18:00:28,160 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:00:28,161 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:00:28,191 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or to the left, right, up or down.\n'''\nAnd the human answered\n'''\nUp.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:28,203 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:00:28,206 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266cd90>
18:00:28,206 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859f40> server_hostname='api.openai.com' timeout=None
18:00:28,213 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266cd10>
18:00:28,214 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:28,215 httpcore.http11 DEBUG send_request_headers.complete
18:00:28,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:28,216 httpcore.http11 DEBUG send_request_body.complete
18:00:28,216 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:28,431 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2b9c6447414e16771bc74604d53d763c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YF2IZaCcr2QQl28Zz1ASq2Ihf_fADTIzydIdR16uf54-1702076428-1-AfYQ8aYu/AUFClEp6kxbourjvTKtmTp0Cct44dYritFKtUkMcbAUkVx9trjhjYi/HLe/WVzdNQ9a+SxydACjUt4=; path=/; expires=Fri, 08-Dec-23 23:30:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=bWMThyFXdmzDK4JwGf7c9IjZi.b9v6WDGhEVBsVJLNI-1702076428427-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289fec5b734cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:28,437 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:28,438 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:28,440 httpcore.http11 DEBUG receive_response_body.complete
18:00:28,440 httpcore.http11 DEBUG response_closed.started
18:00:28,441 httpcore.http11 DEBUG response_closed.complete
18:00:28,441 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:28,474 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or to the left, right, up or down.\n'''\nAnd the human answered\n'''\nUp.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:28,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:28,479 httpcore.http11 DEBUG send_request_headers.complete
18:00:28,479 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:28,479 httpcore.http11 DEBUG send_request_body.complete
18:00:28,480 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:28,724 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'143'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b41d9669c62d5187f2af96d444f9e364'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289fee0ef44cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:28,731 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:28,732 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:28,734 httpcore.http11 DEBUG receive_response_body.complete
18:00:28,735 httpcore.http11 DEBUG response_closed.started
18:00:28,735 httpcore.http11 DEBUG response_closed.complete
18:00:28,736 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:28,752 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:28,757 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:33,960 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:33,967 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:00:33,973 httpcore.connection DEBUG close.started
18:00:33,973 httpcore.connection DEBUG close.complete
18:00:33,974 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:33,976 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266d7d0>
18:00:33,976 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:33,984 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266d710>
18:00:33,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:33,985 httpcore.http11 DEBUG send_request_headers.complete
18:00:33,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:33,986 httpcore.http11 DEBUG send_request_body.complete
18:00:33,987 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:34,604 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:34 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'490'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'db6497489e3b0910acdaec4a2ad54c50'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a0106c403b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:34,610 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:00:34,611 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:34,818 httpcore.http11 DEBUG receive_response_body.complete
18:00:34,819 httpcore.http11 DEBUG response_closed.started
18:00:34,820 httpcore.http11 DEBUG response_closed.complete
18:00:34,820 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:00:34,891 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:00:45,527 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:00:45,532 httpcore.connection DEBUG close.started
18:00:45,532 httpcore.connection DEBUG close.complete
18:00:45,533 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:45,535 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265e750>
18:00:45,535 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:45,541 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265e890>
18:00:45,541 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:45,542 httpcore.http11 DEBUG send_request_headers.complete
18:00:45,542 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:45,573 httpcore.http11 DEBUG send_request_body.complete
18:00:45,574 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:46,419 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'7'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'df8d6a12c5b7dce1fa5e62032bc3f6cc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a058ae7a4ce4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:46,425 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:00:46,426 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:46,426 httpcore.http11 DEBUG receive_response_body.complete
18:00:46,427 httpcore.http11 DEBUG response_closed.started
18:00:46,427 httpcore.http11 DEBUG response_closed.complete
18:00:46,427 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:00:46,428 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:00:46,457 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nRight.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:46,461 httpcore.connection DEBUG close.started
18:00:46,461 httpcore.connection DEBUG close.complete
18:00:46,461 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:00:46,464 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265d890>
18:00:46,464 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859f40> server_hostname='api.openai.com' timeout=None
18:00:46,470 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265ff50>
18:00:46,470 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:46,471 httpcore.http11 DEBUG send_request_headers.complete
18:00:46,471 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:46,472 httpcore.http11 DEBUG send_request_body.complete
18:00:46,472 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:46,731 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'144'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'052a40cd9df75181705f4e77786a7580'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a05e7864300c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:46,737 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:46,738 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:46,740 httpcore.http11 DEBUG receive_response_body.complete
18:00:46,741 httpcore.http11 DEBUG response_closed.started
18:00:46,741 httpcore.http11 DEBUG response_closed.complete
18:00:46,742 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:46,759 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:46,763 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:51,966 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:51,984 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:51,988 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:57,190 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:57,207 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:57,211 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:02,413 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:02,420 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:01:02,427 httpcore.connection DEBUG close.started
18:01:02,427 httpcore.connection DEBUG close.complete
18:01:02,428 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:01:02,594 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265d610>
18:01:02,595 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:01:02,603 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265d350>
18:01:02,603 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:02,605 httpcore.http11 DEBUG send_request_headers.complete
18:01:02,605 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:02,606 httpcore.http11 DEBUG send_request_body.complete
18:01:02,606 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:03,211 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:01:03 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'467'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'dfb6c72e49cdd8069ce88f480b96391f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a0c34fdc4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:03,216 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:01:03,217 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:15,28 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,32 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:15,880 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,882 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:15,929 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,930 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:15,986 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,987 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,30 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,31 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,82 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,83 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,126 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,127 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,178 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,179 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,220 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,221 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:17,467 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vicent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:23:17,489 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:17,520 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee34d0>
18:23:17,521 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:23:17,531 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee3990>
18:23:17,532 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:17,535 httpcore.http11 DEBUG send_request_headers.complete
18:23:17,535 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:17,536 httpcore.http11 DEBUG send_request_body.complete
18:23:17,536 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:18,2 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:17 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e9ca4e281ca6f77f64b908e3f4ba0baf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xUWW4x9NzaNcAa5uVx_gIunLCU5YwGTWv8GSc3X1C_A-1702077797-1-AZdrdYV8eV2OLH0lMBPqoFzfs91CB06uhzFjy97uKWoPurccld0M5lejQa1P+yoML9uPgY9FAHq3l7nOqoTc62M=; path=/; expires=Fri, 08-Dec-23 23:53:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Q_1_OgfTeEUutufDcIQaDF2njOyVvdkVaJCOgTXxRB8-1702077797997-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c15a9e4d4cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:18,11 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:23:18,12 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:18,713 httpcore.http11 DEBUG receive_response_body.complete
18:23:18,714 httpcore.http11 DEBUG response_closed.started
18:23:18,715 httpcore.http11 DEBUG response_closed.complete
18:23:18,715 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:23:18,799 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:23:32,430 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:23:32,443 httpcore.connection DEBUG close.started
18:23:32,443 httpcore.connection DEBUG close.complete
18:23:32,444 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:32,446 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee3990>
18:23:32,446 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:23:32,451 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee3a90>
18:23:32,452 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:32,453 httpcore.http11 DEBUG send_request_headers.complete
18:23:32,453 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:32,481 httpcore.http11 DEBUG send_request_body.complete
18:23:32,482 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:33,466 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:33 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'431'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'552ce54d1a09d6a2d281322c6b96f1c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1b7da5c3049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:33,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:23:33,472 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:33,473 httpcore.http11 DEBUG receive_response_body.complete
18:23:33,473 httpcore.http11 DEBUG response_closed.started
18:23:33,473 httpcore.http11 DEBUG response_closed.complete
18:23:33,474 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:23:33,474 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:23:33,515 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vicent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nTell it.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:33,530 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:33,533 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38150>
18:23:33,533 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65f40> server_hostname='api.openai.com' timeout=None
18:23:33,542 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38110>
18:23:33,542 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:33,544 httpcore.http11 DEBUG send_request_headers.complete
18:23:33,544 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:33,545 httpcore.http11 DEBUG send_request_body.complete
18:23:33,545 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:33,789 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7574a139f9405dd5724740f59e183259'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=OK4QdgFhZe1YNKHqYgNSpHQChB5xRl.PIpZEAh26u88-1702077813-1-AfgS4NdTF3Rn2Ib/AStVPCfOgjpepWx4sYKE4YsLcue4tPgR+hAkJokllr2XzAhTDD0bCNH1gE+JtMdTdw8CVxw=; path=/; expires=Fri, 08-Dec-23 23:53:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=tgHR3w5fbYt2g2Prv1iOPDprn5VMdlJTarIXteunFFE-1702077813783-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1beafc14cc2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:33,798 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:33,799 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:33,801 httpcore.http11 DEBUG receive_response_body.complete
18:23:33,802 httpcore.http11 DEBUG response_closed.started
18:23:33,802 httpcore.http11 DEBUG response_closed.complete
18:23:33,802 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:33,838 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vicent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nTell it.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:33,849 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:33,851 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d39890>
18:23:33,852 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f662a0> server_hostname='api.openai.com' timeout=None
18:23:33,858 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d39d10>
18:23:33,858 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:33,859 httpcore.http11 DEBUG send_request_headers.complete
18:23:33,860 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:33,860 httpcore.http11 DEBUG send_request_body.complete
18:23:33,860 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:34,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'856'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b77e020a7d006c2a9a145018a4a45663'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3HRjSjzp3RWjGVCXNn4ZIPLtk39gs76yTZVri09Lzps-1702077814-1-AV3/GfUWQdHxRHFvlfs0a+TfuOFejekuWcEDusdyRQoI8nX8HVyACadYn0aW530JxlH1v7XIwV1334Wul0g+jmg=; path=/; expires=Fri, 08-Dec-23 23:53:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=4JX4gMGR7KJIDVG95hLkEfOwUECbp3OBKhK.ypi3LMg-1702077814816-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1c0981c4d1c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:34,828 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:34,829 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:34,830 httpcore.http11 DEBUG receive_response_body.complete
18:23:34,830 httpcore.http11 DEBUG response_closed.started
18:23:34,831 httpcore.http11 DEBUG response_closed.complete
18:23:34,831 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:34,841 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "\nGreat, let's start with the first candle. Where would you like me to place it? Please give me a specific location on the cake so I can help you place the candle.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:23:34,845 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:34,846 httpcore.http11 DEBUG send_request_headers.complete
18:23:34,847 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:34,847 httpcore.http11 DEBUG send_request_body.complete
18:23:34,847 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:35,373 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'460'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ea20feffce2c47fc4dc62084b42d1963'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1c6ceb83049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:35,378 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:23:35,378 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:37,27 httpcore.http11 DEBUG receive_response_body.complete
18:23:37,28 httpcore.http11 DEBUG response_closed.started
18:23:37,29 httpcore.http11 DEBUG response_closed.complete
18:23:37,30 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:23:37,103 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:23:56,124 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:23:56,128 httpcore.connection DEBUG close.started
18:23:56,128 httpcore.connection DEBUG close.complete
18:23:56,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:56,131 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55cd0>
18:23:56,131 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:23:56,137 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55d50>
18:23:56,137 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:56,138 httpcore.http11 DEBUG send_request_headers.complete
18:23:56,138 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:56,172 httpcore.http11 DEBUG send_request_body.complete
18:23:56,172 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:57,188 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'532'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'982913517078f6bf97aa09c9ba5d4d67'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c24bd9ae4cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:57,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:23:57,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:57,196 httpcore.http11 DEBUG receive_response_body.complete
18:23:57,196 httpcore.http11 DEBUG response_closed.started
18:23:57,197 httpcore.http11 DEBUG response_closed.complete
18:23:57,198 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:23:57,198 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:23:57,227 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\n\nGreat, let's start with the first candle. Where would you like me to place it? Please give me a specific location on the cake so I can help you place the candle.\n'''\nAnd the human answered\n'''\nput it in the center\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:57,231 httpcore.connection DEBUG close.started
18:23:57,231 httpcore.connection DEBUG close.complete
18:23:57,232 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:57,234 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38110>
18:23:57,235 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65f40> server_hostname='api.openai.com' timeout=None
18:23:57,241 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38bd0>
18:23:57,242 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:57,243 httpcore.http11 DEBUG send_request_headers.complete
18:23:57,243 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:57,244 httpcore.http11 DEBUG send_request_body.complete
18:23:57,244 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:57,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9a7077a8c2e00d80ecd5637c3df36dab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c252cbcc3061-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:57,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:57,459 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:57,461 httpcore.http11 DEBUG receive_response_body.complete
18:23:57,461 httpcore.http11 DEBUG response_closed.started
18:23:57,461 httpcore.http11 DEBUG response_closed.complete
18:23:57,462 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:57,495 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\n\nGreat, let's start with the first candle. Where would you like me to place it? Please give me a specific location on the cake so I can help you place the candle.\n'''\nAnd the human answered\n'''\nput it in the center\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:57,506 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:57,509 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d61350>
18:23:57,509 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f66720> server_hostname='api.openai.com' timeout=None
18:23:57,516 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d63610>
18:23:57,516 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:57,517 httpcore.http11 DEBUG send_request_headers.complete
18:23:57,517 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:57,518 httpcore.http11 DEBUG send_request_body.complete
18:23:57,518 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:58,376 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'770'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5b1a86b0e9bf6900638848b618d2fa14'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=X1jKHHb4hvhU3kk0UkI3emNxF7qmSfUGNULWagG7FXk-1702077838-1-AQAUxjk5QIYmXKUcO2wuk9KCR9JQ1V4gmqDewbj3BXw1bXv/oQR+u8PNMR8ekGW9jiEwf3JCHASUQnGtUWat8m8=; path=/; expires=Fri, 08-Dec-23 23:53:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=0o_wmImkxugk3a9YvyFgUlQ3qNApN1kbwSEktx7guE0-1702077838371-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c2547ddd3059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:58,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:58,383 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:58,385 httpcore.http11 DEBUG receive_response_body.complete
18:23:58,385 httpcore.http11 DEBUG response_closed.started
18:23:58,386 httpcore.http11 DEBUG response_closed.complete
18:23:58,386 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:58,801 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:23:58,805 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:06,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:06,28 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:06,31 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:11,233 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:11,257 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:11,260 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:16,462 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:16,478 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:16,482 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:21,684 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:21,703 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:21,707 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:28,909 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:28,928 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:28,937 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:34,140 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:34,159 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:34,163 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:39,364 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:39,382 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:39,385 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:44,587 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:44,602 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:44,605 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:49,807 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:49,824 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:49,828 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:55,30 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:55,47 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:55,50 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:25:00,252 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:25:00,260 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:25:00,270 httpcore.connection DEBUG close.started
18:25:00,271 httpcore.connection DEBUG close.complete
18:25:00,272 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:00,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55c10>
18:25:00,302 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:00,309 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55e50>
18:25:00,309 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:00,311 httpcore.http11 DEBUG send_request_headers.complete
18:25:00,312 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:00,313 httpcore.http11 DEBUG send_request_body.complete
18:25:00,313 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:00,781 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'355'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bed552900bdaf75d0f9d78e25c298f21'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c3dcfff24ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:00,787 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:25:00,788 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:00,979 httpcore.http11 DEBUG receive_response_body.complete
18:25:00,981 httpcore.http11 DEBUG response_closed.started
18:25:00,981 httpcore.http11 DEBUG response_closed.complete
18:25:00,983 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:25:01,54 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:25:08,662 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:25:08,667 httpcore.connection DEBUG close.started
18:25:08,667 httpcore.connection DEBUG close.complete
18:25:08,668 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:08,670 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80a50>
18:25:08,670 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:08,677 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80ad0>
18:25:08,678 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:08,679 httpcore.http11 DEBUG send_request_headers.complete
18:25:08,679 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:08,714 httpcore.http11 DEBUG send_request_body.complete
18:25:08,714 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:09,479 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:09 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'322'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'84de94c52755d4f33c2b3458de718116'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4113c8b4ce8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:09,485 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:25:09,486 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:09,488 httpcore.http11 DEBUG receive_response_body.complete
18:25:09,489 httpcore.http11 DEBUG response_closed.started
18:25:09,489 httpcore.http11 DEBUG response_closed.complete
18:25:09,490 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:25:09,490 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:25:09,524 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:09,527 httpcore.connection DEBUG close.started
18:25:09,528 httpcore.connection DEBUG close.complete
18:25:09,528 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:09,530 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38bd0>
18:25:09,531 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65f40> server_hostname='api.openai.com' timeout=None
18:25:09,539 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38cd0>
18:25:09,539 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:09,541 httpcore.http11 DEBUG send_request_headers.complete
18:25:09,542 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:09,543 httpcore.http11 DEBUG send_request_body.complete
18:25:09,543 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:09,763 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9f21fed6e24c1380fc32e3547dd920e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c416aa3d4d07-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:09,769 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:09,771 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:09,772 httpcore.http11 DEBUG receive_response_body.complete
18:25:09,772 httpcore.http11 DEBUG response_closed.started
18:25:09,772 httpcore.http11 DEBUG response_closed.complete
18:25:09,773 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:09,805 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:09,817 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:09,819 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d810d0>
18:25:09,819 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65eb0> server_hostname='api.openai.com' timeout=None
18:25:09,824 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d81250>
18:25:09,825 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:09,826 httpcore.http11 DEBUG send_request_headers.complete
18:25:09,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:09,827 httpcore.http11 DEBUG send_request_body.complete
18:25:09,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:10,33 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1d8ee58fbeef267175cd7c2559ad57ef'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fBY4YD7lLKLqufnDVhuWLyIEHNN0OjByFqt4o6sVDIg-1702077910-1-AYLmfmdXUh0cKd42QuWOk4vmSOOjhgGdFA48Qd1n/qeWzI5FlaOo/HYBdNZ+c/y253hnCl05bg3ODkx+h8b5g3A=; path=/; expires=Fri, 08-Dec-23 23:55:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=s8gVlfggjFVWmPbiqNL.Zn9gx1Qw5la5M_EdQStQAHE-1702077910029-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4186875305d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:10,42 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:10,43 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:10,43 httpcore.http11 DEBUG receive_response_body.complete
18:25:10,44 httpcore.http11 DEBUG response_closed.started
18:25:10,44 httpcore.http11 DEBUG response_closed.complete
18:25:10,44 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:10,59 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:25:10,63 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:25:15,265 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:25:15,272 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:25:15,279 httpcore.connection DEBUG close.started
18:25:15,279 httpcore.connection DEBUG close.complete
18:25:15,279 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:15,282 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80990>
18:25:15,282 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:15,288 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80810>
18:25:15,289 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:15,290 httpcore.http11 DEBUG send_request_headers.complete
18:25:15,290 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:15,291 httpcore.http11 DEBUG send_request_body.complete
18:25:15,291 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:15,733 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb95a15999b3418cdd3b4b93e4850bab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c43a9cd74cde-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:15,738 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:25:15,739 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:16,36 httpcore.http11 DEBUG receive_response_body.complete
18:25:16,37 httpcore.http11 DEBUG response_closed.started
18:25:16,38 httpcore.http11 DEBUG response_closed.complete
18:25:16,39 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:25:16,110 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:25:23,813 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:25:23,817 httpcore.connection DEBUG close.started
18:25:23,818 httpcore.connection DEBUG close.complete
18:25:23,818 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:23,821 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d86790>
18:25:23,822 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:23,827 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d86810>
18:25:23,828 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:23,829 httpcore.http11 DEBUG send_request_headers.complete
18:25:23,829 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:23,852 httpcore.http11 DEBUG send_request_body.complete
18:25:23,853 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:24,551 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:24 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'309'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b11b02134efdddac2b04a4256ec8e73d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c46fe8ff4d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:24,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:25:24,557 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:24,559 httpcore.http11 DEBUG receive_response_body.complete
18:25:24,559 httpcore.http11 DEBUG response_closed.started
18:25:24,560 httpcore.http11 DEBUG response_closed.complete
18:25:24,561 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:25:24,562 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:25:24,590 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:24,593 httpcore.connection DEBUG close.started
18:25:24,594 httpcore.connection DEBUG close.complete
18:25:24,594 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:24,597 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d8d8d0>
18:25:24,597 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65eb0> server_hostname='api.openai.com' timeout=None
18:25:24,604 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d8d950>
18:25:24,604 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:24,605 httpcore.http11 DEBUG send_request_headers.complete
18:25:24,606 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:24,606 httpcore.http11 DEBUG send_request_body.complete
18:25:24,606 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:24,820 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3b50e9c7e76b05af90d0138a9f909801'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c474c8bf4d08-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:24,825 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:24,826 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:24,828 httpcore.http11 DEBUG receive_response_body.complete
18:25:24,828 httpcore.http11 DEBUG response_closed.started
18:25:24,829 httpcore.http11 DEBUG response_closed.complete
18:25:24,829 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:24,849 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:25:24,853 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:25:30,55 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:25:30,63 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:25:30,68 httpcore.connection DEBUG close.started
18:25:30,68 httpcore.connection DEBUG close.complete
18:25:30,69 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:30,71 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d86550>
18:25:30,71 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:30,78 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d879d0>
18:25:30,78 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:30,79 httpcore.http11 DEBUG send_request_headers.complete
18:25:30,79 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:30,80 httpcore.http11 DEBUG send_request_body.complete
18:25:30,80 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:30,530 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:30 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'365'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3ca591c8b673a82faccfe25779b920b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c496f9003ba0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:30,534 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:25:30,534 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:30,801 httpcore.http11 DEBUG receive_response_body.complete
18:25:30,802 httpcore.http11 DEBUG response_closed.started
18:25:30,802 httpcore.http11 DEBUG response_closed.complete
18:25:30,803 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:25:30,868 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:25:38,532 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:25:38,536 httpcore.connection DEBUG close.started
18:25:38,537 httpcore.connection DEBUG close.complete
18:25:38,537 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:38,540 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d87bd0>
18:25:38,540 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:38,547 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d84e50>
18:25:38,548 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:38,549 httpcore.http11 DEBUG send_request_headers.complete
18:25:38,549 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:38,562 httpcore.http11 DEBUG send_request_body.complete
18:25:38,563 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:39,691 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:39 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'637'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'98e0711b71b0ae6e5fbd74c71d4cad7e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4cbec0e300c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:39,695 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:25:39,696 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:39,697 httpcore.http11 DEBUG receive_response_body.complete
18:25:39,698 httpcore.http11 DEBUG response_closed.started
18:25:39,698 httpcore.http11 DEBUG response_closed.complete
18:25:39,699 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:25:39,699 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:25:39,730 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:39,733 httpcore.connection DEBUG close.started
18:25:39,734 httpcore.connection DEBUG close.complete
18:25:39,734 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:39,736 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80050>
18:25:39,737 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65eb0> server_hostname='api.openai.com' timeout=None
18:25:39,741 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d81010>
18:25:39,742 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:39,743 httpcore.http11 DEBUG send_request_headers.complete
18:25:39,743 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:39,744 httpcore.http11 DEBUG send_request_body.complete
18:25:39,744 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:39,965 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c46a0462a3848e50c802561ddd0a0f36'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4d3682d6ac6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:39,972 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:39,973 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:39,974 httpcore.http11 DEBUG receive_response_body.complete
18:25:39,974 httpcore.http11 DEBUG response_closed.started
18:25:39,975 httpcore.http11 DEBUG response_closed.complete
18:25:39,975 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:39,990 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:25:39,993 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:29:54,154 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:54,158 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:54,987 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:54,988 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,32 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,33 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,82 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,83 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,125 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,126 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,174 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,175 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,216 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,217 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,266 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,267 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,309 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,310 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:58,168 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:29:58,186 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:58,218 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8934537910>
18:29:58,218 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fdd90> server_hostname='api.openai.com' timeout=5.0
18:29:58,226 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f893447f890>
18:29:58,226 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:58,228 httpcore.http11 DEBUG send_request_headers.complete
18:29:58,228 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:58,228 httpcore.http11 DEBUG send_request_body.complete
18:29:58,229 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:58,686 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:29:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'017bd1ee9bc6e1438c7c05807e0198a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0Is7Y8KR.l9FcBdTCYag6iwuL.YEOQ7bUfhNQqV4iTk-1702078198-1-AcPGqEbMcyFUlXX+syLVmDwI7ieaHi7J+7TO76683ogrZnHCYqPGsiYR7nY3yPGB9uOU6OE0ycTz5vxtvVh/euA=; path=/; expires=Fri, 08-Dec-23 23:59:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=MDogYZKkc0nDuRGyl2pUP7P2jg79vEHDrtw_an_d7vQ-1702078198681-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb22ef42300c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:58,694 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:29:58,694 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:59,607 httpcore.http11 DEBUG receive_response_body.complete
18:29:59,608 httpcore.http11 DEBUG response_closed.started
18:29:59,609 httpcore.http11 DEBUG response_closed.complete
18:29:59,610 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:29:59,695 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:30:13,610 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:30:13,620 httpcore.connection DEBUG close.started
18:30:13,621 httpcore.connection DEBUG close.complete
18:30:13,622 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:30:13,624 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f893449f390>
18:30:13,625 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fdd90> server_hostname='api.openai.com' timeout=5.0
18:30:13,631 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f893447ea90>
18:30:13,632 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:13,633 httpcore.http11 DEBUG send_request_headers.complete
18:30:13,633 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:13,661 httpcore.http11 DEBUG send_request_body.complete
18:30:13,662 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:14,940 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:30:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'620'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fc001f635c0c71ef5e6ad9d95a029e36'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb8338bd4d16-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:14,944 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:30:14,944 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:14,945 httpcore.http11 DEBUG receive_response_body.complete
18:30:14,945 httpcore.http11 DEBUG response_closed.started
18:30:14,946 httpcore.http11 DEBUG response_closed.complete
18:30:14,946 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:30:14,947 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:30:14,985 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:14,997 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:15,34 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344d0050>
18:30:15,35 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fdf40> server_hostname='api.openai.com' timeout=None
18:30:15,44 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344d09d0>
18:30:15,45 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:15,47 httpcore.http11 DEBUG send_request_headers.complete
18:30:15,48 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:15,49 httpcore.http11 DEBUG send_request_body.complete
18:30:15,50 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:15,270 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:30:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'126'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f3c3625e971ea3fb70da5adfcf286b4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dbargJkkEaFHQlRLZ27GrWHvuEM9ku.1CXn.O33WS3k-1702078215-1-AWDr0h2WHGkOftqneN1AjW7w73OWa1JmVT+FlGutLRYMN89juH+VAODdDOZWfm1rNkITDFmoDNR6vapkyerxBpc=; path=/; expires=Sat, 09-Dec-23 00:00:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=b5_Kgpbm9qWypxiqBy4M0qNdlv3lRcqoHaF8N6Km9hI-1702078215265-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb8c0eaf3074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:15,281 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:15,282 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:15,283 httpcore.http11 DEBUG receive_response_body.complete
18:30:15,283 httpcore.http11 DEBUG response_closed.started
18:30:15,283 httpcore.http11 DEBUG response_closed.complete
18:30:15,284 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:15,318 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:15,330 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:15,333 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344d34d0>
18:30:15,334 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fe720> server_hostname='api.openai.com' timeout=None
18:30:15,341 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344c3390>
18:30:15,342 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:15,343 httpcore.http11 DEBUG send_request_headers.complete
18:30:15,343 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:15,344 httpcore.http11 DEBUG send_request_body.complete
18:30:15,344 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:16,33 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:30:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'582'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3ccf74c03bfa36b94aa9ccaa35fa818e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ygw5NT9AtjcNhF8ntOgI2jR7guV_pQD9Oq.y84PJujQ-1702078216-1-AbV1bJE/bLvHlSNhlet46qQwCI7PgaxFt2Akprl01QP3hS9hSFKANB2FuJwdPackoE2vWb4XNKNkjE468H4uiZU=; path=/; expires=Sat, 09-Dec-23 00:00:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ZwmI4wipG.EaPhIYQxoZRWsPiUnvL4cgTTDUs2zRV5I-1702078216029-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb8dede14cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:16,40 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:16,42 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:16,44 httpcore.http11 DEBUG receive_response_body.complete
18:30:16,45 httpcore.http11 DEBUG response_closed.started
18:30:16,45 httpcore.http11 DEBUG response_closed.complete
18:30:16,46 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:16,478 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:16,483 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:30:23,692 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:30:23,709 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:23,713 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:30:28,915 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:30:28,930 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:28,933 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:03,833 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:03,836 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,642 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,643 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,685 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,686 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,735 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,736 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,777 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,778 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,825 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,826 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,867 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,868 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,916 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,917 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,957 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,958 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:05,769 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:32:05,789 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:05,819 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5957190>
18:32:05,820 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:32:05,828 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5957690>
18:32:05,829 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:05,831 httpcore.http11 DEBUG send_request_headers.complete
18:32:05,831 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:05,831 httpcore.http11 DEBUG send_request_body.complete
18:32:05,832 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:06,290 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:06 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'377'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'32613f16b25f4de3d8e5dcd331fbeafd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9HmoBvScVOe.Z.OztyDEvfeNTWsn_yP.MqJ4wSRWs5s-1702078326-1-AQtG60gO3oyV9HIGAEVz8m0h0yRbGJnImquaur/klkYWi4i0ciWutJWjalSgYnGSbhfwQX5eLB1HhSMWnsttuhs=; path=/; expires=Sat, 09-Dec-23 00:02:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BlUebMc3WvduuuIx_5GL781YUhfCu.N1O6lLu65Jm_g-1702078326284-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ce407fb04cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:06,298 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:32:06,299 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:07,60 httpcore.http11 DEBUG receive_response_body.complete
18:32:07,61 httpcore.http11 DEBUG response_closed.started
18:32:07,62 httpcore.http11 DEBUG response_closed.complete
18:32:07,62 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:32:07,141 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:32:20,759 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:32:20,768 httpcore.connection DEBUG close.started
18:32:20,769 httpcore.connection DEBUG close.complete
18:32:20,769 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:20,772 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5957a50>
18:32:20,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:32:20,779 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59578d0>
18:32:20,780 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:20,781 httpcore.http11 DEBUG send_request_headers.complete
18:32:20,781 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:20,813 httpcore.http11 DEBUG send_request_body.complete
18:32:20,813 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:21,995 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'15'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'365'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bf0e59de5342c6686a9ed873c6cb964f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ce9de94d4d0e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:21,998 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:32:21,998 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:21,999 httpcore.http11 DEBUG receive_response_body.complete
18:32:21,999 httpcore.http11 DEBUG response_closed.started
18:32:22,0 httpcore.http11 DEBUG response_closed.complete
18:32:22,0 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:32:22,1 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:32:22,34 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nat the center.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:32:22,45 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:32:22,48 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ac050>
18:32:22,48 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1f40> server_hostname='api.openai.com' timeout=None
18:32:22,55 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ac9d0>
18:32:22,55 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:22,56 httpcore.http11 DEBUG send_request_headers.complete
18:32:22,57 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:22,57 httpcore.http11 DEBUG send_request_body.complete
18:32:22,58 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:22,276 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2293db4494c04809be682fdf7514c255'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=m1zrGgYQjxfwCcem2nnhb5LCrREj0b0xvPFTu60.zD8-1702078342-1-AcBQ5zOi+fmc/SI7ebIixQZATlaXbY+fUIlfhVC5v7OxnFmw2SHl/Nj0kKNuTKXxAVgBc9BZmBMJ82gV8Bid7jE=; path=/; expires=Sat, 09-Dec-23 00:02:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=cvD7tntWNsq.6jpjHkXGxgb_fz.pb.N1RBc_y6XSJ9U-1702078342271-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cea5d9b26ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:22,285 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:32:22,286 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:22,287 httpcore.http11 DEBUG receive_response_body.complete
18:32:22,287 httpcore.http11 DEBUG response_closed.started
18:32:22,287 httpcore.http11 DEBUG response_closed.complete
18:32:22,288 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:32:22,322 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nat the center.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:32:22,332 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:32:22,335 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5df0510>
18:32:22,335 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be2720> server_hostname='api.openai.com' timeout=None
18:32:22,341 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ad810>
18:32:22,341 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:22,342 httpcore.http11 DEBUG send_request_headers.complete
18:32:22,342 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:22,343 httpcore.http11 DEBUG send_request_body.complete
18:32:22,343 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:23,72 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'633'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5e67480df490c2521f325e712ab21bcd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=z0ghITu4MfFJldyk04tPCJw5hPK_t7CCKynH1_NGIiM-1702078343-1-AbvYghKjT0JhRWSQMT3FyCY2GYtGzoeXOdC+jt8wBCVOCGZ7uLqI2CKOUKW+sYEhWgSRaVqL5VBjfYliu6pNSfI=; path=/; expires=Sat, 09-Dec-23 00:02:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kRO4TA0a.aG68ZSpVgsgT.oghKyYLs11qI_aYEythu8-1702078343067-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cea7a9253025-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:23,78 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:32:23,79 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:23,80 httpcore.http11 DEBUG receive_response_body.complete
18:32:23,81 httpcore.http11 DEBUG response_closed.started
18:32:23,82 httpcore.http11 DEBUG response_closed.complete
18:32:23,82 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:32:23,492 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:23,496 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:30,704 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:30,720 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:30,724 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:35,926 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:35,944 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:35,949 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:41,152 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:41,169 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:41,173 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:46,376 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:46,393 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:46,397 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:53,600 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:53,620 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:53,623 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:58,824 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:58,841 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:58,845 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:04,47 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:04,66 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:04,69 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:09,271 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:09,289 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:09,292 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:14,494 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:14,512 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:14,515 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:19,718 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:19,726 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:33:19,732 httpcore.connection DEBUG close.started
18:33:19,732 httpcore.connection DEBUG close.complete
18:33:19,733 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:19,760 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5a17650>
18:33:19,760 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:19,767 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59cbc50>
18:33:19,768 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:19,770 httpcore.http11 DEBUG send_request_headers.complete
18:33:19,771 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:19,772 httpcore.http11 DEBUG send_request_body.complete
18:33:19,772 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:20,491 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'566'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f46fb0a20ea44e0cc7741973439b41ea'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d00e9ebf4d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:20,495 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:33:20,496 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:21,418 httpcore.http11 DEBUG receive_response_body.complete
18:33:21,418 httpcore.http11 DEBUG response_closed.started
18:33:21,419 httpcore.http11 DEBUG response_closed.complete
18:33:21,419 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:33:21,483 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:33:33,469 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:33:33,476 httpcore.connection DEBUG close.started
18:33:33,476 httpcore.connection DEBUG close.complete
18:33:33,476 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:33,479 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de950>
18:33:33,479 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:33,486 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de9d0>
18:33:33,486 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:33,487 httpcore.http11 DEBUG send_request_headers.complete
18:33:33,488 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:33,514 httpcore.http11 DEBUG send_request_body.complete
18:33:33,514 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:34,322 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'354'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6ea4f4f06d0b6bd01a3fca57ec1e0b7b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0644c634ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:34,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:33:34,324 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:34,325 httpcore.http11 DEBUG receive_response_body.complete
18:33:34,325 httpcore.http11 DEBUG response_closed.started
18:33:34,325 httpcore.http11 DEBUG response_closed.complete
18:33:34,326 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:33:34,326 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:33:34,355 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nUh, most of the...\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:33:34,358 httpcore.connection DEBUG close.started
18:33:34,359 httpcore.connection DEBUG close.complete
18:33:34,359 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:33:34,361 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ac9d0>
18:33:34,361 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1f40> server_hostname='api.openai.com' timeout=None
18:33:34,368 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59aca50>
18:33:34,368 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:34,369 httpcore.http11 DEBUG send_request_headers.complete
18:33:34,370 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:34,370 httpcore.http11 DEBUG send_request_body.complete
18:33:34,370 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:34,588 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e160c6b4cd9e533a737dc8610c926234'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d069ca7a4cf2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:34,595 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:33:34,597 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:34,599 httpcore.http11 DEBUG receive_response_body.complete
18:33:34,600 httpcore.http11 DEBUG response_closed.started
18:33:34,601 httpcore.http11 DEBUG response_closed.complete
18:33:34,601 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:33:34,608 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:33:34,612 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:34,613 httpcore.http11 DEBUG send_request_headers.complete
18:33:34,613 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:34,613 httpcore.http11 DEBUG send_request_body.complete
18:33:34,614 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:35,285 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'555'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9e1403a25c2f0f9162f184678aaffec9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d06b5f114ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:35,290 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:33:35,291 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:36,358 httpcore.http11 DEBUG receive_response_body.complete
18:33:36,358 httpcore.http11 DEBUG response_closed.started
18:33:36,359 httpcore.http11 DEBUG response_closed.complete
18:33:36,360 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:33:36,434 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:33:49,118 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:33:49,125 httpcore.connection DEBUG close.started
18:33:49,126 httpcore.connection DEBUG close.complete
18:33:49,126 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:49,129 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59dcb10>
18:33:49,129 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:49,136 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59dd410>
18:33:49,136 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:49,138 httpcore.http11 DEBUG send_request_headers.complete
18:33:49,138 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:49,163 httpcore.http11 DEBUG send_request_body.complete
18:33:49,164 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:50,31 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:50 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'371'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'be53eab8116e395b4c0f9f7211a466da'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0c61c5c4cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:50,35 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:33:50,36 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:50,37 httpcore.http11 DEBUG receive_response_body.complete
18:33:50,37 httpcore.http11 DEBUG response_closed.started
18:33:50,38 httpcore.http11 DEBUG response_closed.complete
18:33:50,38 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:33:50,39 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:33:50,69 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:33:50,78 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:33:50,81 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59edf10>
18:33:50,81 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:33:50,89 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59eded0>
18:33:50,89 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:50,91 httpcore.http11 DEBUG send_request_headers.complete
18:33:50,91 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:50,92 httpcore.http11 DEBUG send_request_body.complete
18:33:50,92 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:50,326 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1ec717c35c2eecaf712d20dc9bd377b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qjIMCtEoaSLJp_MQ2EXqxL30whdS1mIOSN8H3LdfQbM-1702078430-1-AdCwUQ+ZThDSIRTbD3WV0cOeGpDZIzsv0OI9V7PKWjoPN1jxxVhke5+102Sj2kM6zVXOa9bB1e9hF2qOPtSgSqA=; path=/; expires=Sat, 09-Dec-23 00:03:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BihLozpwzEEi8EODi.w2D2yyOgL8lrSw_QiYkSdosDc-1702078430320-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0cc1bb44d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:50,334 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:33:50,335 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:50,336 httpcore.http11 DEBUG receive_response_body.complete
18:33:50,336 httpcore.http11 DEBUG response_closed.started
18:33:50,336 httpcore.http11 DEBUG response_closed.complete
18:33:50,337 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:33:50,370 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:33:50,374 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:50,375 httpcore.http11 DEBUG send_request_headers.complete
18:33:50,375 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:50,376 httpcore.http11 DEBUG send_request_body.complete
18:33:50,376 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:50,592 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1fffccca370d09b92f5eb46b9f6cba81'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0cddf104d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:50,597 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:33:50,598 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:50,600 httpcore.http11 DEBUG receive_response_body.complete
18:33:50,601 httpcore.http11 DEBUG response_closed.started
18:33:50,602 httpcore.http11 DEBUG response_closed.complete
18:33:50,602 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:33:50,618 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:50,621 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:55,823 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:55,829 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:33:55,835 httpcore.connection DEBUG close.started
18:33:55,835 httpcore.connection DEBUG close.complete
18:33:55,836 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:55,838 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ee5d0>
18:33:55,839 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:55,844 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ef790>
18:33:55,845 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:55,847 httpcore.http11 DEBUG send_request_headers.complete
18:33:55,847 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:55,848 httpcore.http11 DEBUG send_request_body.complete
18:33:55,848 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:56,428 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'469'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'74fb29e2d51344f09da55043bc76f8bf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0f00c4e4cd4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:56,433 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:33:56,434 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:56,722 httpcore.http11 DEBUG receive_response_body.complete
18:33:56,722 httpcore.http11 DEBUG response_closed.started
18:33:56,723 httpcore.http11 DEBUG response_closed.complete
18:33:56,723 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:33:56,788 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:34:04,548 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:34:04,555 httpcore.connection DEBUG close.started
18:34:04,555 httpcore.connection DEBUG close.complete
18:34:04,556 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:04,558 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59df110>
18:34:04,559 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:04,567 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de350>
18:34:04,568 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:04,569 httpcore.http11 DEBUG send_request_headers.complete
18:34:04,569 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:04,646 httpcore.http11 DEBUG send_request_body.complete
18:34:04,647 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:05,520 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:05 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c028e0b52c8bf36837d083fa2ef74384'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d12688e14ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:05,524 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:34:05,525 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:05,526 httpcore.http11 DEBUG receive_response_body.complete
18:34:05,527 httpcore.http11 DEBUG response_closed.started
18:34:05,527 httpcore.http11 DEBUG response_closed.complete
18:34:05,528 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:34:05,529 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:34:05,560 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMoved out.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:34:05,563 httpcore.connection DEBUG close.started
18:34:05,563 httpcore.connection DEBUG close.complete
18:34:05,564 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:34:05,566 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59df550>
18:34:05,567 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:34:05,575 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de650>
18:34:05,575 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:05,576 httpcore.http11 DEBUG send_request_headers.complete
18:34:05,577 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:05,578 httpcore.http11 DEBUG send_request_body.complete
18:34:05,578 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:05,815 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2229ce4935f11453a5eeb597cad3ab9a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d12cde264ce9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:05,820 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:34:05,821 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:05,822 httpcore.http11 DEBUG receive_response_body.complete
18:34:05,822 httpcore.http11 DEBUG response_closed.started
18:34:05,822 httpcore.http11 DEBUG response_closed.complete
18:34:05,823 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:34:05,839 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:34:05,843 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:34:11,45 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:34:11,51 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:34:11,58 httpcore.connection DEBUG close.started
18:34:11,59 httpcore.connection DEBUG close.complete
18:34:11,59 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:11,62 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59df090>
18:34:11,62 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:11,70 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59deed0>
18:34:11,70 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:11,71 httpcore.http11 DEBUG send_request_headers.complete
18:34:11,72 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:11,72 httpcore.http11 DEBUG send_request_body.complete
18:34:11,73 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:11,499 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:11 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'352'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6a5cc310aaebe4c5c4ff55b87fe8f352'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d14f39464cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:11,505 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:34:11,506 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:11,777 httpcore.http11 DEBUG receive_response_body.complete
18:34:11,778 httpcore.http11 DEBUG response_closed.started
18:34:11,779 httpcore.http11 DEBUG response_closed.complete
18:34:11,779 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:34:11,845 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:34:19,670 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:34:19,674 httpcore.connection DEBUG close.started
18:34:19,674 httpcore.connection DEBUG close.complete
18:34:19,674 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:19,677 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f7b50>
18:34:19,677 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:19,683 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f7bd0>
18:34:19,683 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:19,685 httpcore.http11 DEBUG send_request_headers.complete
18:34:19,685 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:19,706 httpcore.http11 DEBUG send_request_body.complete
18:34:19,706 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:20,539 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:20 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'498'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb87ba7bf2d4506f73dbd82e4e5e332b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1850f373b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:20,544 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:34:20,546 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:20,547 httpcore.http11 DEBUG receive_response_body.complete
18:34:20,548 httpcore.http11 DEBUG response_closed.started
18:34:20,548 httpcore.http11 DEBUG response_closed.complete
18:34:20,549 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:34:20,550 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:34:20,579 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:34:20,582 httpcore.connection DEBUG close.started
18:34:20,583 httpcore.connection DEBUG close.complete
18:34:20,583 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:34:20,614 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59fedd0>
18:34:20,614 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:34:20,623 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59fee50>
18:34:20,624 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:20,627 httpcore.http11 DEBUG send_request_headers.complete
18:34:20,627 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:20,628 httpcore.http11 DEBUG send_request_body.complete
18:34:20,629 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:20,841 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ad4fe815c833158de85947bd8dc9f37a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d18ae91e4cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:20,848 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:34:20,849 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:20,852 httpcore.http11 DEBUG receive_response_body.complete
18:34:20,853 httpcore.http11 DEBUG response_closed.started
18:34:20,853 httpcore.http11 DEBUG response_closed.complete
18:34:20,854 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:34:20,872 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:34:20,875 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:34:26,77 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:34:26,86 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:34:26,90 httpcore.connection DEBUG close.started
18:34:26,91 httpcore.connection DEBUG close.complete
18:34:26,91 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:26,94 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f5750>
18:34:26,94 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:26,100 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f5ad0>
18:34:26,101 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:26,102 httpcore.http11 DEBUG send_request_headers.complete
18:34:26,102 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:26,102 httpcore.http11 DEBUG send_request_body.complete
18:34:26,103 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:26,535 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:26 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bb950392a890502ad403a97cf3c9a648'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1ad2c93304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:26,540 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:34:26,541 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:26,811 httpcore.http11 DEBUG receive_response_body.complete
18:34:26,812 httpcore.http11 DEBUG response_closed.started
18:34:26,813 httpcore.http11 DEBUG response_closed.complete
18:34:26,814 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:34:26,883 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:34:34,593 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:34:34,597 httpcore.connection DEBUG close.started
18:34:34,597 httpcore.connection DEBUG close.complete
18:34:34,598 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:34,600 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e599dcd0>
18:34:34,600 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:34,605 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e599c390>
18:34:34,606 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:34,607 httpcore.http11 DEBUG send_request_headers.complete
18:34:34,607 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:34,630 httpcore.http11 DEBUG send_request_body.complete
18:34:34,630 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:35,426 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:35 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'336'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'58c6fad6d2b59197e5ebf3181c628e6e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1e24fdf4cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:35,430 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:34:35,431 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:35,432 httpcore.http11 DEBUG receive_response_body.complete
18:34:35,432 httpcore.http11 DEBUG response_closed.started
18:34:35,432 httpcore.http11 DEBUG response_closed.complete
18:34:35,433 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:34:35,433 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:34:35,463 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:34:35,466 httpcore.connection DEBUG close.started
18:34:35,467 httpcore.connection DEBUG close.complete
18:34:35,467 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:34:35,469 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ef010>
18:34:35,470 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:34:35,475 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ee450>
18:34:35,476 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:35,477 httpcore.http11 DEBUG send_request_headers.complete
18:34:35,477 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:35,478 httpcore.http11 DEBUG send_request_body.complete
18:34:35,478 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:35,684 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'38b68a276c8269fbb7b84f4750a6a859'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1e7b8884d1e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:35,690 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:34:35,692 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:35,693 httpcore.http11 DEBUG receive_response_body.complete
18:34:35,693 httpcore.http11 DEBUG response_closed.started
18:34:35,694 httpcore.http11 DEBUG response_closed.complete
18:34:35,694 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:34:35,710 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:34:35,713 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:41:41,494 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:41,498 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,337 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,338 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,381 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,382 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,429 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,430 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,470 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,471 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,518 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,519 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,559 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,560 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,608 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,609 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,649 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,650 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:42:45,929 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:42:45,948 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:42:45,980 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064f850>
18:42:45,981 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:42:45,989 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064fd50>
18:42:45,991 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:42:45,994 httpcore.http11 DEBUG send_request_headers.complete
18:42:45,995 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:42:45,996 httpcore.http11 DEBUG send_request_body.complete
18:42:45,997 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:42:46,464 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:42:46 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'99b41040259ebd3bc782f6f4f2ac88bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=wi_FXDO2QKu2OL8vQus_m1LE9jBhW0NTBOGuxR4CuD4-1702078966-1-AYnT8afk/4CRrar/B4GsZuuHFJv7l0Jj8n2lQ7pSb33yvhl9r3vc7PIxIdvgegevkzEL3LU/53SLXaRDq/DHxX8=; path=/; expires=Sat, 09-Dec-23 00:12:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=08XvDRGHVrTqXpcytxXI9BeyktXmRV1qNTQelLTZ4Y8-1702078966460-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328dde17c603074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:42:46,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:42:46,473 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:42:47,206 httpcore.http11 DEBUG receive_response_body.complete
18:42:47,207 httpcore.http11 DEBUG response_closed.started
18:42:47,208 httpcore.http11 DEBUG response_closed.complete
18:42:47,209 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:42:47,293 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:43:01,20 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:43:01,34 httpcore.connection DEBUG close.started
18:43:01,34 httpcore.connection DEBUG close.complete
18:43:01,35 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:43:01,38 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064fc10>
18:43:01,39 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:43:01,47 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064e3d0>
18:43:01,48 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:01,50 httpcore.http11 DEBUG send_request_headers.complete
18:43:01,50 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:01,82 httpcore.http11 DEBUG send_request_body.complete
18:43:01,83 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:02,4 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:43:02 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2117486d1cb246e760553bc28c2dae1c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328de3f8eb04d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:02,8 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:43:02,9 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:02,9 httpcore.http11 DEBUG receive_response_body.complete
18:43:02,10 httpcore.http11 DEBUG response_closed.started
18:43:02,10 httpcore.http11 DEBUG response_closed.complete
18:43:02,11 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:43:02,12 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:43:02,49 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:43:02,60 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:43:02,62 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc590>
18:43:02,63 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9f40> server_hostname='api.openai.com' timeout=None
18:43:02,70 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc510>
18:43:02,71 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:02,72 httpcore.http11 DEBUG send_request_headers.complete
18:43:02,73 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:02,73 httpcore.http11 DEBUG send_request_body.complete
18:43:02,74 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:02,294 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:43:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd380830568c83b1629eeb170ca5cdc52'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IotWwaSYls2XBWPILfuL.kRIqZN1FfcmaIgKE8d03bM-1702078982-1-AWisfyM23/Nej7pH2wfyLfput/fQKw5Dt1bedUVw+eywK/Vt4vNnc8254ospV1LTxcUItdIqhqpjHaW2XDTI1Iw=; path=/; expires=Sat, 09-Dec-23 00:13:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OSSESw2HPKvvyx4qOyoYOoixayRS28jmxa.0nlKrXlk-1702078982289-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328de45fc5a3b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:02,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:43:02,304 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:02,306 httpcore.http11 DEBUG receive_response_body.complete
18:43:02,306 httpcore.http11 DEBUG response_closed.started
18:43:02,306 httpcore.http11 DEBUG response_closed.complete
18:43:02,307 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:43:02,342 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:43:02,357 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:43:02,360 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504c2d90>
18:43:02,360 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506da720> server_hostname='api.openai.com' timeout=None
18:43:02,367 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504c2d10>
18:43:02,367 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:02,368 httpcore.http11 DEBUG send_request_headers.complete
18:43:02,369 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:02,370 httpcore.http11 DEBUG send_request_body.complete
18:43:02,370 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:03,262 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:43:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'764'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e49cccdeb5a77ff05f9bfe87928556e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ghm66SyyP6DHtF9PC6dGI1JUUnObmysNUC5niSlcnAg-1702078983-1-AfdTfmkzpvpY0gvJUpS4H3zE4VKlF5xbuxlZv6hvrulwhZ16PdzrLZLREzvE4YCWz8g1YFMdItglEXJ5OXrFSQM=; path=/; expires=Sat, 09-Dec-23 00:13:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NMlCLq77tPJASCAw_TcAwUEkFhBL3QAgF39QkRJbHeQ-1702078983256-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328de47cd5e4cfb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:03,269 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:43:03,270 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:03,271 httpcore.http11 DEBUG receive_response_body.complete
18:43:03,272 httpcore.http11 DEBUG response_closed.started
18:43:03,272 httpcore.http11 DEBUG response_closed.complete
18:43:03,273 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:43:03,557 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:03,561 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:10,769 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:10,783 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:10,787 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:15,990 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:16,12 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:16,16 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:21,218 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:21,236 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:21,239 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:26,441 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:26,459 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:26,463 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:33,665 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:33,681 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:33,685 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:38,887 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:38,908 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:38,912 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:44,114 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:44,131 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:44,134 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:49,336 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:49,351 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:49,355 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:54,557 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:54,572 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:54,580 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:59,782 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:59,802 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:59,805 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:05,7 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:05,13 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:44:05,19 httpcore.connection DEBUG close.started
18:44:05,19 httpcore.connection DEBUG close.complete
18:44:05,19 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:05,48 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25081d890>
18:44:05,49 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:05,56 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504cd350>
18:44:05,57 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:05,59 httpcore.http11 DEBUG send_request_headers.complete
18:44:05,59 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:05,61 httpcore.http11 DEBUG send_request_body.complete
18:44:05,61 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:05,623 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'457'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a72d868546398846336e6cb9186059f0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328dfcf9ee63021-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:05,628 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:44:05,630 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:06,754 httpcore.http11 DEBUG receive_response_body.complete
18:44:06,755 httpcore.http11 DEBUG response_closed.started
18:44:06,755 httpcore.http11 DEBUG response_closed.complete
18:44:06,756 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:44:06,817 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:44:19,638 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:44:19,642 httpcore.connection DEBUG close.started
18:44:19,642 httpcore.connection DEBUG close.complete
18:44:19,643 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:19,647 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e2450>
18:44:19,647 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:19,652 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e24d0>
18:44:19,653 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:19,654 httpcore.http11 DEBUG send_request_headers.complete
18:44:19,654 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:19,677 httpcore.http11 DEBUG send_request_body.complete
18:44:19,678 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:21,279 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'891'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'111fa734b29acb5b37bf3cd91c7ade74'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e02adb0f4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:21,282 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:44:21,282 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:21,283 httpcore.http11 DEBUG receive_response_body.complete
18:44:21,284 httpcore.http11 DEBUG response_closed.started
18:44:21,284 httpcore.http11 DEBUG response_closed.complete
18:44:21,285 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:44:21,285 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:44:21,315 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:21,318 httpcore.connection DEBUG close.started
18:44:21,318 httpcore.connection DEBUG close.complete
18:44:21,319 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:21,321 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc510>
18:44:21,321 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9f40> server_hostname='api.openai.com' timeout=None
18:44:21,327 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc5d0>
18:44:21,327 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:21,328 httpcore.http11 DEBUG send_request_headers.complete
18:44:21,329 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:21,329 httpcore.http11 DEBUG send_request_body.complete
18:44:21,329 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:21,565 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3aa1c78749a7b4393dcbb99e0fef59df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e035484a6ac7-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:21,572 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:21,573 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:21,575 httpcore.http11 DEBUG receive_response_body.complete
18:44:21,575 httpcore.http11 DEBUG response_closed.started
18:44:21,575 httpcore.http11 DEBUG response_closed.complete
18:44:21,576 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:21,611 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:21,623 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:21,625 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e0a50>
18:44:21,625 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9eb0> server_hostname='api.openai.com' timeout=None
18:44:21,635 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e1710>
18:44:21,635 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:21,636 httpcore.http11 DEBUG send_request_headers.complete
18:44:21,637 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:21,638 httpcore.http11 DEBUG send_request_body.complete
18:44:21,638 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:21,850 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'bc576522874978d0af920b82881d9940'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lRxa3Yn3qd31UYZEaVnA6qjrTbCfOVzR4Pa5qsVDB2o-1702079061-1-AV9728OAGIXxecbahCvnWFbyT3oUQhO59+ZlJdh1YyfT4n4zC6+HwSHkahCjJi1lpTngOFx92mPv0WtXTKBAJeA=; path=/; expires=Sat, 09-Dec-23 00:14:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=gMYtQlB4yxjNIAvFzMuIVIgXXAmBq6pjavXnKoIEPR8-1702079061846-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0373a7a3b7b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:21,856 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:21,857 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:21,858 httpcore.http11 DEBUG receive_response_body.complete
18:44:21,859 httpcore.http11 DEBUG response_closed.started
18:44:21,859 httpcore.http11 DEBUG response_closed.complete
18:44:21,859 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:21,875 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:21,878 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:27,80 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:27,98 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:27,102 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:32,304 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:32,322 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:32,325 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:37,527 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:37,530 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:44:37,535 httpcore.connection DEBUG close.started
18:44:37,535 httpcore.connection DEBUG close.complete
18:44:37,536 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:37,538 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e0ed0>
18:44:37,539 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:37,544 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e0fd0>
18:44:37,544 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:37,545 httpcore.http11 DEBUG send_request_headers.complete
18:44:37,546 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:37,546 httpcore.http11 DEBUG send_request_body.complete
18:44:37,546 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:38,146 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a167828c9e8827a7be1fc8b095348094'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e09aa9ca4cd0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:38,149 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:44:38,150 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:38,517 httpcore.http11 DEBUG receive_response_body.complete
18:44:38,518 httpcore.http11 DEBUG response_closed.started
18:44:38,519 httpcore.http11 DEBUG response_closed.complete
18:44:38,519 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:44:38,587 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:44:49,934 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:44:49,939 httpcore.connection DEBUG close.started
18:44:49,939 httpcore.connection DEBUG close.complete
18:44:49,940 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:49,942 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e6590>
18:44:49,943 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:49,950 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e6610>
18:44:49,950 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:49,952 httpcore.http11 DEBUG send_request_headers.complete
18:44:49,952 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:49,983 httpcore.http11 DEBUG send_request_body.complete
18:44:49,983 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:51,80 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:51 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'17'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'359'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8eb63832b3b7fb39ad18c876cab499d4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0e83da14cef-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:51,85 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:44:51,86 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:51,87 httpcore.http11 DEBUG receive_response_body.complete
18:44:51,88 httpcore.http11 DEBUG response_closed.started
18:44:51,88 httpcore.http11 DEBUG response_closed.complete
18:44:51,89 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:44:51,90 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:44:51,124 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTop left corner.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:51,128 httpcore.connection DEBUG close.started
18:44:51,129 httpcore.connection DEBUG close.complete
18:44:51,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:51,132 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504fd810>
18:44:51,132 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9f40> server_hostname='api.openai.com' timeout=None
18:44:51,137 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504fd890>
18:44:51,138 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:51,138 httpcore.http11 DEBUG send_request_headers.complete
18:44:51,139 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:51,139 httpcore.http11 DEBUG send_request_body.complete
18:44:51,140 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:51,335 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'29d8292cba0aed70deebd23b81b3c015'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0ef9a414d18-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:51,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:51,345 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:51,346 httpcore.http11 DEBUG receive_response_body.complete
18:44:51,347 httpcore.http11 DEBUG response_closed.started
18:44:51,347 httpcore.http11 DEBUG response_closed.complete
18:44:51,348 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:51,381 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTop left corner.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:51,384 httpcore.connection DEBUG close.started
18:44:51,385 httpcore.connection DEBUG close.complete
18:44:51,385 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:51,387 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e6c50>
18:44:51,388 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506da720> server_hostname='api.openai.com' timeout=None
18:44:51,401 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e4310>
18:44:51,401 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:51,402 httpcore.http11 DEBUG send_request_headers.complete
18:44:51,403 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:51,403 httpcore.http11 DEBUG send_request_body.complete
18:44:51,404 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:52,104 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'606'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8c3b945b27b48f9080f1644271379082'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0f14fa64cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:52,107 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:52,107 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:52,108 httpcore.http11 DEBUG receive_response_body.complete
18:44:52,108 httpcore.http11 DEBUG response_closed.started
18:44:52,109 httpcore.http11 DEBUG response_closed.complete
18:44:52,109 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:52,448 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:52,450 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:59,652 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:59,675 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:59,678 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:04,879 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:04,900 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:04,904 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:10,107 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:10,127 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:10,131 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:15,333 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:15,351 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:15,354 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:22,556 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:22,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:22,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:27,780 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:27,796 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:27,799 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:33,1 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:33,20 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:33,23 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:38,225 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:38,243 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:38,246 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:43,448 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:43,466 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:43,470 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:48,674 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:48,692 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:48,695 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:53,898 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:53,915 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:53,919 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:59,121 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:59,126 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:45:59,131 httpcore.connection DEBUG close.started
18:45:59,131 httpcore.connection DEBUG close.complete
18:45:59,132 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:45:59,163 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e64d0>
18:45:59,164 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:45:59,171 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e4a90>
18:45:59,171 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:45:59,172 httpcore.http11 DEBUG send_request_headers.complete
18:45:59,173 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:45:59,173 httpcore.http11 DEBUG send_request_body.complete
18:45:59,173 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:45:59,670 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:45:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'86b424eb81b7831c353cf4d5979932f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e298d81b3b9f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:45:59,673 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:45:59,673 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:46:00,700 httpcore.http11 DEBUG receive_response_body.complete
18:46:00,701 httpcore.http11 DEBUG response_closed.started
18:46:00,702 httpcore.http11 DEBUG response_closed.complete
18:46:00,703 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:46:00,770 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:47:56,52 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:56,56 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:56,904 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:56,905 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:56,950 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:56,951 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,1 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,2 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,48 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,49 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,101 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,102 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,147 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,149 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,201 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,202 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,249 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,250 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:48:09,925 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:48:09,944 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:48:09,976 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc5689a90>
18:48:09,976 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5645d90> server_hostname='api.openai.com' timeout=5.0
18:48:09,983 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc55bfd10>
18:48:09,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:09,986 httpcore.http11 DEBUG send_request_headers.complete
18:48:09,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:09,987 httpcore.http11 DEBUG send_request_body.complete
18:48:09,988 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:10,456 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:10 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'449a95a7f51aab3ec967c1af2e7d7467'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=e9v_Yq1LjGMEUFZmhDQhdX2BRWr1F4pqoarj3JpJNTE-1702079290-1-ARwwPrWU+5K2XmjUt8yncnIwPTlPZTK+TIrHTNEufnuB+3Mj2QBXVZu0gKsbl/COp3usz96LrMZI1Mo3yMMYcZE=; path=/; expires=Sat, 09-Dec-23 00:18:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ADNQZqI8wiHniLCbIPKsSjE4Czw1gMYxw9uvawUzKEw-1702079290449-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e5ca6d904cf8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:10,463 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:48:10,464 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:11,114 httpcore.http11 DEBUG receive_response_body.complete
18:48:11,115 httpcore.http11 DEBUG response_closed.started
18:48:11,116 httpcore.http11 DEBUG response_closed.complete
18:48:11,117 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:48:11,197 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:48:24,724 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:48:24,735 httpcore.connection DEBUG close.started
18:48:24,735 httpcore.connection DEBUG close.complete
18:48:24,735 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:48:24,738 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc540d290>
18:48:24,738 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5645d90> server_hostname='api.openai.com' timeout=5.0
18:48:24,746 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc540d310>
18:48:24,747 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:24,748 httpcore.http11 DEBUG send_request_headers.complete
18:48:24,748 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:24,783 httpcore.http11 DEBUG send_request_body.complete
18:48:24,784 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:25,762 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:25 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'afec12eeba1bf50ad7035d4d1a3f18dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e626a92b4ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:25,767 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:48:25,768 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:25,769 httpcore.http11 DEBUG receive_response_body.complete
18:48:25,770 httpcore.http11 DEBUG response_closed.started
18:48:25,771 httpcore.http11 DEBUG response_closed.complete
18:48:25,772 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:48:25,773 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:48:25,806 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:48:25,816 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:48:25,818 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc541f990>
18:48:25,819 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5645f40> server_hostname='api.openai.com' timeout=None
18:48:25,824 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc541f950>
18:48:25,825 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:25,826 httpcore.http11 DEBUG send_request_headers.complete
18:48:25,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:25,827 httpcore.http11 DEBUG send_request_body.complete
18:48:25,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:26,39 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7f620ed3632d59c441a29472144e2cf8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WHjNpa9IOIxC1uAayIgMQVuIe3sR4gQsdvz4vpCW3WI-1702079306-1-AVX8P8w3Ms7A353KWBIEYSweKNzXgz3QRBNkwrDnGjEInY5xyVLxE8joKyuhDadUjuHfNFeKPy79x8JOoupdKhQ=; path=/; expires=Sat, 09-Dec-23 00:18:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zs2F1hwN2b6znnmh3UVH5c25Uut56iobzVMew6Ldrx8-1702079306035-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e62d6f404ce4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:26,46 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:48:26,46 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:26,47 httpcore.http11 DEBUG receive_response_body.complete
18:48:26,47 httpcore.http11 DEBUG response_closed.started
18:48:26,48 httpcore.http11 DEBUG response_closed.complete
18:48:26,48 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:48:26,82 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:48:26,93 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:48:26,96 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc55ec410>
18:48:26,96 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5646720> server_hostname='api.openai.com' timeout=None
18:48:26,103 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc5431610>
18:48:26,104 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:26,105 httpcore.http11 DEBUG send_request_headers.complete
18:48:26,105 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:26,106 httpcore.http11 DEBUG send_request_body.complete
18:48:26,106 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:26,935 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'736'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c114ec412e02adfc286bbe8020fbe22d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ewj2m4UQcMA6xJ7gxuZNhZvJpIVitnQvrncsKI4jhr8-1702079306-1-AdkzviaW+F1u6+IDaIAFY+WQvKoYYVabsiqV/001/ApCwCn3Ksa9jisEYJKMQnCUZ3tEvkgTryeG6rDu52MbJQU=; path=/; expires=Sat, 09-Dec-23 00:18:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1IXrh_2oGeGP1CmVdRLwHh_n9mIhlvN17KTPNVwxyW8-1702079306930-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e62f2dd84cf4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:26,942 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:48:26,942 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:26,943 httpcore.http11 DEBUG receive_response_body.complete
18:48:26,944 httpcore.http11 DEBUG response_closed.started
18:48:26,944 httpcore.http11 DEBUG response_closed.complete
18:48:26,944 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:46,538 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:46,543 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,364 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,366 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,413 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,414 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,467 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,468 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,512 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,513 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,568 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,569 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,613 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,614 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,665 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,667 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,710 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,711 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:51:27,217 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:51:27,235 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:27,265 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6f0c590>
18:51:27,266 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f99d90> server_hostname='api.openai.com' timeout=5.0
18:51:27,273 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6f0a5d0>
18:51:27,274 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:27,276 httpcore.http11 DEBUG send_request_headers.complete
18:51:27,277 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:27,278 httpcore.http11 DEBUG send_request_body.complete
18:51:27,278 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:27,739 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'382'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'89ec8f8157188fbdedbedc2939cc4ced'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cv5BcEheV2lQH63JB07Zn4QnxjPzqyFbIcOYJiHIkls-1702079487-1-AXtwi+zeEiCI05U8dZCNhwfnnybf/ryTwM3d+scARDTsC8cWu9PAdPIIiAplRDp7ypQVv2D1Dc46NQ8hrsh+vRA=; path=/; expires=Sat, 09-Dec-23 00:21:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=S.CKZe5di2.CNojoRRbkSiVLweo2LJ3cMTHHG3AYh1E-1702079487732-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ea9b7db14cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:27,746 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:51:27,747 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:28,435 httpcore.http11 DEBUG receive_response_body.complete
18:51:28,436 httpcore.http11 DEBUG response_closed.started
18:51:28,437 httpcore.http11 DEBUG response_closed.complete
18:51:28,438 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:51:28,516 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:51:42,186 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:51:42,195 httpcore.connection DEBUG close.started
18:51:42,196 httpcore.connection DEBUG close.complete
18:51:42,196 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:42,199 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d621d0>
18:51:42,199 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f99d90> server_hostname='api.openai.com' timeout=5.0
18:51:42,204 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d62250>
18:51:42,204 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:42,205 httpcore.http11 DEBUG send_request_headers.complete
18:51:42,206 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:42,233 httpcore.http11 DEBUG send_request_body.complete
18:51:42,234 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:43,7 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:43 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'12'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6e4c48ae0fc4da7f997a08c106ea4897'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eaf8c8426ac7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:43,13 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:51:43,14 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:43,14 httpcore.http11 DEBUG receive_response_body.complete
18:51:43,15 httpcore.http11 DEBUG response_closed.started
18:51:43,15 httpcore.http11 DEBUG response_closed.complete
18:51:43,16 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:51:43,16 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:51:43,51 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nthe middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:43,64 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:43,66 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d80610>
18:51:43,67 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f99f40> server_hostname='api.openai.com' timeout=None
18:51:43,74 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d80590>
18:51:43,74 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:43,76 httpcore.http11 DEBUG send_request_headers.complete
18:51:43,76 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:43,77 httpcore.http11 DEBUG send_request_body.complete
18:51:43,77 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:43,271 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ebb291b2736136fe297c2bc490e8b5d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6IzzDXaNhw6A_oHbLwOXHXIglQGTipgr3.U5WJ7u5kU-1702079503-1-AaLQyDjPIK0dXWyBw0s/OgOeOWeEzqpNixXjT1NkLSCBmX2bMi2mZCMDS9/Qjpe1lo6xQjjaYe8QjdWvTpEG7BI=; path=/; expires=Sat, 09-Dec-23 00:21:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3SJBydyFukFYWn70QWR3ehIh43L2vCm4RjL.0wXZ.lY-1702079503266-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eafe3e243b69-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:43,278 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:43,279 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:43,280 httpcore.http11 DEBUG receive_response_body.complete
18:51:43,280 httpcore.http11 DEBUG response_closed.started
18:51:43,280 httpcore.http11 DEBUG response_closed.complete
18:51:43,281 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:51:43,315 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nthe middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:43,325 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:43,328 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d85dd0>
18:51:43,328 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f9a720> server_hostname='api.openai.com' timeout=None
18:51:43,334 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d85e90>
18:51:43,334 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:43,335 httpcore.http11 DEBUG send_request_headers.complete
18:51:43,336 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:43,336 httpcore.http11 DEBUG send_request_body.complete
18:51:43,337 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:44,154 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'727'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd275a54142d87d510b333b933f105403'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BzcslWb8HcNPpblypowyx4qD82JTHxtYnd64sgVYzOs-1702079504-1-Aa3HhS1CV2iMPSyCXF5hdZImb/5ha8DUyJL/KVcdUPubwXu4zwEftYfixP3TabQ7ivpTB2smnnfyiNkfhQQz/SU=; path=/; expires=Sat, 09-Dec-23 00:21:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Qthr1NCaH.k4eZDNxC7pfvx36kSbYfWLO3JCYmvUBls-1702079504149-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eaffde723074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:44,162 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:44,162 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:44,163 httpcore.http11 DEBUG receive_response_body.complete
18:51:44,164 httpcore.http11 DEBUG response_closed.started
18:51:44,164 httpcore.http11 DEBUG response_closed.complete
18:51:44,164 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:34,922 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:34,925 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,711 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,712 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,750 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,751 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,791 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,792 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,829 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,830 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,869 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,870 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,907 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,908 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,957 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,958 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,997 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,998 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:36,41 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:52:36,53 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:52:36,85 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd6dd0>
18:52:36,86 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a061d90> server_hostname='api.openai.com' timeout=5.0
18:52:36,95 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd7310>
18:52:36,96 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:36,98 httpcore.http11 DEBUG send_request_headers.complete
18:52:36,98 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:36,98 httpcore.http11 DEBUG send_request_body.complete
18:52:36,98 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:36,603 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'775c16faba4146365bd8c0ae07f32222'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Mfmw4EPT_jTakmvNpKDO6jMRDzRtP8VTdGi1AiaFQYA-1702079556-1-AeVKSYgiD1t9lGNvPVmasvUWXlcX6Rz4rrx5I6dTFeSsy5ioeMaL5YwcpnBNu9f99R7nzn0wBUvt4LNYSTm9gCk=; path=/; expires=Sat, 09-Dec-23 00:22:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RFzAmMtwMLoviWsElxfjF0gQuC_Tz0MDfPvOO44BvmU-1702079556598-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ec4998264cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:36,608 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:52:36,608 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:37,410 httpcore.http11 DEBUG receive_response_body.complete
18:52:37,411 httpcore.http11 DEBUG response_closed.started
18:52:37,411 httpcore.http11 DEBUG response_closed.complete
18:52:37,412 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:52:37,483 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:52:51,326 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:52:51,332 httpcore.connection DEBUG close.started
18:52:51,332 httpcore.connection DEBUG close.complete
18:52:51,333 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:52:51,335 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd7250>
18:52:51,335 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a061d90> server_hostname='api.openai.com' timeout=5.0
18:52:51,342 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd7610>
18:52:51,342 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:51,343 httpcore.http11 DEBUG send_request_headers.complete
18:52:51,343 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:51,373 httpcore.http11 DEBUG send_request_body.complete
18:52:51,373 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:52,191 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:52 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'350'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1190784aedabb98b9b1816cd1c691718'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eca8ef044ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:52,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:52:52,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:52,195 httpcore.http11 DEBUG receive_response_body.complete
18:52:52,195 httpcore.http11 DEBUG response_closed.started
18:52:52,195 httpcore.http11 DEBUG response_closed.complete
18:52:52,196 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:52:52,196 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:52:52,215 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:52,226 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:52,228 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a0340d0>
18:52:52,228 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a061f40> server_hostname='api.openai.com' timeout=None
18:52:52,237 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a034090>
18:52:52,237 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:52,238 httpcore.http11 DEBUG send_request_headers.complete
18:52:52,238 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:52,239 httpcore.http11 DEBUG send_request_body.complete
18:52:52,239 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:52,462 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'126'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b5cfd52460b8f786f856cdff10f18595'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WNBnanKjT2zx1FCeLCTfspPIndN7Wzf0zHrr3s3pW4s-1702079572-1-AacBzi4gHxRe5M7gC5kdlUYh+mTmJqTo3cWJqwTrpoF8do9o9w/pJ+JkmX817611AnFus6vHXbWMJkMTI8be+ds=; path=/; expires=Sat, 09-Dec-23 00:22:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qEkBcI7szGPGOXBWdPORCtFUeo0KJFd0gsnViCrBldA-1702079572458-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ecae7bc83008-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:52,466 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:52,467 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:52,468 httpcore.http11 DEBUG receive_response_body.complete
18:52:52,468 httpcore.http11 DEBUG response_closed.started
18:52:52,469 httpcore.http11 DEBUG response_closed.complete
18:52:52,469 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:52,486 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1, surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:52,495 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:52,497 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a023290>
18:52:52,497 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a062720> server_hostname='api.openai.com' timeout=None
18:52:52,503 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a020ed0>
18:52:52,504 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:52,504 httpcore.http11 DEBUG send_request_headers.complete
18:52:52,504 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:52,505 httpcore.http11 DEBUG send_request_body.complete
18:52:52,505 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:53,353 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'759'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6fea5a5d84504d3c70e1b0723cbfdc4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3uo9fb4A5hlcwwhbM4DHbLKQqAnx.pVFQvURi67oK.E-1702079573-1-AXvDqDkGfe8ylgrvbpOJmH1sVrwvvAizG6DEoUaQk36tZBu1jg/XDiK2Rqy/kywhGmWaISH2t3NSHprmRZUerYo=; path=/; expires=Sat, 09-Dec-23 00:22:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=C3caYzHytfZdkIme09_IYeUnnEIBFzQl33oZuxI5710-1702079573350-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ecb02e5b3b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:53,356 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:53,357 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:53,358 httpcore.http11 DEBUG receive_response_body.complete
18:52:53,358 httpcore.http11 DEBUG response_closed.started
18:52:53,358 httpcore.http11 DEBUG response_closed.complete
18:52:53,359 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:53,554 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:52:53,557 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:53:00,762 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:53:00,770 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:53:00,772 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:53:05,973 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:53:05,986 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:53:05,987 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:53:41,707 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:41,710 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,528 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,530 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,579 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,581 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,631 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,632 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,676 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,677 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,728 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,729 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,774 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,775 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,832 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,834 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,880 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,882 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:51,122 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:53:51,142 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:53:51,174 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f6058610>
18:53:51,175 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e5d90> server_hostname='api.openai.com' timeout=5.0
18:53:51,181 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f6061090>
18:53:51,182 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:53:51,183 httpcore.http11 DEBUG send_request_headers.complete
18:53:51,184 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:53:51,184 httpcore.http11 DEBUG send_request_body.complete
18:53:51,184 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:53:51,655 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:53:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ee28c9c26f6477a1f7fbd742e2976d2f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=thxRTcHv4WcPdJuqTdGu.rE6CSxx7Be5tJOUUwFMXnE-1702079631-1-ARJSeC8V96/xLNaEzjJqrqn/Q0xoAgJMrcELjPPbkU0CI10puUWupQotIlvAKil6zi4jA1KAQ6ewh6JBZpZv3is=; path=/; expires=Sat, 09-Dec-23 00:23:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=a9cRWtm88Di0eqdaHTp4y4BS66EudSZZZzOlssMsAMY-1702079631648-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee1eeeaa4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:53:51,667 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:53:51,668 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:53:52,427 httpcore.http11 DEBUG receive_response_body.complete
18:53:52,428 httpcore.http11 DEBUG response_closed.started
18:53:52,429 httpcore.http11 DEBUG response_closed.complete
18:53:52,430 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:53:52,512 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:54:06,458 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:54:06,468 httpcore.connection DEBUG close.started
18:54:06,469 httpcore.connection DEBUG close.complete
18:54:06,469 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:54:06,472 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5eade10>
18:54:06,472 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e5d90> server_hostname='api.openai.com' timeout=5.0
18:54:06,478 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5eade90>
18:54:06,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:54:06,479 httpcore.http11 DEBUG send_request_headers.complete
18:54:06,480 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:54:06,508 httpcore.http11 DEBUG send_request_body.complete
18:54:06,509 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:54:07,298 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:54:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'15'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'79eea58607ea2273c9cbc7676dc585dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee7e79ad3ba5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:54:07,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:54:07,304 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:54:07,306 httpcore.http11 DEBUG receive_response_body.complete
18:54:07,307 httpcore.http11 DEBUG response_closed.started
18:54:07,308 httpcore.http11 DEBUG response_closed.complete
18:54:07,309 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:54:07,310 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:54:07,345 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:54:07,360 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:54:07,364 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ecc610>
18:54:07,364 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e5f40> server_hostname='api.openai.com' timeout=None
18:54:07,370 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ecc590>
18:54:07,371 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:54:07,372 httpcore.http11 DEBUG send_request_headers.complete
18:54:07,372 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:54:07,373 httpcore.http11 DEBUG send_request_body.complete
18:54:07,373 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:54:07,597 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:54:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'412c66d70872091d1f00b7ff86f2589d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yLoFHGZAWxMqZiD0Ku9AIawNZn.sjxp9.uC6buXy_NQ-1702079647-1-AW8zA0kLS/F3M+ByUObm3+6cXLn8lf9xsSuYlHXBS5NGtjbU/3g3bn6nBroqZBsIyC+LPV4cy3qiOSwn8pYXfkc=; path=/; expires=Sat, 09-Dec-23 00:24:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ASop8s9C.97.346TCxsFoC4M2dvULj3I_6brHiRML3g-1702079647592-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee841f484cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:54:07,605 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:54:07,607 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:54:07,609 httpcore.http11 DEBUG receive_response_body.complete
18:54:07,610 httpcore.http11 DEBUG response_closed.started
18:54:07,610 httpcore.http11 DEBUG response_closed.complete
18:54:07,611 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:54:07,646 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1, surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:54:07,659 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:54:07,662 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ed1a90>
18:54:07,663 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e6720> server_hostname='api.openai.com' timeout=None
18:54:07,668 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ed2810>
18:54:07,668 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:54:07,669 httpcore.http11 DEBUG send_request_headers.complete
18:54:07,670 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:54:07,670 httpcore.http11 DEBUG send_request_body.complete
18:54:07,670 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:54:08,569 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:54:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'802'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'73a59ff0790f3ac4a47084f33242f1de'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ovigVkpz1HTHiuqtL9srzDmoTvhTO2BII3yc2rReqxM-1702079648-1-Ae2/H9JZSgVzHGyMa0sI6VRD4uuGamLZ2LpfXlDBZRpLIj3PNRGu3LamzXx0phYheG+n3/klrQpC9SFZUeqYR8s=; path=/; expires=Sat, 09-Dec-23 00:24:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kbnLYr3Z6nPOYndHky9SpbvjWe2poxL8kbUfxBqKX0A-1702079648564-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee85ebe44cc9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:54:08,577 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:54:08,578 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:54:08,578 httpcore.http11 DEBUG receive_response_body.complete
18:54:08,579 httpcore.http11 DEBUG response_closed.started
18:54:08,579 httpcore.http11 DEBUG response_closed.complete
18:54:08,579 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:57:45,844 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:45,850 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,683 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,684 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,733 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,734 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,785 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,786 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,829 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,830 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,879 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,880 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,922 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,923 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,971 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,972 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:47,12 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:47,13 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:50,834 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:57:50,853 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:57:50,898 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6850>
18:57:50,898 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631d90> server_hostname='api.openai.com' timeout=5.0
18:57:50,906 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6d50>
18:57:50,906 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:50,908 httpcore.http11 DEBUG send_request_headers.complete
18:57:50,909 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:50,909 httpcore.http11 DEBUG send_request_body.complete
18:57:50,910 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:51,549 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:57:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'520'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3b96eca2e0f0adc5e3fdb377eb81365'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IvRsw4EWyqP75u9_k8UmWBJe8fgpbv2iaRXRvbRhEDA-1702079871-1-Aa9w8lAwGGkmDaFqWrWqmE0eFzSzF+F5uiEn7yXyRftMbU5JAta9XtSvOpGFdFFcbsEsk9CNvfMcCKK78X3KYro=; path=/; expires=Sat, 09-Dec-23 00:27:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=n804DXmYhBUICp43ibOi_zeYTzFrfGiPs1PQZf8OHwM-1702079871541-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f3f92f4a4cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:51,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:57:51,557 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:52,336 httpcore.http11 DEBUG receive_response_body.complete
18:57:52,337 httpcore.http11 DEBUG response_closed.started
18:57:52,338 httpcore.http11 DEBUG response_closed.complete
18:57:52,339 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:57:52,417 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:58:06,160 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:58:06,170 httpcore.connection DEBUG close.started
18:58:06,170 httpcore.connection DEBUG close.complete
18:58:06,171 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:58:06,173 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6d50>
18:58:06,173 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631d90> server_hostname='api.openai.com' timeout=5.0
18:58:06,180 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6e90>
18:58:06,181 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:06,182 httpcore.http11 DEBUG send_request_headers.complete
18:58:06,182 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:06,215 httpcore.http11 DEBUG send_request_body.complete
18:58:06,215 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:07,24 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:58:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ff25fa70e96caff7bde9b19b211527c7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f458acb23018-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:07,29 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:58:07,29 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:07,30 httpcore.http11 DEBUG receive_response_body.complete
18:58:07,30 httpcore.http11 DEBUG response_closed.started
18:58:07,31 httpcore.http11 DEBUG response_closed.complete
18:58:07,31 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:58:07,32 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:58:07,65 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:07,77 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:07,79 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715fdc50>
18:58:07,80 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631f40> server_hostname='api.openai.com' timeout=None
18:58:07,86 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715fd350>
18:58:07,87 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:07,88 httpcore.http11 DEBUG send_request_headers.complete
18:58:07,88 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:07,88 httpcore.http11 DEBUG send_request_body.complete
18:58:07,89 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:07,313 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:58:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5ed6a9f9d2d30e4543be80a86ff586c3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=G3E8TL4a8hKafqYK81ZWneet7UwuE5ZLoHvnEkF.lZ8-1702079887-1-ARR87A7TjBQy0OAwREz2bL/L0wL1zHCTO+tqJVrG9NjbGT3jzGPYxwq/k/8wqXy6ba6+nNse1egX2lXT95f4G8g=; path=/; expires=Sat, 09-Dec-23 00:28:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=EbKlL5x6HOTuU2zpmvGpktFeB23WTYBRy2pi.o66bKs-1702079887310-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f45e4c384cc3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:07,317 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:07,318 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:07,319 httpcore.http11 DEBUG receive_response_body.complete
18:58:07,319 httpcore.http11 DEBUG response_closed.started
18:58:07,320 httpcore.http11 DEBUG response_closed.complete
18:58:07,320 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:07,359 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:07,372 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:07,375 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8171420190>
18:58:07,375 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172632720> server_hostname='api.openai.com' timeout=None
18:58:07,381 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8171420110>
18:58:07,381 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:07,382 httpcore.http11 DEBUG send_request_headers.complete
18:58:07,382 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:07,383 httpcore.http11 DEBUG send_request_body.complete
18:58:07,383 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:08,332 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:58:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'839'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e001f844add94d9f1ba790550ea41a31'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PRgqPKtcRrmPT5tMYG_bDk3mIJV9E3gZbq2sAnWZ1bc-1702079888-1-AQZaM1buRl1/7SwgVQuU/VaiWgk0F82DBVpwQRP0Zrs3thRYXvc34+dtF3kX3Y/0A1fe35TB0iRgfSbQjVQl6Ug=; path=/; expires=Sat, 09-Dec-23 00:28:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=lQ3QATF2tG1CdKrR0FKlVaOIroZqEoE.x5h20qnM.ss-1702079888327-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f4602cde4ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:08,340 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:08,341 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:08,342 httpcore.http11 DEBUG receive_response_body.complete
18:58:08,342 httpcore.http11 DEBUG response_closed.started
18:58:08,343 httpcore.http11 DEBUG response_closed.complete
18:58:08,343 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:48,906 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:58:48,910 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:58:56,120 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:58:56,134 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:58:56,141 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:01,344 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:01,362 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:01,365 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:06,567 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:06,586 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:06,590 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:11,791 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:11,810 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:11,813 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:19,16 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:19,34 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:19,37 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:24,239 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:24,255 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:24,257 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:29,459 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:29,479 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:29,482 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:34,684 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:34,700 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:34,705 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:39,907 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:39,914 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:59:39,920 httpcore.connection DEBUG close.started
18:59:39,920 httpcore.connection DEBUG close.complete
18:59:39,921 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:59:39,953 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b7010>
18:59:39,953 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631d90> server_hostname='api.openai.com' timeout=5.0
18:59:39,961 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715a0e50>
18:59:39,961 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:59:39,963 httpcore.http11 DEBUG send_request_headers.complete
18:59:39,963 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:59:39,964 httpcore.http11 DEBUG send_request_body.complete
18:59:39,965 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:59:40,477 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:59:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f4e8abc5cdee16d649b4e143ecda98a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f6a2cc7b4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:59:40,482 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:59:40,484 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:59:41,426 httpcore.http11 DEBUG receive_response_body.complete
18:59:41,427 httpcore.http11 DEBUG response_closed.started
18:59:41,427 httpcore.http11 DEBUG response_closed.complete
18:59:41,428 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:59:41,495 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:01:42,181 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:42,184 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,24 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,25 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,67 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,68 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,115 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,116 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,156 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,157 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,204 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,205 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,246 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,247 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,295 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,296 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,336 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,337 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:44,672 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:01:44,687 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:01:44,717 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f13f90>
19:01:44,718 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:01:44,724 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f13ed0>
19:01:44,725 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:01:44,728 httpcore.http11 DEBUG send_request_headers.complete
19:01:44,729 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:01:44,730 httpcore.http11 DEBUG send_request_body.complete
19:01:44,730 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:01:45,369 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:01:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'522'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cd6e9133806440c15d35f02475c3a83d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WVaETcnGkhLhF8PNV19cPKqYMbAZPi5EZyhK5CALbKU-1702080105-1-AfejuIfypisadAKse/Dd3U1Gmq6BtqKTHTR7KzV5/XZ5UWmJWzMVRZKfc9XYBsqrowhZ5vyxQGzZQuogmD1g2Dg=; path=/; expires=Sat, 09-Dec-23 00:31:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OM7OSsBXbfwjVGM4vaibR0NEi1C1qeM3fY99iiT1ZZ0-1702080105364-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f9ae880f3068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:01:45,379 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:01:45,380 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:01:46,158 httpcore.http11 DEBUG receive_response_body.complete
19:01:46,159 httpcore.http11 DEBUG response_closed.started
19:01:46,160 httpcore.http11 DEBUG response_closed.complete
19:01:46,161 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:01:46,247 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:02:00,82 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:02:00,94 httpcore.connection DEBUG close.started
19:02:00,95 httpcore.connection DEBUG close.complete
19:02:00,95 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:02:00,98 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f13ed0>
19:02:00,98 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:02:00,104 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243fcf350>
19:02:00,105 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:02:00,106 httpcore.http11 DEBUG send_request_headers.complete
19:02:00,106 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:02:00,160 httpcore.http11 DEBUG send_request_body.complete
19:02:00,161 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:02:01,39 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:02:01 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'371'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'23cec489945949461f1848e19aa2034f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fa0ead4c4cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:02:01,45 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:02:01,46 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:02:01,47 httpcore.http11 DEBUG receive_response_body.complete
19:02:01,47 httpcore.http11 DEBUG response_closed.started
19:02:01,47 httpcore.http11 DEBUG response_closed.complete
19:02:01,48 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:02:01,49 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:02:01,91 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:02:01,103 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:02:01,105 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d80410>
19:02:01,106 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:02:01,116 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d803d0>
19:02:01,117 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:02:01,118 httpcore.http11 DEBUG send_request_headers.complete
19:02:01,119 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:02:01,119 httpcore.http11 DEBUG send_request_body.complete
19:02:01,120 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:02:01,377 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:02:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fcc9183ac8a21c416d5d0f88fed1b093'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=x8m7i0IsrJIAVIPzhK.sQ9fzVqXJehZ4B4t2LZR5n94-1702080121-1-AaUg6xnIruC9j8M+VcSyHVxfYmRFfWMmBilgKBfe0lv8iUH8G9y7tyumpbHEI8AmhqUgJPxjGkp9t9Vu2new3a8=; path=/; expires=Sat, 09-Dec-23 00:32:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=A65AmvKHgPjBv8Urd0GxGvpA9RWRs2pJn.7iZ1TGXA8-1702080121372-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fa14fe644d0b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:02:01,385 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:02:01,386 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:02:01,387 httpcore.http11 DEBUG receive_response_body.complete
19:02:01,387 httpcore.http11 DEBUG response_closed.started
19:02:01,388 httpcore.http11 DEBUG response_closed.complete
19:02:01,388 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:02:01,423 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:02:01,434 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:02:01,437 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d5fed0>
19:02:01,437 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9e720> server_hostname='api.openai.com' timeout=None
19:02:01,442 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d5fcd0>
19:02:01,443 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:02:01,444 httpcore.http11 DEBUG send_request_headers.complete
19:02:01,444 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:02:01,445 httpcore.http11 DEBUG send_request_body.complete
19:02:01,445 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:02:02,550 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:02:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1014'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ba22ca9eefe7237d9cb5cf93067b8211'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yz8JsX975OWbJv1CWRyPS9VSe494XdcZlsJnK5memO8-1702080122-1-ARYWIvVH7ENMThNzpSWuYg2CAo4g8FuYzSBeqZ6PYhXAvXKz53SqL5mgfeMW8q/vu6YtV8aaU0D8UMhCA5GM4U0=; path=/; expires=Sat, 09-Dec-23 00:32:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=DjpjU9E5MDJWZLYXdzoNAiQoVnXTeO74E3gt7UvXpsQ-1702080122545-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fa170b6d3025-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:02:02,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:02:02,557 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:02:02,558 httpcore.http11 DEBUG receive_response_body.complete
19:02:02,559 httpcore.http11 DEBUG response_closed.started
19:02:02,559 httpcore.http11 DEBUG response_closed.complete
19:02:02,559 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:02:02,582 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:02,586 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:09,794 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:09,808 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:09,812 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:15,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:15,33 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:15,36 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:20,239 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:20,257 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:20,260 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:25,463 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:25,480 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:25,484 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:32,686 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:32,705 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:32,708 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:37,909 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:37,927 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:37,931 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:43,133 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:43,151 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:43,155 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:48,359 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:48,376 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:48,379 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:53,581 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:53,598 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:53,601 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:58,803 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:58,822 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:58,825 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:04,27 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:04,34 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:03:04,40 httpcore.connection DEBUG close.started
19:03:04,40 httpcore.connection DEBUG close.complete
19:03:04,40 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:04,69 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2440e1950>
19:03:04,70 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:04,77 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d8fdd0>
19:03:04,78 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:04,80 httpcore.http11 DEBUG send_request_headers.complete
19:03:04,80 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:04,81 httpcore.http11 DEBUG send_request_body.complete
19:03:04,82 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:04,765 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:04 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'552'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'47945773f414b2f53227d942fb597e27'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fb9e8b694cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:04,769 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:03:04,770 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:05,646 httpcore.http11 DEBUG receive_response_body.complete
19:03:05,647 httpcore.http11 DEBUG response_closed.started
19:03:05,648 httpcore.http11 DEBUG response_closed.complete
19:03:05,649 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:03:05,716 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:03:18,400 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:03:18,406 httpcore.connection DEBUG close.started
19:03:18,407 httpcore.connection DEBUG close.complete
19:03:18,407 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:18,409 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daae10>
19:03:18,410 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:18,416 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daae90>
19:03:18,417 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:18,418 httpcore.http11 DEBUG send_request_headers.complete
19:03:18,418 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:18,442 httpcore.http11 DEBUG send_request_body.complete
19:03:18,443 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:19,161 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:19 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a66179a0c4fc8470c94e186a4cdaac5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fbf81cd74d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:19,166 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:03:19,167 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:19,169 httpcore.http11 DEBUG receive_response_body.complete
19:03:19,169 httpcore.http11 DEBUG response_closed.started
19:03:19,170 httpcore.http11 DEBUG response_closed.complete
19:03:19,171 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:03:19,172 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:03:19,200 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:19,204 httpcore.connection DEBUG close.started
19:03:19,204 httpcore.connection DEBUG close.complete
19:03:19,204 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:19,207 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243da9bd0>
19:03:19,207 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:03:19,214 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daa990>
19:03:19,214 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:19,215 httpcore.http11 DEBUG send_request_headers.complete
19:03:19,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:19,216 httpcore.http11 DEBUG send_request_body.complete
19:03:19,216 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:19,441 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'132'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4d850911e3ab92dc8e2131898e4fd3cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fbfd1ac44d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:19,447 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:19,447 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:19,448 httpcore.http11 DEBUG receive_response_body.complete
19:03:19,449 httpcore.http11 DEBUG response_closed.started
19:03:19,449 httpcore.http11 DEBUG response_closed.complete
19:03:19,450 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:19,482 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:19,493 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:19,496 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fd50>
19:03:19,496 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:03:19,501 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fe10>
19:03:19,501 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:19,503 httpcore.http11 DEBUG send_request_headers.complete
19:03:19,503 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:19,503 httpcore.http11 DEBUG send_request_body.complete
19:03:19,504 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:19,733 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'138'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7af4f9f0af9180030c819aa00c2c97c4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YFaREg4nOIA.DoUyA6p0fLht9BLGrpMUsf.bX1tFE5U-1702080199-1-AdZnRyw64l0yHTxiBzC5sLkrk8ZBoBY5wYaBG0TNQWeBj2pppOUxaZQjWUvbpLcb7zQCRFkfq380c58hWF1BHDo=; path=/; expires=Sat, 09-Dec-23 00:33:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=mlhRjw1nqy4Op7tWJvXGRo01vSJo6cVXOcVD.rYMTac-1702080199729-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fbfeec334cf8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:19,738 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:19,739 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:19,741 httpcore.http11 DEBUG receive_response_body.complete
19:03:19,741 httpcore.http11 DEBUG response_closed.started
19:03:19,742 httpcore.http11 DEBUG response_closed.complete
19:03:19,742 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:19,756 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:19,759 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:24,960 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:24,978 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:24,981 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:30,183 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:30,200 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:30,203 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:35,405 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:35,413 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:03:35,420 httpcore.connection DEBUG close.started
19:03:35,420 httpcore.connection DEBUG close.complete
19:03:35,420 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:35,423 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243da9410>
19:03:35,424 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:35,431 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daaf90>
19:03:35,432 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:35,433 httpcore.http11 DEBUG send_request_headers.complete
19:03:35,434 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:35,434 httpcore.http11 DEBUG send_request_body.complete
19:03:35,435 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:35,879 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1171da99a282cf7ce62b08886bc57a78'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fc6279ae3059-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:35,885 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:03:35,885 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:36,337 httpcore.http11 DEBUG receive_response_body.complete
19:03:36,338 httpcore.http11 DEBUG response_closed.started
19:03:36,338 httpcore.http11 DEBUG response_closed.complete
19:03:36,340 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:03:36,413 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:03:47,981 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:03:47,986 httpcore.connection DEBUG close.started
19:03:47,986 httpcore.connection DEBUG close.complete
19:03:47,986 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:47,989 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2f90>
19:03:47,989 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:47,995 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db3010>
19:03:47,995 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:47,996 httpcore.http11 DEBUG send_request_headers.complete
19:03:47,997 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:48,30 httpcore.http11 DEBUG send_request_body.complete
19:03:48,31 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:48,902 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'40'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'68ec42b20cc7ab24e5f95cabbc8e2f06'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fcb0fb504cf2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:48,909 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:03:48,910 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:48,911 httpcore.http11 DEBUG receive_response_body.complete
19:03:48,912 httpcore.http11 DEBUG response_closed.started
19:03:48,913 httpcore.http11 DEBUG response_closed.complete
19:03:48,914 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:03:48,914 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:03:48,943 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:48,946 httpcore.connection DEBUG close.started
19:03:48,947 httpcore.connection DEBUG close.complete
19:03:48,947 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:48,949 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2110>
19:03:48,950 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:03:48,957 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2190>
19:03:48,958 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:48,959 httpcore.http11 DEBUG send_request_headers.complete
19:03:48,959 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:48,959 httpcore.http11 DEBUG send_request_body.complete
19:03:48,960 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:49,171 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd147926c3c075eb20118aeae2ce65ca4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fcb6fb7c3051-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:49,176 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:49,177 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:49,179 httpcore.http11 DEBUG receive_response_body.complete
19:03:49,180 httpcore.http11 DEBUG response_closed.started
19:03:49,181 httpcore.http11 DEBUG response_closed.complete
19:03:49,182 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:49,218 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:49,221 httpcore.connection DEBUG close.started
19:03:49,221 httpcore.connection DEBUG close.complete
19:03:49,222 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:49,224 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d8c710>
19:03:49,225 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9e720> server_hostname='api.openai.com' timeout=None
19:03:49,231 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7da50>
19:03:49,232 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:49,233 httpcore.http11 DEBUG send_request_headers.complete
19:03:49,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:49,234 httpcore.http11 DEBUG send_request_body.complete
19:03:49,234 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:49,770 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2ef90031b681f7b24d8722b25668f953'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fcb8bd8f4cf8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:49,777 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:49,778 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:49,780 httpcore.http11 DEBUG receive_response_body.complete
19:03:49,781 httpcore.http11 DEBUG response_closed.started
19:03:49,781 httpcore.http11 DEBUG response_closed.complete
19:03:49,782 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:49,798 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:49,801 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:57,3 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:57,21 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:57,28 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:02,230 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:02,248 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:02,251 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:07,453 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:07,471 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:07,475 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:12,677 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:12,693 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:12,697 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:19,898 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:19,915 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:19,918 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:25,120 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:25,137 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:25,142 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:30,344 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:30,362 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:30,366 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:35,568 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:35,574 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:04:35,579 httpcore.connection DEBUG close.started
19:04:35,579 httpcore.connection DEBUG close.complete
19:04:35,580 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:04:35,609 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2f10>
19:04:35,609 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:04:35,617 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2490>
19:04:35,618 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:35,620 httpcore.http11 DEBUG send_request_headers.complete
19:04:35,621 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:35,622 httpcore.http11 DEBUG send_request_body.complete
19:04:35,623 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:36,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bc13ad7bf9a0d19998e061321b92e1dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fddaaca64cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:36,131 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:04:36,132 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:37,157 httpcore.http11 DEBUG receive_response_body.complete
19:04:37,158 httpcore.http11 DEBUG response_closed.started
19:04:37,159 httpcore.http11 DEBUG response_closed.complete
19:04:37,161 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:04:37,228 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:04:49,833 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:04:49,837 httpcore.connection DEBUG close.started
19:04:49,838 httpcore.connection DEBUG close.complete
19:04:49,838 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:04:49,867 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dabe10>
19:04:49,868 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:04:49,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243da9c50>
19:04:49,876 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:49,878 httpcore.http11 DEBUG send_request_headers.complete
19:04:49,878 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:49,903 httpcore.http11 DEBUG send_request_body.complete
19:04:49,904 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:50,643 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:50 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fa17006c87aeb734210acccb7315c945'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe33b8df4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:50,646 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:04:50,646 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:50,647 httpcore.http11 DEBUG receive_response_body.complete
19:04:50,647 httpcore.http11 DEBUG response_closed.started
19:04:50,648 httpcore.http11 DEBUG response_closed.complete
19:04:50,648 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:04:50,649 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:04:50,678 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:04:50,681 httpcore.connection DEBUG close.started
19:04:50,681 httpcore.connection DEBUG close.complete
19:04:50,682 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:04:50,684 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2990>
19:04:50,685 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:04:50,690 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc06d0>
19:04:50,691 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:50,691 httpcore.http11 DEBUG send_request_headers.complete
19:04:50,692 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:50,692 httpcore.http11 DEBUG send_request_body.complete
19:04:50,692 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:50,903 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'70b7b71bd7c0cc2625ed9785264198e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe38dd264cef-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:50,909 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:04:50,910 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:50,911 httpcore.http11 DEBUG receive_response_body.complete
19:04:50,912 httpcore.http11 DEBUG response_closed.started
19:04:50,912 httpcore.http11 DEBUG response_closed.complete
19:04:50,913 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:04:50,946 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:04:50,949 httpcore.connection DEBUG close.started
19:04:50,949 httpcore.connection DEBUG close.complete
19:04:50,950 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:04:50,952 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fe10>
19:04:50,953 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:04:50,957 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fd10>
19:04:50,958 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:50,959 httpcore.http11 DEBUG send_request_headers.complete
19:04:50,959 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:50,959 httpcore.http11 DEBUG send_request_body.complete
19:04:50,960 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:51,189 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'137'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'eadafd5d547cf97835c778ad942fc690'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe3a7cd24cd6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:51,194 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:04:51,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:51,196 httpcore.http11 DEBUG receive_response_body.complete
19:04:51,196 httpcore.http11 DEBUG response_closed.started
19:04:51,197 httpcore.http11 DEBUG response_closed.complete
19:04:51,197 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:04:51,214 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:51,217 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:56,419 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:56,435 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:56,439 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:01,641 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:01,661 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:01,664 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:06,867 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:06,874 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:05:06,879 httpcore.connection DEBUG close.started
19:05:06,880 httpcore.connection DEBUG close.complete
19:05:06,880 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:06,883 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daac10>
19:05:06,883 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:05:06,892 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dab5d0>
19:05:06,892 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:06,894 httpcore.http11 DEBUG send_request_headers.complete
19:05:06,894 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:06,894 httpcore.http11 DEBUG send_request_body.complete
19:05:06,895 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:07,526 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'484'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e4cb57ceb0b846f02c4076695ac13f9f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe9e1d834cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:07,532 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:05:07,532 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:07,894 httpcore.http11 DEBUG receive_response_body.complete
19:05:07,895 httpcore.http11 DEBUG response_closed.started
19:05:07,895 httpcore.http11 DEBUG response_closed.complete
19:05:07,896 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:05:07,962 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:05:19,401 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:05:19,405 httpcore.connection DEBUG close.started
19:05:19,406 httpcore.connection DEBUG close.complete
19:05:19,406 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:19,409 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7f4d0>
19:05:19,409 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:05:19,417 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f0e510>
19:05:19,418 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:19,419 httpcore.http11 DEBUG send_request_headers.complete
19:05:19,419 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:19,451 httpcore.http11 DEBUG send_request_body.complete
19:05:19,452 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:20,337 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:20 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'434'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4f98f20d22b2d1683bedf6b5b69f56f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328feec5de83059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:20,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:05:20,344 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:20,346 httpcore.http11 DEBUG receive_response_body.complete
19:05:20,346 httpcore.http11 DEBUG response_closed.started
19:05:20,347 httpcore.http11 DEBUG response_closed.complete
19:05:20,347 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:05:20,348 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:05:20,376 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it between the first candle and second candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:20,380 httpcore.connection DEBUG close.started
19:05:20,380 httpcore.connection DEBUG close.complete
19:05:20,381 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:20,384 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc06d0>
19:05:20,384 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:05:20,389 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2750>
19:05:20,390 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:20,391 httpcore.http11 DEBUG send_request_headers.complete
19:05:20,391 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:20,391 httpcore.http11 DEBUG send_request_body.complete
19:05:20,392 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:20,618 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2a9b177b774968eda5a755ad3b1f1625'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fef27e484cdb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:20,623 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:20,624 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:20,625 httpcore.http11 DEBUG receive_response_body.complete
19:05:20,626 httpcore.http11 DEBUG response_closed.started
19:05:20,626 httpcore.http11 DEBUG response_closed.complete
19:05:20,627 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:20,662 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it between the first candle and second candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:20,666 httpcore.connection DEBUG close.started
19:05:20,666 httpcore.connection DEBUG close.complete
19:05:20,666 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:20,669 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d5fcd0>
19:05:20,669 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9e720> server_hostname='api.openai.com' timeout=None
19:05:20,675 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db3c90>
19:05:20,675 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:20,676 httpcore.http11 DEBUG send_request_headers.complete
19:05:20,676 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:20,677 httpcore.http11 DEBUG send_request_body.complete
19:05:20,677 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:21,712 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'952'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9a5d8bc83c80f762753f90ca58062994'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fef439413068-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:21,719 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:21,720 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:21,722 httpcore.http11 DEBUG receive_response_body.complete
19:05:21,722 httpcore.http11 DEBUG response_closed.started
19:05:21,723 httpcore.http11 DEBUG response_closed.complete
19:05:21,723 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:22,326 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:22,329 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:29,531 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:29,551 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:29,554 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:34,755 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:34,773 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:34,776 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:39,978 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:39,996 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:40,0 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:45,204 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:45,221 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:45,224 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:52,426 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:52,443 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:52,447 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:57,650 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:57,668 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:57,672 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:02,875 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:02,893 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:02,896 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:08,98 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:08,119 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:08,122 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:13,324 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:13,340 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:13,344 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:18,546 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:18,554 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:18,559 httpcore.connection DEBUG close.started
19:06:18,559 httpcore.connection DEBUG close.complete
19:06:18,560 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:18,590 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd0c10>
19:06:18,590 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:18,598 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd0210>
19:06:18,599 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:18,601 httpcore.http11 DEBUG send_request_headers.complete
19:06:18,601 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:18,602 httpcore.http11 DEBUG send_request_body.complete
19:06:18,602 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:19,186 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'507'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9986ac1178e3429391ead91f39c3c691'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329005e48ec4ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:19,192 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:19,193 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:20,200 httpcore.http11 DEBUG receive_response_body.complete
19:06:20,201 httpcore.http11 DEBUG response_closed.started
19:06:20,202 httpcore.http11 DEBUG response_closed.complete
19:06:20,203 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:20,276 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:32,866 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:32,872 httpcore.connection DEBUG close.started
19:06:32,872 httpcore.connection DEBUG close.complete
19:06:32,872 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:32,875 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd2dd0>
19:06:32,875 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:32,883 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd2e50>
19:06:32,884 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:32,885 httpcore.http11 DEBUG send_request_headers.complete
19:06:32,885 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:32,911 httpcore.http11 DEBUG send_request_body.complete
19:06:32,911 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:33,708 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:33 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'352'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0c56ab70c1a50f4276d3aa4ef9ad6048'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900b78e6c4cc8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:33,710 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:33,710 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:33,711 httpcore.http11 DEBUG receive_response_body.complete
19:06:33,711 httpcore.http11 DEBUG response_closed.started
19:06:33,712 httpcore.http11 DEBUG response_closed.complete
19:06:33,712 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:33,713 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:33,741 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nTo the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:33,745 httpcore.connection DEBUG close.started
19:06:33,745 httpcore.connection DEBUG close.complete
19:06:33,746 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:33,748 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc6d10>
19:06:33,749 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:06:33,755 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc5410>
19:06:33,755 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:33,756 httpcore.http11 DEBUG send_request_headers.complete
19:06:33,756 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:33,757 httpcore.http11 DEBUG send_request_body.complete
19:06:33,757 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:33,976 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'114'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f24d6a64c7bb4aeeb758034f6d20aa68'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900bcfd1b4cf0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:33,982 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:33,983 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:33,984 httpcore.http11 DEBUG receive_response_body.complete
19:06:33,985 httpcore.http11 DEBUG response_closed.started
19:06:33,985 httpcore.http11 DEBUG response_closed.complete
19:06:33,986 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:34,20 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nTo the right.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:34,23 httpcore.connection DEBUG close.started
19:06:34,23 httpcore.connection DEBUG close.complete
19:06:34,24 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:34,26 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fc90>
19:06:34,26 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:06:34,31 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7ead0>
19:06:34,32 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:34,33 httpcore.http11 DEBUG send_request_headers.complete
19:06:34,33 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:34,34 httpcore.http11 DEBUG send_request_body.complete
19:06:34,34 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:34,300 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'149'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0ddfa16731c4ae7b4d27222bc48afb81'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900bebf0c6ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:34,307 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:34,308 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:34,310 httpcore.http11 DEBUG receive_response_body.complete
19:06:34,310 httpcore.http11 DEBUG response_closed.started
19:06:34,311 httpcore.http11 DEBUG response_closed.complete
19:06:34,312 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:34,328 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:34,333 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:39,536 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:39,541 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:39,547 httpcore.connection DEBUG close.started
19:06:39,547 httpcore.connection DEBUG close.complete
19:06:39,548 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:39,550 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc7750>
19:06:39,551 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:39,558 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc6f50>
19:06:39,559 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:39,560 httpcore.http11 DEBUG send_request_headers.complete
19:06:39,560 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:39,561 httpcore.http11 DEBUG send_request_body.complete
19:06:39,561 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:40,15 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0aeb6b288e56d919359f1689fff77ed2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900e14a354d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:40,20 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:40,21 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:40,224 httpcore.http11 DEBUG receive_response_body.complete
19:06:40,225 httpcore.http11 DEBUG response_closed.started
19:06:40,226 httpcore.http11 DEBUG response_closed.complete
19:06:40,227 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:40,296 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:48,11 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:48,17 httpcore.connection DEBUG close.started
19:06:48,17 httpcore.connection DEBUG close.complete
19:06:48,17 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:48,20 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc1490>
19:06:48,20 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:48,26 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc1850>
19:06:48,26 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:48,27 httpcore.http11 DEBUG send_request_headers.complete
19:06:48,27 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:48,47 httpcore.http11 DEBUG send_request_body.complete
19:06:48,48 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:48,924 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f18a096a7e1711fdce19e6c6c6222b0b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832901162afe4cc2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:48,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:48,929 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:48,931 httpcore.http11 DEBUG receive_response_body.complete
19:06:48,931 httpcore.http11 DEBUG response_closed.started
19:06:48,932 httpcore.http11 DEBUG response_closed.complete
19:06:48,933 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:48,934 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:48,964 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:48,967 httpcore.connection DEBUG close.started
19:06:48,967 httpcore.connection DEBUG close.complete
19:06:48,967 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:48,970 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd0950>
19:06:48,970 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:06:48,975 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd1e50>
19:06:48,976 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:48,977 httpcore.http11 DEBUG send_request_headers.complete
19:06:48,977 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:48,978 httpcore.http11 DEBUG send_request_body.complete
19:06:48,978 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:49,196 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'682b7add316cb684eca57e0761a74c7f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329011c1c143074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:49,202 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:49,203 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:49,204 httpcore.http11 DEBUG receive_response_body.complete
19:06:49,205 httpcore.http11 DEBUG response_closed.started
19:06:49,205 httpcore.http11 DEBUG response_closed.complete
19:06:49,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:49,222 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:49,225 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:54,427 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:54,434 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:54,438 httpcore.connection DEBUG close.started
19:06:54,438 httpcore.connection DEBUG close.complete
19:06:54,439 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:54,441 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc3a10>
19:06:54,442 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:54,447 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc38d0>
19:06:54,447 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:54,448 httpcore.http11 DEBUG send_request_headers.complete
19:06:54,449 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:54,449 httpcore.http11 DEBUG send_request_body.complete
19:06:54,450 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:54,894 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:54 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'361'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7f9da588ced1feb5a11bfc8e0b8aec1e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329013e4f763b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:54,898 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:54,899 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:55,183 httpcore.http11 DEBUG receive_response_body.complete
19:06:55,184 httpcore.http11 DEBUG response_closed.started
19:06:55,184 httpcore.http11 DEBUG response_closed.complete
19:06:55,185 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:55,255 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:07:02,917 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:07:02,923 httpcore.connection DEBUG close.started
19:07:02,923 httpcore.connection DEBUG close.complete
19:07:02,924 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:07:02,926 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2cd0>
19:07:02,926 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:07:02,933 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2450>
19:07:02,934 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:02,936 httpcore.http11 DEBUG send_request_headers.complete
19:07:02,937 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:02,961 httpcore.http11 DEBUG send_request_body.complete
19:07:02,962 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:03,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:07:03 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'336'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0abb778d97b7ab6f4b7a6690c7fc2d9b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832901735e784d17-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:03,826 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:07:03,826 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:03,827 httpcore.http11 DEBUG receive_response_body.complete
19:07:03,828 httpcore.http11 DEBUG response_closed.started
19:07:03,828 httpcore.http11 DEBUG response_closed.complete
19:07:03,829 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:07:03,829 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:07:03,860 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:07:03,863 httpcore.connection DEBUG close.started
19:07:03,864 httpcore.connection DEBUG close.complete
19:07:03,864 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:07:03,867 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daaa90>
19:07:03,867 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:07:03,871 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dab110>
19:07:03,872 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:03,873 httpcore.http11 DEBUG send_request_headers.complete
19:07:03,873 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:03,873 httpcore.http11 DEBUG send_request_body.complete
19:07:03,874 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:04,98 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:07:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'560151d52e6f22bc122fc976618478f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329017939f93021-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:04,102 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:07:04,103 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:04,104 httpcore.http11 DEBUG receive_response_body.complete
19:07:04,105 httpcore.http11 DEBUG response_closed.started
19:07:04,106 httpcore.http11 DEBUG response_closed.complete
19:07:04,107 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:07:04,124 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:07:04,128 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:09,330 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:07:09,349 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:07:09,353 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:14,556 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:07:14,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:07:14,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:19,783 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:57:59,805 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:57:59,808 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,645 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,646 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,687 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,688 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,736 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,737 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,777 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,778 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,825 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,826 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,867 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,868 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,916 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,917 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,957 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,958 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:01,936 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:58:01,960 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:58:01,991 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d92a1210>
17:58:01,992 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe4d9b25f40> server_hostname='api.openai.com' timeout=5.0
17:58:02,2 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d92a1790>
17:58:02,3 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:58:02,4 httpcore.http11 DEBUG send_request_headers.complete
17:58:02,4 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:58:02,5 httpcore.http11 DEBUG send_request_body.complete
17:58:02,5 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:58:02,121 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Sun, 10 Dec 2023 22:58:02 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'301'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'6b9dd969f554d62dd7c38779e16b3186'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zRASVXUDfI9b82JFgDgTP4yp0XxepOTHvgd1BUgb5Fs-1702249082-1-AT+wBGFq5TDPxJp8fbNyFiBVVhrYDHOVSBDqGrSGmaiOxgyoea8mW1+afzgla8Uj0e/0xEZ1Be58yoBSQ3NxJSI=; path=/; expires=Sun, 10-Dec-23 23:28:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fDHMsjGlcCJh_Q1Ax5TCq3DGWyFafgmZaJ_GZkCjMrc-1702249082116-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339171a88f93b9a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:58:02,131 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 401 Unauthorized"
17:58:02,131 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:58:02,132 httpcore.http11 DEBUG receive_response_body.complete
17:58:02,132 httpcore.http11 DEBUG response_closed.started
17:58:02,133 httpcore.http11 DEBUG response_closed.complete
17:58:02,133 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "401 Unauthorized"
18:01:12,977 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:12,981 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,789 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,790 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,837 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,838 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,886 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,887 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,929 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,930 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,988 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,989 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:14,30 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:14,31 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:14,79 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:14,80 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:14,121 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:14,122 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:15,723 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:01:15,747 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:01:15,781 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673810>
18:01:15,782 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fde20> server_hostname='api.openai.com' timeout=5.0
18:01:15,789 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673d10>
18:01:15,790 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:15,792 httpcore.http11 DEBUG send_request_headers.complete
18:01:15,792 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:15,793 httpcore.http11 DEBUG send_request_body.complete
18:01:15,793 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:16,337 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:01:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'13a21ea9b957e5f9ba5cc08774ef8e1c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_PkASAQaztgStxMVOD6LEfjyEN_pQiOfVHwtHaRHn4A-1702249276-1-AaeCGXCsfwnpBuOpj5BsunlqwKVJ4Wxe4AWLAnQ25/yCWj8zLZslFPNd23n2hzACm1cMYS3WTPYPMLA4SmW+MNs=; path=/; expires=Sun, 10-Dec-23 23:31:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=TDwxJAVHwfOnl.i.1mFxOac4V1ZDw7Je8KZGz_8XrW8-1702249276329-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391bd5ba234cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:16,344 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:01:16,345 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:01:17,129 httpcore.http11 DEBUG receive_response_body.complete
18:01:17,130 httpcore.http11 DEBUG response_closed.started
18:01:17,130 httpcore.http11 DEBUG response_closed.complete
18:01:17,131 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:01:17,212 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:01:30,933 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:01:30,943 httpcore.connection DEBUG close.started
18:01:30,943 httpcore.connection DEBUG close.complete
18:01:30,944 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:01:30,946 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68acaeecd0>
18:01:30,946 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fde20> server_hostname='api.openai.com' timeout=5.0
18:01:30,952 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673f10>
18:01:30,953 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:30,954 httpcore.http11 DEBUG send_request_headers.complete
18:01:30,954 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:30,976 httpcore.http11 DEBUG send_request_body.complete
18:01:30,977 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:31,899 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:01:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'404'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3348cb32091b7521a81be7bf7757f52d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391c347ce83b69-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:31,904 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:01:31,905 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:01:31,906 httpcore.http11 DEBUG receive_response_body.complete
18:01:31,906 httpcore.http11 DEBUG response_closed.started
18:01:31,907 httpcore.http11 DEBUG response_closed.complete
18:01:31,907 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:01:31,908 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:01:31,948 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:01:31,960 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:01:31,963 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6d42d0>
18:01:31,963 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fdfd0> server_hostname='api.openai.com' timeout=None
18:01:31,969 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6d4290>
18:01:31,969 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:31,970 httpcore.http11 DEBUG send_request_headers.complete
18:01:31,971 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:31,971 httpcore.http11 DEBUG send_request_body.complete
18:01:31,971 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:32,466 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:01:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'288'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'76be7950cd2c3dad305b51b741b6f3e4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SG1Fw8cOCJch9u3E4DwQmUXJAm8Xyt0fw5HMPQR.Zkk-1702249292-1-AcqKbTjuMeSOWFP1P7AJsoUwFv47E03sqT6gBxEen2RpINLv9vjlTiPi4hwMgY6LXdIha4YNCi4TXW0HazIEsDQ=; path=/; expires=Sun, 10-Dec-23 23:31:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rGL0sbEaUyYfGufGhvasF._kxzdAjqIoN5rugWUsiHc-1702249292463-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391c3ad8673b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:32,472 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:01:32,473 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:01:32,474 httpcore.http11 DEBUG receive_response_body.complete
18:01:32,475 httpcore.http11 DEBUG response_closed.started
18:01:32,475 httpcore.http11 DEBUG response_closed.complete
18:01:32,476 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:01:32,514 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:01:32,524 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:01:32,527 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6dc410>
18:01:32,527 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fe7b0> server_hostname='api.openai.com' timeout=None
18:01:32,536 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6de850>
18:01:32,536 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:32,538 httpcore.http11 DEBUG send_request_headers.complete
18:01:32,538 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:32,539 httpcore.http11 DEBUG send_request_body.complete
18:01:32,539 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:33,187 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:01:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'544'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3d766cdec300c046ae1f73f727f7d290'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_x2viZhoF9IFeKtUnuJYsGLarmFjksDchRGQgG1Nojk-1702249293-1-Ab5aPKH6D0C1RIYzQ6B5Syi7lVYmKcP2YqSqA9vJLwrcYTQSerz/bkkh8YbKIOcUZKX6fcCSLaP8eDRmRXArhl0=; path=/; expires=Sun, 10-Dec-23 23:31:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=N8825IhUlGj8BiUyyCLYXRt0nxLbZVuR83iaZ_bcA0M-1702249293183-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391c3e5e154d0d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:33,194 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:01:33,195 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:01:33,196 httpcore.http11 DEBUG receive_response_body.complete
18:01:33,197 httpcore.http11 DEBUG response_closed.started
18:01:33,197 httpcore.http11 DEBUG response_closed.complete
18:01:33,198 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:01:33,219 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:33,261 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:38,972 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:38,990 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:38,995 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:41,997 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:42,15 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:42,19 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:45,21 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:45,40 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:45,44 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:48,447 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:48,468 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:48,471 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:54,173 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:54,193 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:54,197 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:57,599 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:57,616 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:57,620 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:02:01,24 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:02:01,31 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:02:01,38 httpcore.connection DEBUG close.started
18:02:01,39 httpcore.connection DEBUG close.complete
18:02:01,40 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:02:01,42 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673f10>
18:02:01,43 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fde20> server_hostname='api.openai.com' timeout=5.0
18:02:01,51 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673e10>
18:02:01,52 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:02:01,53 httpcore.http11 DEBUG send_request_headers.complete
18:02:01,54 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:02:01,54 httpcore.http11 DEBUG send_request_body.complete
18:02:01,55 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:02:01,831 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:02:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'650'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f30394fa62cc8a5670d0364fdbe212bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391cf099c33bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:02:01,835 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:02:01,836 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:02:02,952 httpcore.http11 DEBUG receive_response_body.complete
18:02:02,952 httpcore.http11 DEBUG response_closed.started
18:02:02,953 httpcore.http11 DEBUG response_closed.complete
18:02:02,953 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:02:03,18 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:02:15,657 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:02:15,661 httpcore.connection DEBUG close.started
18:02:15,662 httpcore.connection DEBUG close.complete
18:02:15,662 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:02:15,664 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac5061d0>
18:02:15,665 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fde20> server_hostname='api.openai.com' timeout=5.0
18:02:15,673 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac506250>
18:02:15,673 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:02:15,674 httpcore.http11 DEBUG send_request_headers.complete
18:02:15,675 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:02:15,684 httpcore.http11 DEBUG send_request_body.complete
18:02:15,685 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:02:16,502 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:02:16 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b539798969e852940532c14c0625ff22'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391d4bfff83b94-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:02:16,507 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:02:16,507 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:02:16,508 httpcore.http11 DEBUG receive_response_body.complete
18:02:16,509 httpcore.http11 DEBUG response_closed.started
18:02:16,509 httpcore.http11 DEBUG response_closed.complete
18:02:16,510 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:02:16,511 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:02:16,545 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:02:16,548 httpcore.connection DEBUG close.started
18:02:16,549 httpcore.connection DEBUG close.complete
18:02:16,549 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:02:16,579 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6d4250>
18:02:16,579 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fdfd0> server_hostname='api.openai.com' timeout=None
18:02:16,588 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6d41d0>
18:02:16,589 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:02:16,591 httpcore.http11 DEBUG send_request_headers.complete
18:02:16,592 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:02:16,593 httpcore.http11 DEBUG send_request_body.complete
18:02:16,594 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:02:16,947 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:02:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'252'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0e0757184eca8408870abbbae71daf16'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391d51b86d4cd9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:02:16,954 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:02:16,954 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:02:16,955 httpcore.http11 DEBUG receive_response_body.complete
18:02:16,956 httpcore.http11 DEBUG response_closed.started
18:02:16,956 httpcore.http11 DEBUG response_closed.complete
18:02:16,956 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:02:16,988 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location, or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:02:16,999 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:02:17,1 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac505890>
18:02:17,2 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fdf40> server_hostname='api.openai.com' timeout=None
18:02:17,9 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac505790>
18:02:17,9 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:02:17,11 httpcore.http11 DEBUG send_request_headers.complete
18:02:17,11 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:02:17,12 httpcore.http11 DEBUG send_request_body.complete
18:02:17,12 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:02:17,415 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:02:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'314'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ca83690eb6e9408ebc62ef63d18deda7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HyelhPJsiodedacVgfsY5gbX1gDuIuL0k.diFjBmrb8-1702249337-1-AYmKQe6BrN7deZcXrhvj/29n/Y3J/aC3v95xYA1pAqBdHzaH3Q8TTPsHIHzt3DMHWRW6hoTR0dancbHcO6S8EA4=; path=/; expires=Sun, 10-Dec-23 23:32:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=xZSzJ38IPp7gfdB.6wiZA6qJJ_d4zENPoDDGaLXbiKU-1702249337412-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391d545ade3b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:02:17,421 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:02:17,421 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:02:17,423 httpcore.http11 DEBUG receive_response_body.complete
18:02:17,423 httpcore.http11 DEBUG response_closed.started
18:02:17,424 httpcore.http11 DEBUG response_closed.complete
18:02:17,425 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:07:52,176 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:52,181 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,3 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,5 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,50 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,51 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,102 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,103 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,145 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,147 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,197 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,198 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,242 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,243 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,294 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,295 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,339 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,340 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:54,186 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:07:54,203 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:07:54,235 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f8d9310>
18:07:54,236 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:07:54,243 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f8dff10>
18:07:54,245 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:07:54,247 httpcore.http11 DEBUG send_request_headers.complete
18:07:54,248 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:07:54,249 httpcore.http11 DEBUG send_request_body.complete
18:07:54,249 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:07:54,764 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:07:54 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'405'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'79c3ed4270e2636767015fcb3ab2d58f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cVf_jErXT2PAKJ5Gri8bvJ8FDWJUO1sKGfT09AVrZVM-1702249674-1-AR+g0WR6eVVvO5PZQXDF8POAu+51QPiQXFFHUIDursPAWKGZl6pvrT/DMe2co4Y6G79pfRWHK3d1fUfUnwEdmm4=; path=/; expires=Sun, 10-Dec-23 23:37:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=n1NHhX6ivKLr54k38h7BMF_3t1EPRwBm.nG5znHPcK8-1702249674758-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339259009024d1d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:07:54,773 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:07:54,774 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:07:55,616 httpcore.http11 DEBUG receive_response_body.complete
18:07:55,618 httpcore.http11 DEBUG response_closed.started
18:07:55,618 httpcore.http11 DEBUG response_closed.complete
18:07:55,620 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:07:55,707 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:08:09,478 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:08:09,487 httpcore.connection DEBUG close.started
18:08:09,487 httpcore.connection DEBUG close.complete
18:08:09,488 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:08:09,490 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f8df790>
18:08:09,491 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:08:09,495 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f8df7d0>
18:08:09,496 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:09,497 httpcore.http11 DEBUG send_request_headers.complete
18:08:09,497 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:09,523 httpcore.http11 DEBUG send_request_body.complete
18:08:09,523 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:10,428 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:10 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'493'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cfa0635d9db78a82706c9f664e13fe4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833925ef5f613b9f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:10,433 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:08:10,434 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:10,436 httpcore.http11 DEBUG receive_response_body.complete
18:08:10,436 httpcore.http11 DEBUG response_closed.started
18:08:10,437 httpcore.http11 DEBUG response_closed.complete
18:08:10,438 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:08:10,439 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:08:10,474 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:08:10,485 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:08:10,487 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744490>
18:08:10,488 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969fd0> server_hostname='api.openai.com' timeout=None
18:08:10,495 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744450>
18:08:10,495 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:10,497 httpcore.http11 DEBUG send_request_headers.complete
18:08:10,497 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:10,498 httpcore.http11 DEBUG send_request_body.complete
18:08:10,498 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:10,698 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'97'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'15a31ad29b7ac9294640957e2e2f2cd6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PU9Td4dTzT35uM7oyNU5RjpPlMZMn85RECbc2lMYYFw-1702249690-1-AT9Nc/F4zrXFpSrXCRBY3NvIFGC5v3FnvK/1tVL8Si5wQehQTMZHOcBK0kvsw+COSPKS6OAE9fy4x+u1gsJLJQM=; path=/; expires=Sun, 10-Dec-23 23:38:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=p5wCJ2pqRuQJym2M0wwlGmDfw18CpmxgXIr.G8EjEpk-1702249690693-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833925f598bc4d01-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:10,705 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:08:10,706 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:10,708 httpcore.http11 DEBUG receive_response_body.complete
18:08:10,709 httpcore.http11 DEBUG response_closed.started
18:08:10,710 httpcore.http11 DEBUG response_closed.complete
18:08:10,710 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:08:10,745 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:08:10,756 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:08:10,758 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744dd0>
18:08:10,759 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f96a7b0> server_hostname='api.openai.com' timeout=None
18:08:10,764 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f7462d0>
18:08:10,765 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:10,766 httpcore.http11 DEBUG send_request_headers.complete
18:08:10,766 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:10,767 httpcore.http11 DEBUG send_request_body.complete
18:08:10,767 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:11,134 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'266'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'826a6feadf67c0824e8a7c7b6b136327'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Z8lZt0gxcsGWenuSHuAUV1KKAnM2zhTxAwecTH53ECs-1702249691-1-AdzylJktaiW2TLSAJxTVPSOQ2ATr/P5aK7vMlEcHSMdTTnJVenqsSGYkBBYncYH3Kdsg7ZaWIZk4/IVejuA89fA=; path=/; expires=Sun, 10-Dec-23 23:38:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=B1QVvNjpvG_3ENhsG3maU2n4np_B36glSji.BWdouOM-1702249691130-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833925f74c643b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:11,143 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:08:11,144 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:11,146 httpcore.http11 DEBUG receive_response_body.complete
18:08:11,146 httpcore.http11 DEBUG response_closed.started
18:08:11,146 httpcore.http11 DEBUG response_closed.complete
18:08:11,147 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:08:11,165 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:11,169 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:16,877 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:16,891 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:16,895 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:20,897 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:20,913 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:20,916 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:23,918 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:23,938 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:23,942 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:27,346 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:27,362 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:27,366 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:33,68 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:33,90 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:33,96 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:36,500 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:36,519 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:36,522 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:40,724 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:40,731 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:08:40,739 httpcore.connection DEBUG close.started
18:08:40,739 httpcore.connection DEBUG close.complete
18:08:40,739 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:08:40,742 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5fb5f950>
18:08:40,742 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:08:40,748 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f92c590>
18:08:40,749 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:40,750 httpcore.http11 DEBUG send_request_headers.complete
18:08:40,750 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:40,751 httpcore.http11 DEBUG send_request_body.complete
18:08:40,751 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:41,432 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:41 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'566'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f8691637c734e716f3f1895bf4ee2924'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833926b2b9063045-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:41,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:08:41,435 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:42,422 httpcore.http11 DEBUG receive_response_body.complete
18:08:42,423 httpcore.http11 DEBUG response_closed.started
18:08:42,423 httpcore.http11 DEBUG response_closed.complete
18:08:42,424 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:08:42,491 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:08:55,41 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:08:55,46 httpcore.connection DEBUG close.started
18:08:55,47 httpcore.connection DEBUG close.complete
18:08:55,47 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:08:55,78 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772b10>
18:08:55,78 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:08:55,86 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772b90>
18:08:55,86 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:55,88 httpcore.http11 DEBUG send_request_headers.complete
18:08:55,89 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:55,103 httpcore.http11 DEBUG send_request_body.complete
18:08:55,104 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:55,997 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:55 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'381'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'67956e25e283587b6b6f815e4f465584'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339270c4cc06ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:56,0 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:08:56,1 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:56,2 httpcore.http11 DEBUG receive_response_body.complete
18:08:56,2 httpcore.http11 DEBUG response_closed.started
18:08:56,3 httpcore.http11 DEBUG response_closed.complete
18:08:56,3 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:08:56,4 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:08:56,38 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:08:56,43 httpcore.connection DEBUG close.started
18:08:56,44 httpcore.connection DEBUG close.complete
18:08:56,45 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:08:56,47 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744450>
18:08:56,48 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969fd0> server_hostname='api.openai.com' timeout=None
18:08:56,54 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744590>
18:08:56,54 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:56,55 httpcore.http11 DEBUG send_request_headers.complete
18:08:56,55 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:56,56 httpcore.http11 DEBUG send_request_body.complete
18:08:56,56 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:56,421 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'271'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1157ee10f7993910953db80f46d2b7be'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339271259e93b70-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:56,428 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:08:56,429 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:56,431 httpcore.http11 DEBUG receive_response_body.complete
18:08:56,432 httpcore.http11 DEBUG response_closed.started
18:08:56,433 httpcore.http11 DEBUG response_closed.complete
18:08:56,434 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:08:56,441 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:08:56,444 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:56,446 httpcore.http11 DEBUG send_request_headers.complete
18:08:56,446 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:56,446 httpcore.http11 DEBUG send_request_body.complete
18:08:56,447 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:56,951 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'413'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e379fadd4ab427cd58baca90680ecdb6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392714cedc6ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:56,955 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:08:56,956 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:58,71 httpcore.http11 DEBUG receive_response_body.complete
18:08:58,72 httpcore.http11 DEBUG response_closed.started
18:08:58,72 httpcore.http11 DEBUG response_closed.complete
18:08:58,73 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:08:58,143 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:09:10,784 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:09:10,792 httpcore.connection DEBUG close.started
18:09:10,793 httpcore.connection DEBUG close.complete
18:09:10,793 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:09:10,796 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f771c10>
18:09:10,796 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:09:10,812 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772390>
18:09:10,813 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:10,815 httpcore.http11 DEBUG send_request_headers.complete
18:09:10,815 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:10,836 httpcore.http11 DEBUG send_request_body.complete
18:09:10,836 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:11,656 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:11 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'6'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'358'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3beb33c0af10b65c68e494f7ee4855ba'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339276e9a644cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:11,661 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:09:11,661 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:11,663 httpcore.http11 DEBUG receive_response_body.complete
18:09:11,663 httpcore.http11 DEBUG response_closed.started
18:09:11,664 httpcore.http11 DEBUG response_closed.complete
18:09:11,665 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:09:11,666 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:09:11,698 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNope.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:11,713 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:09:11,716 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f781fd0>
18:09:11,717 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969f40> server_hostname='api.openai.com' timeout=None
18:09:11,722 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f782890>
18:09:11,722 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:11,723 httpcore.http11 DEBUG send_request_headers.complete
18:09:11,723 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:11,724 httpcore.http11 DEBUG send_request_body.complete
18:09:11,724 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:12,102 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'263'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8cf3225dd05b5f288be87ac0d50dcecb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IEY134K2lQWXxSte6z9gsejg5.Mtdxo8vnqY0oMLy0o-1702249752-1-AXzePmROvRCdo1r+Yszv/3ujA0XdaqyX4NpnPUGQAeochSYamcY/0iAtFtRLcPFL2+knuozt4p2Rb1SQf+BSdcs=; path=/; expires=Sun, 10-Dec-23 23:39:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=XBUX6Y8JgE2a2KkbijoRxhwrf8GgCyRFg59YnfTwCZ8-1702249752097-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392774498e3b8d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:12,111 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:12,112 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:12,114 httpcore.http11 DEBUG receive_response_body.complete
18:09:12,114 httpcore.http11 DEBUG response_closed.started
18:09:12,114 httpcore.http11 DEBUG response_closed.complete
18:09:12,115 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:12,147 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNope.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:12,150 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:12,151 httpcore.http11 DEBUG send_request_headers.complete
18:09:12,152 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:12,152 httpcore.http11 DEBUG send_request_body.complete
18:09:12,152 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:12,593 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'347'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7439ac1831bfacdfc28a56df3ab21c39'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392776fd963b8d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:12,599 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:12,599 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:12,601 httpcore.http11 DEBUG receive_response_body.complete
18:09:12,601 httpcore.http11 DEBUG response_closed.started
18:09:12,602 httpcore.http11 DEBUG response_closed.complete
18:09:12,602 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:12,612 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:09:12,615 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:12,616 httpcore.http11 DEBUG send_request_headers.complete
18:09:12,617 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:12,617 httpcore.http11 DEBUG send_request_body.complete
18:09:12,617 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:13,69 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:13 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'387'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'670341e1ced7d1615694071e4ff7580b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392779d9d04cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:13,74 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:09:13,75 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:13,979 httpcore.http11 DEBUG receive_response_body.complete
18:09:13,980 httpcore.http11 DEBUG response_closed.started
18:09:13,981 httpcore.http11 DEBUG response_closed.complete
18:09:13,981 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:09:14,52 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:09:25,413 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:09:25,417 httpcore.connection DEBUG close.started
18:09:25,418 httpcore.connection DEBUG close.complete
18:09:25,419 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:09:25,421 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f7734d0>
18:09:25,421 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:09:25,426 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f773cd0>
18:09:25,427 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:25,428 httpcore.http11 DEBUG send_request_headers.complete
18:09:25,428 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:25,452 httpcore.http11 DEBUG send_request_body.complete
18:09:25,453 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:49,553 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:49 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'23705'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'96ce27e9c230ee9973002e799c9de4f3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833927c9e9ba4cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:49,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:09:49,558 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:49,559 httpcore.http11 DEBUG receive_response_body.complete
18:09:49,559 httpcore.http11 DEBUG response_closed.started
18:09:49,560 httpcore.http11 DEBUG response_closed.complete
18:09:49,560 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:09:49,561 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:09:49,590 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhich way should I move? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove left.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:49,594 httpcore.connection DEBUG close.started
18:09:49,594 httpcore.connection DEBUG close.complete
18:09:49,595 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:09:49,597 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772ad0>
18:09:49,597 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969f40> server_hostname='api.openai.com' timeout=None
18:09:49,602 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772b10>
18:09:49,603 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:49,604 httpcore.http11 DEBUG send_request_headers.complete
18:09:49,604 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:49,604 httpcore.http11 DEBUG send_request_body.complete
18:09:49,605 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:49,806 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ffee0b4e210f9cbb0fb52135da611834'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833928610af53b82-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:49,812 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:49,814 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:49,816 httpcore.http11 DEBUG receive_response_body.complete
18:09:49,816 httpcore.http11 DEBUG response_closed.started
18:09:49,817 httpcore.http11 DEBUG response_closed.complete
18:09:49,818 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:49,833 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:49,838 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:53,241 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:53,248 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:09:53,253 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:53,254 httpcore.http11 DEBUG send_request_headers.complete
18:09:53,254 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:53,254 httpcore.http11 DEBUG send_request_body.complete
18:09:53,255 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:53,828 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:53 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c4c71f03a74302f8ba46a4655fe92a15'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392877d9004cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:53,833 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:09:53,834 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:54,302 httpcore.http11 DEBUG receive_response_body.complete
18:09:54,303 httpcore.http11 DEBUG response_closed.started
18:09:54,303 httpcore.http11 DEBUG response_closed.complete
18:09:54,304 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:09:54,371 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:10:03,643 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:10:03,647 httpcore.connection DEBUG close.started
18:10:03,648 httpcore.connection DEBUG close.complete
18:10:03,648 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:10:03,677 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f78b8d0>
18:10:03,678 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:10:03,685 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f78b950>
18:10:03,686 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:03,688 httpcore.http11 DEBUG send_request_headers.complete
18:10:03,688 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:03,712 httpcore.http11 DEBUG send_request_body.complete
18:10:03,712 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:04,742 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:04 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'360'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3e9c0d48eef0da4f05f9990a9e08764'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833928b90f114cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:04,748 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:10:04,749 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:04,750 httpcore.http11 DEBUG receive_response_body.complete
18:10:04,750 httpcore.http11 DEBUG response_closed.started
18:10:04,750 httpcore.http11 DEBUG response_closed.complete
18:10:04,751 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:10:04,751 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:10:04,778 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:10:04,781 httpcore.connection DEBUG close.started
18:10:04,782 httpcore.connection DEBUG close.complete
18:10:04,782 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:10:04,784 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f792c50>
18:10:04,785 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969f40> server_hostname='api.openai.com' timeout=None
18:10:04,790 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f792cd0>
18:10:04,790 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:04,791 httpcore.http11 DEBUG send_request_headers.complete
18:10:04,791 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:04,792 httpcore.http11 DEBUG send_request_body.complete
18:10:04,792 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:05,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'143'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd3d097f75f55bf6a993287e4b73bd03d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833928bffac56ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:05,28 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:10:05,28 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:05,30 httpcore.http11 DEBUG receive_response_body.complete
18:10:05,30 httpcore.http11 DEBUG response_closed.started
18:10:05,31 httpcore.http11 DEBUG response_closed.complete
18:10:05,31 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:10:05,39 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:10:05,43 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:05,44 httpcore.http11 DEBUG send_request_headers.complete
18:10:05,44 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:05,44 httpcore.http11 DEBUG send_request_body.complete
18:10:05,45 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:05,680 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'03bd15dea41dfa04da6f92cf8aa00337'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833928c18fe34cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:05,683 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:10:05,684 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:06,617 httpcore.http11 DEBUG receive_response_body.complete
18:10:06,618 httpcore.http11 DEBUG response_closed.started
18:10:06,618 httpcore.http11 DEBUG response_closed.complete
18:10:06,619 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:10:06,687 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:10:18,129 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:10:18,133 httpcore.connection DEBUG close.started
18:10:18,134 httpcore.connection DEBUG close.complete
18:10:18,134 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:10:18,136 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f788690>
18:10:18,137 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:10:18,143 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f78bc50>
18:10:18,144 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:18,145 httpcore.http11 DEBUG send_request_headers.complete
18:10:18,145 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:18,165 httpcore.http11 DEBUG send_request_body.complete
18:10:18,166 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:18,965 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'27'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1462df083379627bfe48314bcbda90e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833929136888304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:18,970 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:10:18,971 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:18,972 httpcore.http11 DEBUG receive_response_body.complete
18:10:18,973 httpcore.http11 DEBUG response_closed.started
18:10:18,974 httpcore.http11 DEBUG response_closed.complete
18:10:18,974 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:10:18,974 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:10:19,1 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhich way should I move? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes, it's a good location.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:10:19,4 httpcore.connection DEBUG close.started
18:10:19,5 httpcore.connection DEBUG close.complete
18:10:19,5 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:10:19,8 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f773f10>
18:10:19,8 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969f40> server_hostname='api.openai.com' timeout=None
18:10:19,15 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772d50>
18:10:19,15 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:19,16 httpcore.http11 DEBUG send_request_headers.complete
18:10:19,17 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:19,17 httpcore.http11 DEBUG send_request_body.complete
18:10:19,17 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:19,252 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'942ba2346a269c3de98f9555b3db5935'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392918d8404cfb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:19,259 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:10:19,260 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:19,262 httpcore.http11 DEBUG receive_response_body.complete
18:10:19,263 httpcore.http11 DEBUG response_closed.started
18:10:19,264 httpcore.http11 DEBUG response_closed.complete
18:10:19,264 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:10:19,272 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:10:19,276 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:19,277 httpcore.http11 DEBUG send_request_headers.complete
18:10:19,277 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:19,277 httpcore.http11 DEBUG send_request_body.complete
18:10:19,278 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:19,747 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'346de604f5815a16c141006342e95aa8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339291a7bfa304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:19,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:10:19,752 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:20,683 httpcore.http11 DEBUG receive_response_body.complete
18:10:20,684 httpcore.http11 DEBUG response_closed.started
18:10:20,685 httpcore.http11 DEBUG response_closed.complete
18:10:20,686 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:10:20,754 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:14:52,683 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:52,688 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,528 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,530 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,573 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,574 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,622 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,623 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,668 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,669 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,723 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,725 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,782 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,783 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,830 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,831 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,871 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,872 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:58,41 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:14:58,59 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:14:58,90 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fefd3c90>
18:14:58,91 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f50fef99e20> server_hostname='api.openai.com' timeout=5.0
18:14:58,100 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fef0fc10>
18:14:58,101 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:58,104 httpcore.http11 DEBUG send_request_headers.complete
18:14:58,105 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:58,105 httpcore.http11 DEBUG send_request_body.complete
18:14:58,106 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:58,755 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:14:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'525'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2201e80530b27812b40ef3cf120a0151'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YBEIF76WUlGtVVFgsScBrpQr5rQe12WQrE8JQPJeV_I-1702250098-1-AYzEC0ru6ONZnGDlYCDG/tDVjZqPOzX77dVscdqg3os7H70+tW/clnqvrAxlafFlFH0J4cV2Ayuj8WrfD/3/Zu0=; path=/; expires=Sun, 10-Dec-23 23:44:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ttaR.WItJw.Wk2Jh2Vd3vSQNp3NEsu73W6pINfCIKUI-1702250098749-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392fe92fdb4d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:58,763 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:14:58,763 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:59,442 httpcore.http11 DEBUG receive_response_body.complete
18:14:59,443 httpcore.http11 DEBUG response_closed.started
18:14:59,444 httpcore.http11 DEBUG response_closed.complete
18:14:59,445 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:14:59,530 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:15:13,86 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:15:13,100 httpcore.connection DEBUG close.started
18:15:13,100 httpcore.connection DEBUG close.complete
18:15:13,101 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:15:13,103 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fef0fd50>
18:15:13,103 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f50fef99e20> server_hostname='api.openai.com' timeout=5.0
18:15:13,108 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fef0eed0>
18:15:13,109 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:13,110 httpcore.http11 DEBUG send_request_headers.complete
18:15:13,110 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:13,141 httpcore.http11 DEBUG send_request_body.complete
18:15:13,142 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:13,977 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:15:13 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'374'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ca38a87b90128c13d3bcedc870665e1f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393046fa6e4d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:13,982 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:15:13,984 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:13,985 httpcore.http11 DEBUG receive_response_body.complete
18:15:13,986 httpcore.http11 DEBUG response_closed.started
18:15:13,986 httpcore.http11 DEBUG response_closed.complete
18:15:13,987 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:15:13,988 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:15:14,26 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only. Answer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:15:14,38 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:15:14,40 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fed74c90>
18:15:14,41 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f50fef99fd0> server_hostname='api.openai.com' timeout=None
18:15:14,45 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fed74c50>
18:15:14,46 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:14,47 httpcore.http11 DEBUG send_request_headers.complete
18:15:14,47 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:14,47 httpcore.http11 DEBUG send_request_body.complete
18:15:14,48 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:14,378 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:15:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'241'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a2ac7ca9390279a21655a29897a11d98'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6ZRULtM4zrLydltExvbUoLkc2DhHqwFsbP9236dknC0-1702250114-1-AZJHVoAN9rmvBKAYWm7ZyTW0Oux0USd2nQJwqPZ1QbkE9erA0RujCGz3++ujM32poRxF7nJ3+IcV/jxH7e9B9/U=; path=/; expires=Sun, 10-Dec-23 23:45:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=lDLO4UAlA3ril7oSwiMwGnoRhWHdDdegedwjh5ci.ps-1702250114373-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339304ccb0e4d19-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:14,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:15:14,384 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:14,386 httpcore.http11 DEBUG receive_response_body.complete
18:15:14,386 httpcore.http11 DEBUG response_closed.started
18:15:14,387 httpcore.http11 DEBUG response_closed.complete
18:15:14,387 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:15:14,422 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:15:14,434 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:15:14,436 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fed75950>
18:15:14,437 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f50fef9a330> server_hostname='api.openai.com' timeout=None
18:15:14,446 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fed75990>
18:15:14,447 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:14,449 httpcore.http11 DEBUG send_request_headers.complete
18:15:14,449 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:14,451 httpcore.http11 DEBUG send_request_body.complete
18:15:14,451 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:14,952 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:15:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'402'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'59b3d7e351673e69131f3b8c3b42d489'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RNwnucsesZLUtfcNKQs9ULF33cgqST1aiS128h5Qkso-1702250114-1-AYSHS8lfAVhqM2zy9X8MbXLfJREWjDjkSQOLmOzbOXvo0CYfvYMiotIyIFEYzVoY69v46J9U7wLio81agreBLoM=; path=/; expires=Sun, 10-Dec-23 23:45:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=oSE7pz7sk.i7qfYck.pVCSA9e8ljIbhN48lNbrackFc-1702250114948-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339304f4f334ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:14,956 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:15:14,957 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:14,958 httpcore.http11 DEBUG receive_response_body.complete
18:15:14,959 httpcore.http11 DEBUG response_closed.started
18:15:14,959 httpcore.http11 DEBUG response_closed.complete
18:15:14,960 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:15:14,969 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Great! I'll place the first candle in the middle. Now, where should I place the next candle? Shall we continue with the candle placement?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:15:14,973 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:14,974 httpcore.http11 DEBUG send_request_headers.complete
18:15:14,974 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:14,975 httpcore.http11 DEBUG send_request_body.complete
18:15:14,975 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:15,479 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:15:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bae895adf54f0214ef378d431fdb5f74'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833930529a484d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:15,483 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:15:15,484 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:17,2 httpcore.http11 DEBUG receive_response_body.complete
18:15:17,3 httpcore.http11 DEBUG response_closed.started
18:15:17,4 httpcore.http11 DEBUG response_closed.complete
18:15:17,4 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:15:17,82 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:18:05,698 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:05,702 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,517 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,518 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,560 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,561 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,610 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,611 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,652 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,653 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,702 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,703 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,745 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,746 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,795 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,796 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,837 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,838 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:07,198 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:18:07,217 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:07,249 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871a9b37d0>
18:18:07,249 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f871aa55d90> server_hostname='api.openai.com' timeout=5.0
18:18:07,256 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871a9c7010>
18:18:07,257 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:07,259 httpcore.http11 DEBUG send_request_headers.complete
18:18:07,259 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:07,260 httpcore.http11 DEBUG send_request_body.complete
18:18:07,260 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:07,722 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:18:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'372'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cf78c8172bc3e96e5d2b3d8f2a52148d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3Fr2BikjoTIGdyBVfm5MXmftt9V.lc6j_pK_QOlPN6o-1702250287-1-AXnrxMpRvKWiNepqQUnPf3XQt4xb+GjTbH05vuI7teUgjlWLOTnLq6zKnzjmGzVb286iclHBrL46H6ZZWrjfRik=; path=/; expires=Sun, 10-Dec-23 23:48:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=KrsfD3K136WiCRADgb7eozfG0vmwE_Wu8__D4bBhOTM-1702250287715-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833934875a364cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:07,731 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:18:07,732 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:08,591 httpcore.http11 DEBUG receive_response_body.complete
18:18:08,592 httpcore.http11 DEBUG response_closed.started
18:18:08,593 httpcore.http11 DEBUG response_closed.complete
18:18:08,594 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:18:08,672 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:18:25,577 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:25,581 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,393 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,394 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,443 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,444 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,492 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,493 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,534 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,535 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,585 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,586 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,628 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,630 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,678 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,679 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,720 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,722 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:27,948 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:18:27,968 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:27,971 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4cc58150>
18:18:27,972 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7e4c935d90> server_hostname='api.openai.com' timeout=5.0
18:18:27,977 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c8ab950>
18:18:27,978 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:27,979 httpcore.http11 DEBUG send_request_headers.complete
18:18:27,979 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:27,980 httpcore.http11 DEBUG send_request_body.complete
18:18:27,980 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:28,489 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:18:28 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'85ed5a24e75e99da8a0ccba371353489'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Uq5CJojlrGHFYlx.oT42gF0oRWXEyeO86jhiyO0vh28-1702250308-1-AaSv+Xtzo7qh4NBhzbDLW0X9lCquHelqQT4Sm3hnYaq4hM3eFkjplPHa10WXbe7qTK6yzcB2zf/82wMsnWvK/XA=; path=/; expires=Sun, 10-Dec-23 23:48:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kxUcIADBP3GHbFl6n7AQxEI38zm3KnoPq87uYkv_KXU-1702250308483-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393508da5e4d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:28,496 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:18:28,496 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:29,169 httpcore.http11 DEBUG receive_response_body.complete
18:18:29,170 httpcore.http11 DEBUG response_closed.started
18:18:29,171 httpcore.http11 DEBUG response_closed.complete
18:18:29,172 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:18:29,254 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:18:42,934 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:18:42,943 httpcore.connection DEBUG close.started
18:18:42,944 httpcore.connection DEBUG close.complete
18:18:42,944 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:42,947 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c8ab210>
18:18:42,947 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7e4c935d90> server_hostname='api.openai.com' timeout=5.0
18:18:42,954 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c8abc10>
18:18:42,954 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:42,956 httpcore.http11 DEBUG send_request_headers.complete
18:18:42,956 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:43,77 httpcore.http11 DEBUG send_request_body.complete
18:18:43,78 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:43,912 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:18:43 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a36ab64a8412a9e9b61d0d46160545fe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833935667e1c4ce0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:43,917 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:18:43,918 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:43,919 httpcore.http11 DEBUG receive_response_body.complete
18:18:43,919 httpcore.http11 DEBUG response_closed.started
18:18:43,920 httpcore.http11 DEBUG response_closed.complete
18:18:43,920 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:18:43,921 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:18:49,324 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only. Answer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:18:49,335 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:18:49,337 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c708fd0>
18:18:49,338 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7e4c935f40> server_hostname='api.openai.com' timeout=None
18:18:49,344 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c708310>
18:18:49,345 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:49,346 httpcore.http11 DEBUG send_request_headers.complete
18:18:49,346 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:49,347 httpcore.http11 DEBUG send_request_body.complete
18:18:49,347 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:49,533 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:18:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'91'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'05ee611f0a3458568b22ac77221d675f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jrip2MolwvqAq94XUTVERGobcUwb.F55tntZcFeK9fc-1702250329-1-Ab0DpzcJ4FT8o6gx0OMLbY9TavvTiuN1erTHEG8Ig6KuDbyH3ayL2BFAPKpC01Eb0r23K3WzmSIU73lHZ4MXeIA=; path=/; expires=Sun, 10-Dec-23 23:48:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=GL289jtese.YHxvW.H4iFXdLGaOGRrEA27b7EgNtrww-1702250329529-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339358e6b3f3021-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:49,539 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:18:49,540 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:49,541 httpcore.http11 DEBUG receive_response_body.complete
18:18:49,541 httpcore.http11 DEBUG response_closed.started
18:18:49,541 httpcore.http11 DEBUG response_closed.complete
18:18:49,542 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:22:26,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only. Answer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:22:26,709 httpcore.connection DEBUG close.started
18:22:26,709 httpcore.connection DEBUG close.complete
18:22:26,709 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:22:26,740 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c731290>
18:22:26,740 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7e4c935f40> server_hostname='api.openai.com' timeout=None
18:22:26,750 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c708210>
18:22:26,750 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:22:26,751 httpcore.http11 DEBUG send_request_headers.complete
18:22:26,751 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:22:26,751 httpcore.http11 DEBUG send_request_body.complete
18:22:26,751 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:22:26,960 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:22:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6651a5ed6ae79e2ee95ad8b51a14182c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393add3a4e4cde-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:22:26,961 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:22:26,961 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:22:26,962 httpcore.http11 DEBUG receive_response_body.complete
18:22:26,962 httpcore.http11 DEBUG response_closed.started
18:22:26,962 httpcore.http11 DEBUG response_closed.complete
18:22:26,962 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:22:48,66 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:48,72 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:48,874 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:48,875 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:48,918 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:48,919 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:48,962 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:48,963 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,10 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,11 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,51 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,52 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,90 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,91 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,132 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,133 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,170 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,171 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,211 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:22:49,224 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:22:49,228 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f300298bb10>
18:22:49,228 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3002799d90> server_hostname='api.openai.com' timeout=5.0
18:22:49,233 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002712850>
18:22:49,234 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:22:49,235 httpcore.http11 DEBUG send_request_headers.complete
18:22:49,235 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:22:49,235 httpcore.http11 DEBUG send_request_body.complete
18:22:49,235 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:22:49,702 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:22:49 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'74142f0d6133fa67396a2275f7195861'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=foAHfeqvSILOUn9T8RaGhaj.CeAJ7FXQavJgiilhIPI-1702250569-1-AS3VmZohHmV1SAsPSsp4UyAaDx1tHc4r11AEidMNMkGxWsNzXJGKWuZr8znEXalLlNnU5YMwtZprU9seOV+NcC8=; path=/; expires=Sun, 10-Dec-23 23:52:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RwfpaTuRDC48FS8lKd9MU5W85MPUlD2lRmuyxVETbAI-1702250569697-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393b69bd244cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:22:49,709 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:22:49,710 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:22:50,370 httpcore.http11 DEBUG receive_response_body.complete
18:22:50,371 httpcore.http11 DEBUG response_closed.started
18:22:50,371 httpcore.http11 DEBUG response_closed.complete
18:22:50,372 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:22:50,447 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:23:03,764 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:23:03,770 httpcore.connection DEBUG close.started
18:23:03,771 httpcore.connection DEBUG close.complete
18:23:03,771 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:03,773 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002712750>
18:23:03,773 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3002799d90> server_hostname='api.openai.com' timeout=5.0
18:23:03,780 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002712850>
18:23:03,780 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:03,781 httpcore.http11 DEBUG send_request_headers.complete
18:23:03,781 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:03,804 httpcore.http11 DEBUG send_request_body.complete
18:23:03,804 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:05,429 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:23:05 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'891'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'90dcd84cfb3dc9347e42a5d045893c73'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393bc4aa293b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:05,432 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:23:05,432 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:05,433 httpcore.http11 DEBUG receive_response_body.complete
18:23:05,434 httpcore.http11 DEBUG response_closed.started
18:23:05,434 httpcore.http11 DEBUG response_closed.complete
18:23:05,435 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:23:05,436 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:23:28,950 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only. Answer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:28,959 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:28,989 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002565350>
18:23:28,990 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3002799f40> server_hostname='api.openai.com' timeout=None
18:23:28,997 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002564c10>
18:23:28,998 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:29,0 httpcore.http11 DEBUG send_request_headers.complete
18:23:29,0 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:29,1 httpcore.http11 DEBUG send_request_body.complete
18:23:29,2 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:29,483 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:23:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'229'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6715f73abab7283a7325ff5dfb385b43'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ci_cwy00BM.tVJBS2Fdpy8ON4nc2YKD8u1WO7oSr2UU-1702250609-1-ATdo0z4XJOuFd2KOUjhQMOzrCoAj4UPajT50RNhSZYAKdRN/kQedam4TZbSGxQPmBfMqguuVDjCO2Gv4CPFZqQg=; path=/; expires=Sun, 10-Dec-23 23:53:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=eWjqMZzg0pDNoajjAqVtiCyyS1tW1FCzN62g8EO7.so-1702250609478-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393c624ed64cfe-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:29,491 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:29,492 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:29,494 httpcore.http11 DEBUG receive_response_body.complete
18:23:29,494 httpcore.http11 DEBUG response_closed.started
18:23:29,495 httpcore.http11 DEBUG response_closed.complete
18:23:29,495 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:27:13,35 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:13,39 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:13,876 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:13,877 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:13,918 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:13,919 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:13,966 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:13,967 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,7 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,8 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,58 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,59 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,101 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,102 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,150 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,151 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,191 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,192 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:15,96 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:27:15,116 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:27:15,144 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85e55950>
18:27:15,145 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:27:15,151 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bcff50>
18:27:15,152 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:27:15,155 httpcore.http11 DEBUG send_request_headers.complete
18:27:15,156 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:27:15,157 httpcore.http11 DEBUG send_request_body.complete
18:27:15,157 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:27:15,795 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:27:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'519'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4b3983cbd1cb6cc7346266abac83a15f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dMmOZQ0JULMIc0r.1EjhvN4L8lbeOn33sCS.70eux3s-1702250835-1-Ae39Zt1NCEDhUyXpnW7Q57ru9D6d6G++DhH3xOjXIH9gdjf8/H55q7x2Qq0nblE9hguq2Z7i2ahRaJi8P8ul6f0=; path=/; expires=Sun, 10-Dec-23 23:57:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=n6IWS65iUi5bQOAbypttO1OWjjFL8iaX2ZpewILkmh0-1702250835788-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833941e7bade4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:27:15,804 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:27:15,804 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:27:16,447 httpcore.http11 DEBUG receive_response_body.complete
18:27:16,448 httpcore.http11 DEBUG response_closed.started
18:27:16,449 httpcore.http11 DEBUG response_closed.complete
18:27:16,450 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:27:16,530 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:27:30,108 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:27:30,117 httpcore.connection DEBUG close.started
18:27:30,117 httpcore.connection DEBUG close.complete
18:27:30,118 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:27:30,136 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bcf9d0>
18:27:30,136 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:27:30,141 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bcf490>
18:27:30,142 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:27:30,144 httpcore.http11 DEBUG send_request_headers.complete
18:27:30,144 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:27:30,178 httpcore.http11 DEBUG send_request_body.complete
18:27:30,179 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:27:31,306 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:27:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'356'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2722a3d74e5a07691c96f15c90e420ee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833942456cc94d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:27:31,311 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:27:31,312 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:27:31,314 httpcore.http11 DEBUG receive_response_body.complete
18:27:31,314 httpcore.http11 DEBUG response_closed.started
18:27:31,314 httpcore.http11 DEBUG response_closed.complete
18:27:31,315 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:27:31,315 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:27:33,16 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nit in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:27:33,26 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:27:33,28 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c2d290>
18:27:33,29 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5df40> server_hostname='api.openai.com' timeout=None
18:27:33,36 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c2c490>
18:27:33,36 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:27:33,38 httpcore.http11 DEBUG send_request_headers.complete
18:27:33,38 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:27:33,39 httpcore.http11 DEBUG send_request_body.complete
18:27:33,39 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:27:33,422 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:27:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'262'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'08187b12569367f7a7977b49a5638613'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RnmsGl7ybGF3j2havTSPbvneG9XfHe7Km00NR8BfLYA-1702250853-1-Ador60hahNlEC0UYPEUZ+oomrsVloKDjmldAbDYf1EQ9SQIAR1D/TSwaQJyH1lBSMJCZ2C18RDfz+obJ6vx59VI=; path=/; expires=Sun, 10-Dec-23 23:57:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3j63d.VkYK2F8TkzRE42hoV85qzD7wDQ1hbPzgj4IH8-1702250853417-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833942577cd33bac-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:27:33,429 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:27:33,429 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:27:33,430 httpcore.http11 DEBUG receive_response_body.complete
18:27:33,431 httpcore.http11 DEBUG response_closed.started
18:27:33,431 httpcore.http11 DEBUG response_closed.complete
18:27:33,431 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:27:43,155 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nit in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:27:43,170 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:27:43,173 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85e6d510>
18:27:43,174 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5e720> server_hostname='api.openai.com' timeout=None
18:27:43,182 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c383d0>
18:27:43,182 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:27:43,183 httpcore.http11 DEBUG send_request_headers.complete
18:27:43,183 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:27:43,184 httpcore.http11 DEBUG send_request_body.complete
18:27:43,184 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:27:43,845 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:27:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'565'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'51710cf6d814b7221366eec87e141aee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ScxEsQMcvsqj0LNxUP4.C8aeibCItNs3eR6wMK22opE-1702250863-1-AT+MFhWg+LN8BXCOjZvXqJjXIS9Tau/QiONzWcH8K5yxcUwO2vaoqDBXGRPX2zfa1XNO9AnalXO7eOySp6FamYs=; path=/; expires=Sun, 10-Dec-23 23:57:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zUFYOLtu3eO.v9UJpAWt1OAa1X5x.9ACeBTAyxk4RiM-1702250863841-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83394296eec84d01-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:27:43,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:27:43,851 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:27:43,852 httpcore.http11 DEBUG receive_response_body.complete
18:27:43,852 httpcore.http11 DEBUG response_closed.started
18:27:43,853 httpcore.http11 DEBUG response_closed.complete
18:27:43,853 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:27:53,411 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:27:53,418 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:27:59,130 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:27:59,143 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:27:59,147 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:03,149 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:03,166 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:03,172 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:05,175 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:05,192 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:05,196 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:08,599 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:08,610 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:08,614 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:14,316 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:14,339 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:14,343 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:18,545 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:18,561 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:18,565 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:22,767 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:22,775 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:28:22,782 httpcore.connection DEBUG close.started
18:28:22,782 httpcore.connection DEBUG close.complete
18:28:22,783 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:28:22,812 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bc5a50>
18:28:22,812 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:28:22,818 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c00550>
18:28:22,819 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:22,820 httpcore.http11 DEBUG send_request_headers.complete
18:28:22,821 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:22,821 httpcore.http11 DEBUG send_request_body.complete
18:28:22,822 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:23,333 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'37a0066913245bad713cdb10900f081a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339438eaa6f4cd5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:23,338 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:28:23,338 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:24,320 httpcore.http11 DEBUG receive_response_body.complete
18:28:24,321 httpcore.http11 DEBUG response_closed.started
18:28:24,322 httpcore.http11 DEBUG response_closed.complete
18:28:24,323 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:28:24,390 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:28:37,52 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:28:37,57 httpcore.connection DEBUG close.started
18:28:37,57 httpcore.connection DEBUG close.complete
18:28:37,58 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:28:37,60 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63e50>
18:28:37,61 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:28:37,66 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63dd0>
18:28:37,66 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:37,67 httpcore.http11 DEBUG send_request_headers.complete
18:28:37,68 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:37,95 httpcore.http11 DEBUG send_request_body.complete
18:28:37,96 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:37,864 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4ff6840067741eb489715e0100963f08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833943e7ae524ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:37,867 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:28:37,868 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:37,868 httpcore.http11 DEBUG receive_response_body.complete
18:28:37,869 httpcore.http11 DEBUG response_closed.started
18:28:37,869 httpcore.http11 DEBUG response_closed.complete
18:28:37,870 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:28:37,870 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:28:37,911 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:28:37,918 httpcore.connection DEBUG close.started
18:28:37,919 httpcore.connection DEBUG close.complete
18:28:37,919 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:28:37,922 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bc56d0>
18:28:37,922 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5df40> server_hostname='api.openai.com' timeout=None
18:28:37,929 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bc4c90>
18:28:37,929 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:37,930 httpcore.http11 DEBUG send_request_headers.complete
18:28:37,931 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:37,931 httpcore.http11 DEBUG send_request_body.complete
18:28:37,931 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:38,116 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3bd0b35cfeb73be88bafb2a5de920d25'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833943ed18544d10-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:38,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:28:38,124 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:38,125 httpcore.http11 DEBUG receive_response_body.complete
18:28:38,126 httpcore.http11 DEBUG response_closed.started
18:28:38,126 httpcore.http11 DEBUG response_closed.complete
18:28:38,127 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:28:38,135 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:28:38,139 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:38,140 httpcore.http11 DEBUG send_request_headers.complete
18:28:38,140 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:38,141 httpcore.http11 DEBUG send_request_body.complete
18:28:38,141 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:38,746 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3125c5142be4667e95e93bc968df00a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833943ee6cf14ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:38,749 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:28:38,750 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:39,796 httpcore.http11 DEBUG receive_response_body.complete
18:28:39,797 httpcore.http11 DEBUG response_closed.started
18:28:39,797 httpcore.http11 DEBUG response_closed.complete
18:28:39,798 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:28:39,869 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:28:52,597 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:28:52,605 httpcore.connection DEBUG close.started
18:28:52,606 httpcore.connection DEBUG close.complete
18:28:52,607 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:28:52,609 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6eb10>
18:28:52,610 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:28:52,617 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6eb90>
18:28:52,618 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:52,619 httpcore.http11 DEBUG send_request_headers.complete
18:28:52,619 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:52,641 httpcore.http11 DEBUG send_request_body.complete
18:28:52,642 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:53,514 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:53 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'405'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e39107a0817e2e283f2c707988603ffc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83394448dad23049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:53,519 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:28:53,520 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:53,521 httpcore.http11 DEBUG receive_response_body.complete
18:28:53,522 httpcore.http11 DEBUG response_closed.started
18:28:53,523 httpcore.http11 DEBUG response_closed.complete
18:28:53,524 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:28:53,525 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:28:53,553 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:28:53,564 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:28:53,567 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a72010>
18:28:53,567 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:28:53,574 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a70a90>
18:28:53,575 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:53,576 httpcore.http11 DEBUG send_request_headers.complete
18:28:53,576 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:53,577 httpcore.http11 DEBUG send_request_body.complete
18:28:53,577 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:53,783 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f857ad7a9b8739c27172ba93662e40f0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EA96UyBcDvl4ueK.X2C0F_tLjgOh8awfDZNul6_d2KI-1702250933-1-AQAOkQfpWFEGEeiE9DjndQxf+4V14lImFKKGFgoOvTYOAf5CA9OjFGwRqqDO1O+ipFFalqqILG4IQvGgF4Tk8p4=; path=/; expires=Sun, 10-Dec-23 23:58:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=iMoN4lCOMzoZEriww95DbHlmbyvai8qe8t0OOOXTq1Q-1702250933778-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339444edad04cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:53,788 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:28:53,789 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:53,790 httpcore.http11 DEBUG receive_response_body.complete
18:28:53,790 httpcore.http11 DEBUG response_closed.started
18:28:53,790 httpcore.http11 DEBUG response_closed.complete
18:28:53,791 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:28:53,823 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:28:53,826 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:53,827 httpcore.http11 DEBUG send_request_headers.complete
18:28:53,827 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:53,828 httpcore.http11 DEBUG send_request_body.complete
18:28:53,828 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:54,35 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'102'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'211081085895da6e811f2c90399c7f6f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833944506efd4cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:54,40 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:28:54,41 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:54,42 httpcore.http11 DEBUG receive_response_body.complete
18:28:54,42 httpcore.http11 DEBUG response_closed.started
18:28:54,43 httpcore.http11 DEBUG response_closed.complete
18:28:54,43 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:29:13,947 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:29:13,951 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:29:17,354 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:29:21,931 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:29:21,942 httpcore.connection DEBUG close.started
18:29:21,943 httpcore.connection DEBUG close.complete
18:29:21,943 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:21,946 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6ea50>
18:29:21,946 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:29:21,953 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6ec90>
18:29:21,954 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:21,956 httpcore.http11 DEBUG send_request_headers.complete
18:29:21,956 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:21,957 httpcore.http11 DEBUG send_request_body.complete
18:29:21,958 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:22,389 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:22 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'367'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'979a81f5258f49b4bbbbb4256451c03e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83394500397f3045-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:22,392 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:29:22,392 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:22,903 httpcore.http11 DEBUG receive_response_body.complete
18:29:22,904 httpcore.http11 DEBUG response_closed.started
18:29:22,904 httpcore.http11 DEBUG response_closed.complete
18:29:22,905 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:29:22,970 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:29:32,110 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:29:32,115 httpcore.connection DEBUG close.started
18:29:32,116 httpcore.connection DEBUG close.complete
18:29:32,116 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:32,147 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6f850>
18:29:32,148 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:29:32,155 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6da10>
18:29:32,156 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:32,158 httpcore.http11 DEBUG send_request_headers.complete
18:29:32,158 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:32,182 httpcore.http11 DEBUG send_request_body.complete
18:29:32,182 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:32,975 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:32 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'377'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'08c73bcfc63f87d5da80c04a71fc337f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339453ff91b4cc9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:32,980 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:29:32,982 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:32,982 httpcore.http11 DEBUG receive_response_body.complete
18:29:32,983 httpcore.http11 DEBUG response_closed.started
18:29:32,983 httpcore.http11 DEBUG response_closed.complete
18:29:32,983 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:29:32,984 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:29:34,444 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:29:34,448 httpcore.connection DEBUG close.started
18:29:34,448 httpcore.connection DEBUG close.complete
18:29:34,449 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:29:34,452 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63a90>
18:29:34,452 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:29:34,460 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63250>
18:29:34,461 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:34,462 httpcore.http11 DEBUG send_request_headers.complete
18:29:34,462 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:34,463 httpcore.http11 DEBUG send_request_body.complete
18:29:34,463 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:34,698 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e503836278193ce47638ceda9684a09d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339454e6e4a4d0e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:34,702 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:29:34,703 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:34,704 httpcore.http11 DEBUG receive_response_body.complete
18:29:34,705 httpcore.http11 DEBUG response_closed.started
18:29:34,706 httpcore.http11 DEBUG response_closed.complete
18:29:34,706 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:29:43,979 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:29:43,984 httpcore.connection DEBUG close.started
18:29:43,985 httpcore.connection DEBUG close.complete
18:29:43,986 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:43,989 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c2fe50>
18:29:43,990 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:29:43,997 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c2d510>
18:29:43,998 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:44,1 httpcore.http11 DEBUG send_request_headers.complete
18:29:44,1 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:44,2 httpcore.http11 DEBUG send_request_body.complete
18:29:44,2 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:44,460 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:44 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'383'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb18ba3b82e16f029a1763a5852a3f7c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339458a0f6a4ce4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:44,465 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:29:44,466 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:45,472 httpcore.http11 DEBUG receive_response_body.complete
18:29:45,473 httpcore.http11 DEBUG response_closed.started
18:29:45,474 httpcore.http11 DEBUG response_closed.complete
18:29:45,476 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:29:45,539 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:29:57,247 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:29:57,251 httpcore.connection DEBUG close.started
18:29:57,251 httpcore.connection DEBUG close.complete
18:29:57,252 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:57,254 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62090>
18:29:57,254 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:29:57,260 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63d10>
18:29:57,260 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:57,262 httpcore.http11 DEBUG send_request_headers.complete
18:29:57,262 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:57,286 httpcore.http11 DEBUG send_request_body.complete
18:29:57,287 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:58,91 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:58 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'32'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'387'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ba415ca9df9257d4b996207952ca4a72'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833945dce8a14ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:58,96 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:29:58,97 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:58,98 httpcore.http11 DEBUG receive_response_body.complete
18:29:58,98 httpcore.http11 DEBUG response_closed.started
18:29:58,99 httpcore.http11 DEBUG response_closed.complete
18:29:58,99 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:29:58,100 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:30:02,259 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhich way should I move? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nThank you so much for watching!\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:02,262 httpcore.connection DEBUG close.started
18:30:02,263 httpcore.connection DEBUG close.complete
18:30:02,263 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:02,266 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62510>
18:30:02,266 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:30:02,273 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63490>
18:30:02,274 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:02,275 httpcore.http11 DEBUG send_request_headers.complete
18:30:02,275 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:02,276 httpcore.http11 DEBUG send_request_body.complete
18:30:02,276 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:02,531 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:30:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'158'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1aab0328b03570f532ab88d67a7aba57'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833945fc3b984cf9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:02,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:02,538 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:02,540 httpcore.http11 DEBUG receive_response_body.complete
18:30:02,541 httpcore.http11 DEBUG response_closed.started
18:30:02,542 httpcore.http11 DEBUG response_closed.complete
18:30:02,542 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:22,800 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:30:22,807 httpcore.connection DEBUG close.started
18:30:22,808 httpcore.connection DEBUG close.complete
18:30:22,809 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:30:22,812 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62350>
18:30:22,813 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:30:22,820 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62f10>
18:30:22,821 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:22,823 httpcore.http11 DEBUG send_request_headers.complete
18:30:22,824 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:22,825 httpcore.http11 DEBUG send_request_body.complete
18:30:22,826 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:23,446 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:30:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'506'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'268c2f33158358a5d5fdbdb21cfb3759'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339467caee14cf2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:23,450 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:30:23,450 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:24,367 httpcore.http11 DEBUG receive_response_body.complete
18:30:24,368 httpcore.http11 DEBUG response_closed.started
18:30:24,369 httpcore.http11 DEBUG response_closed.complete
18:30:24,370 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:30:24,440 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:30:36,327 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:30:36,334 httpcore.connection DEBUG close.started
18:30:36,334 httpcore.connection DEBUG close.complete
18:30:36,335 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:30:36,364 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6c510>
18:30:36,365 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:30:36,371 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6e410>
18:30:36,372 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:36,374 httpcore.http11 DEBUG send_request_headers.complete
18:30:36,374 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:36,388 httpcore.http11 DEBUG send_request_body.complete
18:30:36,388 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:37,217 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:30:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'385'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1fb7f8c695df8055b51e8638cb6d8316'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833946d15d903bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:37,221 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:30:37,222 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:37,223 httpcore.http11 DEBUG receive_response_body.complete
18:30:37,224 httpcore.http11 DEBUG response_closed.started
18:30:37,225 httpcore.http11 DEBUG response_closed.complete
18:30:37,225 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:30:37,226 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:30:39,616 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhich way should I move? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:39,620 httpcore.connection DEBUG close.started
18:30:39,621 httpcore.connection DEBUG close.complete
18:30:39,621 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:39,624 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62310>
18:30:39,624 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:30:39,628 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62510>
18:30:39,629 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:39,630 httpcore.http11 DEBUG send_request_headers.complete
18:30:39,630 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:39,630 httpcore.http11 DEBUG send_request_body.complete
18:30:39,631 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:39,829 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:30:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'97'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'85c67e224e63e42a38f7b53fac8321ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833946e5baba3ba6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:39,833 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:39,834 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:39,836 httpcore.http11 DEBUG receive_response_body.complete
18:30:39,836 httpcore.http11 DEBUG response_closed.started
18:30:39,837 httpcore.http11 DEBUG response_closed.complete
18:30:39,837 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:49,26 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:49,29 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:30:52,431 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:31:00,38 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:31:00,42 httpcore.connection DEBUG close.started
18:31:00,43 httpcore.connection DEBUG close.complete
18:31:00,43 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:31:00,46 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6e410>
18:31:00,47 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:31:00,57 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6d090>
18:31:00,58 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:31:00,60 httpcore.http11 DEBUG send_request_headers.complete
18:31:00,60 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:31:00,61 httpcore.http11 DEBUG send_request_body.complete
18:31:00,62 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:31:00,848 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:31:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'495'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c7f9b9e2ff7babd0701c1a033c557ab6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833947656e2b4d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:31:00,852 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:31:00,853 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:31:01,256 httpcore.http11 DEBUG receive_response_body.complete
18:31:01,256 httpcore.http11 DEBUG response_closed.started
18:31:01,257 httpcore.http11 DEBUG response_closed.complete
18:31:01,258 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:31:01,327 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:31:10,539 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:31:10,543 httpcore.connection DEBUG close.started
18:31:10,544 httpcore.connection DEBUG close.complete
18:31:10,544 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:31:10,547 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a5c910>
18:31:10,547 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:31:10,554 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a711d0>
18:31:10,554 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:31:10,556 httpcore.http11 DEBUG send_request_headers.complete
18:31:10,557 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:31:10,576 httpcore.http11 DEBUG send_request_body.complete
18:31:10,576 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:31:11,437 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:31:11 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'385'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'08738ebfc30d414b0fc6e47c54167d0f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833947a6fb224d10-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:31:11,443 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:31:11,443 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:31:11,444 httpcore.http11 DEBUG receive_response_body.complete
18:31:11,444 httpcore.http11 DEBUG response_closed.started
18:31:11,444 httpcore.http11 DEBUG response_closed.complete
18:31:11,445 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:31:11,445 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:31:13,806 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:31:13,810 httpcore.connection DEBUG close.started
18:31:13,810 httpcore.connection DEBUG close.complete
18:31:13,811 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:31:13,814 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c03150>
18:31:13,814 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:31:13,823 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a70c90>
18:31:13,824 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:31:13,827 httpcore.http11 DEBUG send_request_headers.complete
18:31:13,827 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:31:13,828 httpcore.http11 DEBUG send_request_body.complete
18:31:13,829 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:31:14,30 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:31:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'badad1bfb12f53b9bede997031f21874'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833947bb693a4d13-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:31:14,33 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:31:14,33 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:31:14,34 httpcore.http11 DEBUG receive_response_body.complete
18:31:14,35 httpcore.http11 DEBUG response_closed.started
18:31:14,35 httpcore.http11 DEBUG response_closed.complete
18:31:14,35 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:32:30,882 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:32:30,888 httpcore.connection DEBUG close.started
18:32:30,888 httpcore.connection DEBUG close.complete
18:32:30,889 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:30,918 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bcc2d0>
18:32:30,919 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:32:30,926 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85e575d0>
18:32:30,927 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:30,929 httpcore.http11 DEBUG send_request_headers.complete
18:32:30,929 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:30,930 httpcore.http11 DEBUG send_request_body.complete
18:32:30,930 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:31,582 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:32:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'528'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'77982bf970461d93a697beabc1ab6d38'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339499d4f4b4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:31,589 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:32:31,589 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:32,516 httpcore.http11 DEBUG receive_response_body.complete
18:32:32,516 httpcore.http11 DEBUG response_closed.started
18:32:32,517 httpcore.http11 DEBUG response_closed.complete
18:32:32,517 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:32:32,587 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:32:44,463 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:32:44,470 httpcore.connection DEBUG close.started
18:32:44,471 httpcore.connection DEBUG close.complete
18:32:44,471 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:44,474 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a5c2d0>
18:32:44,474 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:32:44,480 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62050>
18:32:44,481 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:44,482 httpcore.http11 DEBUG send_request_headers.complete
18:32:44,482 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:44,503 httpcore.http11 DEBUG send_request_body.complete
18:32:44,503 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:45,414 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:32:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'382'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4aed386639c7dd435f5ed1b59c2957df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833949f20b5c3010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:45,417 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:32:45,417 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:45,418 httpcore.http11 DEBUG receive_response_body.complete
18:32:45,419 httpcore.http11 DEBUG response_closed.started
18:32:45,419 httpcore.http11 DEBUG response_closed.complete
18:32:45,420 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:32:45,420 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:37:21,618 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:21,622 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,443 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,444 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,482 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,483 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,523 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,524 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,561 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,562 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,603 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,604 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,642 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,643 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,684 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,684 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,722 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,723 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,763 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:37:22,779 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:22,825 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd45f19d0>
18:37:22,826 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:37:22,833 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd452ead0>
18:37:22,834 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:22,835 httpcore.http11 DEBUG send_request_headers.complete
18:37:22,836 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:22,837 httpcore.http11 DEBUG send_request_body.complete
18:37:22,837 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:23,328 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:37:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9fe82e4978f9b0b2b13dac0d61489afb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SrbmLKj5imP1MptlGe5uA5D.hauXlYRW0mYTBl2LBc0-1702251443-1-AaBD3iBrs5q2ArjjgcK1kmmFoQu2zyVWF5CARUTYob7fnA2/FJwg3f8OM6g061HJjhpdYZheFBla7ERjR629KAs=; path=/; expires=Mon, 11-Dec-23 00:07:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=03cG33Du84xOSHL4bSkG5DpSIFHk74PY1ObBmFYVo.U-1702251443323-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833950bdbca94cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:23,333 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:37:23,333 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:23,972 httpcore.http11 DEBUG receive_response_body.complete
18:37:23,973 httpcore.http11 DEBUG response_closed.started
18:37:23,973 httpcore.http11 DEBUG response_closed.complete
18:37:23,974 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:37:24,43 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:37:37,674 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:37:37,681 httpcore.connection DEBUG close.started
18:37:37,682 httpcore.connection DEBUG close.complete
18:37:37,682 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:37,709 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd452ead0>
18:37:37,710 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:37:37,718 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd452ef10>
18:37:37,718 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:37,719 httpcore.http11 DEBUG send_request_headers.complete
18:37:37,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:37,756 httpcore.http11 DEBUG send_request_body.complete
18:37:37,756 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:38,701 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:37:38 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'38f86c4e1b61d05e7998d93ba8677971'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339511aca314cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:38,703 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:37:38,704 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:38,704 httpcore.http11 DEBUG receive_response_body.complete
18:37:38,705 httpcore.http11 DEBUG response_closed.started
18:37:38,705 httpcore.http11 DEBUG response_closed.complete
18:37:38,705 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:37:38,706 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:37:43,673 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:43,685 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:43,688 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4594490>
18:37:43,688 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9f40> server_hostname='api.openai.com' timeout=None
18:37:43,693 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4594450>
18:37:43,694 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:43,695 httpcore.http11 DEBUG send_request_headers.complete
18:37:43,696 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:43,696 httpcore.http11 DEBUG send_request_body.complete
18:37:43,696 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:43,896 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:37:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'98'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1f605846dc7667288f8e849043ff8e99'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5t4.EtCQQYyl4G23CIMifpZlwcITeXRBMlGPwF1n2_o-1702251463-1-AaSkn+O2wUS/cmpsIT295i4aU0My4PKpi0b0oItP7xOSGYPbVCd16cDNdKpPdQDTkeXBKFckUM5XbRHA7oC5Yj4=; path=/; expires=Mon, 11-Dec-23 00:07:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qj183FqzZXWx5dajsA4Trxv7AzUs43SFtUPstZizlHQ-1702251463891-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833951401cfa4d1e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:43,904 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:43,905 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:43,908 httpcore.http11 DEBUG receive_response_body.complete
18:37:43,909 httpcore.http11 DEBUG response_closed.started
18:37:43,909 httpcore.http11 DEBUG response_closed.complete
18:37:43,910 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:45,894 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:45,905 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:45,907 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43a62d0>
18:37:45,907 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45ba720> server_hostname='api.openai.com' timeout=None
18:37:45,913 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43add50>
18:37:45,913 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:45,914 httpcore.http11 DEBUG send_request_headers.complete
18:37:45,914 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:45,914 httpcore.http11 DEBUG send_request_body.complete
18:37:45,914 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:46,710 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:37:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'682'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7020e0386b6828014c96e980496d863d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4AQufKSLvwrIWQwFMjC8IBq_6Y6o0ifPDvK07fxhQdU-1702251466-1-AfhipoLqTEj09xVIYrTKLr3ZwSPOS9pMxkrczDHabNkiV0cPBQJ14J30u80Jq6svn6cxksU/GfBkmaOqFSuGSdk=; path=/; expires=Mon, 11-Dec-23 00:07:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kyAjse6lqUxb46quKzJzkMkdIoqju_rtmUiEICmwOqc-1702251466706-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339514dfda84cc3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:46,713 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:46,714 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:46,714 httpcore.http11 DEBUG receive_response_body.complete
18:37:46,714 httpcore.http11 DEBUG response_closed.started
18:37:46,715 httpcore.http11 DEBUG response_closed.complete
18:37:46,715 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:46,729 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:37:46,732 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:37:52,436 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:37:52,444 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:37:52,447 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:37:56,448 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:37:56,460 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:37:56,463 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:37:58,464 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:37:58,476 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:37:58,479 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:38:01,880 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:38:01,894 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:38:01,897 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:38:07,598 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:38:07,613 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:38:07,616 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:38:11,817 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:38:11,828 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:38:11,832 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:38:16,33 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:38:16,38 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:38:16,43 httpcore.connection DEBUG close.started
18:38:16,43 httpcore.connection DEBUG close.complete
18:38:16,44 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:38:16,46 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd47af0d0>
18:38:16,47 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:38:16,53 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd456f8d0>
18:38:16,53 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:16,54 httpcore.http11 DEBUG send_request_headers.complete
18:38:16,54 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:16,54 httpcore.http11 DEBUG send_request_body.complete
18:38:16,54 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:16,563 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'53064eb61f53afbc0fea5ca429dd07b2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339520a59c53b8d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:16,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:38:16,564 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:17,754 httpcore.http11 DEBUG receive_response_body.complete
18:38:17,754 httpcore.http11 DEBUG response_closed.started
18:38:17,755 httpcore.http11 DEBUG response_closed.complete
18:38:17,755 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:38:17,820 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:38:30,130 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:38:30,135 httpcore.connection DEBUG close.started
18:38:30,135 httpcore.connection DEBUG close.complete
18:38:30,135 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:38:30,150 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43c7590>
18:38:30,150 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:38:30,157 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43c7610>
18:38:30,158 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:30,159 httpcore.http11 DEBUG send_request_headers.complete
18:38:30,159 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:30,182 httpcore.http11 DEBUG send_request_body.complete
18:38:30,182 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:31,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8c425d4ed0b052769f6983fb8ab536c3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952627cfe4cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:31,26 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:38:31,26 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:31,27 httpcore.http11 DEBUG receive_response_body.complete
18:38:31,28 httpcore.http11 DEBUG response_closed.started
18:38:31,28 httpcore.http11 DEBUG response_closed.complete
18:38:31,29 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:38:31,29 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:38:31,42 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:38:31,45 httpcore.connection DEBUG close.started
18:38:31,45 httpcore.connection DEBUG close.complete
18:38:31,46 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:38:31,48 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be7d0>
18:38:31,48 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9f40> server_hostname='api.openai.com' timeout=None
18:38:31,52 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be8d0>
18:38:31,52 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:31,53 httpcore.http11 DEBUG send_request_headers.complete
18:38:31,53 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:31,53 httpcore.http11 DEBUG send_request_body.complete
18:38:31,53 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:31,278 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fbf795989fc47e1389ed699459e96085'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952681ef03b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:31,280 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:38:31,280 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:31,281 httpcore.http11 DEBUG receive_response_body.complete
18:38:31,281 httpcore.http11 DEBUG response_closed.started
18:38:31,281 httpcore.http11 DEBUG response_closed.complete
18:38:31,281 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:38:31,286 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:38:31,288 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:31,288 httpcore.http11 DEBUG send_request_headers.complete
18:38:31,288 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:31,289 httpcore.http11 DEBUG send_request_body.complete
18:38:31,289 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:31,804 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'423'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f0e2bc274abe56f0fd9f1adb2fc8ccc6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952698ae94cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:31,807 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:38:31,807 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:32,884 httpcore.http11 DEBUG receive_response_body.complete
18:38:32,884 httpcore.http11 DEBUG response_closed.started
18:38:32,885 httpcore.http11 DEBUG response_closed.complete
18:38:32,885 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:38:32,952 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:38:45,486 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:38:45,491 httpcore.connection DEBUG close.started
18:38:45,491 httpcore.connection DEBUG close.complete
18:38:45,491 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:38:45,494 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be1d0>
18:38:45,494 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:38:45,500 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d1c90>
18:38:45,500 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:45,501 httpcore.http11 DEBUG send_request_headers.complete
18:38:45,501 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:45,517 httpcore.http11 DEBUG send_request_body.complete
18:38:45,517 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:46,267 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'dd0afa963d3a4bcc2f3c703af7243e4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952c26f7f3051-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:46,269 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:38:46,270 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:46,271 httpcore.http11 DEBUG receive_response_body.complete
18:38:46,271 httpcore.http11 DEBUG response_closed.started
18:38:46,272 httpcore.http11 DEBUG response_closed.complete
18:38:46,272 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:38:46,273 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:38:46,288 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:38:46,297 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:38:46,299 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bebd0>
18:38:46,299 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:38:46,305 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bf8d0>
18:38:46,305 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:46,306 httpcore.http11 DEBUG send_request_headers.complete
18:38:46,306 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:46,306 httpcore.http11 DEBUG send_request_body.complete
18:38:46,307 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:46,533 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'124'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fb8abba098f686406fba78cff3432ada'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cmmCM_Zo0jVTVtBhkZ_O.VJ37_WIWr6Ho2R5g_JKNKk-1702251526-1-AT3GVX8XfIXYofnQ0FBC+T82uG3pm7JehLtD6DZ2iyc6aYo4tRMiqjhTUm1iUU4XrkeNt+VtSFXFyssd8eXe1iw=; path=/; expires=Mon, 11-Dec-23 00:08:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=hay7yOGDOuAGJjB8aAG2L0epW6Hf8rsiQ6Xv5x6QRus-1702251526530-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952c76c4a2ffc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:46,536 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:38:46,537 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:46,538 httpcore.http11 DEBUG receive_response_body.complete
18:38:46,538 httpcore.http11 DEBUG response_closed.started
18:38:46,539 httpcore.http11 DEBUG response_closed.complete
18:38:46,539 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:39:10,6 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:39:10,10 httpcore.connection DEBUG close.started
18:39:10,11 httpcore.connection DEBUG close.complete
18:39:10,11 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:39:10,13 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d0650>
18:39:10,14 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:39:10,19 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d0f10>
18:39:10,20 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:39:10,22 httpcore.http11 DEBUG send_request_headers.complete
18:39:10,23 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:39:10,24 httpcore.http11 DEBUG send_request_body.complete
18:39:10,24 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:39:10,234 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:39:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'77'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c97d025a7965aa52830a1f71577ecf94'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339535baf8c3b94-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:39:10,241 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:39:10,241 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:39:10,242 httpcore.http11 DEBUG receive_response_body.complete
18:39:10,243 httpcore.http11 DEBUG response_closed.started
18:39:10,243 httpcore.http11 DEBUG response_closed.complete
18:39:10,244 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:39:35,925 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:39:35,930 httpcore.connection DEBUG close.started
18:39:35,931 httpcore.connection DEBUG close.complete
18:39:35,931 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:39:35,962 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43a6ed0>
18:39:35,962 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:39:35,969 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d1c90>
18:39:35,969 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:39:35,970 httpcore.http11 DEBUG send_request_headers.complete
18:39:35,971 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:39:35,971 httpcore.http11 DEBUG send_request_body.complete
18:39:35,971 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:39:36,611 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:39:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3687e1aa2846e253200659e3477bba60'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833953fddbd74ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:39:36,613 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:39:36,614 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:39:37,516 httpcore.http11 DEBUG receive_response_body.complete
18:39:37,516 httpcore.http11 DEBUG response_closed.started
18:39:37,516 httpcore.http11 DEBUG response_closed.complete
18:39:37,516 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:39:37,588 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:39:50,219 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:39:50,222 httpcore.connection DEBUG close.started
18:39:50,222 httpcore.connection DEBUG close.complete
18:39:50,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:39:50,225 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43dc510>
18:39:50,225 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:39:50,230 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43ddfd0>
18:39:50,230 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:39:50,231 httpcore.http11 DEBUG send_request_headers.complete
18:39:50,231 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:39:50,247 httpcore.http11 DEBUG send_request_body.complete
18:39:50,247 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:39:51,41 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:39:51 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e5cdbcb70fcd86e06383d02f403b3828'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83395456fc653071-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:39:51,43 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:39:51,44 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:39:51,45 httpcore.http11 DEBUG receive_response_body.complete
18:39:51,45 httpcore.http11 DEBUG response_closed.started
18:39:51,45 httpcore.http11 DEBUG response_closed.complete
18:39:51,46 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:39:51,47 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:39:51,64 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove down.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:39:51,66 httpcore.connection DEBUG close.started
18:39:51,66 httpcore.connection DEBUG close.complete
18:39:51,66 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:39:51,69 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43c7850>
18:39:51,69 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:39:51,75 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43c6790>
18:39:51,75 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:39:51,76 httpcore.http11 DEBUG send_request_headers.complete
18:39:51,76 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:39:51,76 httpcore.http11 DEBUG send_request_body.complete
18:39:51,76 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:39:51,304 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:39:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b8566eb31ae18bca6b2d35741cbf54b8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339545c3e2b4cdc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:39:51,307 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:39:51,308 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:39:51,310 httpcore.http11 DEBUG receive_response_body.complete
18:39:51,310 httpcore.http11 DEBUG response_closed.started
18:39:51,310 httpcore.http11 DEBUG response_closed.complete
18:39:51,311 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:40:02,882 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:02,887 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:06,290 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:06,293 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:40:06,298 httpcore.connection DEBUG close.started
18:40:06,298 httpcore.connection DEBUG close.complete
18:40:06,298 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:40:06,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d0f10>
18:40:06,301 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:40:06,308 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d32d0>
18:40:06,308 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:06,309 httpcore.http11 DEBUG send_request_headers.complete
18:40:06,309 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:06,309 httpcore.http11 DEBUG send_request_body.complete
18:40:06,309 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:06,716 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:06 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'334'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7941bdc4995452b881d862fa368d6dd2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833954bb683e4cf3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:06,719 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:40:06,720 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:07,189 httpcore.http11 DEBUG receive_response_body.complete
18:40:07,189 httpcore.http11 DEBUG response_closed.started
18:40:07,189 httpcore.http11 DEBUG response_closed.complete
18:40:07,190 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:40:07,256 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:40:16,479 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:40:16,482 httpcore.connection DEBUG close.started
18:40:16,483 httpcore.connection DEBUG close.complete
18:40:16,483 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:40:16,485 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4597910>
18:40:16,485 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:40:16,490 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4597890>
18:40:16,490 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:16,491 httpcore.http11 DEBUG send_request_headers.complete
18:40:16,491 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:16,510 httpcore.http11 DEBUG send_request_body.complete
18:40:16,510 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:17,478 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:17 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'30'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'452'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'88a74919ea39b13d948300e1fb0db2b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833954fb1bbc3035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:17,480 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:40:17,480 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:17,481 httpcore.http11 DEBUG receive_response_body.complete
18:40:17,481 httpcore.http11 DEBUG response_closed.started
18:40:17,482 httpcore.http11 DEBUG response_closed.complete
18:40:17,482 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:40:17,482 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:40:17,499 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes, this is a good location.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:40:17,501 httpcore.connection DEBUG close.started
18:40:17,501 httpcore.connection DEBUG close.complete
18:40:17,501 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:40:17,503 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd475e0d0>
18:40:17,503 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:40:17,508 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4553050>
18:40:17,509 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:17,509 httpcore.http11 DEBUG send_request_headers.complete
18:40:17,509 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:17,510 httpcore.http11 DEBUG send_request_body.complete
18:40:17,510 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:17,729 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9d67205852ae010e6a9417a04cffe500'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833955016c723b7c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:17,731 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:40:17,732 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:17,733 httpcore.http11 DEBUG receive_response_body.complete
18:40:17,733 httpcore.http11 DEBUG response_closed.started
18:40:17,733 httpcore.http11 DEBUG response_closed.complete
18:40:17,734 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:40:17,744 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:17,748 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:21,149 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:21,159 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:21,163 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:23,164 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:23,174 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:23,176 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:26,578 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:26,582 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:40:26,586 httpcore.connection DEBUG close.started
18:40:26,586 httpcore.connection DEBUG close.complete
18:40:26,586 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:40:26,589 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd45976d0>
18:40:26,589 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:40:26,596 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4597110>
18:40:26,596 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:26,598 httpcore.http11 DEBUG send_request_headers.complete
18:40:26,598 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:26,598 httpcore.http11 DEBUG send_request_body.complete
18:40:26,599 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:27,240 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'492'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'622ae5cc6f0b87915e0ee4303da39355'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339553a395f4cd6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:27,242 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:40:27,243 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:27,712 httpcore.http11 DEBUG receive_response_body.complete
18:40:27,713 httpcore.http11 DEBUG response_closed.started
18:40:27,713 httpcore.http11 DEBUG response_closed.complete
18:40:27,713 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:40:27,782 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:40:39,543 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:40:39,546 httpcore.connection DEBUG close.started
18:40:39,546 httpcore.connection DEBUG close.complete
18:40:39,547 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:40:39,575 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d3e10>
18:40:39,575 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:40:39,584 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d32d0>
18:40:39,584 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:39,586 httpcore.http11 DEBUG send_request_headers.complete
18:40:39,586 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:39,618 httpcore.http11 DEBUG send_request_body.complete
18:40:39,619 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:40,518 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:40 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd209f5f1ab02199868d6c94bf561b52a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339558b6bfc4cee-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:40,520 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:40:40,521 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:40,522 httpcore.http11 DEBUG receive_response_body.complete
18:40:40,522 httpcore.http11 DEBUG response_closed.started
18:40:40,522 httpcore.http11 DEBUG response_closed.complete
18:40:40,522 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:40:40,523 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:40:40,539 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:40:40,542 httpcore.connection DEBUG close.started
18:40:40,542 httpcore.connection DEBUG close.complete
18:40:40,542 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:40:40,545 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bc9d0>
18:40:40,545 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9f40> server_hostname='api.openai.com' timeout=None
18:40:40,550 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43beb50>
18:40:40,550 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:40,551 httpcore.http11 DEBUG send_request_headers.complete
18:40:40,551 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:40,551 httpcore.http11 DEBUG send_request_body.complete
18:40:40,552 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:40,748 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b52b5b9122db231d037f11173ee7c757'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833955917d834ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:40,749 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:40:40,750 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:40,750 httpcore.http11 DEBUG receive_response_body.complete
18:40:40,751 httpcore.http11 DEBUG response_closed.started
18:40:40,751 httpcore.http11 DEBUG response_closed.complete
18:40:40,751 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:40:40,769 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:40:40,771 httpcore.connection DEBUG close.started
18:40:40,771 httpcore.connection DEBUG close.complete
18:40:40,771 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:40:40,773 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43ade10>
18:40:40,774 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45ba720> server_hostname='api.openai.com' timeout=None
18:40:40,779 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bf5d0>
18:40:40,779 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:40,780 httpcore.http11 DEBUG send_request_headers.complete
18:40:40,780 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:40,781 httpcore.http11 DEBUG send_request_body.complete
18:40:40,781 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:41,210 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'295'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'70bd026149698ecf49dc20ecb4ab9e91'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83395592ed673b7b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:41,212 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:40:41,213 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:41,214 httpcore.http11 DEBUG receive_response_body.complete
18:40:41,214 httpcore.http11 DEBUG response_closed.started
18:40:41,214 httpcore.http11 DEBUG response_closed.complete
18:40:41,214 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:40:41,321 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:41,323 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:47,25 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:47,36 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:47,40 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:51,41 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:51,54 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:51,58 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:53,59 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:53,73 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:53,77 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:56,478 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:56,491 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:56,494 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:41:02,195 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:41:02,209 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:41:02,212 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:41:05,213 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:41:05,220 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:41:05,222 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:41:08,229 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:41:08,233 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:41:08,236 httpcore.connection DEBUG close.started
18:41:08,237 httpcore.connection DEBUG close.complete
18:41:08,237 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:41:08,240 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43dd990>
18:41:08,240 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:41:08,248 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d23d0>
18:41:08,248 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:41:08,249 httpcore.http11 DEBUG send_request_headers.complete
18:41:08,249 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:41:08,250 httpcore.http11 DEBUG send_request_body.complete
18:41:08,250 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:41:08,858 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:41:08 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'610a21926a873a7ac5ac84c8b8dd86a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339563e8dd24ce9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:41:08,860 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:41:08,861 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:41:09,738 httpcore.http11 DEBUG receive_response_body.complete
18:41:09,739 httpcore.http11 DEBUG response_closed.started
18:41:09,739 httpcore.http11 DEBUG response_closed.complete
18:41:09,739 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:41:09,810 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:41:22,353 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:41:22,357 httpcore.connection DEBUG close.started
18:41:22,358 httpcore.connection DEBUG close.complete
18:41:22,358 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:41:22,360 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43e0750>
18:41:22,360 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:41:22,366 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43e07d0>
18:41:22,366 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:41:22,367 httpcore.http11 DEBUG send_request_headers.complete
18:41:22,367 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:41:22,388 httpcore.http11 DEBUG send_request_body.complete
18:41:22,388 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:41:23,112 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:41:23 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'6'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'337'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4cb8547939400fc805ce4d960e075c73'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83395696ccc34cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:41:23,115 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:41:23,116 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:41:23,116 httpcore.http11 DEBUG receive_response_body.complete
18:41:23,117 httpcore.http11 DEBUG response_closed.started
18:41:23,117 httpcore.http11 DEBUG response_closed.complete
18:41:23,118 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:41:23,118 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:41:30,562 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNope.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:41:30,565 httpcore.connection DEBUG close.started
18:41:30,565 httpcore.connection DEBUG close.complete
18:41:30,566 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:41:30,568 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43beb50>
18:41:30,569 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9f40> server_hostname='api.openai.com' timeout=None
18:41:30,575 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be950>
18:41:30,575 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:41:30,576 httpcore.http11 DEBUG send_request_headers.complete
18:41:30,577 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:41:30,577 httpcore.http11 DEBUG send_request_body.complete
18:41:30,577 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:41:30,784 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:41:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'24458a8760ba7836c077d48bf5b70b3a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833956ca1fb46ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:41:30,791 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:41:30,792 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:41:30,794 httpcore.http11 DEBUG receive_response_body.complete
18:41:30,794 httpcore.http11 DEBUG response_closed.started
18:41:30,795 httpcore.http11 DEBUG response_closed.complete
18:41:30,795 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:42:50,837 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:42:50,845 httpcore.connection DEBUG close.started
18:42:50,846 httpcore.connection DEBUG close.complete
18:42:50,846 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:42:50,877 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be410>
18:42:50,877 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:42:50,886 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bef50>
18:42:50,887 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:42:50,889 httpcore.http11 DEBUG send_request_headers.complete
18:42:50,890 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:42:50,891 httpcore.http11 DEBUG send_request_body.complete
18:42:50,892 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:42:51,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:42:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'463'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'31bb36c3a5c14b054f5ebadf2420160f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833958c00d733b8e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:42:51,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:42:51,461 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:42:52,427 httpcore.http11 DEBUG receive_response_body.complete
18:42:52,427 httpcore.http11 DEBUG response_closed.started
18:42:52,428 httpcore.http11 DEBUG response_closed.complete
18:42:52,429 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:42:52,498 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:43:05,221 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:43:05,225 httpcore.connection DEBUG close.started
18:43:05,225 httpcore.connection DEBUG close.complete
18:43:05,225 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:43:05,228 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43ac910>
18:43:05,228 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:43:05,234 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43aef50>
18:43:05,235 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:05,236 httpcore.http11 DEBUG send_request_headers.complete
18:43:05,236 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:05,259 httpcore.http11 DEBUG send_request_body.complete
18:43:05,259 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:06,66 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:43:06 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c6ee445f946cfce66fb9adf37669553f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83395919beae4ce3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:06,68 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:43:06,68 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:06,69 httpcore.http11 DEBUG receive_response_body.complete
18:43:06,69 httpcore.http11 DEBUG response_closed.started
18:43:06,70 httpcore.http11 DEBUG response_closed.complete
18:43:06,70 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:43:06,70 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:43:22,85 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:43:22,89 httpcore.connection DEBUG close.started
18:43:22,89 httpcore.connection DEBUG close.complete
18:43:22,89 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:43:22,92 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bf350>
18:43:22,92 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:43:22,97 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bcf50>
18:43:22,97 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:22,98 httpcore.http11 DEBUG send_request_headers.complete
18:43:22,99 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:22,99 httpcore.http11 DEBUG send_request_body.complete
18:43:22,99 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:22,304 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:43:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a5124994f4f7f476e85b69d699fedc73'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833959831dae4ce7-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:22,310 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:43:22,312 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:22,312 httpcore.http11 DEBUG receive_response_body.complete
18:43:22,313 httpcore.http11 DEBUG response_closed.started
18:43:22,313 httpcore.http11 DEBUG response_closed.complete
18:43:22,313 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:27,702 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:27,705 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,508 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,509 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,560 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,560 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,604 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,605 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,646 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,647 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,694 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,695 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,737 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,738 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,781 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,782 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,821 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,822 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,864 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:49:28,876 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:49:28,908 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288ddcd0>
18:49:28,908 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:49:28,917 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288de250>
18:49:28,917 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:28,919 httpcore.http11 DEBUG send_request_headers.complete
18:49:28,919 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:28,919 httpcore.http11 DEBUG send_request_body.complete
18:49:28,920 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:29,398 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:49:29 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'562909cfa3600614bf296015dd3528bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=R8DVj9e765PJ5E73YwCNxHht0D4euHt8INkVP6Iy.Sk-1702252169-1-AX89QSbkvhZikxnSCF+a41Wa+Nq/wRr2FehHdKUrVVJjxkUIC0O2kYpbPPYqbWswKilCjF0oYUnxrs4CuP+H0s4=; path=/; expires=Mon, 11-Dec-23 00:19:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=aaGRaB_.b4KkkDv4gNS6ZRQLDVSwaH4F.DojrZXY4_g-1702252169393-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396277cd634ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:29,405 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:49:29,405 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:30,210 httpcore.http11 DEBUG receive_response_body.complete
18:49:30,210 httpcore.http11 DEBUG response_closed.started
18:49:30,211 httpcore.http11 DEBUG response_closed.complete
18:49:30,211 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:49:30,283 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:49:44,67 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:49:44,76 httpcore.connection DEBUG close.started
18:49:44,76 httpcore.connection DEBUG close.complete
18:49:44,76 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:49:44,79 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288de250>
18:49:44,79 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:49:44,86 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288ddb50>
18:49:44,87 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:44,87 httpcore.http11 DEBUG send_request_headers.complete
18:49:44,87 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:44,117 httpcore.http11 DEBUG send_request_body.complete
18:49:44,117 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:44,863 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:49:44 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'409'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd3fe8db6cc52f6baad71ee62db10c84c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833962d68ed34d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:44,866 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:49:44,866 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:44,867 httpcore.http11 DEBUG receive_response_body.complete
18:49:44,867 httpcore.http11 DEBUG response_closed.started
18:49:44,868 httpcore.http11 DEBUG response_closed.complete
18:49:44,868 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:49:44,869 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:49:44,887 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:49:44,895 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:49:44,897 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628933fd0>
18:49:44,897 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:49:44,903 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628932790>
18:49:44,903 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:44,904 httpcore.http11 DEBUG send_request_headers.complete
18:49:44,904 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:44,904 httpcore.http11 DEBUG send_request_body.complete
18:49:44,905 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:45,165 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:49:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'93a3bd3c4d140af64f758301f7792804'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FswVi.q.hr9FshPT72k.FEK2HD5EaTy322RnGtwJ_Gs-1702252185-1-AdUq5I91x2Cr/owyCVBuqNjZ6KmqSErQwf3eHDXyUos+ul0x0sWdExxYpuxOXdypZ3hi/+XHMrHD5gmm/K/uthA=; path=/; expires=Mon, 11-Dec-23 00:19:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NGDr5gXwFzVgZMbHVGrvJh4xkk006WR0oiXIn67Hg.0-1702252185161-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833962dbacd23010-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:45,170 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:49:45,170 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:45,171 httpcore.http11 DEBUG receive_response_body.complete
18:49:45,171 httpcore.http11 DEBUG response_closed.started
18:49:45,171 httpcore.http11 DEBUG response_closed.complete
18:49:45,172 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:45,188 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:49:45,199 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:49:45,201 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289406d0>
18:49:45,201 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628966720> server_hostname='api.openai.com' timeout=None
18:49:45,210 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289408d0>
18:49:45,210 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:45,211 httpcore.http11 DEBUG send_request_headers.complete
18:49:45,211 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:45,212 httpcore.http11 DEBUG send_request_body.complete
18:49:45,212 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:45,840 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:49:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'361'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'eced275818ed6d7d378aa888ac9ca952'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mlmjq7d17hgHkeKAIRG5.KR0sfWuwr1a3sqUat4y5yQ-1702252185-1-AS9dvfIF05lySg0tBLmDbK+umsDSI//6Tv3A29yq0wRLbYNGiesTyOdHZt86jVDSG3NMRNdnxcuWFMvamBaLhTA=; path=/; expires=Mon, 11-Dec-23 00:19:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=hXN1RTWGBD58QAzqISNGshIvVUUeq8A8gM_d9rn6LdE-1702252185837-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833962dd99eb3b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:45,841 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:49:45,842 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:45,842 httpcore.http11 DEBUG receive_response_body.complete
18:49:45,842 httpcore.http11 DEBUG response_closed.started
18:49:45,843 httpcore.http11 DEBUG response_closed.complete
18:49:45,843 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:45,854 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:49:45,858 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:49:51,564 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:49:51,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:49:51,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:49:55,580 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:49:55,591 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:49:55,594 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:49:57,595 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:49:57,607 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:49:57,610 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:01,12 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:01,26 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:01,30 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:06,731 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:06,746 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:06,749 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:10,152 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:10,158 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:10,162 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:13,964 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:13,969 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:50:13,974 httpcore.connection DEBUG close.started
18:50:13,975 httpcore.connection DEBUG close.complete
18:50:13,976 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:13,979 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288de3d0>
18:50:13,979 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:50:13,985 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628952c90>
18:50:13,985 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:13,986 httpcore.http11 DEBUG send_request_headers.complete
18:50:13,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:13,986 httpcore.http11 DEBUG send_request_body.complete
18:50:13,986 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:14,497 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:14 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'422'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e490463db15c65c574e3526cb0c2aef8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833963916b614cee-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:14,499 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:50:14,500 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:15,517 httpcore.http11 DEBUG receive_response_body.complete
18:50:15,518 httpcore.http11 DEBUG response_closed.started
18:50:15,518 httpcore.http11 DEBUG response_closed.complete
18:50:15,519 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:50:15,590 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:50:28,286 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:50:28,289 httpcore.connection DEBUG close.started
18:50:28,289 httpcore.connection DEBUG close.complete
18:50:28,289 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:28,292 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628775b10>
18:50:28,292 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:50:28,304 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628775b90>
18:50:28,304 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:28,305 httpcore.http11 DEBUG send_request_headers.complete
18:50:28,305 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:28,325 httpcore.http11 DEBUG send_request_body.complete
18:50:28,326 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:29,575 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:29 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'790'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'715130dcc15e153f6611ca70089c7fe5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833963eae8db4cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:29,578 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:50:29,578 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:29,579 httpcore.http11 DEBUG receive_response_body.complete
18:50:29,579 httpcore.http11 DEBUG response_closed.started
18:50:29,580 httpcore.http11 DEBUG response_closed.complete
18:50:29,580 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:50:29,581 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:50:33,207 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:50:33,210 httpcore.connection DEBUG close.started
18:50:33,210 httpcore.connection DEBUG close.complete
18:50:33,211 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:50:33,238 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628932790>
18:50:33,239 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:50:33,246 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628932a50>
18:50:33,247 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:33,248 httpcore.http11 DEBUG send_request_headers.complete
18:50:33,248 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:33,249 httpcore.http11 DEBUG send_request_body.complete
18:50:33,249 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:33,460 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'be78f464628fc3d353a5105b7cff7f9f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396409cae94cff-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:33,466 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:50:33,466 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:33,468 httpcore.http11 DEBUG receive_response_body.complete
18:50:33,468 httpcore.http11 DEBUG response_closed.started
18:50:33,469 httpcore.http11 DEBUG response_closed.complete
18:50:33,470 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:50:41,948 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:50:41,954 httpcore.connection DEBUG close.started
18:50:41,955 httpcore.connection DEBUG close.complete
18:50:41,955 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:41,957 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628775910>
18:50:41,958 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:50:41,965 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287778d0>
18:50:41,966 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:41,967 httpcore.http11 DEBUG send_request_headers.complete
18:50:41,967 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:41,968 httpcore.http11 DEBUG send_request_body.complete
18:50:41,968 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:42,643 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'541'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7f27529b00cadc4f4247c07d6699cef0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833964404f6c3bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:42,648 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:50:42,649 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:43,765 httpcore.http11 DEBUG receive_response_body.complete
18:50:43,766 httpcore.http11 DEBUG response_closed.started
18:50:43,767 httpcore.http11 DEBUG response_closed.complete
18:50:43,768 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:50:43,837 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:50:56,523 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:50:56,528 httpcore.connection DEBUG close.started
18:50:56,529 httpcore.connection DEBUG close.complete
18:50:56,529 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:56,532 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877a250>
18:50:56,532 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:50:56,540 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628779d90>
18:50:56,541 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:56,542 httpcore.http11 DEBUG send_request_headers.complete
18:50:56,543 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:56,569 httpcore.http11 DEBUG send_request_body.complete
18:50:56,570 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:59,531 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'33'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'2577'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0e1ae68e8f06a19e6ebc9ec49b8d6d45'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339649b68494d13-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:59,535 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:50:59,536 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:59,537 httpcore.http11 DEBUG receive_response_body.complete
18:50:59,538 httpcore.http11 DEBUG response_closed.started
18:50:59,539 httpcore.http11 DEBUG response_closed.complete
18:50:59,539 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:50:59,540 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:51:03,175 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:03,178 httpcore.connection DEBUG close.started
18:51:03,178 httpcore.connection DEBUG close.complete
18:51:03,179 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:03,181 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628775b50>
18:51:03,181 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:51:03,189 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287776d0>
18:51:03,190 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:03,191 httpcore.http11 DEBUG send_request_headers.complete
18:51:03,191 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:03,192 httpcore.http11 DEBUG send_request_body.complete
18:51:03,192 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:03,416 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:51:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0c6ff69d1118effaf32c7b60c56b9862'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833964c4fc414ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:03,419 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:03,419 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:03,420 httpcore.http11 DEBUG receive_response_body.complete
18:51:03,421 httpcore.http11 DEBUG response_closed.started
18:51:03,421 httpcore.http11 DEBUG response_closed.complete
18:51:03,421 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:51:17,985 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:51:17,990 httpcore.connection DEBUG close.started
18:51:17,991 httpcore.connection DEBUG close.complete
18:51:17,991 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:17,994 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287782d0>
18:51:17,994 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:51:18,1 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628779590>
18:51:18,2 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:18,3 httpcore.http11 DEBUG send_request_headers.complete
18:51:18,3 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:18,4 httpcore.http11 DEBUG send_request_body.complete
18:51:18,4 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:18,508 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:51:18 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'64fa82d1920c92aaae945692257005b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833965218c843b69-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:18,512 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:51:18,513 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:19,543 httpcore.http11 DEBUG receive_response_body.complete
18:51:19,544 httpcore.http11 DEBUG response_closed.started
18:51:19,544 httpcore.http11 DEBUG response_closed.complete
18:51:19,545 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:51:19,609 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:51:32,229 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:51:32,237 httpcore.connection DEBUG close.started
18:51:32,238 httpcore.connection DEBUG close.complete
18:51:32,238 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:32,241 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877a290>
18:51:32,241 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:51:32,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628779a10>
18:51:32,252 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:32,254 httpcore.http11 DEBUG send_request_headers.complete
18:51:32,255 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:32,278 httpcore.http11 DEBUG send_request_body.complete
18:51:32,278 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:34,773 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:51:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'1'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'2059'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'222c03c2cb3ab18aebb69ff9551b34d0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339657a9c574d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:34,779 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:51:34,780 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:34,782 httpcore.http11 DEBUG receive_response_body.complete
18:51:34,782 httpcore.http11 DEBUG response_closed.started
18:51:34,783 httpcore.http11 DEBUG response_closed.complete
18:51:34,783 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:51:34,784 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 2 column 1 (char 1)
18:52:58,371 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\n\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:58,379 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:58,408 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962878f6d0>
18:52:58,408 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f96289662a0> server_hostname='api.openai.com' timeout=None
18:52:58,416 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628784f50>
18:52:58,416 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:58,416 httpcore.http11 DEBUG send_request_headers.complete
18:52:58,416 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:58,417 httpcore.http11 DEBUG send_request_body.complete
18:52:58,417 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:58,999 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:52:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'494'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e5e107b4483bdc7757695d1cac6771e2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2Nbu6WKY8fxrypT93HrwCx4m5i2tomieidJBD1JU7xw-1702252378-1-AerYuyZgW018Q0CGixRiwmVsB8i+YgiWldRgTNW4l8gIQbRtwOtQ+a1kGEEWnRsz5W/NbSrVkxdO9V6VkxzqXNM=; path=/; expires=Mon, 11-Dec-23 00:22:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=drqGY2bYdARnWxAN7CcBLa5DU0J35kPVnrhZ.Y2chp4-1702252378996-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833967951f743b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:59,0 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:59,1 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:59,1 httpcore.http11 DEBUG receive_response_body.complete
18:52:59,1 httpcore.http11 DEBUG response_closed.started
18:52:59,1 httpcore.http11 DEBUG response_closed.complete
18:52:59,1 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:56:26,580 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\n\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:56:26,585 httpcore.connection DEBUG close.started
18:56:26,586 httpcore.connection DEBUG close.complete
18:56:26,586 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:56:26,618 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288dd650>
18:56:26,619 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:56:26,625 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288dcd90>
18:56:26,626 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:26,628 httpcore.http11 DEBUG send_request_headers.complete
18:56:26,629 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:26,629 httpcore.http11 DEBUG send_request_body.complete
18:56:26,630 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:26,919 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6425257f1ddea36910a5939992c8d4c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396caa6a5c4ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:26,925 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:56:26,926 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:26,927 httpcore.http11 DEBUG receive_response_body.complete
18:56:26,928 httpcore.http11 DEBUG response_closed.started
18:56:26,928 httpcore.http11 DEBUG response_closed.complete
18:56:26,929 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:56:32,656 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:56:32,660 httpcore.connection DEBUG close.started
18:56:32,661 httpcore.connection DEBUG close.complete
18:56:32,661 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:56:32,664 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628777110>
18:56:32,664 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:56:32,669 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628774e50>
18:56:32,669 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:32,670 httpcore.http11 DEBUG send_request_headers.complete
18:56:32,670 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:32,670 httpcore.http11 DEBUG send_request_body.complete
18:56:32,670 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:33,163 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:33 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'423'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a49c54822889dad1c2a4fe00e0130e4d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396cd039524d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:33,164 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:56:33,165 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:34,319 httpcore.http11 DEBUG receive_response_body.complete
18:56:34,320 httpcore.http11 DEBUG response_closed.started
18:56:34,320 httpcore.http11 DEBUG response_closed.complete
18:56:34,320 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:56:34,386 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:56:47,119 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:56:47,122 httpcore.connection DEBUG close.started
18:56:47,122 httpcore.connection DEBUG close.complete
18:56:47,122 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:56:47,125 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877bad0>
18:56:47,125 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:56:47,130 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877a650>
18:56:47,130 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:47,131 httpcore.http11 DEBUG send_request_headers.complete
18:56:47,131 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:47,148 httpcore.http11 DEBUG send_request_body.complete
18:56:47,149 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:47,882 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:47 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'abd0a6dcdedeb780f8ad9f091e18289c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396d2a99914d12-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:47,884 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:56:47,885 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:47,885 httpcore.http11 DEBUG receive_response_body.complete
18:56:47,886 httpcore.http11 DEBUG response_closed.started
18:56:47,886 httpcore.http11 DEBUG response_closed.complete
18:56:47,887 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:56:47,887 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:56:47,901 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:56:47,903 httpcore.connection DEBUG close.started
18:56:47,903 httpcore.connection DEBUG close.complete
18:56:47,904 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:56:47,906 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628794c10>
18:56:47,906 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:56:47,916 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628795d90>
18:56:47,917 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:47,917 httpcore.http11 DEBUG send_request_headers.complete
18:56:47,917 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:47,918 httpcore.http11 DEBUG send_request_body.complete
18:56:47,918 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:48,120 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7a8196d2b12ce1ae20bff665e08be803'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396d2f79c44cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:48,123 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:56:48,123 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:48,124 httpcore.http11 DEBUG receive_response_body.complete
18:56:48,125 httpcore.http11 DEBUG response_closed.started
18:56:48,125 httpcore.http11 DEBUG response_closed.complete
18:56:48,125 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:56:48,143 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:56:48,152 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:56:48,154 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628797550>
18:56:48,155 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965eb0> server_hostname='api.openai.com' timeout=None
18:56:48,163 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628797510>
18:56:48,163 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:48,164 httpcore.http11 DEBUG send_request_headers.complete
18:56:48,164 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:48,165 httpcore.http11 DEBUG send_request_body.complete
18:56:48,165 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:48,410 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'de02c87569ed0c5a0120e69c5b3bcfff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=l1b0gmDk1KUQNpG2iqy9jcISzeIYQfuQjBRe4pBes8M-1702252608-1-ATaR8grI+hXMLb98/oAdTT2NFuYBIEjktYg5wGmxzANkGDnCXhRdezXtPTLGDp5SDFS5TuxA/83lNfS8N4rfseQ=; path=/; expires=Mon, 11-Dec-23 00:26:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=hxNJEysRqiJA8M_O5Lyfp0_nj2JFJdECzP3curslDKY-1702252608406-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396d3108804d10-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:48,414 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:56:48,415 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:48,416 httpcore.http11 DEBUG receive_response_body.complete
18:56:48,417 httpcore.http11 DEBUG response_closed.started
18:56:48,417 httpcore.http11 DEBUG response_closed.complete
18:56:48,417 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:56:56,848 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:56:56,851 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:00,254 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:00,273 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:00,277 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:02,279 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:02,297 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:02,301 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:05,703 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:17,134 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:57:17,139 httpcore.connection DEBUG close.started
18:57:17,139 httpcore.connection DEBUG close.complete
18:57:17,140 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:57:17,142 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287581d0>
18:57:17,143 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:57:17,151 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962875bbd0>
18:57:17,151 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:17,152 httpcore.http11 DEBUG send_request_headers.complete
18:57:17,152 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:17,153 httpcore.http11 DEBUG send_request_body.complete
18:57:17,153 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:17,643 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:57:17 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'34e013a52f342d0cfe4bb0e430087ffe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396de63f104d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:17,645 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:57:17,646 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:18,0 httpcore.http11 DEBUG receive_response_body.complete
18:57:18,1 httpcore.http11 DEBUG response_closed.started
18:57:18,1 httpcore.http11 DEBUG response_closed.complete
18:57:18,1 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:57:18,66 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:57:29,564 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:57:29,567 httpcore.connection DEBUG close.started
18:57:29,568 httpcore.connection DEBUG close.complete
18:57:29,568 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:57:29,596 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628941a50>
18:57:29,596 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:57:29,604 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289405d0>
18:57:29,605 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:29,606 httpcore.http11 DEBUG send_request_headers.complete
18:57:29,606 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:29,632 httpcore.http11 DEBUG send_request_body.complete
18:57:29,632 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:30,528 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:57:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'446'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2b3dd893561ff0b8d9b39ab8d84d485f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396e3408de2ffc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:30,530 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:57:30,530 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:30,530 httpcore.http11 DEBUG receive_response_body.complete
18:57:30,530 httpcore.http11 DEBUG response_closed.started
18:57:30,531 httpcore.http11 DEBUG response_closed.complete
18:57:30,531 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:57:30,531 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:57:30,546 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:57:30,548 httpcore.connection DEBUG close.started
18:57:30,549 httpcore.connection DEBUG close.complete
18:57:30,549 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:57:30,552 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628796710>
18:57:30,552 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:57:30,558 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628795350>
18:57:30,558 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:30,559 httpcore.http11 DEBUG send_request_headers.complete
18:57:30,559 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:30,560 httpcore.http11 DEBUG send_request_body.complete
18:57:30,560 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:30,764 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:57:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7d598fbbec85f3156b902bb4652c2920'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396e39fc594d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:30,765 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:57:30,766 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:30,766 httpcore.http11 DEBUG receive_response_body.complete
18:57:30,767 httpcore.http11 DEBUG response_closed.started
18:57:30,767 httpcore.http11 DEBUG response_closed.complete
18:57:30,767 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:57:30,784 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:57:30,786 httpcore.connection DEBUG close.started
18:57:30,787 httpcore.connection DEBUG close.complete
18:57:30,787 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:57:30,789 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289408d0>
18:57:30,789 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628966720> server_hostname='api.openai.com' timeout=None
18:57:30,795 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628942690>
18:57:30,795 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:30,796 httpcore.http11 DEBUG send_request_headers.complete
18:57:30,796 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:30,796 httpcore.http11 DEBUG send_request_body.complete
18:57:30,797 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:31,238 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:57:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'313'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3984d6a4ef232d7144898f63c420794b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396e3b7bf14cc3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:31,240 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:57:31,242 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:31,243 httpcore.http11 DEBUG receive_response_body.complete
18:57:31,243 httpcore.http11 DEBUG response_closed.started
18:57:31,244 httpcore.http11 DEBUG response_closed.complete
18:57:31,244 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:57:31,256 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:31,259 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:36,960 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:36,972 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:36,975 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:40,977 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:40,989 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:40,992 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:42,994 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:43,8 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:43,11 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:46,413 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:46,425 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:46,428 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:52,129 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:52,136 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:52,140 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:56,741 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:56,752 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:56,755 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:59,757 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:59,760 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:57:59,765 httpcore.connection DEBUG close.started
18:57:59,765 httpcore.connection DEBUG close.complete
18:57:59,766 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:57:59,768 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628944190>
18:57:59,769 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:57:59,775 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628944d90>
18:57:59,776 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:59,776 httpcore.http11 DEBUG send_request_headers.complete
18:57:59,776 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:59,777 httpcore.http11 DEBUG send_request_body.complete
18:57:59,777 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:00,306 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'440'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8098998e25183ca8d93ef168300ff4a3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396ef098273b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:00,309 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:58:00,309 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:01,192 httpcore.http11 DEBUG receive_response_body.complete
18:58:01,192 httpcore.http11 DEBUG response_closed.started
18:58:01,192 httpcore.http11 DEBUG response_closed.complete
18:58:01,193 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:58:01,257 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:58:13,699 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:58:13,704 httpcore.connection DEBUG close.started
18:58:13,704 httpcore.connection DEBUG close.complete
18:58:13,704 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:58:13,739 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289419d0>
18:58:13,739 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:58:13,747 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289427d0>
18:58:13,747 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:13,747 httpcore.http11 DEBUG send_request_headers.complete
18:58:13,748 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:13,769 httpcore.http11 DEBUG send_request_body.complete
18:58:13,769 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:14,470 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a4b14359589a2e376aab6f7e3314b24e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396f47ea604cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:14,472 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:58:14,473 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:14,474 httpcore.http11 DEBUG receive_response_body.complete
18:58:14,474 httpcore.http11 DEBUG response_closed.started
18:58:14,474 httpcore.http11 DEBUG response_closed.complete
18:58:14,474 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:58:14,475 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:58:17,975 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:17,979 httpcore.connection DEBUG close.started
18:58:17,979 httpcore.connection DEBUG close.complete
18:58:17,980 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:17,982 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628796710>
18:58:17,982 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:58:17,987 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628794d10>
18:58:17,987 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:17,988 httpcore.http11 DEBUG send_request_headers.complete
18:58:17,989 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:17,989 httpcore.http11 DEBUG send_request_body.complete
18:58:17,989 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:18,258 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e7d22cb339715ace6dca206daf2ea18e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396f626d0c4d10-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:18,260 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:18,261 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:18,262 httpcore.http11 DEBUG receive_response_body.complete
18:58:18,263 httpcore.http11 DEBUG response_closed.started
18:58:18,263 httpcore.http11 DEBUG response_closed.complete
18:58:18,264 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:20,197 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:20,202 httpcore.connection DEBUG close.started
18:58:20,203 httpcore.connection DEBUG close.complete
18:58:20,203 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:20,206 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877ba10>
18:58:20,206 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965eb0> server_hostname='api.openai.com' timeout=None
18:58:20,212 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628778350>
18:58:20,213 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:20,214 httpcore.http11 DEBUG send_request_headers.complete
18:58:20,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:20,215 httpcore.http11 DEBUG send_request_body.complete
18:58:20,215 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:20,430 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'13009fd7eb152147d2a0e11aa80e2ed1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396f7058913b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:20,437 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:20,438 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:20,440 httpcore.http11 DEBUG receive_response_body.complete
18:58:20,441 httpcore.http11 DEBUG response_closed.started
18:58:20,442 httpcore.http11 DEBUG response_closed.complete
18:58:20,442 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:26,995 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:58:26,999 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:58:30,401 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:58:34,901 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:58:34,905 httpcore.connection DEBUG close.started
18:58:34,906 httpcore.connection DEBUG close.complete
18:58:34,906 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:58:34,935 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289419d0>
18:58:34,936 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:58:34,943 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628940a90>
18:58:34,944 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:34,946 httpcore.http11 DEBUG send_request_headers.complete
18:58:34,946 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:34,948 httpcore.http11 DEBUG send_request_body.complete
18:58:34,948 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:35,439 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'369'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3c63ce22d66981555ff82bb92ad56b1b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396fcc6def4d16-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:35,446 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:58:35,447 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:35,926 httpcore.http11 DEBUG receive_response_body.complete
18:58:35,927 httpcore.http11 DEBUG response_closed.started
18:58:35,928 httpcore.http11 DEBUG response_closed.complete
18:58:35,929 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:58:36,2 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:58:45,102 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:58:45,108 httpcore.connection DEBUG close.started
18:58:45,109 httpcore.connection DEBUG close.complete
18:58:45,109 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:58:45,112 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962878f2d0>
18:58:45,112 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:58:45,119 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628785990>
18:58:45,119 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:45,121 httpcore.http11 DEBUG send_request_headers.complete
18:58:45,121 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:45,147 httpcore.http11 DEBUG send_request_body.complete
18:58:45,148 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:45,910 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9f58fe9f78da98dbf5db6b8fc123faf3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339700c0a154cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:45,915 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:58:45,915 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:45,916 httpcore.http11 DEBUG receive_response_body.complete
18:58:45,917 httpcore.http11 DEBUG response_closed.started
18:58:45,917 httpcore.http11 DEBUG response_closed.complete
18:58:45,918 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:58:45,918 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:58:49,216 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:49,222 httpcore.connection DEBUG close.started
18:58:49,223 httpcore.connection DEBUG close.complete
18:58:49,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:49,225 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628778350>
18:58:49,226 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965eb0> server_hostname='api.openai.com' timeout=None
18:58:49,231 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877ae50>
18:58:49,231 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:49,232 httpcore.http11 DEBUG send_request_headers.complete
18:58:49,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:49,233 httpcore.http11 DEBUG send_request_body.complete
18:58:49,233 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:49,470 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'143'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'144c1025b1cb1e8332569fddc4583776'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397025bb634cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:49,474 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:49,475 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:49,476 httpcore.http11 DEBUG receive_response_body.complete
18:58:49,476 httpcore.http11 DEBUG response_closed.started
18:58:49,477 httpcore.http11 DEBUG response_closed.complete
18:58:49,478 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:59:23,890 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nno\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:59:23,891 httpcore.connection DEBUG close.started
18:59:23,891 httpcore.connection DEBUG close.complete
18:59:23,891 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:59:23,893 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877b190>
18:59:23,893 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:59:23,899 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628942ed0>
18:59:23,899 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:59:23,899 httpcore.http11 DEBUG send_request_headers.complete
18:59:23,899 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:59:23,899 httpcore.http11 DEBUG send_request_body.complete
18:59:23,899 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:59:24,121 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:59:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b199193e30ec727f363c2298fe490b97'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833970fe69b24cdc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:59:24,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:59:24,122 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:59:24,123 httpcore.http11 DEBUG receive_response_body.complete
18:59:24,123 httpcore.http11 DEBUG response_closed.started
18:59:24,123 httpcore.http11 DEBUG response_closed.complete
18:59:24,123 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:59:49,237 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:59:49,242 httpcore.connection DEBUG close.started
18:59:49,243 httpcore.connection DEBUG close.complete
18:59:49,244 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:59:49,272 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628922710>
18:59:49,273 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:59:49,283 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289024d0>
18:59:49,284 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:59:49,285 httpcore.http11 DEBUG send_request_headers.complete
18:59:49,285 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:59:49,285 httpcore.http11 DEBUG send_request_body.complete
18:59:49,285 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:59:49,860 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:59:49 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6feaa47a260ac3fbf86e01074fc1dabe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339719d0eb94d02-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:59:49,862 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:59:49,863 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:59:51,145 httpcore.http11 DEBUG receive_response_body.complete
18:59:51,146 httpcore.http11 DEBUG response_closed.started
18:59:51,146 httpcore.http11 DEBUG response_closed.complete
18:59:51,147 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:59:51,213 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:00:04,443 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:00:04,445 httpcore.connection DEBUG close.started
19:00:04,445 httpcore.connection DEBUG close.complete
19:00:04,446 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:00:04,448 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289420d0>
19:00:04,448 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
19:00:04,454 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289416d0>
19:00:04,454 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:00:04,455 httpcore.http11 DEBUG send_request_headers.complete
19:00:04,455 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:00:04,479 httpcore.http11 DEBUG send_request_body.complete
19:00:04,479 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:00:06,189 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:00:06 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1210'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'41f2b3ffc6195944e30d574d9b33160e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833971fbdf0c4d16-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:00:06,191 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:00:06,192 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:00:06,192 httpcore.http11 DEBUG receive_response_body.complete
19:00:06,193 httpcore.http11 DEBUG response_closed.started
19:00:06,193 httpcore.http11 DEBUG response_closed.complete
19:00:06,194 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:00:06,194 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:00:06,209 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:00:06,211 httpcore.connection DEBUG close.started
19:00:06,211 httpcore.connection DEBUG close.complete
19:00:06,212 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:00:06,214 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287787d0>
19:00:06,214 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965eb0> server_hostname='api.openai.com' timeout=None
19:00:06,221 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877ad10>
19:00:06,222 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:00:06,222 httpcore.http11 DEBUG send_request_headers.complete
19:00:06,223 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:00:06,224 httpcore.http11 DEBUG send_request_body.complete
19:00:06,224 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:00:06,469 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:00:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fd26bf6744d78ec7a7cfea440cfbcd97'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397206e9863b6f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:00:06,472 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:00:06,472 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:00:06,473 httpcore.http11 DEBUG receive_response_body.complete
19:00:06,474 httpcore.http11 DEBUG response_closed.started
19:00:06,474 httpcore.http11 DEBUG response_closed.complete
19:00:06,474 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:00:41,349 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:00:41,355 httpcore.connection DEBUG close.started
19:00:41,356 httpcore.connection DEBUG close.complete
19:00:41,356 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:00:41,359 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628796590>
19:00:41,360 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
19:00:41,368 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877a490>
19:00:41,369 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:00:41,370 httpcore.http11 DEBUG send_request_headers.complete
19:00:41,370 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:00:41,371 httpcore.http11 DEBUG send_request_body.complete
19:00:41,371 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:00:42,64 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:00:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'554'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ff266b7e5b619e675155c96a34d4d8ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833972e29d7c6ac5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:00:42,69 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:00:42,70 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:00:43,165 httpcore.http11 DEBUG receive_response_body.complete
19:00:43,166 httpcore.http11 DEBUG response_closed.started
19:00:43,167 httpcore.http11 DEBUG response_closed.complete
19:00:43,168 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:00:43,238 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:04:52,65 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,68 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:52,863 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,864 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:52,904 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,905 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:52,948 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,949 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:52,990 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,991 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,39 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:53,40 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,78 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:53,79 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,120 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:53,121 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,158 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:53,158 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,199 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:04:53,212 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:04:53,242 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646adf2250>
19:04:53,242 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:04:53,252 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646adf2810>
19:04:53,253 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:53,254 httpcore.http11 DEBUG send_request_headers.complete
19:04:53,254 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:53,255 httpcore.http11 DEBUG send_request_body.complete
19:04:53,255 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:53,724 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:04:53 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'01614ab28a0763ded7a2cfd79fbbd4ed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dESuM6846RyfB.hkjjnVnyGPkbDEMLXZ694ApVICkWk-1702253093-1-AQznIs2m4B1gYs8bwcefcEJBxAIuOm2kkT2O31utPeOF+sU2JDIpmwBHcMXqyH8lB+4qMq7utqpSbZJGls2IBiI=; path=/; expires=Mon, 11-Dec-23 00:34:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=W4iiWQ.QBaNdeHOB4fr9UjOUK9s9Qr1YHTRQAbd5Aiw-1702253093718-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397908dc463b7c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:53,730 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:04:53,731 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:54,322 httpcore.http11 DEBUG receive_response_body.complete
19:04:54,323 httpcore.http11 DEBUG response_closed.started
19:04:54,323 httpcore.http11 DEBUG response_closed.complete
19:04:54,324 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:04:54,396 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:05:07,540 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:05:07,549 httpcore.connection DEBUG close.started
19:05:07,549 httpcore.connection DEBUG close.complete
19:05:07,550 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:07,552 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646adf2b50>
19:05:07,552 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:05:07,560 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646adf29d0>
19:05:07,560 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:07,561 httpcore.http11 DEBUG send_request_headers.complete
19:05:07,561 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:07,591 httpcore.http11 DEBUG send_request_body.complete
19:05:07,591 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:08,522 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:08 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'35'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'443'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'981891826e3e5296916c85c8d4fbfa08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833979624a4e3010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:08,524 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:05:08,525 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:08,525 httpcore.http11 DEBUG receive_response_body.complete
19:05:08,526 httpcore.http11 DEBUG response_closed.started
19:05:08,526 httpcore.http11 DEBUG response_closed.complete
19:05:08,526 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:05:08,527 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:05:08,545 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\ncut it on the top side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:08,553 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:08,555 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae47f90>
19:05:08,555 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81f40> server_hostname='api.openai.com' timeout=None
19:05:08,561 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae46650>
19:05:08,562 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:08,562 httpcore.http11 DEBUG send_request_headers.complete
19:05:08,562 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:08,563 httpcore.http11 DEBUG send_request_body.complete
19:05:08,563 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:08,802 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5945d6a6abe356cd61c26b002235acc4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ItZGKj4_iuKzLzArP9GKrwnuCvkor454v1XT2CveRCQ-1702253108-1-AVCPhtaW4t7yi+pfPJbQO57oAdVmMRrdlYyBu9ZJg4T9j3gLzOCuyuOWJ4Wf5FHcKiw4K34NkkjSYlpMcmxXkAU=; path=/; expires=Mon, 11-Dec-23 00:35:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=iMjtDbae7eW7Jkt3D._jO.8Al4mK3DZJKekBO38FKaw-1702253108798-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397968880c4cde-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:08,805 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:08,806 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:08,807 httpcore.http11 DEBUG receive_response_body.complete
19:05:08,808 httpcore.http11 DEBUG response_closed.started
19:05:08,808 httpcore.http11 DEBUG response_closed.complete
19:05:08,809 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:08,825 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\ncut it on the top side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:08,833 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:08,835 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae33390>
19:05:08,835 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae82720> server_hostname='api.openai.com' timeout=None
19:05:08,840 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae330d0>
19:05:08,840 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:08,841 httpcore.http11 DEBUG send_request_headers.complete
19:05:08,841 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:08,841 httpcore.http11 DEBUG send_request_body.complete
19:05:08,842 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:09,276 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'333'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6fcd2763f6dbaba60f6fea777bdbcd57'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aetaN_7AzM4xIzp5BgKomDridy1Z7dZI2sk6OQBWx94-1702253109-1-ASHVdXjw0WlVFxI+SKtiL6T8rTV/HjsnhqG2OAvJg849NohdDlcBm7qYyRGj8u6Al+8V5Fz0Ujb2L/0t1uY+yLA=; path=/; expires=Mon, 11-Dec-23 00:35:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=DU0NwkrszD9FxxQn_.OhZ9ZcnUWeDC64iKVTZwl5IfI-1702253109272-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339796a48a04d0e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:09,279 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:09,279 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:09,281 httpcore.http11 DEBUG receive_response_body.complete
19:05:09,281 httpcore.http11 DEBUG response_closed.started
19:05:09,281 httpcore.http11 DEBUG response_closed.complete
19:05:09,282 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:09,293 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:09,297 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:15,3 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:15,14 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:15,20 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:19,21 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:19,32 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:19,35 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:21,36 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:21,47 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:21,51 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:24,453 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:24,462 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:24,466 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:30,168 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:30,183 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:30,185 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:33,586 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:33,598 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:33,601 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:38,202 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:38,205 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:05:38,210 httpcore.connection DEBUG close.started
19:05:38,210 httpcore.connection DEBUG close.complete
19:05:38,211 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:38,213 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646cc20b50>
19:05:38,214 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:05:38,220 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac77d10>
19:05:38,220 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:38,221 httpcore.http11 DEBUG send_request_headers.complete
19:05:38,221 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:38,221 httpcore.http11 DEBUG send_request_body.complete
19:05:38,221 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:38,775 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'479'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'649a1c477a4b09aabbc12d8b7934d0c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397a21e8323b69-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:38,777 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:05:38,777 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:39,987 httpcore.http11 DEBUG receive_response_body.complete
19:05:39,988 httpcore.http11 DEBUG response_closed.started
19:05:39,988 httpcore.http11 DEBUG response_closed.complete
19:05:39,989 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:05:40,55 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:05:52,967 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:05:52,970 httpcore.connection DEBUG close.started
19:05:52,970 httpcore.connection DEBUG close.complete
19:05:52,971 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:52,973 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac85d10>
19:05:52,973 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:05:52,980 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac85d90>
19:05:52,981 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:52,981 httpcore.http11 DEBUG send_request_headers.complete
19:05:52,981 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:53,18 httpcore.http11 DEBUG send_request_body.complete
19:05:53,19 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:53,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:53 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'405'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ef68ed35dc140ff690f2103ede31794a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397a7e2f704d07-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:53,823 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:05:53,823 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:53,824 httpcore.http11 DEBUG receive_response_body.complete
19:05:53,824 httpcore.http11 DEBUG response_closed.started
19:05:53,825 httpcore.http11 DEBUG response_closed.complete
19:05:53,825 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:05:53,826 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:05:57,210 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nOh.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:57,213 httpcore.connection DEBUG close.started
19:05:57,213 httpcore.connection DEBUG close.complete
19:05:57,214 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:57,243 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae5bc90>
19:05:57,244 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81f40> server_hostname='api.openai.com' timeout=None
19:05:57,252 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae58790>
19:05:57,252 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:57,254 httpcore.http11 DEBUG send_request_headers.complete
19:05:57,255 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:57,256 httpcore.http11 DEBUG send_request_body.complete
19:05:57,256 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:57,468 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1f20efe55a5d1e0345b937078f96611d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397a98d8c24ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:57,470 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:57,471 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:57,471 httpcore.http11 DEBUG receive_response_body.complete
19:05:57,472 httpcore.http11 DEBUG response_closed.started
19:05:57,472 httpcore.http11 DEBUG response_closed.complete
19:05:57,472 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:02,661 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nOh.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:02,675 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:02,678 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac903d0>
19:06:02,679 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae822a0> server_hostname='api.openai.com' timeout=None
19:06:02,684 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac91050>
19:06:02,684 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:02,685 httpcore.http11 DEBUG send_request_headers.complete
19:06:02,685 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:02,686 httpcore.http11 DEBUG send_request_body.complete
19:06:02,686 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:03,788 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1001'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c44e1303a4034029e11d2ac0cdc146c2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0npIv6NSko5cMLcvxuaJNli2IjCUECXPVCCeDEgppw8-1702253163-1-AUpw/cGcdGii3vElQgkWsjswCx6Jry4LMzS8sWvSThYYeJNPaEzZKP2NFQHSTRvseBKhDeDd9ACPk2YWcy5u5cs=; path=/; expires=Mon, 11-Dec-23 00:36:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fXnQVEzXI2CaEfRmE7apDqRly4HJKj3N6xV3M2i5ahE-1702253163784-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397abacdb13b7c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:03,795 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:03,795 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:03,796 httpcore.http11 DEBUG receive_response_body.complete
19:06:03,797 httpcore.http11 DEBUG response_closed.started
19:06:03,797 httpcore.http11 DEBUG response_closed.complete
19:06:03,797 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:05,38 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:05,47 httpcore.connection DEBUG close.started
19:06:05,48 httpcore.connection DEBUG close.complete
19:06:05,48 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:05,51 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac85c50>
19:06:05,52 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:06:05,60 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac85e90>
19:06:05,61 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:05,63 httpcore.http11 DEBUG send_request_headers.complete
19:06:05,63 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:05,64 httpcore.http11 DEBUG send_request_body.complete
19:06:05,65 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:05,847 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'564'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b9add2be188b537381b5ccd8fa317bd9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397ac9ae394cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:05,853 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:05,854 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:06,803 httpcore.http11 DEBUG receive_response_body.complete
19:06:06,804 httpcore.http11 DEBUG response_closed.started
19:06:06,805 httpcore.http11 DEBUG response_closed.complete
19:06:06,805 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:06,872 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:19,598 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:19,603 httpcore.connection DEBUG close.started
19:06:19,603 httpcore.connection DEBUG close.complete
19:06:19,603 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:19,606 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae47a90>
19:06:19,606 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:06:19,612 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae44810>
19:06:19,612 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:19,613 httpcore.http11 DEBUG send_request_headers.complete
19:06:19,614 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:19,637 httpcore.http11 DEBUG send_request_body.complete
19:06:19,637 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:20,644 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:20 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'8'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'609'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'adceeb6d508d75fd45d5497b71effa72'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397b2498d34cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:20,650 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:20,650 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:20,651 httpcore.http11 DEBUG receive_response_body.complete
19:06:20,651 httpcore.http11 DEBUG response_closed.started
19:06:20,652 httpcore.http11 DEBUG response_closed.complete
19:06:20,652 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:20,652 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:24,513 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nUh, no.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:24,517 httpcore.connection DEBUG close.started
19:06:24,518 httpcore.connection DEBUG close.complete
19:06:24,518 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:24,521 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae5abd0>
19:06:24,521 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81f40> server_hostname='api.openai.com' timeout=None
19:06:24,525 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae5aa50>
19:06:24,526 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:24,527 httpcore.http11 DEBUG send_request_headers.complete
19:06:24,527 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:24,528 httpcore.http11 DEBUG send_request_body.complete
19:06:24,528 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:24,741 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7de66aacde0adf9cc07b444d138ba67a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397b434b6e3074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:24,747 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:24,747 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:24,749 httpcore.http11 DEBUG receive_response_body.complete
19:06:24,749 httpcore.http11 DEBUG response_closed.started
19:06:24,749 httpcore.http11 DEBUG response_closed.complete
19:06:24,750 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:26,789 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nUh, no.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:26,801 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:26,804 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac90e90>
19:06:26,804 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81eb0> server_hostname='api.openai.com' timeout=None
19:06:26,813 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac922d0>
19:06:26,813 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:26,814 httpcore.http11 DEBUG send_request_headers.complete
19:06:26,815 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:26,815 httpcore.http11 DEBUG send_request_body.complete
19:06:26,816 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:27,40 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b23a57b1b0251625c1d98df71dfde876'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=eLZwTFFPiSLwRnPkFp0PFKZZT9RRbiJngEUjxEd7Gwg-1702253187-1-ATwMl4PmTrW9Yd3jhEA+qdKONou/s9/1LJ/fvNaxwy7Uf3jT5EDml0lAE6HLX+mkQZUpuvLrLMvR9QCPtEQbxVU=; path=/; expires=Mon, 11-Dec-23 00:36:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=6MiRwbsX26ULPrnemN6iY.ex.nIWfqaUArcnuhhcA7M-1702253187034-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397b519cc63049-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:27,46 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:27,47 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:27,48 httpcore.http11 DEBUG receive_response_body.complete
19:06:27,48 httpcore.http11 DEBUG response_closed.started
19:06:27,49 httpcore.http11 DEBUG response_closed.complete
19:06:27,49 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:35,32 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit (You can say move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:35,40 httpcore.connection DEBUG close.started
19:06:35,41 httpcore.connection DEBUG close.complete
19:06:35,42 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:35,44 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae44810>
19:06:35,44 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:06:35,48 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae47850>
19:06:35,49 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:35,50 httpcore.http11 DEBUG send_request_headers.complete
19:06:35,50 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:35,50 httpcore.http11 DEBUG send_request_body.complete
19:06:35,51 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:35,566 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a9abb3bb5abb82b9dea3e723652ca976'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397b851be53045-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:35,571 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:35,572 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:36,823 httpcore.http11 DEBUG receive_response_body.complete
19:06:36,824 httpcore.http11 DEBUG response_closed.started
19:06:36,825 httpcore.http11 DEBUG response_closed.complete
19:06:36,826 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:36,897 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:50,5 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:50,9 httpcore.connection DEBUG close.started
19:06:50,10 httpcore.connection DEBUG close.complete
19:06:50,10 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:50,13 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac975d0>
19:06:50,13 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:06:50,19 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac97650>
19:06:50,19 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:50,20 httpcore.http11 DEBUG send_request_headers.complete
19:06:50,21 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:50,45 httpcore.http11 DEBUG send_request_body.complete
19:06:50,45 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:50,931 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:50 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'345'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'098c19f748ac1ec7cc5322b29d2ebb6b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397be2ac786aca-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:50,935 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:50,936 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:50,937 httpcore.http11 DEBUG receive_response_body.complete
19:06:50,937 httpcore.http11 DEBUG response_closed.started
19:06:50,938 httpcore.http11 DEBUG response_closed.complete
19:06:50,938 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:50,939 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:53,491 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit (You can say move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:53,495 httpcore.connection DEBUG close.started
19:06:53,495 httpcore.connection DEBUG close.complete
19:06:53,496 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:53,498 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac954d0>
19:06:53,498 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81eb0> server_hostname='api.openai.com' timeout=None
19:06:53,509 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac94310>
19:06:53,510 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:53,511 httpcore.http11 DEBUG send_request_headers.complete
19:06:53,511 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:53,512 httpcore.http11 DEBUG send_request_body.complete
19:06:53,512 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:53,745 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'192b9517dbf3538510b63ac62462e5b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397bf878384cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:53,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:53,752 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:53,753 httpcore.http11 DEBUG receive_response_body.complete
19:06:53,754 httpcore.http11 DEBUG response_closed.started
19:06:53,754 httpcore.http11 DEBUG response_closed.complete
19:06:53,755 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:58,940 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:58,944 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:02,347 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:07:02,349 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:07:02,351 httpcore.connection DEBUG close.started
19:07:02,351 httpcore.connection DEBUG close.complete
19:07:02,352 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:07:02,381 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac97510>
19:07:02,382 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:07:02,390 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac95e10>
19:07:02,390 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:02,391 httpcore.http11 DEBUG send_request_headers.complete
19:07:02,392 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:02,392 httpcore.http11 DEBUG send_request_body.complete
19:07:02,392 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:03,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:07:03 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'546'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'aea29359e8c3026e1afb29a2b4d70471'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397c2ff94d3008-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:03,25 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:07:03,26 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:03,538 httpcore.http11 DEBUG receive_response_body.complete
19:07:03,539 httpcore.http11 DEBUG response_closed.started
19:07:03,539 httpcore.http11 DEBUG response_closed.complete
19:07:03,540 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:07:03,610 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:07:12,863 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:07:12,868 httpcore.connection DEBUG close.started
19:07:12,868 httpcore.connection DEBUG close.complete
19:07:12,868 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:07:12,871 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646b07a010>
19:07:12,871 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:07:12,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae336d0>
19:07:12,876 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:12,877 httpcore.http11 DEBUG send_request_headers.complete
19:07:12,877 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:12,896 httpcore.http11 DEBUG send_request_body.complete
19:07:12,897 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:13,687 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:07:13 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'335'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'118fd1932b830071819641c7395c6af0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397c717b1c4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:13,689 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:07:13,690 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:13,690 httpcore.http11 DEBUG receive_response_body.complete
19:07:13,691 httpcore.http11 DEBUG response_closed.started
19:07:13,691 httpcore.http11 DEBUG response_closed.complete
19:07:13,692 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:07:13,692 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:07:13,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:07:13,709 httpcore.connection DEBUG close.started
19:07:13,710 httpcore.connection DEBUG close.complete
19:07:13,710 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:07:13,712 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac96ad0>
19:07:13,712 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81eb0> server_hostname='api.openai.com' timeout=None
19:07:13,719 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae474d0>
19:07:13,719 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:13,720 httpcore.http11 DEBUG send_request_headers.complete
19:07:13,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:13,720 httpcore.http11 DEBUG send_request_body.complete
19:07:13,720 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:13,960 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:07:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'142'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'35d0d7388bb26d42af9cb47949ae1b31'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397c76ca594cee-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:13,963 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:07:13,964 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:13,965 httpcore.http11 DEBUG receive_response_body.complete
19:07:13,965 httpcore.http11 DEBUG response_closed.started
19:07:13,965 httpcore.http11 DEBUG response_closed.complete
19:07:13,966 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:10:17,213 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:17,217 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,31 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,32 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,71 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,72 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,113 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,114 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,150 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,151 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,191 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,192 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,229 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,230 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,270 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,271 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,307 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,308 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,347 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:10:18,358 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:10:18,390 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb0a610>
19:10:18,390 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:10:18,401 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb0ab90>
19:10:18,402 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:10:18,404 httpcore.http11 DEBUG send_request_headers.complete
19:10:18,404 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:10:18,404 httpcore.http11 DEBUG send_request_body.complete
19:10:18,405 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:10:18,915 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:10:18 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'402'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5d490dfa44f6f14a787a936e69922df4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LZJybGucfFmLR5hBp_eUm8WSZm5L65ZUt9g7LmKD4Ek-1702253418-1-ASDC2EsgNJRJ193GXXbPKX+ypUUbL3LaleFTbToMPpblsdjNNa+58GZqK8pcg7e3ERO562xAPnetBvsOGZzaNYc=; path=/; expires=Mon, 11-Dec-23 00:40:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=swQjQTXv6Y1v_ThahLWut_wLr4EYnrh0Tj5FLfBoWiQ-1702253418909-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833980f90b394cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:10:18,922 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:10:18,923 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:10:19,421 httpcore.http11 DEBUG receive_response_body.complete
19:10:19,421 httpcore.http11 DEBUG response_closed.started
19:10:19,422 httpcore.http11 DEBUG response_closed.complete
19:10:19,422 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:10:19,494 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:10:33,117 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:10:33,128 httpcore.connection DEBUG close.started
19:10:33,128 httpcore.connection DEBUG close.complete
19:10:33,128 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:10:33,131 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb0ac90>
19:10:33,131 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:10:33,136 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb09fd0>
19:10:33,137 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:10:33,137 httpcore.http11 DEBUG send_request_headers.complete
19:10:33,137 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:10:33,175 httpcore.http11 DEBUG send_request_body.complete
19:10:33,176 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:10:34,9 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:10:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'84d01f3ec7031c2ae88951640902b94e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339815519594cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:10:34,12 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:10:34,12 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:10:34,13 httpcore.http11 DEBUG receive_response_body.complete
19:10:34,14 httpcore.http11 DEBUG response_closed.started
19:10:34,14 httpcore.http11 DEBUG response_closed.complete
19:10:34,14 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:10:34,15 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:10:34,36 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:10:34,46 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:10:34,49 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb5fa90>
19:10:34,49 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99fd0> server_hostname='api.openai.com' timeout=None
19:10:34,54 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb5f210>
19:10:34,54 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:10:34,54 httpcore.http11 DEBUG send_request_headers.complete
19:10:34,55 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:10:34,55 httpcore.http11 DEBUG send_request_body.complete
19:10:34,55 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:10:34,262 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:10:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd2c312ecd0fd90d2f92088f2c5691559'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XZ._7QVjqThqBzCZc7I4QYdw6Y09Id.CraUDJNOi4IQ-1702253434-1-AWnH1nS6NOYyNcEvfwHRnVTMQj1nZNMyFMXYDcVGyDc/lMfRIaYBZ7UeEKIBCmwhaZD+1R7g1XRjEReUMawky8I=; path=/; expires=Mon, 11-Dec-23 00:40:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=hxw_U_uC4RfkR5HM3Bse4DwfnWVjvSvk_LAnuge9Sxo-1702253434257-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339815ad9c84ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:10:34,265 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:10:34,266 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:10:34,266 httpcore.http11 DEBUG receive_response_body.complete
19:10:34,267 httpcore.http11 DEBUG response_closed.started
19:10:34,267 httpcore.http11 DEBUG response_closed.complete
19:10:34,267 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:10:34,285 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:10:34,295 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:10:34,298 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb02d90>
19:10:34,298 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd9a7b0> server_hostname='api.openai.com' timeout=None
19:10:34,308 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb4bf90>
19:10:34,308 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:10:34,309 httpcore.http11 DEBUG send_request_headers.complete
19:10:34,309 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:10:34,309 httpcore.http11 DEBUG send_request_body.complete
19:10:34,310 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:10:35,118 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:10:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'704'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fc56da9d1ef2c819507d3e33fb62c078'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=USq6VtGe5hn_6gjxC9o0.USFNHcNTTUbfzVb8FKeFHM-1702253435-1-AUIq1Oe2SX4c8BeGyG5VSMwz7WBk/3tV7UfvEyWw0N6t7WSchvLvzBvv30DIPCvmqae0yUYcJA/L1hxohz4nm2g=; path=/; expires=Mon, 11-Dec-23 00:40:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RHwP0.OkQDnX07ou3aWMe72tXeLMBZx_0._GsbX75oU-1702253435114-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339815c6f524cf6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:10:35,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:10:35,122 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:10:35,122 httpcore.http11 DEBUG receive_response_body.complete
19:10:35,123 httpcore.http11 DEBUG response_closed.started
19:10:35,123 httpcore.http11 DEBUG response_closed.complete
19:10:35,123 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:10:35,135 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:35,138 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:40,844 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:40,856 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:40,858 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:44,859 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:44,871 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:44,875 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:46,877 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:46,889 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:46,893 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:50,294 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:50,305 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:50,307 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:56,8 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:56,20 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:56,22 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:11:00,223 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:11:00,235 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:11:00,239 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:11:04,440 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:11:04,444 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:11:04,448 httpcore.connection DEBUG close.started
19:11:04,448 httpcore.connection DEBUG close.complete
19:11:04,449 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:04,451 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb09fd0>
19:11:04,451 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:04,458 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb4b610>
19:11:04,459 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:04,460 httpcore.http11 DEBUG send_request_headers.complete
19:11:04,460 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:04,461 httpcore.http11 DEBUG send_request_body.complete
19:11:04,461 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:05,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'545'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4c0412f9f2d4fafd5ddcb53ce48941dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398218ed1a4ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:05,128 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:11:05,128 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:06,235 httpcore.http11 DEBUG receive_response_body.complete
19:11:06,235 httpcore.http11 DEBUG response_closed.started
19:11:06,236 httpcore.http11 DEBUG response_closed.complete
19:11:06,236 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:11:06,301 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:11:19,286 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:11:19,292 httpcore.connection DEBUG close.started
19:11:19,293 httpcore.connection DEBUG close.complete
19:11:19,294 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:19,324 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9de90>
19:11:19,324 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:19,333 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9df10>
19:11:19,333 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:19,334 httpcore.http11 DEBUG send_request_headers.complete
19:11:19,335 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:19,355 httpcore.http11 DEBUG send_request_body.complete
19:11:19,356 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:19,971 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:19 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'354'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1ed6cdaffce3d60a68b7786c24da913c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398275d96b3010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:19,974 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:11:19,974 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:19,975 httpcore.http11 DEBUG receive_response_body.complete
19:11:19,975 httpcore.http11 DEBUG response_closed.started
19:11:19,975 httpcore.http11 DEBUG response_closed.complete
19:11:19,976 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:11:19,976 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:11:22,314 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nOh.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:11:22,318 httpcore.connection DEBUG close.started
19:11:22,318 httpcore.connection DEBUG close.complete
19:11:22,319 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:11:22,321 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb6d090>
19:11:22,321 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99fd0> server_hostname='api.openai.com' timeout=None
19:11:22,326 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb6e3d0>
19:11:22,327 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:22,328 httpcore.http11 DEBUG send_request_headers.complete
19:11:22,328 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:22,329 httpcore.http11 DEBUG send_request_body.complete
19:11:22,329 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:22,531 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5730482f489141ec295f76bba0075e4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833982888a233b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:22,535 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:11:22,536 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:22,537 httpcore.http11 DEBUG receive_response_body.complete
19:11:22,538 httpcore.http11 DEBUG response_closed.started
19:11:22,538 httpcore.http11 DEBUG response_closed.complete
19:11:22,538 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:11:24,759 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nOh.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:11:24,770 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:11:24,773 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9a85d0>
19:11:24,773 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd9a330> server_hostname='api.openai.com' timeout=None
19:11:24,781 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9a8550>
19:11:24,782 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:24,784 httpcore.http11 DEBUG send_request_headers.complete
19:11:24,784 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:24,785 httpcore.http11 DEBUG send_request_body.complete
19:11:24,785 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:26,6 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ebc1359c965e011a6fa1bb5e6d8e7ba2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mhuKJsxI_0iL.juMxcOFpM92dL0037qBgi.0MCaWuuM-1702253486-1-AUsUIWTeeEPgfUsrMn2rS87dAv1Awj9MB8kMt9wk9fKsnwc/xDxs0/GgptdNQ91khKpUR+1foS7dtUpQplE53+s=; path=/; expires=Mon, 11-Dec-23 00:41:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=95Sa335F2n9dF_YueM6XNRKuW22uN07m8g5Kh4UUOLE-1702253486001-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398297ee744cef-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:26,14 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:11:26,15 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:26,17 httpcore.http11 DEBUG receive_response_body.complete
19:11:26,18 httpcore.http11 DEBUG response_closed.started
19:11:26,18 httpcore.http11 DEBUG response_closed.complete
19:11:26,18 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:11:27,383 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:11:27,387 httpcore.connection DEBUG close.started
19:11:27,387 httpcore.connection DEBUG close.complete
19:11:27,388 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:27,390 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb5f3d0>
19:11:27,390 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:27,396 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb5f790>
19:11:27,396 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:27,397 httpcore.http11 DEBUG send_request_headers.complete
19:11:27,398 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:27,398 httpcore.http11 DEBUG send_request_body.complete
19:11:27,398 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:28,95 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:28 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'571'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c4a563a85d747358f9a6f46debcdb37f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833982a838a83031-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:28,99 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:11:28,99 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:29,127 httpcore.http11 DEBUG receive_response_body.complete
19:11:29,128 httpcore.http11 DEBUG response_closed.started
19:11:29,129 httpcore.http11 DEBUG response_closed.complete
19:11:29,130 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:11:29,199 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:11:42,93 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:11:42,98 httpcore.connection DEBUG close.started
19:11:42,99 httpcore.connection DEBUG close.complete
19:11:42,99 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:42,101 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9e250>
19:11:42,102 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:42,107 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9e0d0>
19:11:42,107 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:42,108 httpcore.http11 DEBUG send_request_headers.complete
19:11:42,109 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:42,130 httpcore.http11 DEBUG send_request_body.complete
19:11:42,131 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:42,929 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:42 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'402'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2ea10db861527f1d4492dd03a68b8296'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833983042a4a6ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:42,935 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:11:42,936 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:42,937 httpcore.http11 DEBUG receive_response_body.complete
19:11:42,937 httpcore.http11 DEBUG response_closed.started
19:11:42,938 httpcore.http11 DEBUG response_closed.complete
19:11:42,938 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:11:42,938 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:11:44,745 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:11:44,748 httpcore.connection DEBUG close.started
19:11:44,749 httpcore.connection DEBUG close.complete
19:11:44,749 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:11:44,751 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb6de90>
19:11:44,752 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99fd0> server_hostname='api.openai.com' timeout=None
19:11:44,757 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb6cd50>
19:11:44,758 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:44,759 httpcore.http11 DEBUG send_request_headers.complete
19:11:44,759 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:44,760 httpcore.http11 DEBUG send_request_body.complete
19:11:44,760 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:44,987 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a3ba143a16836bb44b8a444b1eb22896'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398314ba343049-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:44,994 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:11:44,994 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:44,995 httpcore.http11 DEBUG receive_response_body.complete
19:11:44,995 httpcore.http11 DEBUG response_closed.started
19:11:44,996 httpcore.http11 DEBUG response_closed.complete
19:11:44,996 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:11:47,338 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:11:47,349 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:11:47,352 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9f610>
19:11:47,352 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99f40> server_hostname='api.openai.com' timeout=None
19:11:47,359 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb1b510>
19:11:47,359 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:47,361 httpcore.http11 DEBUG send_request_headers.complete
19:11:47,361 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:47,361 httpcore.http11 DEBUG send_request_body.complete
19:11:47,362 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:47,633 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ade5b778b8ad7a61eb56a96fdb69289b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GRcshvpM7rmVWC_BRwWKoIjRONantNguu7AHtEDDBPU-1702253507-1-AY/rIszYphaZU2HMpPuit6LO9RMrGTM48W+QcFGqvWRsDJhyhPWuBouBTG1jBwIru49MjxragjdwYUBMdAHCvTc=; path=/; expires=Mon, 11-Dec-23 00:41:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3BjPo21y.M24TEVsVScq_JbAH0v1h8.kMZ8OHBIOOM4-1702253507628-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833983250c983b7b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:47,641 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:11:47,642 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:47,643 httpcore.http11 DEBUG receive_response_body.complete
19:11:47,643 httpcore.http11 DEBUG response_closed.started
19:11:47,643 httpcore.http11 DEBUG response_closed.complete
19:11:47,644 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:11:59,601 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:11:59,607 httpcore.connection DEBUG close.started
19:11:59,607 httpcore.connection DEBUG close.complete
19:11:59,608 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:59,610 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb71550>
19:11:59,611 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:59,616 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb70310>
19:11:59,616 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:59,617 httpcore.http11 DEBUG send_request_headers.complete
19:11:59,617 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:59,618 httpcore.http11 DEBUG send_request_body.complete
19:11:59,618 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:00,74 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'24e828a0f6c7c08a9de6fddb1dc717d8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833983719c04304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:00,79 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:12:00,80 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:01,152 httpcore.http11 DEBUG receive_response_body.complete
19:12:01,152 httpcore.http11 DEBUG response_closed.started
19:12:01,153 httpcore.http11 DEBUG response_closed.complete
19:12:01,153 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:12:01,223 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:12:13,52 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:12:13,58 httpcore.connection DEBUG close.started
19:12:13,58 httpcore.connection DEBUG close.complete
19:12:13,59 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:12:13,61 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3b10>
19:12:13,61 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:12:13,69 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3310>
19:12:13,70 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:13,71 httpcore.http11 DEBUG send_request_headers.complete
19:12:13,71 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:13,95 httpcore.http11 DEBUG send_request_body.complete
19:12:13,96 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:14,152 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'342'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5e44b9cfa208a8540e6f19041f929e3f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833983c5b8033068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:14,158 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:12:14,159 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:14,161 httpcore.http11 DEBUG receive_response_body.complete
19:12:14,161 httpcore.http11 DEBUG response_closed.started
19:12:14,162 httpcore.http11 DEBUG response_closed.complete
19:12:14,162 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:12:14,163 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:12:28,338 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:12:28,344 httpcore.connection DEBUG close.started
19:12:28,344 httpcore.connection DEBUG close.complete
19:12:28,345 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:12:28,374 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9e1d0>
19:12:28,375 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99f40> server_hostname='api.openai.com' timeout=None
19:12:28,381 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb1b510>
19:12:28,381 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:28,382 httpcore.http11 DEBUG send_request_headers.complete
19:12:28,382 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:28,383 httpcore.http11 DEBUG send_request_body.complete
19:12:28,383 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:28,594 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ef5030c7d9f51b81fa96ef83cbf72b64'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833984256a7d3ba0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:28,598 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:12:28,598 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:28,599 httpcore.http11 DEBUG receive_response_body.complete
19:12:28,599 httpcore.http11 DEBUG response_closed.started
19:12:28,600 httpcore.http11 DEBUG response_closed.complete
19:12:28,600 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:12:34,451 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:12:34,455 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:12:37,857 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:12:37,861 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:12:37,864 httpcore.connection DEBUG close.started
19:12:37,865 httpcore.connection DEBUG close.complete
19:12:37,865 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:12:37,868 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3310>
19:12:37,868 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:12:37,875 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3b50>
19:12:37,875 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:37,876 httpcore.http11 DEBUG send_request_headers.complete
19:12:37,876 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:37,877 httpcore.http11 DEBUG send_request_body.complete
19:12:37,877 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:38,357 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd05c351da20fed9b38cf9b7513cc7c89'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398460b95d4cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:38,360 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:12:38,360 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:39,220 httpcore.http11 DEBUG receive_response_body.complete
19:12:39,221 httpcore.http11 DEBUG response_closed.started
19:12:39,221 httpcore.http11 DEBUG response_closed.complete
19:12:39,222 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:12:39,292 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:12:51,198 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:12:51,200 httpcore.connection DEBUG close.started
19:12:51,200 httpcore.connection DEBUG close.complete
19:12:51,201 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:12:51,203 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9a8ed0>
19:12:51,204 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:12:51,214 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9a8c90>
19:12:51,215 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:51,216 httpcore.http11 DEBUG send_request_headers.complete
19:12:51,216 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:51,244 httpcore.http11 DEBUG send_request_body.complete
19:12:51,245 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:52,111 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:52 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'542'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e2c0aed319c3e168b4c7a4e9b73ef76d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833984b418b34cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:52,113 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:12:52,114 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:52,115 httpcore.http11 DEBUG receive_response_body.complete
19:12:52,116 httpcore.http11 DEBUG response_closed.started
19:12:52,116 httpcore.http11 DEBUG response_closed.complete
19:12:52,116 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:12:52,117 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:12:52,133 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:12:52,135 httpcore.connection DEBUG close.started
19:12:52,135 httpcore.connection DEBUG close.complete
19:12:52,135 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:12:52,137 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3c50>
19:12:52,138 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99f40> server_hostname='api.openai.com' timeout=None
19:12:52,143 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb1b510>
19:12:52,143 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:52,144 httpcore.http11 DEBUG send_request_headers.complete
19:12:52,144 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:52,145 httpcore.http11 DEBUG send_request_body.complete
19:12:52,145 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:52,356 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fb32e7d05e8acb036f731468012e7bb8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833984b9e97e3061-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:52,358 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:12:52,359 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:52,360 httpcore.http11 DEBUG receive_response_body.complete
19:12:52,361 httpcore.http11 DEBUG response_closed.started
19:12:52,361 httpcore.http11 DEBUG response_closed.complete
19:12:52,361 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:13:08,601 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:13:08,606 httpcore.connection DEBUG close.started
19:13:08,606 httpcore.connection DEBUG close.complete
19:13:08,607 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:13:08,609 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3610>
19:13:08,610 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:13:08,616 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3150>
19:13:08,616 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:13:08,617 httpcore.http11 DEBUG send_request_headers.complete
19:13:08,618 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:13:08,618 httpcore.http11 DEBUG send_request_body.complete
19:13:08,618 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:13:09,59 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:13:09 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'355'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6d1a40e83bd7f98a844a56896f4e1552'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398520dd7c4d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:13:09,64 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:13:09,65 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:13:09,877 httpcore.http11 DEBUG receive_response_body.complete
19:13:09,878 httpcore.http11 DEBUG response_closed.started
19:13:09,879 httpcore.http11 DEBUG response_closed.complete
19:13:09,879 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:13:09,948 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:13:21,865 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:13:21,869 httpcore.connection DEBUG close.started
19:13:21,869 httpcore.connection DEBUG close.complete
19:13:21,869 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:13:21,872 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9ab510>
19:13:21,873 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:13:21,880 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9aba50>
19:13:21,880 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:13:21,881 httpcore.http11 DEBUG send_request_headers.complete
19:13:21,881 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:13:21,904 httpcore.http11 DEBUG send_request_body.complete
19:13:21,905 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:13:22,635 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:13:22 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'340'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd51c3d7026d38ca65afc534889edb400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398573ce0d4cc3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:13:22,639 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:13:22,640 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:13:22,641 httpcore.http11 DEBUG receive_response_body.complete
19:13:22,641 httpcore.http11 DEBUG response_closed.started
19:13:22,641 httpcore.http11 DEBUG response_closed.complete
19:13:22,642 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:13:22,643 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:13:25,132 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:13:25,136 httpcore.connection DEBUG close.started
19:13:25,136 httpcore.connection DEBUG close.complete
19:13:25,136 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:13:25,139 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb0ac90>
19:13:25,140 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99f40> server_hostname='api.openai.com' timeout=None
19:13:25,146 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb08290>
19:13:25,146 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:13:25,148 httpcore.http11 DEBUG send_request_headers.complete
19:13:25,148 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:13:25,149 httpcore.http11 DEBUG send_request_body.complete
19:13:25,149 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:13:25,312 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:13:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'76'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cdeccef7287b26585fdf74274d592a1a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833985882b483074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:13:25,318 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:13:25,319 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:13:25,320 httpcore.http11 DEBUG receive_response_body.complete
19:13:25,320 httpcore.http11 DEBUG response_closed.started
19:13:25,320 httpcore.http11 DEBUG response_closed.complete
19:13:25,321 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:14:49,282 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:49,285 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,99 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,100 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,141 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,141 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,183 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,183 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,221 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,222 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,267 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,268 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,307 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,308 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,351 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,352 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,391 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,391 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,433 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:14:50,448 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:14:50,479 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b3033390>
19:14:50,479 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:14:50,489 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2daac90>
19:14:50,489 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:14:50,491 httpcore.http11 DEBUG send_request_headers.complete
19:14:50,491 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:14:50,491 httpcore.http11 DEBUG send_request_body.complete
19:14:50,491 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:14:50,954 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:14:50 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2ab7c188f138885146ed4c3be65b7dca'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=MkFQP08Uw6yJripRKehqDralaYB16igcPEKQFoyZJ70-1702253690-1-AT3m5NDKRq49JxMBkFDhOz0RfjanJQ4UR/ghdIkYpVlnNTVf7s8BPLGdiF+/laKYhwD7isjjViP2RA+76ddMjSE=; path=/; expires=Mon, 11-Dec-23 00:44:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pr3SgU94luGhMpAXfS1JiZS9wgAA4xwky8cT5mTpdeI-1702253690949-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339879d9dea4d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:14:50,961 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:14:50,962 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:14:51,572 httpcore.http11 DEBUG receive_response_body.complete
19:14:51,573 httpcore.http11 DEBUG response_closed.started
19:14:51,574 httpcore.http11 DEBUG response_closed.complete
19:14:51,575 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:14:51,648 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:15:05,164 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:15:05,173 httpcore.connection DEBUG close.started
19:15:05,173 httpcore.connection DEBUG close.complete
19:15:05,174 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:15:05,176 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2daac90>
19:15:05,176 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:15:05,183 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2daa990>
19:15:05,183 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:05,184 httpcore.http11 DEBUG send_request_headers.complete
19:15:05,184 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:05,210 httpcore.http11 DEBUG send_request_body.complete
19:15:05,210 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:07,524 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1808'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6226f6ae3edb71631d27edfafded7ee5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833987f96b354cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:07,526 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:15:07,527 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:07,528 httpcore.http11 DEBUG receive_response_body.complete
19:15:07,528 httpcore.http11 DEBUG response_closed.started
19:15:07,528 httpcore.http11 DEBUG response_closed.complete
19:15:07,529 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:15:07,530 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:15:07,550 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:15:07,557 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:15:07,559 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0d150>
19:15:07,559 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39f40> server_hostname='api.openai.com' timeout=None
19:15:07,567 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0cc90>
19:15:07,567 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:07,568 httpcore.http11 DEBUG send_request_headers.complete
19:15:07,568 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:07,568 httpcore.http11 DEBUG send_request_body.complete
19:15:07,569 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:07,778 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c1e4e4bdfafb70485a87552245475ecc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QjcF4JWv0JZVbMIPsaZVkmrotLCKWaxf5zSSAr_7Bao-1702253707-1-AenMVS26+NpoPRWH3P3KMxd6f8Fqy9R6odzIHKCto1J2T7DGnQvGpKvfZ3PINnb4b7LxzSs5VDKRdBPCOxxz5bE=; path=/; expires=Mon, 11-Dec-23 00:45:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=L.kIw4Byf9LMsdiGLoM.YQsgTWDeHodYhYEihqOoRbE-1702253707775-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833988084b974d16-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:07,780 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:15:07,780 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:07,781 httpcore.http11 DEBUG receive_response_body.complete
19:15:07,782 httpcore.http11 DEBUG response_closed.started
19:15:07,782 httpcore.http11 DEBUG response_closed.complete
19:15:07,782 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:15:07,804 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:15:07,815 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:15:07,817 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0e1d0>
19:15:07,817 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e3a720> server_hostname='api.openai.com' timeout=None
19:15:07,825 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e1c110>
19:15:07,825 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:07,826 httpcore.http11 DEBUG send_request_headers.complete
19:15:07,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:07,827 httpcore.http11 DEBUG send_request_body.complete
19:15:07,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:08,226 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'298'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a596540673445f7b28949a394805e5e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4nllwFMRUrmN2G40MDsL3hP9n0p3ItqtnrKhHNaU_js-1702253708-1-AQjUhwlCT7Kwq8+Y9poozh09pgF6GW9XgqtiwFc/Fkz0ynZCUAij81pVGedb8poJf5Eo3E1eptjEO7SWpXqSDd4=; path=/; expires=Mon, 11-Dec-23 00:45:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=x5SBT_napHMaRMAlUqXqqaW5bs5DYGuEfFSJCTfhY9A-1702253708222-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398809ec624ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:08,229 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:15:08,230 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:08,231 httpcore.http11 DEBUG receive_response_body.complete
19:15:08,231 httpcore.http11 DEBUG response_closed.started
19:15:08,232 httpcore.http11 DEBUG response_closed.complete
19:15:08,232 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:15:08,245 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:08,248 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:13,954 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:13,966 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:13,968 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:17,970 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:17,981 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:17,983 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:19,985 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:19,997 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:20,0 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:23,401 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:23,416 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:23,419 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:29,121 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:29,134 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:29,137 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:32,538 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:32,551 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:32,554 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:36,755 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:36,759 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:15:36,764 httpcore.connection DEBUG close.started
19:15:36,764 httpcore.connection DEBUG close.complete
19:15:36,765 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:15:36,781 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2dcadd0>
19:15:36,782 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:15:36,789 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2daa410>
19:15:36,790 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:36,791 httpcore.http11 DEBUG send_request_headers.complete
19:15:36,791 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:36,792 httpcore.http11 DEBUG send_request_body.complete
19:15:36,792 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:37,457 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:37 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'529'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b1dc3c65b35d475ae98df22c095489e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833988bef8cc4ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:37,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:15:37,460 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:38,476 httpcore.http11 DEBUG receive_response_body.complete
19:15:38,477 httpcore.http11 DEBUG response_closed.started
19:15:38,477 httpcore.http11 DEBUG response_closed.complete
19:15:38,478 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:15:38,542 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:15:51,462 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:15:51,464 httpcore.connection DEBUG close.started
19:15:51,465 httpcore.connection DEBUG close.complete
19:15:51,465 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:15:51,493 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c3e150>
19:15:51,494 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:15:51,503 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c3e1d0>
19:15:51,503 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:51,505 httpcore.http11 DEBUG send_request_headers.complete
19:15:51,505 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:51,516 httpcore.http11 DEBUG send_request_body.complete
19:15:51,516 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:52,457 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:52 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'33'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9b9dace439fd456959227a6cc89d8129'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339891ae8323b9f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:52,460 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:15:52,460 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:52,461 httpcore.http11 DEBUG receive_response_body.complete
19:15:52,462 httpcore.http11 DEBUG response_closed.started
19:15:52,462 httpcore.http11 DEBUG response_closed.complete
19:15:52,462 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:15:52,463 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:15:54,709 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:15:54,713 httpcore.connection DEBUG close.started
19:15:54,713 httpcore.connection DEBUG close.complete
19:15:54,714 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:15:54,716 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0cc90>
19:15:54,717 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39f40> server_hostname='api.openai.com' timeout=None
19:15:54,723 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0cd50>
19:15:54,723 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:54,724 httpcore.http11 DEBUG send_request_headers.complete
19:15:54,725 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:54,725 httpcore.http11 DEBUG send_request_body.complete
19:15:54,726 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:54,944 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd595857be0774895d4acf0888fab8a8f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339892f098f4cc8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:54,951 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:15:54,952 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:54,954 httpcore.http11 DEBUG receive_response_body.complete
19:15:54,954 httpcore.http11 DEBUG response_closed.started
19:15:54,955 httpcore.http11 DEBUG response_closed.complete
19:15:54,955 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:15:57,772 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:15:57,785 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:15:57,788 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c49c90>
19:15:57,789 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e3a2a0> server_hostname='api.openai.com' timeout=None
19:15:57,796 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c49d10>
19:15:57,797 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:57,798 httpcore.http11 DEBUG send_request_headers.complete
19:15:57,799 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:57,799 httpcore.http11 DEBUG send_request_body.complete
19:15:57,799 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:58,788 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'900'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'81b42bdc118286991e0163fc79559690'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lq47OOELNs_4CK8WS3cCn4PE7a1IpOvaqKqSMj5SSq4-1702253758-1-AUMD33gPBIZS28dZ1YVZa+3BCwE8VW6/vi/Jae/+kXTknCqBeus435FLLucfhy6Ybj2GEiUKLMQ7SaN8tu8BEz4=; path=/; expires=Mon, 11-Dec-23 00:45:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qHiD3sEYWFoTfe5uFFNlocb99IqZ.KLXYAsrjpDHtaA-1702253758784-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833989423cfb4d06-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:58,794 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:15:58,795 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:58,797 httpcore.http11 DEBUG receive_response_body.complete
19:15:58,797 httpcore.http11 DEBUG response_closed.started
19:15:58,798 httpcore.http11 DEBUG response_closed.complete
19:15:58,798 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:16:00,825 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:16:00,831 httpcore.connection DEBUG close.started
19:16:00,831 httpcore.connection DEBUG close.complete
19:16:00,832 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:16:00,834 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c3e090>
19:16:00,834 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:16:00,842 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c499d0>
19:16:00,843 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:16:00,845 httpcore.http11 DEBUG send_request_headers.complete
19:16:00,845 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:16:00,846 httpcore.http11 DEBUG send_request_body.complete
19:16:00,846 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:16:01,368 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:16:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'036538c30ee0178d8eb7e7ba1bbbcd6a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833989554b804d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:16:01,373 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:16:01,374 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:16:02,511 httpcore.http11 DEBUG receive_response_body.complete
19:16:02,512 httpcore.http11 DEBUG response_closed.started
19:16:02,513 httpcore.http11 DEBUG response_closed.complete
19:16:02,514 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:16:02,583 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:16:15,477 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:16:15,483 httpcore.connection DEBUG close.started
19:16:15,483 httpcore.connection DEBUG close.complete
19:16:15,484 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:16:15,486 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2dd9990>
19:16:15,487 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:16:15,493 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2dd8150>
19:16:15,494 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:16:15,495 httpcore.http11 DEBUG send_request_headers.complete
19:16:15,495 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:16:15,520 httpcore.http11 DEBUG send_request_body.complete
19:16:15,521 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:16:16,337 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:16:16 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'32'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'344'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7f77996282e38619049111b771844d01'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833989b0df824ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:16:16,341 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:16:16,342 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:16:16,344 httpcore.http11 DEBUG receive_response_body.complete
19:16:16,344 httpcore.http11 DEBUG response_closed.started
19:16:16,345 httpcore.http11 DEBUG response_closed.complete
19:16:16,346 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:16:16,346 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:17:39,730 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:39,734 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,549 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,550 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,592 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,593 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,641 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,642 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,682 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,683 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,732 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,733 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,773 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,774 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,821 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,822 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,863 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,864 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:41,649 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:17:41,669 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:17:41,700 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c9c9a50>
19:17:41,701 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:17:41,709 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c753cd0>
19:17:41,711 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:17:41,714 httpcore.http11 DEBUG send_request_headers.complete
19:17:41,715 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:17:41,716 httpcore.http11 DEBUG send_request_body.complete
19:17:41,716 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:17:42,234 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:17:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'401'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'eb0bdf9975b090f4aaa0b093f55da1d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ZexuZSwdSjJeteQNxZAv5ilk5tzrJFUjA5Lqg.RKnL4-1702253862-1-AS5OpTK9E7cqQtL+umZgPkQ8+O8/tevcHJxDAGeh0cPEiXPljDFx2ZBwWofyzk10dqren9VnbV+TOvINHwLthrA=; path=/; expires=Mon, 11-Dec-23 00:47:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=02KGEy0lMVmBQwRFm3L4YknJTAE2VWymN1I7K2JJWmA-1702253862228-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398bcbbc2f4ce2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:17:42,244 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:17:42,244 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:17:43,47 httpcore.http11 DEBUG receive_response_body.complete
19:17:43,48 httpcore.http11 DEBUG response_closed.started
19:17:43,49 httpcore.http11 DEBUG response_closed.complete
19:17:43,50 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:17:43,134 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:17:56,912 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:17:56,923 httpcore.connection DEBUG close.started
19:17:56,924 httpcore.connection DEBUG close.complete
19:17:56,924 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:17:56,927 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c753cd0>
19:17:56,927 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:17:56,935 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c752f90>
19:17:56,935 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:17:56,936 httpcore.http11 DEBUG send_request_headers.complete
19:17:56,937 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:17:56,967 httpcore.http11 DEBUG send_request_body.complete
19:17:56,968 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:17:57,849 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:17:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'db9f1e608dd6c1c63a4d512e90870d89'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398c2adc814cf2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:17:57,854 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:17:57,855 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:17:57,855 httpcore.http11 DEBUG receive_response_body.complete
19:17:57,856 httpcore.http11 DEBUG response_closed.started
19:17:57,856 httpcore.http11 DEBUG response_closed.complete
19:17:57,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:17:57,857 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:17:57,892 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:17:57,903 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:17:57,906 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0d10>
19:17:57,906 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5fd0> server_hostname='api.openai.com' timeout=None
19:17:57,913 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0cd0>
19:17:57,914 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:17:57,915 httpcore.http11 DEBUG send_request_headers.complete
19:17:57,915 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:17:57,916 httpcore.http11 DEBUG send_request_body.complete
19:17:57,916 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:17:58,113 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:17:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9688e1c2594d97a7a7d401ffdc3a3ad3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=oJb0mPIgSqi7sXkdmWaHtLNsCpI66VBdOV8IxiH6fCk-1702253878-1-AalAJJQskCThZNASThGpq3XQh3hBVFMBcdlAS7xF+dTGl5mxW6EFPy2jbFVQiuEOqvefwRyh1z3iUsLFwF6Y5Bg=; path=/; expires=Mon, 11-Dec-23 00:47:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=PkshBTyzcP4hT77dfrgI0pOHQITLnF5jnTPYtDMwwoE-1702253878108-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398c30ff134ced-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:17:58,120 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:17:58,121 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:17:58,122 httpcore.http11 DEBUG receive_response_body.complete
19:17:58,122 httpcore.http11 DEBUG response_closed.started
19:17:58,123 httpcore.http11 DEBUG response_closed.complete
19:17:58,123 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:17:58,159 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:17:58,169 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:17:58,172 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b83d0>
19:17:58,173 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d67b0> server_hostname='api.openai.com' timeout=None
19:17:58,178 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b1890>
19:17:58,179 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:17:58,180 httpcore.http11 DEBUG send_request_headers.complete
19:17:58,180 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:17:58,181 httpcore.http11 DEBUG send_request_body.complete
19:17:58,181 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:17:58,939 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:17:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'645'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'56f74994df1f38cb6b9053c32d8e8332'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=wHFZcABNZBB97UhqangS6hDpjVzabA86dCJ1ADYdmQY-1702253878-1-AT//g3lV/EvEBn3j0twAydTJb0A9Q/ZjYhqtTM5XKqQA5lq/QxH/crkXRpyGCc0k2zW+jRFrsGETNa9uu76TZ6Q=; path=/; expires=Mon, 11-Dec-23 00:47:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=5FEgdi_fCco6jTJ29VK_Ycmb_rwXaU61mHF.0GTNjrs-1702253878936-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398c32af124ce0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:17:58,946 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:17:58,947 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:17:58,949 httpcore.http11 DEBUG receive_response_body.complete
19:17:58,950 httpcore.http11 DEBUG response_closed.started
19:17:58,950 httpcore.http11 DEBUG response_closed.complete
19:17:58,951 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:17:58,970 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:17:58,974 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:04,682 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:04,695 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:04,698 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:09,400 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:09,421 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:09,424 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:11,426 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:11,443 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:11,446 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:14,851 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:14,864 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:14,868 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:20,570 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:20,589 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:20,592 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:24,794 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:24,808 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:24,811 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:29,13 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:29,21 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:18:29,27 httpcore.connection DEBUG close.started
19:18:29,28 httpcore.connection DEBUG close.complete
19:18:29,28 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:18:29,31 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1e44ac10>
19:18:29,31 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:18:29,37 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7cf290>
19:18:29,37 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:29,38 httpcore.http11 DEBUG send_request_headers.complete
19:18:29,39 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:29,39 httpcore.http11 DEBUG send_request_body.complete
19:18:29,40 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:29,712 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:29 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'430'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'70b4873c27fb044d9d3ccc9481b77cf2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398cf37b764d02-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:29,716 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:18:29,718 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:30,802 httpcore.http11 DEBUG receive_response_body.complete
19:18:30,803 httpcore.http11 DEBUG response_closed.started
19:18:30,803 httpcore.http11 DEBUG response_closed.complete
19:18:30,804 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:18:30,869 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:18:43,754 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:18:43,759 httpcore.connection DEBUG close.started
19:18:43,760 httpcore.connection DEBUG close.complete
19:18:43,760 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:18:43,789 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e2750>
19:18:43,790 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:18:43,799 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e27d0>
19:18:43,800 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:43,802 httpcore.http11 DEBUG send_request_headers.complete
19:18:43,802 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:43,821 httpcore.http11 DEBUG send_request_body.complete
19:18:43,822 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:44,564 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:44 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'33'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'faec38cb6db2a3482cfa457d68be4167'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398d4fce383b7c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:44,569 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:18:44,570 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:44,572 httpcore.http11 DEBUG receive_response_body.complete
19:18:44,572 httpcore.http11 DEBUG response_closed.started
19:18:44,573 httpcore.http11 DEBUG response_closed.complete
19:18:44,574 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:18:44,575 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:18:47,48 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:18:47,52 httpcore.connection DEBUG close.started
19:18:47,52 httpcore.connection DEBUG close.complete
19:18:47,52 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:18:47,55 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0cd0>
19:18:47,55 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5fd0> server_hostname='api.openai.com' timeout=None
19:18:47,61 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b02d0>
19:18:47,62 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:47,63 httpcore.http11 DEBUG send_request_headers.complete
19:18:47,63 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:47,63 httpcore.http11 DEBUG send_request_body.complete
19:18:47,64 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:47,271 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dd414abcf9a0ed1c66411810cdac394c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398d642ae64d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:47,277 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:18:47,278 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:47,279 httpcore.http11 DEBUG receive_response_body.complete
19:18:47,279 httpcore.http11 DEBUG response_closed.started
19:18:47,280 httpcore.http11 DEBUG response_closed.complete
19:18:47,280 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:18:49,706 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:18:49,719 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:18:49,722 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7f1450>
19:18:49,722 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d6330> server_hostname='api.openai.com' timeout=None
19:18:49,729 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7f1410>
19:18:49,730 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:49,731 httpcore.http11 DEBUG send_request_headers.complete
19:18:49,731 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:49,732 httpcore.http11 DEBUG send_request_body.complete
19:18:49,732 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:50,905 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1076'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'76e54168b06c28d57d444b7efd3c9cb6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fOgOuYfcz2M3jhVwrJZvRPRDpmKfye.lkxa62YBcO8s-1702253930-1-Aej5ptzgMFdtQEvYP5lD5pNcPP0/khTUoHKM8rb0D9dWKJV4SttZKcbGzEtm2y+Plt5iEM43GykQwVLIEsyh1qY=; path=/; expires=Mon, 11-Dec-23 00:48:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=cqU5YGvwHGPTfIyrj4bBcJMm.Yr4W.bHATFjUSNdHpM-1702253930901-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398d74ddc93b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:50,912 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:18:50,913 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:50,914 httpcore.http11 DEBUG receive_response_body.complete
19:18:50,914 httpcore.http11 DEBUG response_closed.started
19:18:50,915 httpcore.http11 DEBUG response_closed.complete
19:18:50,915 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:18:51,677 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:18:51,682 httpcore.connection DEBUG close.started
19:18:51,682 httpcore.connection DEBUG close.complete
19:18:51,683 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:18:51,686 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e2690>
19:18:51,686 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:18:51,692 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e3d10>
19:18:51,693 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:51,694 httpcore.http11 DEBUG send_request_headers.complete
19:18:51,694 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:51,694 httpcore.http11 DEBUG send_request_body.complete
19:18:51,695 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:52,252 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'462'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2788f663dc024e6fbcf76c4fd8cbac45'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398d81191f4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:52,256 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:18:52,256 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:53,918 httpcore.http11 DEBUG receive_response_body.complete
19:18:53,919 httpcore.http11 DEBUG response_closed.started
19:18:53,920 httpcore.http11 DEBUG response_closed.complete
19:18:53,921 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:18:53,986 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:19:10,26 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:19:10,31 httpcore.connection DEBUG close.started
19:19:10,31 httpcore.connection DEBUG close.complete
19:19:10,31 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:19:10,34 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7ccfd0>
19:19:10,34 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:19:10,44 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7cf090>
19:19:10,44 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:10,45 httpcore.http11 DEBUG send_request_headers.complete
19:19:10,46 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:10,66 httpcore.http11 DEBUG send_request_body.complete
19:19:10,66 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:10,899 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:10 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'93df7b9ba2ebb651d45f32d791342c40'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398df3cd0d3b8d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:10,904 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:19:10,905 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:10,906 httpcore.http11 DEBUG receive_response_body.complete
19:19:10,907 httpcore.http11 DEBUG response_closed.started
19:19:10,907 httpcore.http11 DEBUG response_closed.complete
19:19:10,908 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:19:10,909 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:19:13,966 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:19:13,973 httpcore.connection DEBUG close.started
19:19:13,974 httpcore.connection DEBUG close.complete
19:19:13,974 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:19:13,977 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0d90>
19:19:13,978 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5fd0> server_hostname='api.openai.com' timeout=None
19:19:13,986 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0c90>
19:19:13,986 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:13,987 httpcore.http11 DEBUG send_request_headers.complete
19:19:13,987 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:13,988 httpcore.http11 DEBUG send_request_body.complete
19:19:13,988 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:14,201 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c5fdc8af31e21b5d3ecab103986ded4b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398e0c6c3a4d1d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:14,205 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:19:14,206 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:14,207 httpcore.http11 DEBUG receive_response_body.complete
19:19:14,208 httpcore.http11 DEBUG response_closed.started
19:19:14,208 httpcore.http11 DEBUG response_closed.complete
19:19:14,209 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:19:16,492 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:19:16,505 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:19:16,508 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7bbd10>
19:19:16,508 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5f40> server_hostname='api.openai.com' timeout=None
19:19:16,514 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7badd0>
19:19:16,514 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:16,515 httpcore.http11 DEBUG send_request_headers.complete
19:19:16,515 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:16,516 httpcore.http11 DEBUG send_request_body.complete
19:19:16,516 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:16,708 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'96'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'487bb9ae7187fa669bb9d1d7071fc042'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pQyNsUp0OZb3YrNYuO3V8WzYl00FZ29zCpxaBtpJdxk-1702253956-1-AV3RshiYZF13x0xMQOT4taWsQrmxTuWYOaZhhFRoWmI64FGvlluKGaMKK9aMFFkQx6DL38cmruHANNaRAVX1ASI=; path=/; expires=Mon, 11-Dec-23 00:49:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1Wf6LzaSDfzPte2d57LYXG6PP3eJClXV_PRiUG1jwh8-1702253956704-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398e1c3fee4cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:16,716 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:19:16,717 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:16,720 httpcore.http11 DEBUG receive_response_body.complete
19:19:16,721 httpcore.http11 DEBUG response_closed.started
19:19:16,722 httpcore.http11 DEBUG response_closed.complete
19:19:16,722 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:19:24,441 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:19:24,444 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:19:27,845 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:19:27,849 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:19:27,853 httpcore.connection DEBUG close.started
19:19:27,853 httpcore.connection DEBUG close.complete
19:19:27,853 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:19:27,856 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c79ddd0>
19:19:27,856 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:19:27,863 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c79fd10>
19:19:27,864 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:27,864 httpcore.http11 DEBUG send_request_headers.complete
19:19:27,864 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:27,865 httpcore.http11 DEBUG send_request_body.complete
19:19:27,865 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:28,395 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:28 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a216955114d1b8a768f9da8258f34c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398e6328b64cd2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:28,397 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:19:28,398 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:29,387 httpcore.http11 DEBUG receive_response_body.complete
19:19:29,388 httpcore.http11 DEBUG response_closed.started
19:19:29,388 httpcore.http11 DEBUG response_closed.complete
19:19:29,389 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:19:29,453 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:19:42,481 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:19:42,485 httpcore.connection DEBUG close.started
19:19:42,485 httpcore.connection DEBUG close.complete
19:19:42,486 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:19:42,488 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e1410>
19:19:42,489 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:19:42,498 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e3410>
19:19:42,498 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:42,499 httpcore.http11 DEBUG send_request_headers.complete
19:19:42,499 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:42,519 httpcore.http11 DEBUG send_request_body.complete
19:19:42,519 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:43,301 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:43 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'375'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b13dd1940fee99287c27d0ed5f9c6cd7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398ebe9aef4ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:43,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:19:43,304 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:43,305 httpcore.http11 DEBUG receive_response_body.complete
19:19:43,305 httpcore.http11 DEBUG response_closed.started
19:19:43,306 httpcore.http11 DEBUG response_closed.complete
19:19:43,306 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:19:43,306 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:19:43,322 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:19:43,324 httpcore.connection DEBUG close.started
19:19:43,324 httpcore.connection DEBUG close.complete
19:19:43,324 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:19:43,326 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7ee6d0>
19:19:43,327 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5f40> server_hostname='api.openai.com' timeout=None
19:19:43,333 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7eeb10>
19:19:43,333 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:43,334 httpcore.http11 DEBUG send_request_headers.complete
19:19:43,334 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:43,334 httpcore.http11 DEBUG send_request_body.complete
19:19:43,334 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:43,562 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'114'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e2fd3f926691a60009aaff9a62f400b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398ec3db6b4ce0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:43,565 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:19:43,565 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:43,566 httpcore.http11 DEBUG receive_response_body.complete
19:19:43,567 httpcore.http11 DEBUG response_closed.started
19:19:43,567 httpcore.http11 DEBUG response_closed.complete
19:19:43,567 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:19:43,577 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:19:43,581 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:19:46,982 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:19:46,996 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:19:46,998 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:19:48,999 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:19:49,12 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:19:49,14 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:19:52,416 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:19:52,420 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:19:52,424 httpcore.connection DEBUG close.started
19:19:52,425 httpcore.connection DEBUG close.complete
19:19:52,425 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:19:52,454 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7ee9d0>
19:19:52,455 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:19:52,461 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7ef290>
19:19:52,461 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:52,462 httpcore.http11 DEBUG send_request_headers.complete
19:19:52,463 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:52,463 httpcore.http11 DEBUG send_request_body.complete
19:19:52,463 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:52,892 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e48af9c5f7d6b3a1e7a4a972085c29db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398efcedd34ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:52,894 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:19:52,895 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:53,244 httpcore.http11 DEBUG receive_response_body.complete
19:19:53,245 httpcore.http11 DEBUG response_closed.started
19:19:53,245 httpcore.http11 DEBUG response_closed.complete
19:19:53,246 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:19:53,317 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:22:01,267 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:01,272 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,100 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,101 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,141 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,142 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,182 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,183 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,220 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,221 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,262 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,263 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,301 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,302 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,344 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,345 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,382 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,383 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,424 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:22:02,436 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:22:02,467 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5659f39f10>
19:22:02,468 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f5659d41d90> server_hostname='api.openai.com' timeout=5.0
19:22:02,474 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5659cb6990>
19:22:02,475 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:02,478 httpcore.http11 DEBUG send_request_headers.complete
19:22:02,478 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:02,479 httpcore.http11 DEBUG send_request_body.complete
19:22:02,479 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:02,939 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:02 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4e846bf9d38ea6f9c1ef454758339dc5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=d01v3Cv4aF0lUkU1tTWMeRjjNI4p5j5v63fu6oKmSsU-1702254122-1-AViGSdFZL7JuRsSWw4VEKDD8hDZcVOT5LQf/rnUc19dUx9Cmdmlk+GML6vaXFK5wey1tK4j20yRkAoC4bNqOF1U=; path=/; expires=Mon, 11-Dec-23 00:52:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=jt00WE01edee3u8RN.zl5fILhhX5nXnr_aQXFPT7rEI-1702254122934-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833992297df63b8e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:02,946 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:22:02,947 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:03,836 httpcore.http11 DEBUG receive_response_body.complete
19:22:03,836 httpcore.http11 DEBUG response_closed.started
19:22:03,837 httpcore.http11 DEBUG response_closed.complete
19:22:03,838 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:22:03,911 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:22:20,706 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:20,708 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,520 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,521 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,563 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,564 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,611 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,612 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,652 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,653 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,700 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,701 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,742 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,743 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,791 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,792 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,833 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,834 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:39,802 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:22:39,818 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:22:39,821 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff7050>
19:22:39,821 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:22:39,827 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff7690>
19:22:39,828 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:39,829 httpcore.http11 DEBUG send_request_headers.complete
19:22:39,829 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:39,829 httpcore.http11 DEBUG send_request_body.complete
19:22:39,829 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:40,320 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2177fa04c2e624c9f627d40207e6b1c5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9WncUoexr8J_zQBKTiPzmzk7qKc8KmERYdmUprhELgA-1702254160-1-AQCBMXVhQUtuK5CT8r/MFWFuFJCXbrUnUayiUSoHj3UpC9v0WmBNHkIPIOnDeZQUcM1oJiHrIjRSjiC6K51IdoI=; path=/; expires=Mon, 11-Dec-23 00:52:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1RaLLMnsB236E.R6unv5znE36df_fKslyLBZFL2W0ww-1702254160314-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399312eb2e3bab-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:40,327 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:22:40,328 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:41,95 httpcore.http11 DEBUG receive_response_body.complete
19:22:41,96 httpcore.http11 DEBUG response_closed.started
19:22:41,96 httpcore.http11 DEBUG response_closed.complete
19:22:41,97 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:22:41,169 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:22:54,924 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:22:54,931 httpcore.connection DEBUG close.started
19:22:54,931 httpcore.connection DEBUG close.complete
19:22:54,931 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:22:54,934 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff7710>
19:22:54,934 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:22:54,946 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff6790>
19:22:54,947 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:54,948 httpcore.http11 DEBUG send_request_headers.complete
19:22:54,948 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:55,0 httpcore.http11 DEBUG send_request_body.complete
19:22:55,0 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:55,984 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:55 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'420'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'85b02cc36aab6aa657173fdbe2559628'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833993716a6a4d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:55,987 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:22:55,987 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:55,988 httpcore.http11 DEBUG receive_response_body.complete
19:22:55,988 httpcore.http11 DEBUG response_closed.started
19:22:55,989 httpcore.http11 DEBUG response_closed.complete
19:22:55,989 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:22:55,990 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:22:56,7 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:22:56,16 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:22:56,18 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e45090>
19:22:56,18 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:22:56,22 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e45050>
19:22:56,22 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:56,23 httpcore.http11 DEBUG send_request_headers.complete
19:22:56,23 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:56,23 httpcore.http11 DEBUG send_request_body.complete
19:22:56,23 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:56,233 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6f2f90e4cb38b2b6250715b136015ffc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=p8B8aPrnMjTtTRY72SCYfnWH.eROApi6jjJfy6fIvxc-1702254176-1-AeaJsCWQ+mIhYr3nDe1ewNbpZNikkbMcEyTDdWVSzK6ZbYXEJinOxGNPxhtXIVDW8YyFXVAJEWu3tjV+k0jepVE=; path=/; expires=Mon, 11-Dec-23 00:52:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=bd0SUxcrqq4czscH5xSnqGoikz7aUISD2QIdrwas1Ik-1702254176230-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833993782ccc6ac9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:56,236 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:22:56,237 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:56,238 httpcore.http11 DEBUG receive_response_body.complete
19:22:56,238 httpcore.http11 DEBUG response_closed.started
19:22:56,238 httpcore.http11 DEBUG response_closed.complete
19:22:56,238 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:22:56,257 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:22:56,265 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:22:56,267 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5d150>
19:22:56,267 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308072720> server_hostname='api.openai.com' timeout=None
19:22:56,273 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5dd50>
19:22:56,273 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:56,274 httpcore.http11 DEBUG send_request_headers.complete
19:22:56,274 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:56,274 httpcore.http11 DEBUG send_request_body.complete
19:22:56,275 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:57,26 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'641'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'404252409f32fccf882558f3c1480963'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=x5yfz7Y9bTkVW6ShymPwM7MnLeb2ydVmd7wwuqAp5yg-1702254177-1-AaMVe9qqlrnO4WeUxvQmEjlc2bLKSlTVPV067EX1UF8ToQoBfNpCdPXplP51fPrvaKEunzkhIDrxvZyhy21BmYc=; path=/; expires=Mon, 11-Dec-23 00:52:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=o0ujnLAAPSgGiUFQ8paHQIeiP6Yw1.sZTYwR3qtKPJw-1702254177022-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399379bf0e4cf8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:57,29 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:22:57,30 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:57,31 httpcore.http11 DEBUG receive_response_body.complete
19:22:57,32 httpcore.http11 DEBUG response_closed.started
19:22:57,32 httpcore.http11 DEBUG response_closed.complete
19:22:57,32 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:22:57,45 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:22:57,49 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:02,757 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:02,767 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:02,770 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:07,472 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:07,484 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:07,487 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:09,488 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:09,501 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:09,502 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:12,904 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:12,916 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:12,918 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:18,619 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:18,630 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:18,634 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:22,835 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:22,846 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:22,849 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:27,50 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:27,54 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:23:27,58 httpcore.connection DEBUG close.started
19:23:27,58 httpcore.connection DEBUG close.complete
19:23:27,58 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:23:27,88 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff6790>
19:23:27,88 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:23:27,98 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e35990>
19:23:27,99 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:27,100 httpcore.http11 DEBUG send_request_headers.complete
19:23:27,100 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:27,101 httpcore.http11 DEBUG send_request_body.complete
19:23:27,101 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:27,614 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7c94656bea0a69da7cc439af74b9fa7a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339943a68204d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:27,615 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:23:27,616 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:28,643 httpcore.http11 DEBUG receive_response_body.complete
19:23:28,644 httpcore.http11 DEBUG response_closed.started
19:23:28,644 httpcore.http11 DEBUG response_closed.complete
19:23:28,645 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:23:28,715 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:23:41,690 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:23:41,692 httpcore.connection DEBUG close.started
19:23:41,692 httpcore.connection DEBUG close.complete
19:23:41,693 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:23:41,695 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7bd50>
19:23:41,695 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:23:41,702 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7bdd0>
19:23:41,702 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:41,703 httpcore.http11 DEBUG send_request_headers.complete
19:23:41,703 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:41,723 httpcore.http11 DEBUG send_request_body.complete
19:23:41,724 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:42,616 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:42 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'33'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'444'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1657bdc658cf694c25d822fb73de5851'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399495adcc4ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:42,618 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:23:42,618 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:42,619 httpcore.http11 DEBUG receive_response_body.complete
19:23:42,619 httpcore.http11 DEBUG response_closed.started
19:23:42,620 httpcore.http11 DEBUG response_closed.complete
19:23:42,620 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:23:42,621 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:23:42,638 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:23:42,640 httpcore.connection DEBUG close.started
19:23:42,640 httpcore.connection DEBUG close.complete
19:23:42,640 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:23:42,643 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e45050>
19:23:42,643 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:23:42,650 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e450d0>
19:23:42,650 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:42,651 httpcore.http11 DEBUG send_request_headers.complete
19:23:42,651 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:42,651 httpcore.http11 DEBUG send_request_body.complete
19:23:42,652 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:42,869 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a6ab88b62a3985c8fbc778409a71a479'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339949b9adc3068-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:42,873 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:23:42,873 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:42,874 httpcore.http11 DEBUG receive_response_body.complete
19:23:42,874 httpcore.http11 DEBUG response_closed.started
19:23:42,875 httpcore.http11 DEBUG response_closed.complete
19:23:42,875 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:23:42,892 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:23:42,902 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:23:42,905 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7e5d0>
19:23:42,905 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff3080722a0> server_hostname='api.openai.com' timeout=None
19:23:42,912 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7e0d0>
19:23:42,912 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:42,913 httpcore.http11 DEBUG send_request_headers.complete
19:23:42,913 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:42,913 httpcore.http11 DEBUG send_request_body.complete
19:23:42,913 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:43,878 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'867'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'eec537e554c3cabafd4bebea5f94292b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=f2xuTtTueZZUvb6LbbiNWGc4RfghtmhR_q5RzawNO5w-1702254223-1-Afnj5zbRlfPocz5NRjkZ1IsySMVm6kI7fGVgPMCdjGmBrme3PBstMPyFaSn37ed+17pUICbs2AlotF5nz0xbvgA=; path=/; expires=Mon, 11-Dec-23 00:53:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kxnHky3QXOcgmuOuV7Nrba3eg2hUcyh4nayBhhvwQTc-1702254223874-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339949d3f544d14-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:43,882 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:23:43,882 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:43,883 httpcore.http11 DEBUG receive_response_body.complete
19:23:43,884 httpcore.http11 DEBUG response_closed.started
19:23:43,884 httpcore.http11 DEBUG response_closed.complete
19:23:43,884 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:23:43,888 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:23:43,890 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:43,891 httpcore.http11 DEBUG send_request_headers.complete
19:23:43,891 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:43,891 httpcore.http11 DEBUG send_request_body.complete
19:23:43,891 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:44,453 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:44 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'486'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd2777b978b6a85b045248da1b5c15d13'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833994a35cf74ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:44,455 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:23:44,455 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:46,206 httpcore.http11 DEBUG receive_response_body.complete
19:23:46,206 httpcore.http11 DEBUG response_closed.started
19:23:46,207 httpcore.http11 DEBUG response_closed.complete
19:23:46,207 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:23:46,279 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:24:02,277 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:24:02,280 httpcore.connection DEBUG close.started
19:24:02,280 httpcore.connection DEBUG close.complete
19:24:02,280 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:24:02,283 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89990>
19:24:02,283 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:24:02,291 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89a10>
19:24:02,291 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:02,292 httpcore.http11 DEBUG send_request_headers.complete
19:24:02,292 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:02,313 httpcore.http11 DEBUG send_request_body.complete
19:24:02,313 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:03,291 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:03 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'553'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b6458e1a8ead35edfe254344603eafa5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833995165e454d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:03,293 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:24:03,294 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:03,295 httpcore.http11 DEBUG receive_response_body.complete
19:24:03,295 httpcore.http11 DEBUG response_closed.started
19:24:03,296 httpcore.http11 DEBUG response_closed.complete
19:24:03,296 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:24:03,297 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:24:03,313 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nOK.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:03,315 httpcore.connection DEBUG close.started
19:24:03,316 httpcore.connection DEBUG close.complete
19:24:03,316 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:03,318 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8cb50>
19:24:03,319 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:24:03,329 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8cbd0>
19:24:03,330 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:03,331 httpcore.http11 DEBUG send_request_headers.complete
19:24:03,331 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:03,331 httpcore.http11 DEBUG send_request_body.complete
19:24:03,332 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:03,549 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'96'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b87b3d0c9b1379604fdce6f0dd6c2fe7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339951cd9204cf4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:03,551 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:03,552 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:03,553 httpcore.http11 DEBUG receive_response_body.complete
19:24:03,554 httpcore.http11 DEBUG response_closed.started
19:24:03,554 httpcore.http11 DEBUG response_closed.complete
19:24:03,554 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:03,575 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nOK.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:03,577 httpcore.connection DEBUG close.started
19:24:03,577 httpcore.connection DEBUG close.complete
19:24:03,577 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:03,579 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8a810>
19:24:03,580 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff3080722a0> server_hostname='api.openai.com' timeout=None
19:24:03,585 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89f10>
19:24:03,585 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:03,586 httpcore.http11 DEBUG send_request_headers.complete
19:24:03,586 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:03,586 httpcore.http11 DEBUG send_request_body.complete
19:24:03,586 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:04,683 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1003'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ee5309ca4c5cd9893f2a3b7b344a0748'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339951e6c403b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:04,685 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:04,686 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:04,687 httpcore.http11 DEBUG receive_response_body.complete
19:24:04,688 httpcore.http11 DEBUG response_closed.started
19:24:04,688 httpcore.http11 DEBUG response_closed.complete
19:24:04,688 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:04,695 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Great! Let's give it a try. Can you please place the candle in this spot? If you don't like it, we can move it to the left, right, up, or down. What do you think?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:24:04,697 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:04,697 httpcore.http11 DEBUG send_request_headers.complete
19:24:04,697 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:04,698 httpcore.http11 DEBUG send_request_body.complete
19:24:04,698 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:05,407 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'586'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2aacc8f272f97faa5b834d6f5ef174d5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833995255c744d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:05,409 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:24:05,410 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:06,874 httpcore.http11 DEBUG receive_response_body.complete
19:24:06,874 httpcore.http11 DEBUG response_closed.started
19:24:06,874 httpcore.http11 DEBUG response_closed.complete
19:24:06,875 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:24:06,945 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:24:22,510 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:24:22,512 httpcore.connection DEBUG close.started
19:24:22,512 httpcore.connection DEBUG close.complete
19:24:22,513 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:24:22,515 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7f050>
19:24:22,515 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:24:22,521 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7f090>
19:24:22,522 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:22,522 httpcore.http11 DEBUG send_request_headers.complete
19:24:22,523 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:22,544 httpcore.http11 DEBUG send_request_body.complete
19:24:22,545 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:23,490 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:23 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'488'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'202f8b982926c3929b6bf364e33488bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399594cc2d6ac9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:23,492 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:24:23,492 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:23,493 httpcore.http11 DEBUG receive_response_body.complete
19:24:23,494 httpcore.http11 DEBUG response_closed.started
19:24:23,494 httpcore.http11 DEBUG response_closed.complete
19:24:23,494 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:24:23,495 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:24:23,512 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nGreat! Let's give it a try. Can you please place the candle in this spot? If you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nYes, let's put it here.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:23,515 httpcore.connection DEBUG close.started
19:24:23,515 httpcore.connection DEBUG close.complete
19:24:23,515 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:23,518 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e650>
19:24:23,518 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:24:23,524 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e510>
19:24:23,525 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:23,525 httpcore.http11 DEBUG send_request_headers.complete
19:24:23,525 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:23,526 httpcore.http11 DEBUG send_request_body.complete
19:24:23,526 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:23,766 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6d6853fb64f8b5315898f5a81ad65e85'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339959b09874d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:23,767 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:23,768 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:23,768 httpcore.http11 DEBUG receive_response_body.complete
19:24:23,768 httpcore.http11 DEBUG response_closed.started
19:24:23,768 httpcore.http11 DEBUG response_closed.complete
19:24:23,769 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:23,784 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nGreat! Let's give it a try. Can you please place the candle in this spot? If you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nYes, let's put it here.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:23,795 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:23,797 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9ce10>
19:24:23,798 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:24:23,806 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9c2d0>
19:24:23,806 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:23,807 httpcore.http11 DEBUG send_request_headers.complete
19:24:23,807 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:23,809 httpcore.http11 DEBUG send_request_body.complete
19:24:23,809 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:24,10 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b0d275018ffd448704535395825e5e21'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1d.2truoJQQlBjLLgF3tsadu7_eHS4bAYBwdIP_m1VU-1702254264-1-AZZwKwmpLtShBG7Qzyrl1OQOONK9u1CHzyc77In7pi5J8F1rHWz+wSWcRpzaHCap1HgjcA4JLNQP9dKkKJX+uac=; path=/; expires=Mon, 11-Dec-23 00:54:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zpuD9WEyjvI0avTRnFUXAe6sbEX4Z_Eb27PMBD7sV.k-1702254264007-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339959ccece4d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:24,14 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:24,14 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:24,15 httpcore.http11 DEBUG receive_response_body.complete
19:24:24,15 httpcore.http11 DEBUG response_closed.started
19:24:24,15 httpcore.http11 DEBUG response_closed.complete
19:24:24,16 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:24,28 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:24,31 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:27,432 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:27,439 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:27,442 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:29,443 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:29,456 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:29,458 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:32,859 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:32,863 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:24:32,868 httpcore.connection DEBUG close.started
19:24:32,869 httpcore.connection DEBUG close.complete
19:24:32,870 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:24:32,898 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7d050>
19:24:32,899 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:24:32,905 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7d850>
19:24:32,905 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:32,906 httpcore.http11 DEBUG send_request_headers.complete
19:24:32,907 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:32,907 httpcore.http11 DEBUG send_request_body.complete
19:24:32,907 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:33,331 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:33 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'351'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'18814dd6c98af4f85c98269c5f1c0846'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833995d5ab5c4ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:33,333 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:24:33,333 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:33,775 httpcore.http11 DEBUG receive_response_body.complete
19:24:33,776 httpcore.http11 DEBUG response_closed.started
19:24:33,776 httpcore.http11 DEBUG response_closed.complete
19:24:33,776 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:24:33,841 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:24:45,352 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:24:45,355 httpcore.connection DEBUG close.started
19:24:45,356 httpcore.connection DEBUG close.complete
19:24:45,356 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:24:45,358 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e4d0>
19:24:45,358 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:24:45,363 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8f2d0>
19:24:45,363 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:45,364 httpcore.http11 DEBUG send_request_headers.complete
19:24:45,364 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:45,389 httpcore.http11 DEBUG send_request_body.complete
19:24:45,389 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:46,594 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'40'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'694'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'127a1705b528c357eb42c6c5ea8e28f7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833996238e106ac6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:46,596 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:24:46,597 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:46,598 httpcore.http11 DEBUG receive_response_body.complete
19:24:46,598 httpcore.http11 DEBUG response_closed.started
19:24:46,598 httpcore.http11 DEBUG response_closed.complete
19:24:46,599 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:24:46,599 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:24:46,613 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:46,615 httpcore.connection DEBUG close.started
19:24:46,615 httpcore.connection DEBUG close.complete
19:24:46,616 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:46,618 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e510>
19:24:46,618 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:24:46,623 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8d6d0>
19:24:46,623 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:46,624 httpcore.http11 DEBUG send_request_headers.complete
19:24:46,624 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:46,624 httpcore.http11 DEBUG send_request_body.complete
19:24:46,624 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:46,799 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'91'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7dda8eaaa9b867fc53c17234f7db5309'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339962b68aa4d01-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:46,800 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:46,801 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:46,801 httpcore.http11 DEBUG receive_response_body.complete
19:24:46,802 httpcore.http11 DEBUG response_closed.started
19:24:46,802 httpcore.http11 DEBUG response_closed.complete
19:24:46,802 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:46,818 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:46,820 httpcore.connection DEBUG close.started
19:24:46,820 httpcore.connection DEBUG close.complete
19:24:46,820 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:46,823 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5de90>
19:24:46,823 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308072720> server_hostname='api.openai.com' timeout=None
19:24:46,828 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5cd50>
19:24:46,828 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:46,829 httpcore.http11 DEBUG send_request_headers.complete
19:24:46,829 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:46,829 httpcore.http11 DEBUG send_request_body.complete
19:24:46,829 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:47,214 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'289'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'16e18f53dbfad557d18c1a402bc02d82'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339962caafe4d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:47,216 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:47,217 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:47,218 httpcore.http11 DEBUG receive_response_body.complete
19:24:47,219 httpcore.http11 DEBUG response_closed.started
19:24:47,219 httpcore.http11 DEBUG response_closed.complete
19:24:47,219 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:47,229 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:47,231 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:52,933 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:52,944 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:52,947 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:57,648 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:57,660 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:57,663 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:59,664 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:59,675 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:59,678 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:03,80 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:03,91 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:25:03,94 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:08,796 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:08,808 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:25:08,811 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:12,616 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:12,627 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:25:12,630 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:16,432 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:16,435 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:25:16,439 httpcore.connection DEBUG close.started
19:25:16,439 httpcore.connection DEBUG close.complete
19:25:16,439 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:25:16,442 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8a490>
19:25:16,442 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:25:16,450 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89ad0>
19:25:16,450 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:16,451 httpcore.http11 DEBUG send_request_headers.complete
19:25:16,451 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:16,452 httpcore.http11 DEBUG send_request_body.complete
19:25:16,452 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:16,955 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'418'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'57066f5a577cbdb7cb0e6fc26bd56cd7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833996e5de344cd5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:16,957 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:25:16,957 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:18,110 httpcore.http11 DEBUG receive_response_body.complete
19:25:18,111 httpcore.http11 DEBUG response_closed.started
19:25:18,111 httpcore.http11 DEBUG response_closed.complete
19:25:18,111 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:25:18,170 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:25:31,192 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:25:31,195 httpcore.connection DEBUG close.started
19:25:31,195 httpcore.connection DEBUG close.complete
19:25:31,195 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:25:31,198 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9da10>
19:25:31,198 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:25:31,206 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9d450>
19:25:31,206 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:31,207 httpcore.http11 DEBUG send_request_headers.complete
19:25:31,207 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:31,222 httpcore.http11 DEBUG send_request_body.complete
19:25:31,222 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:32,42 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:32 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'358'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f4f5280b35026594bc9422dff6422924'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399742080f4cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:32,44 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:25:32,45 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:32,46 httpcore.http11 DEBUG receive_response_body.complete
19:25:32,46 httpcore.http11 DEBUG response_closed.started
19:25:32,46 httpcore.http11 DEBUG response_closed.complete
19:25:32,46 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:25:32,47 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:25:32,64 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:25:32,65 httpcore.connection DEBUG close.started
19:25:32,66 httpcore.connection DEBUG close.complete
19:25:32,66 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:25:32,68 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7afd0>
19:25:32,68 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:25:32,73 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7aa10>
19:25:32,73 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:32,74 httpcore.http11 DEBUG send_request_headers.complete
19:25:32,74 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:32,74 httpcore.http11 DEBUG send_request_body.complete
19:25:32,74 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:32,292 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ed1e78da6c426a87c42e5f31c2553fc7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997477d0b305d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:32,295 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:25:32,296 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:32,297 httpcore.http11 DEBUG receive_response_body.complete
19:25:32,297 httpcore.http11 DEBUG response_closed.started
19:25:32,298 httpcore.http11 DEBUG response_closed.complete
19:25:32,298 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:25:32,313 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:25:32,315 httpcore.connection DEBUG close.started
19:25:32,316 httpcore.connection DEBUG close.complete
19:25:32,316 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:25:32,318 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7e5d0>
19:25:32,318 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:25:32,324 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7f590>
19:25:32,325 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:32,325 httpcore.http11 DEBUG send_request_headers.complete
19:25:32,325 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:32,326 httpcore.http11 DEBUG send_request_body.complete
19:25:32,326 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:32,565 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'783600ed48e329b3d39480425dfaa50b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997490a6e4cde-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:32,568 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:25:32,568 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:32,569 httpcore.http11 DEBUG receive_response_body.complete
19:25:32,569 httpcore.http11 DEBUG response_closed.started
19:25:32,570 httpcore.http11 DEBUG response_closed.complete
19:25:32,570 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:25:32,580 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:25:32,583 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:35,984 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:35,987 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:25:35,992 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:35,993 httpcore.http11 DEBUG send_request_headers.complete
19:25:35,994 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:35,994 httpcore.http11 DEBUG send_request_body.complete
19:25:35,994 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:36,665 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'546'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd3b7bfdc74474a4634533790d0ac82f3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339975ffc1c4cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:36,667 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:25:36,668 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:37,673 httpcore.http11 DEBUG receive_response_body.complete
19:25:37,674 httpcore.http11 DEBUG response_closed.started
19:25:37,674 httpcore.http11 DEBUG response_closed.complete
19:25:37,675 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:25:37,741 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:25:50,595 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:25:50,597 httpcore.connection DEBUG close.started
19:25:50,598 httpcore.connection DEBUG close.complete
19:25:50,598 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:25:50,627 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8c090>
19:25:50,628 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:25:50,634 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8f0d0>
19:25:50,634 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:50,635 httpcore.http11 DEBUG send_request_headers.complete
19:25:50,636 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:50,661 httpcore.http11 DEBUG send_request_body.complete
19:25:50,661 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:51,500 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:51 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'353'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'13eddda7ba892c4ee5650bb640b76f40'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997bb78094cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:51,503 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:25:51,503 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:51,504 httpcore.http11 DEBUG receive_response_body.complete
19:25:51,505 httpcore.http11 DEBUG response_closed.started
19:25:51,505 httpcore.http11 DEBUG response_closed.complete
19:25:51,505 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:25:51,506 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:25:51,519 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nThank you for watching!\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:25:51,521 httpcore.connection DEBUG close.started
19:25:51,521 httpcore.connection DEBUG close.complete
19:25:51,522 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:25:51,524 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9e190>
19:25:51,524 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:25:51,531 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9fc10>
19:25:51,531 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:51,532 httpcore.http11 DEBUG send_request_headers.complete
19:25:51,532 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:51,532 httpcore.http11 DEBUG send_request_body.complete
19:25:51,532 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:51,772 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'137'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4b0c0e878b02125b407de79dff4134a1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997c1186c4d0b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:51,773 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:25:51,774 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:51,774 httpcore.http11 DEBUG receive_response_body.complete
19:25:51,775 httpcore.http11 DEBUG response_closed.started
19:25:51,775 httpcore.http11 DEBUG response_closed.complete
19:25:51,775 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:25:51,781 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:25:51,784 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:51,785 httpcore.http11 DEBUG send_request_headers.complete
19:25:51,786 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:51,786 httpcore.http11 DEBUG send_request_body.complete
19:25:51,786 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:52,425 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'521'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b45148ba6d6efe31e8506d0c542b26cb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997c2aeed4cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:52,427 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:25:52,427 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:53,525 httpcore.http11 DEBUG receive_response_body.complete
19:25:53,526 httpcore.http11 DEBUG response_closed.started
19:25:53,526 httpcore.http11 DEBUG response_closed.complete
19:25:53,526 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:25:53,590 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:26:06,543 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:26:06,547 httpcore.connection DEBUG close.started
19:26:06,547 httpcore.connection DEBUG close.complete
19:26:06,547 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:26:06,550 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e80190>
19:26:06,550 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:26:06,555 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e80290>
19:26:06,556 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:06,556 httpcore.http11 DEBUG send_request_headers.complete
19:26:06,556 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:06,577 httpcore.http11 DEBUG send_request_body.complete
19:26:06,577 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:07,413 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'24678155cb2d72eab145ab367efb8b02'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339981efb503025-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:07,415 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:26:07,416 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:07,417 httpcore.http11 DEBUG receive_response_body.complete
19:26:07,417 httpcore.http11 DEBUG response_closed.started
19:26:07,418 httpcore.http11 DEBUG response_closed.complete
19:26:07,418 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:26:07,418 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:26:07,434 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:07,436 httpcore.connection DEBUG close.started
19:26:07,437 httpcore.connection DEBUG close.complete
19:26:07,437 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:07,439 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9fc10>
19:26:07,439 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:26:07,444 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9e490>
19:26:07,444 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:07,444 httpcore.http11 DEBUG send_request_headers.complete
19:26:07,444 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:07,445 httpcore.http11 DEBUG send_request_body.complete
19:26:07,445 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:07,622 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'77'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'02aea47d129f69e09b0c4647e639b76b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998248f953b94-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:07,624 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:26:07,625 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:07,626 httpcore.http11 DEBUG receive_response_body.complete
19:26:07,627 httpcore.http11 DEBUG response_closed.started
19:26:07,627 httpcore.http11 DEBUG response_closed.complete
19:26:07,627 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:26:07,639 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:26:07,641 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:26:11,42 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:26:11,55 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:26:11,59 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:26:13,62 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:26:13,72 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:26:13,76 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:26:16,478 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:26:16,481 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:26:16,485 httpcore.connection DEBUG close.started
19:26:16,485 httpcore.connection DEBUG close.complete
19:26:16,486 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:26:16,488 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8d690>
19:26:16,489 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:26:16,495 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9d750>
19:26:16,495 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:16,496 httpcore.http11 DEBUG send_request_headers.complete
19:26:16,496 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:16,497 httpcore.http11 DEBUG send_request_body.complete
19:26:16,497 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:17,172 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:17 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'512'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6dd37640c7b4525d519b0265c802fbd5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339985d1a5d304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:17,175 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:26:17,175 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:17,536 httpcore.http11 DEBUG receive_response_body.complete
19:26:17,536 httpcore.http11 DEBUG response_closed.started
19:26:17,537 httpcore.http11 DEBUG response_closed.complete
19:26:17,537 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:26:17,611 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:26:28,898 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:26:28,901 httpcore.connection DEBUG close.started
19:26:28,901 httpcore.connection DEBUG close.complete
19:26:28,901 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:26:28,903 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8fed0>
19:26:28,904 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:26:28,911 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8ecd0>
19:26:28,911 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:28,912 httpcore.http11 DEBUG send_request_headers.complete
19:26:28,912 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:28,939 httpcore.http11 DEBUG send_request_body.complete
19:26:28,939 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:30,41 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb4052a16f81e2381d7d70e97e2e7080'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998aabf7d3074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:30,43 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:26:30,43 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:30,44 httpcore.http11 DEBUG receive_response_body.complete
19:26:30,45 httpcore.http11 DEBUG response_closed.started
19:26:30,45 httpcore.http11 DEBUG response_closed.complete
19:26:30,45 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:26:30,46 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:26:30,61 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nDo you have suggestions?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:30,62 httpcore.connection DEBUG close.started
19:26:30,63 httpcore.connection DEBUG close.complete
19:26:30,63 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:30,65 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8add0>
19:26:30,65 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:26:30,72 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89c50>
19:26:30,72 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:30,73 httpcore.http11 DEBUG send_request_headers.complete
19:26:30,73 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:30,73 httpcore.http11 DEBUG send_request_body.complete
19:26:30,73 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:30,283 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c01fa7420b3c66b684dc96c7c15693ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998b1fbfb4cec-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:30,286 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:26:30,286 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:30,287 httpcore.http11 DEBUG receive_response_body.complete
19:26:30,287 httpcore.http11 DEBUG response_closed.started
19:26:30,288 httpcore.http11 DEBUG response_closed.complete
19:26:30,288 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:26:30,306 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nDo you have suggestions?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:30,308 httpcore.connection DEBUG close.started
19:26:30,308 httpcore.connection DEBUG close.complete
19:26:30,308 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:30,311 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e897d0>
19:26:30,311 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff3080722a0> server_hostname='api.openai.com' timeout=None
19:26:30,316 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5e850>
19:26:30,316 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:30,317 httpcore.http11 DEBUG send_request_headers.complete
19:26:30,317 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:30,317 httpcore.http11 DEBUG send_request_body.complete
19:26:30,317 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:31,494 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1068'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a27aa1af5a65621e54e0290fec79ef28'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998b3783c4cc9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:31,497 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:26:31,497 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:31,499 httpcore.http11 DEBUG receive_response_body.complete
19:26:31,499 httpcore.http11 DEBUG response_closed.started
19:26:31,499 httpcore.http11 DEBUG response_closed.complete
19:26:31,499 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:26:31,505 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'I suggest placing the third candle in the center of the cake. Would you like me to place it there for you? If so, I can do that for you. Otherwise, please let me know where you would like me to place the third candle.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:26:31,508 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:31,509 httpcore.http11 DEBUG send_request_headers.complete
19:26:31,509 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:31,510 httpcore.http11 DEBUG send_request_body.complete
19:26:31,510 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:32,138 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:32 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'516'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'02e6296107af7026456231f35f0160aa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998baea623074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:32,140 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:26:32,141 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:34,547 httpcore.http11 DEBUG receive_response_body.complete
19:26:34,547 httpcore.http11 DEBUG response_closed.started
19:26:34,547 httpcore.http11 DEBUG response_closed.complete
19:26:34,548 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:26:34,619 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:26:57,473 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen9.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:26:57,477 httpcore.connection DEBUG close.started
19:26:57,478 httpcore.connection DEBUG close.complete
19:26:57,478 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:26:57,507 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e82d90>
19:26:57,507 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:26:57,516 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e82e90>
19:26:57,516 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:57,517 httpcore.http11 DEBUG send_request_headers.complete
19:26:57,518 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:57,555 httpcore.http11 DEBUG send_request_body.complete
19:26:57,556 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:59,412 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c8b5b6bfd7cbe1fa5907edce57654d3d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339995d79054cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:59,414 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:26:59,414 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:59,415 httpcore.http11 DEBUG receive_response_body.complete
19:26:59,415 httpcore.http11 DEBUG response_closed.started
19:26:59,415 httpcore.http11 DEBUG response_closed.complete
19:26:59,415 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:26:59,416 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:26:59,430 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI suggest placing the third candle in the center of the cake. Would you like me to place it there for you? If so, I can do that for you. Otherwise, please let me know where you would like me to place the third candle.\n'''\nAnd the human answered\n'''\nNo, the first candle is in the center. Place it to the right of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:59,432 httpcore.connection DEBUG close.started
19:26:59,433 httpcore.connection DEBUG close.complete
19:26:59,433 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:59,435 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8bc50>
19:26:59,436 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:26:59,441 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8a310>
19:26:59,441 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:59,442 httpcore.http11 DEBUG send_request_headers.complete
19:26:59,442 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:59,442 httpcore.http11 DEBUG send_request_body.complete
19:26:59,442 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:59,650 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'de1531f8455db1c73c3ddc8b5441b70b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833999698d5b4ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:59,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:26:59,652 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:59,652 httpcore.http11 DEBUG receive_response_body.complete
19:26:59,653 httpcore.http11 DEBUG response_closed.started
19:26:59,653 httpcore.http11 DEBUG response_closed.complete
19:26:59,653 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:26:59,673 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nI suggest placing the third candle in the center of the cake. Would you like me to place it there for you? If so, I can do that for you. Otherwise, please let me know where you would like me to place the third candle.\n'''\nAnd the human answered\n'''\nNo, the first candle is in the center. Place it to the right of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:59,675 httpcore.connection DEBUG close.started
19:26:59,675 httpcore.connection DEBUG close.complete
19:26:59,676 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:59,678 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e50890>
19:26:59,678 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308072720> server_hostname='api.openai.com' timeout=None
19:26:59,685 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5cd50>
19:26:59,685 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:59,686 httpcore.http11 DEBUG send_request_headers.complete
19:26:59,686 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:59,686 httpcore.http11 DEBUG send_request_body.complete
19:26:59,686 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:00,385 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'587'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c3175a9b546a60622de85ca067168b7b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339996b0fab4d04-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:00,388 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:27:00,388 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:00,390 httpcore.http11 DEBUG receive_response_body.complete
19:27:00,390 httpcore.http11 DEBUG response_closed.started
19:27:00,390 httpcore.http11 DEBUG response_closed.complete
19:27:00,391 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:27:00,403 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:00,407 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:06,108 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:06,122 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:06,125 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:10,826 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:10,835 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:10,839 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:12,840 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:12,852 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:12,855 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:16,256 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:16,270 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:16,272 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:21,973 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:21,984 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:21,987 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:26,589 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:26,601 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:26,604 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:30,806 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:30,809 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:27:30,814 httpcore.connection DEBUG close.started
19:27:30,814 httpcore.connection DEBUG close.complete
19:27:30,815 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:27:30,855 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7d6d0>
19:27:30,855 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:27:30,863 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8d950>
19:27:30,864 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:30,864 httpcore.http11 DEBUG send_request_headers.complete
19:27:30,865 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:30,865 httpcore.http11 DEBUG send_request_body.complete
19:27:30,865 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:31,378 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2ccb698828b08263cd36a8ba8636fa38'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399a2dee4d3b99-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:31,380 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:27:31,381 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:32,470 httpcore.http11 DEBUG receive_response_body.complete
19:27:32,471 httpcore.http11 DEBUG response_closed.started
19:27:32,471 httpcore.http11 DEBUG response_closed.complete
19:27:32,472 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:27:32,536 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen10.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:27:45,399 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen10.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:27:45,402 httpcore.connection DEBUG close.started
19:27:45,402 httpcore.connection DEBUG close.complete
19:27:45,403 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:27:45,405 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9d410>
19:27:45,405 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:27:45,413 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9c290>
19:27:45,413 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:45,414 httpcore.http11 DEBUG send_request_headers.complete
19:27:45,414 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:45,423 httpcore.http11 DEBUG send_request_body.complete
19:27:45,423 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:46,192 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'16'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2e1a63fa118c564811b04744796fa3fa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399a88dd164ce3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:46,194 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:27:46,195 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:46,196 httpcore.http11 DEBUG receive_response_body.complete
19:27:46,196 httpcore.http11 DEBUG response_closed.started
19:27:46,196 httpcore.http11 DEBUG response_closed.complete
19:27:46,197 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:27:46,197 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:27:46,213 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nUh, move right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:27:46,215 httpcore.connection DEBUG close.started
19:27:46,215 httpcore.connection DEBUG close.complete
19:27:46,215 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:27:46,218 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e826d0>
19:27:46,218 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:27:46,224 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e81f10>
19:27:46,224 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:46,225 httpcore.http11 DEBUG send_request_headers.complete
19:27:46,225 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:46,226 httpcore.http11 DEBUG send_request_body.complete
19:27:46,226 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:46,427 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7a9c9bf7f7c0dd57c526c4a4d83e1736'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399a8dec1c4d17-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:46,429 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:27:46,429 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:46,430 httpcore.http11 DEBUG receive_response_body.complete
19:27:46,430 httpcore.http11 DEBUG response_closed.started
19:27:46,430 httpcore.http11 DEBUG response_closed.complete
19:27:46,430 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:27:46,445 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nUh, move right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:27:46,447 httpcore.connection DEBUG close.started
19:27:46,447 httpcore.connection DEBUG close.complete
19:27:46,447 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:27:46,449 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9e6d0>
19:27:46,449 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:27:46,457 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9c210>
19:27:46,458 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:46,458 httpcore.http11 DEBUG send_request_headers.complete
19:27:46,458 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:46,459 httpcore.http11 DEBUG send_request_body.complete
19:27:46,459 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:46,681 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8c9b318084ce63b46e5659c1ba6df5b8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399a8f5fa04ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:46,684 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:27:46,685 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:46,686 httpcore.http11 DEBUG receive_response_body.complete
19:27:46,687 httpcore.http11 DEBUG response_closed.started
19:27:46,688 httpcore.http11 DEBUG response_closed.complete
19:27:46,688 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:27:46,697 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:46,700 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:50,101 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:50,105 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:27:50,110 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:50,111 httpcore.http11 DEBUG send_request_headers.complete
19:27:50,111 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:50,112 httpcore.http11 DEBUG send_request_body.complete
19:27:50,112 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:50,624 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:50 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'385c57c4c50c534871ce9dbd3382221d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399aa639514ce3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:50,626 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:27:50,626 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:51,724 httpcore.http11 DEBUG receive_response_body.complete
19:27:51,725 httpcore.http11 DEBUG response_closed.started
19:27:51,725 httpcore.http11 DEBUG response_closed.complete
19:27:51,726 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:27:51,794 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen11.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:28:04,788 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen11.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:28:04,792 httpcore.connection DEBUG close.started
19:28:04,792 httpcore.connection DEBUG close.complete
19:28:04,793 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:28:04,823 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9e910>
19:28:04,824 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:28:04,831 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9f0d0>
19:28:04,832 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:04,833 httpcore.http11 DEBUG send_request_headers.complete
19:28:04,833 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:04,866 httpcore.http11 DEBUG send_request_body.complete
19:28:04,866 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:05,823 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:05 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'446'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'73e5ffea3597d626ff1f8af3923ad92a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b0239f34cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:05,825 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:28:05,825 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:05,826 httpcore.http11 DEBUG receive_response_body.complete
19:28:05,826 httpcore.http11 DEBUG response_closed.started
19:28:05,826 httpcore.http11 DEBUG response_closed.complete
19:28:05,827 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:28:05,827 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:28:05,845 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nThank you for watching!\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:28:05,847 httpcore.connection DEBUG close.started
19:28:05,847 httpcore.connection DEBUG close.complete
19:28:05,847 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:28:05,849 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e7d0>
19:28:05,850 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:28:05,856 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e6d0>
19:28:05,856 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:05,857 httpcore.http11 DEBUG send_request_headers.complete
19:28:05,857 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:05,857 httpcore.http11 DEBUG send_request_body.complete
19:28:05,857 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:06,61 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'91'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'947e530137a112c992c99df058803682'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b089cec4ce2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:06,64 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:28:06,65 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:06,66 httpcore.http11 DEBUG receive_response_body.complete
19:28:06,66 httpcore.http11 DEBUG response_closed.started
19:28:06,66 httpcore.http11 DEBUG response_closed.complete
19:28:06,67 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:28:06,73 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:28:06,77 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:06,78 httpcore.http11 DEBUG send_request_headers.complete
19:28:06,78 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:06,78 httpcore.http11 DEBUG send_request_body.complete
19:28:06,78 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:06,590 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:06 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'432'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fa2ffa16792fa9ac377bdf113be8fb80'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b09fa4b4cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:06,592 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:28:06,593 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:07,833 httpcore.http11 DEBUG receive_response_body.complete
19:28:07,833 httpcore.http11 DEBUG response_closed.started
19:28:07,834 httpcore.http11 DEBUG response_closed.complete
19:28:07,834 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:28:07,903 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen12.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:28:20,931 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen12.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:28:20,938 httpcore.connection DEBUG close.started
19:28:20,938 httpcore.connection DEBUG close.complete
19:28:20,939 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:28:20,941 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89910>
19:28:20,941 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:28:20,947 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89250>
19:28:20,947 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:20,948 httpcore.http11 DEBUG send_request_headers.complete
19:28:20,948 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:20,968 httpcore.http11 DEBUG send_request_body.complete
19:28:20,969 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:21,835 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'3'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'374'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b65a28209f153d0a0c7cbcae94687b05'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b66efe04cd2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:21,837 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:28:21,838 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:21,838 httpcore.http11 DEBUG receive_response_body.complete
19:28:21,838 httpcore.http11 DEBUG response_closed.started
19:28:21,839 httpcore.http11 DEBUG response_closed.complete
19:28:21,839 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:28:21,839 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:28:21,856 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\n. \n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:28:21,858 httpcore.connection DEBUG close.started
19:28:21,858 httpcore.connection DEBUG close.complete
19:28:21,858 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:28:21,861 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ea5550>
19:28:21,861 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:28:21,867 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ea4190>
19:28:21,867 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:21,868 httpcore.http11 DEBUG send_request_headers.complete
19:28:21,868 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:21,868 httpcore.http11 DEBUG send_request_body.complete
19:28:21,868 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:22,101 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'131'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4edfc78154eed74f563c97880a9c9f51'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b6cace94cc8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:22,104 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:28:22,105 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:22,106 httpcore.http11 DEBUG receive_response_body.complete
19:28:22,106 httpcore.http11 DEBUG response_closed.started
19:28:22,107 httpcore.http11 DEBUG response_closed.complete
19:28:22,107 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:28:22,115 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:28:22,117 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:22,117 httpcore.http11 DEBUG send_request_headers.complete
19:28:22,117 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:22,118 httpcore.http11 DEBUG send_request_body.complete
19:28:22,118 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:22,623 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:22 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'416'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2066db80d0438168871f47e3e705f269'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b6e39a34cd2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:22,626 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:28:22,626 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:23,810 httpcore.http11 DEBUG receive_response_body.complete
19:28:23,811 httpcore.http11 DEBUG response_closed.started
19:28:23,811 httpcore.http11 DEBUG response_closed.complete
19:28:23,811 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:28:23,879 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen13.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:28:36,825 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen13.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:28:36,829 httpcore.connection DEBUG close.started
19:28:36,829 httpcore.connection DEBUG close.complete
19:28:36,830 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:28:36,833 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8de50>
19:28:36,833 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:28:36,841 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8d3d0>
19:28:36,842 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:36,843 httpcore.http11 DEBUG send_request_headers.complete
19:28:36,843 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:36,862 httpcore.http11 DEBUG send_request_body.complete
19:28:36,863 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:37,640 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'383a9930b8c2a31eb3fdb3f36d410eee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399bca4e074d04-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:37,642 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:28:37,643 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:37,644 httpcore.http11 DEBUG receive_response_body.complete
19:28:37,644 httpcore.http11 DEBUG response_closed.started
19:28:37,644 httpcore.http11 DEBUG response_closed.complete
19:28:37,645 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:28:37,645 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:28:37,662 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:28:37,664 httpcore.connection DEBUG close.started
19:28:37,664 httpcore.connection DEBUG close.complete
19:28:37,664 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:28:37,667 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9fe50>
19:28:37,667 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:28:37,672 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9ebd0>
19:28:37,673 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:37,673 httpcore.http11 DEBUG send_request_headers.complete
19:28:37,673 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:37,674 httpcore.http11 DEBUG send_request_body.complete
19:28:37,674 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:37,849 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'55'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fe463c78e55c5d98cf4eb20f763e5631'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399bcf7e5b4d0c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:37,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:28:37,852 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:37,853 httpcore.http11 DEBUG receive_response_body.complete
19:28:37,854 httpcore.http11 DEBUG response_closed.started
19:28:37,854 httpcore.http11 DEBUG response_closed.complete
19:28:37,854 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:28:37,864 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:28:37,868 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:28:41,269 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:28:41,280 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:28:41,284 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:28:43,286 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:28:43,302 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:28:43,306 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:28:46,708 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:26:09,613 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:09,617 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,457 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,458 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,499 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,501 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,548 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,549 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,589 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,590 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,637 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,638 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,679 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,680 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,728 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,729 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,769 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,770 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:16,250 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:26:16,268 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:26:16,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f61ca68e290>
21:26:16,301 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f61ca4e1d00> server_hostname='api.openai.com' timeout=5.0
21:26:16,310 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f61ca463210>
21:26:16,311 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:26:16,313 httpcore.http11 DEBUG send_request_headers.complete
21:26:16,314 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:26:16,314 httpcore.http11 DEBUG send_request_body.complete
21:26:16,314 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:26:16,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Mon, 11 Dec 2023 02:26:16 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'301'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'd6de30f7f00cc1bcf6f2f234c349293c'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JJB9INgJeSl5LoDG03GJPlyI9VXvKVUUNhbAOVLFvU8-1702261576-1-AYUsGCgwi8BibGVipcg/fi4He0C+LR7MlVL6vP9ELROa10I6bnYF6axq8Sf/ykbP2v4C0gO4J5ucsfH1Fs46iRY=; path=/; expires=Mon, 11-Dec-23 02:56:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1mU5YpNIzMJVAynjtDln4ZQoiwxEARrRbvdBP2cCPmE-1702261576448-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4823fca74d13-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:26:16,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 401 Unauthorized"
21:26:16,459 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:26:16,460 httpcore.http11 DEBUG receive_response_body.complete
21:26:16,460 httpcore.http11 DEBUG response_closed.started
21:26:16,460 httpcore.http11 DEBUG response_closed.complete
21:26:16,461 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "401 Unauthorized"
21:30:53,645 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:53,649 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,479 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,481 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,528 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,529 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,581 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,582 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,626 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,627 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,680 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,681 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,725 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,726 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,779 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,780 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,823 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,825 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:56,620 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:30:56,651 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:30:56,681 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee7decd0>
21:30:56,681 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:30:56,693 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee563350>
21:30:56,694 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:30:56,697 httpcore.http11 DEBUG send_request_headers.complete
21:30:56,698 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:30:56,699 httpcore.http11 DEBUG send_request_body.complete
21:30:56,699 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:30:57,248 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:30:57 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a5fdd0405b088fe85bce202263e25342'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SL1dtDakfruMYlYTGJA4Hsfb9pIBBNMMExE8jT9Y5hM-1702261857-1-ATMGs8iwUmqKODgBlqat3oFAKzw6qFbJjR0R2kIejazX7zQx9fOQsaCnOALu5aVxQe6yo/j5F3rmkAC4KMvzmZ8=; path=/; expires=Mon, 11-Dec-23 03:00:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=9W7jy0qiL.SNtSqG4uAbj1vwrGqRHlvRpp5YzXRRtQQ-1702261857242-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4efc5ad73074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:30:57,257 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:30:57,258 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:30:58,75 httpcore.http11 DEBUG receive_response_body.complete
21:30:58,76 httpcore.http11 DEBUG response_closed.started
21:30:58,77 httpcore.http11 DEBUG response_closed.complete
21:30:58,78 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:30:58,174 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:31:11,470 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:31:11,480 httpcore.connection DEBUG close.started
21:31:11,480 httpcore.connection DEBUG close.complete
21:31:11,481 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:31:11,483 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee563350>
21:31:11,484 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:31:11,490 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee563450>
21:31:11,490 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:11,491 httpcore.http11 DEBUG send_request_headers.complete
21:31:11,492 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:11,521 httpcore.http11 DEBUG send_request_body.complete
21:31:11,522 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:12,407 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:12 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'358'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'09bf72f5b1fcfab0837e996032cd520d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4f58d8e64cf2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:12,412 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:31:12,413 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:12,414 httpcore.http11 DEBUG receive_response_body.complete
21:31:12,414 httpcore.http11 DEBUG response_closed.started
21:31:12,414 httpcore.http11 DEBUG response_closed.complete
21:31:12,414 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:31:12,415 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:31:12,448 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:31:12,460 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:31:12,462 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3c4750>
21:31:12,462 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:31:12,475 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee587510>
21:31:12,476 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:12,477 httpcore.http11 DEBUG send_request_headers.complete
21:31:12,478 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:12,479 httpcore.http11 DEBUG send_request_body.complete
21:31:12,479 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:12,794 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e26d9c4bd9db007c4f8ff7f44c59d988'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uNHjk5DBjFfh93cDtHiXrv2zQcjEwWZIfyOxvQUTJEs-1702261872-1-Ae6SsFXsVivMNMMaGAjcJ79viWFVWV0N8FSU9qLlWW/90XIsumH7SlRMHTpQuEooeEKpa7TT8Gp4BRI+DifsxZo=; path=/; expires=Mon, 11-Dec-23 03:01:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=uHjIHkk3TITcczHFyROvfwJhtClgT9qBfyhsQJKPTy8-1702261872789-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4f5efa203b70-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:12,798 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:31:12,799 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:12,800 httpcore.http11 DEBUG receive_response_body.complete
21:31:12,801 httpcore.http11 DEBUG response_closed.started
21:31:12,801 httpcore.http11 DEBUG response_closed.complete
21:31:12,802 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:31:12,837 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:31:12,848 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:31:12,851 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3cb7d0>
21:31:12,851 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e2690> server_hostname='api.openai.com' timeout=None
21:31:12,857 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3cb750>
21:31:12,857 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:12,859 httpcore.http11 DEBUG send_request_headers.complete
21:31:12,859 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:12,860 httpcore.http11 DEBUG send_request_body.complete
21:31:12,860 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:13,661 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'685'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b1d22c5325860909301a20abf0e939cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ZH0cPMaAXqMKrsfL0pBa.pYZlfYO.SShdhyRGfqdWIY-1702261873-1-AduAyOlpfCDeFcqjqvHR8aDtePV0qT+bxwCF1XCgDbFvpbax2guebkiw5TXyxIZUeujju0yPZkq/ZmGwq0CXGrI=; path=/; expires=Mon, 11-Dec-23 03:01:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=vYkGchIG5PfFfVYflJtGWNph9bk1nr.2z7Gyvgol9Ko-1702261873656-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4f615eff4d02-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:13,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:31:13,671 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:13,672 httpcore.http11 DEBUG receive_response_body.complete
21:31:13,672 httpcore.http11 DEBUG response_closed.started
21:31:13,673 httpcore.http11 DEBUG response_closed.complete
21:31:13,673 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:31:13,692 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:13,696 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:20,204 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:20,217 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:20,220 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:25,222 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:25,240 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:25,242 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:27,245 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:27,261 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:27,264 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:30,666 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:30,684 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:30,688 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:37,190 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:37,207 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:37,211 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:41,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:41,32 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:41,35 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:44,837 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:44,843 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:31:44,849 httpcore.connection DEBUG close.started
21:31:44,850 httpcore.connection DEBUG close.complete
21:31:44,850 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:31:44,868 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee563450>
21:31:44,868 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:31:44,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee562590>
21:31:44,876 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:44,878 httpcore.http11 DEBUG send_request_headers.complete
21:31:44,879 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:44,880 httpcore.http11 DEBUG send_request_body.complete
21:31:44,880 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:45,469 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'426'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'45442f37e0d4469cabfc53d8f4de84c7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50297d814d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:45,474 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:31:45,475 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:46,585 httpcore.http11 DEBUG receive_response_body.complete
21:31:46,586 httpcore.http11 DEBUG response_closed.started
21:31:46,587 httpcore.http11 DEBUG response_closed.complete
21:31:46,588 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:31:46,654 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:31:59,39 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:31:59,43 httpcore.connection DEBUG close.started
21:31:59,43 httpcore.connection DEBUG close.complete
21:31:59,44 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:31:59,73 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee3d0>
21:31:59,73 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:31:59,83 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee450>
21:31:59,83 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:59,85 httpcore.http11 DEBUG send_request_headers.complete
21:31:59,86 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:59,103 httpcore.http11 DEBUG send_request_body.complete
21:31:59,103 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:59,854 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'03858aa243573cbbe100af37f8262101'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50825b414ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:59,859 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:31:59,859 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:59,860 httpcore.http11 DEBUG receive_response_body.complete
21:31:59,861 httpcore.http11 DEBUG response_closed.started
21:31:59,861 httpcore.http11 DEBUG response_closed.complete
21:31:59,862 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:31:59,863 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:31:59,903 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:31:59,908 httpcore.connection DEBUG close.started
21:31:59,909 httpcore.connection DEBUG close.complete
21:31:59,910 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:31:59,912 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee585b50>
21:31:59,913 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:31:59,924 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee587390>
21:31:59,925 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:59,926 httpcore.http11 DEBUG send_request_headers.complete
21:31:59,926 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:59,926 httpcore.http11 DEBUG send_request_body.complete
21:31:59,927 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:00,173 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9987e9dc2e9045af592d203016bbbc82'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50878e694d10-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:00,179 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:00,179 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:00,181 httpcore.http11 DEBUG receive_response_body.complete
21:32:00,182 httpcore.http11 DEBUG response_closed.started
21:32:00,182 httpcore.http11 DEBUG response_closed.complete
21:32:00,182 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:00,215 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:00,226 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:00,229 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee010>
21:32:00,229 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:32:00,236 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3edd90>
21:32:00,236 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:00,237 httpcore.http11 DEBUG send_request_headers.complete
21:32:00,238 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:00,238 httpcore.http11 DEBUG send_request_body.complete
21:32:00,239 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:00,470 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'40a1d7476bf510b4016dc12fba20c804'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=m0stj1GetuehKfRK6KIZYbAzsOm27YLXKaZqggl0V4g-1702261920-1-AWI2u1KRqvk7NCZnnSrXzLD64W985f9HCXlERIblnYYFHIprDZGFLA47moL4vq1CY7knnRQSJ3xZpTXZXpvqDyE=; path=/; expires=Mon, 11-Dec-23 03:02:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LkIcgm4ZVOc8zcNQnJaUtkjpm8dn.kUkW4nYZno4q_U-1702261920466-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50897bd24cf9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:00,479 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:00,480 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:00,482 httpcore.http11 DEBUG receive_response_body.complete
21:32:00,482 httpcore.http11 DEBUG response_closed.started
21:32:00,482 httpcore.http11 DEBUG response_closed.complete
21:32:00,483 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:00,498 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:00,501 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:03,903 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:03,910 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:32:03,916 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:03,916 httpcore.http11 DEBUG send_request_headers.complete
21:32:03,917 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:03,917 httpcore.http11 DEBUG send_request_body.complete
21:32:03,917 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:04,472 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:04 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'431'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'087732f4f4a4b1206066619d5f0fc89f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50a07d1b4ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:04,477 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:32:04,478 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:05,697 httpcore.http11 DEBUG receive_response_body.complete
21:32:05,698 httpcore.http11 DEBUG response_closed.started
21:32:05,699 httpcore.http11 DEBUG response_closed.complete
21:32:05,699 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:32:05,765 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:32:18,174 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:32:18,178 httpcore.connection DEBUG close.started
21:32:18,178 httpcore.connection DEBUG close.complete
21:32:18,178 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:32:18,181 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fe350>
21:32:18,182 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:32:18,187 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fe3d0>
21:32:18,188 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:18,189 httpcore.http11 DEBUG send_request_headers.complete
21:32:18,189 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:18,212 httpcore.http11 DEBUG send_request_body.complete
21:32:18,213 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:18,949 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'8'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'334'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5643c38069bf148ebb0f591e549fba13'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50f9a94a3035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:18,955 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:32:18,956 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:18,957 httpcore.http11 DEBUG receive_response_body.complete
21:32:18,958 httpcore.http11 DEBUG response_closed.started
21:32:18,958 httpcore.http11 DEBUG response_closed.complete
21:32:18,959 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:32:18,959 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:32:18,989 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nmove up\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:18,992 httpcore.connection DEBUG close.started
21:32:18,992 httpcore.connection DEBUG close.complete
21:32:18,993 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:18,995 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee409610>
21:32:18,995 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:32:19,1 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee409690>
21:32:19,2 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:19,2 httpcore.http11 DEBUG send_request_headers.complete
21:32:19,3 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:19,3 httpcore.http11 DEBUG send_request_body.complete
21:32:19,3 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:19,226 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'46e3b63a19c4ffb23d4feb1ba59f17d0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50fecd456ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:19,232 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:19,232 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:19,234 httpcore.http11 DEBUG receive_response_body.complete
21:32:19,235 httpcore.http11 DEBUG response_closed.started
21:32:19,235 httpcore.http11 DEBUG response_closed.complete
21:32:19,236 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:19,254 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:19,259 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:22,662 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:22,669 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:32:22,675 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:22,676 httpcore.http11 DEBUG send_request_headers.complete
21:32:22,677 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:22,677 httpcore.http11 DEBUG send_request_body.complete
21:32:22,678 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:23,221 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'448'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a75956324677a633cf0e596b3b6886fc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5115bd803035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:23,226 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:32:23,227 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:24,186 httpcore.http11 DEBUG receive_response_body.complete
21:32:24,187 httpcore.http11 DEBUG response_closed.started
21:32:24,188 httpcore.http11 DEBUG response_closed.complete
21:32:24,189 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:32:24,258 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:32:36,297 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:32:36,303 httpcore.connection DEBUG close.started
21:32:36,303 httpcore.connection DEBUG close.complete
21:32:36,304 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:32:36,307 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed750>
21:32:36,307 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:32:36,313 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fea10>
21:32:36,314 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:36,315 httpcore.http11 DEBUG send_request_headers.complete
21:32:36,315 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:36,341 httpcore.http11 DEBUG send_request_body.complete
21:32:36,341 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:37,57 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'319'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9ae297fcd419e06615cc46f293fb15f7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a516afb364d1d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:37,62 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:32:37,63 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:37,65 httpcore.http11 DEBUG receive_response_body.complete
21:32:37,65 httpcore.http11 DEBUG response_closed.started
21:32:37,66 httpcore.http11 DEBUG response_closed.complete
21:32:37,66 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:32:37,67 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:32:37,93 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:37,97 httpcore.connection DEBUG close.started
21:32:37,97 httpcore.connection DEBUG close.complete
21:32:37,97 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:37,100 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed4d0>
21:32:37,100 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:32:37,106 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed950>
21:32:37,106 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:37,107 httpcore.http11 DEBUG send_request_headers.complete
21:32:37,107 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:37,108 httpcore.http11 DEBUG send_request_body.complete
21:32:37,108 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:37,321 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dfc18c62139e352ad66e78d2393b4c6a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a516fefcb4ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:37,325 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:37,325 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:37,326 httpcore.http11 DEBUG receive_response_body.complete
21:32:37,327 httpcore.http11 DEBUG response_closed.started
21:32:37,327 httpcore.http11 DEBUG response_closed.complete
21:32:37,328 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:37,346 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:37,349 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:40,751 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:40,769 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:40,771 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:42,774 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:42,790 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:42,794 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:46,197 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:46,204 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:32:46,213 httpcore.connection DEBUG close.started
21:32:46,213 httpcore.connection DEBUG close.complete
21:32:46,214 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:32:46,217 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed210>
21:32:46,217 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:32:46,224 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee350>
21:32:46,224 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:46,226 httpcore.http11 DEBUG send_request_headers.complete
21:32:46,226 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:46,227 httpcore.http11 DEBUG send_request_body.complete
21:32:46,227 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:46,666 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:46 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'365'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ed9a0e954a06bd6ee7073bfe5db5c5cb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a51a8ea853b69-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:46,671 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:32:46,671 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:47,44 httpcore.http11 DEBUG receive_response_body.complete
21:32:47,45 httpcore.http11 DEBUG response_closed.started
21:32:47,46 httpcore.http11 DEBUG response_closed.complete
21:32:47,47 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:32:47,122 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:32:58,70 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:32:58,74 httpcore.connection DEBUG close.started
21:32:58,74 httpcore.connection DEBUG close.complete
21:32:58,75 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:32:58,77 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40ba10>
21:32:58,78 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:32:58,84 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40ba90>
21:32:58,84 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:58,85 httpcore.http11 DEBUG send_request_headers.complete
21:32:58,86 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:58,119 httpcore.http11 DEBUG send_request_body.complete
21:32:58,120 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:59,68 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'34'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'453'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cbd31d82cf83385b432ec196181a6ab1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a51f30a693b8d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:59,73 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:32:59,74 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:59,75 httpcore.http11 DEBUG receive_response_body.complete
21:32:59,76 httpcore.http11 DEBUG response_closed.started
21:32:59,77 httpcore.http11 DEBUG response_closed.complete
21:32:59,77 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:32:59,78 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:32:59,106 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTo the right of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:59,109 httpcore.connection DEBUG close.started
21:32:59,109 httpcore.connection DEBUG close.complete
21:32:59,110 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:59,140 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3c8f90>
21:32:59,141 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:32:59,147 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee5870d0>
21:32:59,148 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:59,149 httpcore.http11 DEBUG send_request_headers.complete
21:32:59,150 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:59,150 httpcore.http11 DEBUG send_request_body.complete
21:32:59,150 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:59,369 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0c76573e1ba7b0ef84386376a4508467'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a51f9ac603b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:59,376 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:59,377 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:59,378 httpcore.http11 DEBUG receive_response_body.complete
21:32:59,379 httpcore.http11 DEBUG response_closed.started
21:32:59,379 httpcore.http11 DEBUG response_closed.complete
21:32:59,379 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:59,412 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTo the right of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:59,415 httpcore.connection DEBUG close.started
21:32:59,416 httpcore.connection DEBUG close.complete
21:32:59,416 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:59,418 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3cba10>
21:32:59,419 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e2690> server_hostname='api.openai.com' timeout=None
21:32:59,426 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3c9210>
21:32:59,426 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:59,428 httpcore.http11 DEBUG send_request_headers.complete
21:32:59,428 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:59,428 httpcore.http11 DEBUG send_request_body.complete
21:32:59,429 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:00,82 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'564'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'156af51638724f7dedcf10841137f8cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a51fb6d173031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:00,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:33:00,89 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:00,91 httpcore.http11 DEBUG receive_response_body.complete
21:33:00,92 httpcore.http11 DEBUG response_closed.started
21:33:00,93 httpcore.http11 DEBUG response_closed.complete
21:33:00,94 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:33:00,385 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:00,387 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:06,889 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:06,907 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:06,911 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:11,914 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:11,932 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:11,936 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:13,938 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:13,955 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:13,957 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:17,359 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:17,376 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:17,380 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:23,884 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:23,898 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:23,900 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:27,303 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:27,321 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:27,325 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:32,326 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:32,329 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:33:32,333 httpcore.connection DEBUG close.started
21:33:32,333 httpcore.connection DEBUG close.complete
21:33:32,333 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:33:32,336 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40b950>
21:33:32,337 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:33:32,345 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40bb90>
21:33:32,346 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:32,347 httpcore.http11 DEBUG send_request_headers.complete
21:33:32,348 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:32,349 httpcore.http11 DEBUG send_request_body.complete
21:33:32,349 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:33,51 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:33 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'576'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1f6668d7e5a96e0a944a54c39a914158'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a52c92c804d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:33,56 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:33:33,58 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:34,17 httpcore.http11 DEBUG receive_response_body.complete
21:33:34,18 httpcore.http11 DEBUG response_closed.started
21:33:34,19 httpcore.http11 DEBUG response_closed.complete
21:33:34,20 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:33:34,94 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:33:46,40 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:33:46,45 httpcore.connection DEBUG close.started
21:33:46,46 httpcore.connection DEBUG close.complete
21:33:46,46 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:33:47,75 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fe8d0>
21:33:47,76 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:33:47,84 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ff250>
21:33:47,84 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:47,86 httpcore.http11 DEBUG send_request_headers.complete
21:33:47,86 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:47,108 httpcore.http11 DEBUG send_request_body.complete
21:33:47,108 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:47,919 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:47 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'393'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd2c59e781a211f7ffd650b7a904739da'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a53254b754d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:47,922 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:33:47,922 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:47,923 httpcore.http11 DEBUG receive_response_body.complete
21:33:47,923 httpcore.http11 DEBUG response_closed.started
21:33:47,924 httpcore.http11 DEBUG response_closed.complete
21:33:47,924 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:33:47,925 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:33:47,959 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:33:47,962 httpcore.connection DEBUG close.started
21:33:47,963 httpcore.connection DEBUG close.complete
21:33:47,963 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:33:47,966 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40c690>
21:33:47,966 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:33:47,971 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40d950>
21:33:47,971 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:47,972 httpcore.http11 DEBUG send_request_headers.complete
21:33:47,973 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:47,973 httpcore.http11 DEBUG send_request_body.complete
21:33:47,973 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:48,174 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dccc9cd3a08a4335716411f516549b12'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a532adb9c4d0e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:48,179 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:33:48,180 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:48,181 httpcore.http11 DEBUG receive_response_body.complete
21:33:48,182 httpcore.http11 DEBUG response_closed.started
21:33:48,182 httpcore.http11 DEBUG response_closed.complete
21:33:48,183 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:33:48,216 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:33:48,219 httpcore.connection DEBUG close.started
21:33:48,220 httpcore.connection DEBUG close.complete
21:33:48,220 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:33:48,223 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3effd0>
21:33:48,223 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:33:48,230 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed4d0>
21:33:48,230 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:48,231 httpcore.http11 DEBUG send_request_headers.complete
21:33:48,231 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:48,232 httpcore.http11 DEBUG send_request_body.complete
21:33:48,232 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:48,416 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'64'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7bf6edd219607fe8215436b9ff1452c8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a532c79674d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:48,422 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:33:48,423 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:48,424 httpcore.http11 DEBUG receive_response_body.complete
21:33:48,425 httpcore.http11 DEBUG response_closed.started
21:33:48,425 httpcore.http11 DEBUG response_closed.complete
21:33:48,425 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:33:48,442 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:48,445 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:51,853 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:51,860 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:33:51,867 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:51,868 httpcore.http11 DEBUG send_request_headers.complete
21:33:51,868 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:51,868 httpcore.http11 DEBUG send_request_body.complete
21:33:51,869 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:52,547 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'568'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'540b242be95bca3af6639193a9531e76'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a53432e3e4d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:52,552 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:33:52,553 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:53,612 httpcore.http11 DEBUG receive_response_body.complete
21:33:53,612 httpcore.http11 DEBUG response_closed.started
21:33:53,613 httpcore.http11 DEBUG response_closed.complete
21:33:53,614 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:33:53,677 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:34:06,249 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:34:06,253 httpcore.connection DEBUG close.started
21:34:06,253 httpcore.connection DEBUG close.complete
21:34:06,254 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:34:06,282 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40c350>
21:34:06,282 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:34:06,289 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40e750>
21:34:06,290 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:06,291 httpcore.http11 DEBUG send_request_headers.complete
21:34:06,292 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:06,308 httpcore.http11 DEBUG send_request_body.complete
21:34:06,308 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:07,317 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'408'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'aedd01f2feb1c7990e3b21e61a1e15d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a539d5e354cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:07,322 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:34:07,323 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:07,324 httpcore.http11 DEBUG receive_response_body.complete
21:34:07,325 httpcore.http11 DEBUG response_closed.started
21:34:07,326 httpcore.http11 DEBUG response_closed.complete
21:34:07,326 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:34:07,327 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:34:07,356 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\noff to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:34:07,359 httpcore.connection DEBUG close.started
21:34:07,359 httpcore.connection DEBUG close.complete
21:34:07,360 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:34:07,362 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ff290>
21:34:07,362 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:34:07,367 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ff590>
21:34:07,368 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:07,369 httpcore.http11 DEBUG send_request_headers.complete
21:34:07,369 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:07,370 httpcore.http11 DEBUG send_request_body.complete
21:34:07,370 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:07,604 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'93aa6898e113ef52e2e4964c7bf2995b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a53a40e204cdc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:07,610 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:34:07,610 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:07,611 httpcore.http11 DEBUG receive_response_body.complete
21:34:07,611 httpcore.http11 DEBUG response_closed.started
21:34:07,612 httpcore.http11 DEBUG response_closed.complete
21:34:07,612 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:34:07,628 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:34:07,631 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:34:11,33 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:34:11,39 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:34:11,46 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:11,47 httpcore.http11 DEBUG send_request_headers.complete
21:34:11,48 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:11,48 httpcore.http11 DEBUG send_request_body.complete
21:34:11,49 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:11,541 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:11 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8ef990cbba80b93fd1e7b0e61cd7817d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a53bb0eee4cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:11,544 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:34:11,545 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:12,832 httpcore.http11 DEBUG receive_response_body.complete
21:34:12,833 httpcore.http11 DEBUG response_closed.started
21:34:12,834 httpcore.http11 DEBUG response_closed.complete
21:34:12,835 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:34:12,904 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:34:25,504 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:34:25,510 httpcore.connection DEBUG close.started
21:34:25,511 httpcore.connection DEBUG close.complete
21:34:25,512 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:34:25,515 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee408110>
21:34:25,515 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:34:25,521 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40a050>
21:34:25,521 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:25,523 httpcore.http11 DEBUG send_request_headers.complete
21:34:25,523 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:25,549 httpcore.http11 DEBUG send_request_body.complete
21:34:25,550 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:26,627 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:26 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'13'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'49e8da70b170eb6e034d6d09aefcdc3a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a54158be64ce9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:26,632 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:34:26,632 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:26,633 httpcore.http11 DEBUG receive_response_body.complete
21:34:26,634 httpcore.http11 DEBUG response_closed.started
21:34:26,634 httpcore.http11 DEBUG response_closed.complete
21:34:26,635 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:34:26,636 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:34:26,667 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nto the right\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:34:26,670 httpcore.connection DEBUG close.started
21:34:26,671 httpcore.connection DEBUG close.complete
21:34:26,671 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:34:26,674 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee41a6d0>
21:34:26,674 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:34:26,683 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee419450>
21:34:26,684 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:26,686 httpcore.http11 DEBUG send_request_headers.complete
21:34:26,686 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:26,686 httpcore.http11 DEBUG send_request_body.complete
21:34:26,687 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:26,924 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ccb10f64b49ebe419a5b3cada5b4358a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a541cc8d64cdb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:26,931 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:34:26,932 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:26,934 httpcore.http11 DEBUG receive_response_body.complete
21:34:26,934 httpcore.http11 DEBUG response_closed.started
21:34:26,934 httpcore.http11 DEBUG response_closed.complete
21:34:26,935 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:34:26,950 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:34:26,952 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:34:30,354 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:34:30,361 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:34:30,370 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:30,371 httpcore.http11 DEBUG send_request_headers.complete
21:34:30,371 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:30,372 httpcore.http11 DEBUG send_request_body.complete
21:34:30,372 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:30,890 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:30 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'442'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6362d0e0dcc82a1dc52654da560ba6e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5433db824ce9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:30,894 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:34:30,895 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:31,884 httpcore.http11 DEBUG receive_response_body.complete
21:34:31,885 httpcore.http11 DEBUG response_closed.started
21:34:31,885 httpcore.http11 DEBUG response_closed.complete
21:34:31,885 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:34:31,949 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:34:44,492 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:34:44,496 httpcore.connection DEBUG close.started
21:34:44,497 httpcore.connection DEBUG close.complete
21:34:44,497 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:34:44,500 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fc650>
21:34:44,500 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:34:44,507 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fe990>
21:34:44,508 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:44,509 httpcore.http11 DEBUG send_request_headers.complete
21:34:44,509 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:44,531 httpcore.http11 DEBUG send_request_body.complete
21:34:44,531 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:45,308 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'10'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'332'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9815f66d5b4d225f05ee89374d692c52'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a548c2a6f4d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:45,313 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:34:45,314 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:45,316 httpcore.http11 DEBUG receive_response_body.complete
21:34:45,316 httpcore.http11 DEBUG response_closed.started
21:34:45,317 httpcore.http11 DEBUG response_closed.complete
21:34:45,318 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:34:45,318 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:34:45,346 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove down\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:34:45,349 httpcore.connection DEBUG close.started
21:34:45,350 httpcore.connection DEBUG close.complete
21:34:45,350 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:34:45,352 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40e2d0>
21:34:45,352 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:34:45,359 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40dd50>
21:34:45,359 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:45,361 httpcore.http11 DEBUG send_request_headers.complete
21:34:45,361 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:45,361 httpcore.http11 DEBUG send_request_body.complete
21:34:45,362 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:45,573 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6a15a67c9fe9d68265b61654785d2d86'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a54918b503b7b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:45,578 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:34:45,578 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:45,579 httpcore.http11 DEBUG receive_response_body.complete
21:34:45,580 httpcore.http11 DEBUG response_closed.started
21:34:45,580 httpcore.http11 DEBUG response_closed.complete
21:34:45,580 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:34:45,597 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:34:45,601 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:34:49,3 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:34:49,12 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:34:49,17 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:49,18 httpcore.http11 DEBUG send_request_headers.complete
21:34:49,18 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:49,19 httpcore.http11 DEBUG send_request_body.complete
21:34:49,19 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:49,559 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:49 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'448'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'98c69fddd15f3fec2544b6cffa878638'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a54a859b34d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:49,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:34:49,565 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:50,756 httpcore.http11 DEBUG receive_response_body.complete
21:34:50,756 httpcore.http11 DEBUG response_closed.started
21:34:50,757 httpcore.http11 DEBUG response_closed.complete
21:34:50,758 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:34:50,821 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:35:03,305 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent9.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:35:03,310 httpcore.connection DEBUG close.started
21:35:03,310 httpcore.connection DEBUG close.complete
21:35:03,311 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:35:03,313 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ec610>
21:35:03,313 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:35:03,320 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee0d0>
21:35:03,320 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:03,322 httpcore.http11 DEBUG send_request_headers.complete
21:35:03,322 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:03,339 httpcore.http11 DEBUG send_request_body.complete
21:35:03,340 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:04,220 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:04 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8a2b2673fa04feb4a54c656af725fcf0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5501ca703061-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:04,222 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:35:04,223 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:04,223 httpcore.http11 DEBUG receive_response_body.complete
21:35:04,224 httpcore.http11 DEBUG response_closed.started
21:35:04,224 httpcore.http11 DEBUG response_closed.complete
21:35:04,224 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:35:04,225 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:35:04,251 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:35:04,255 httpcore.connection DEBUG close.started
21:35:04,255 httpcore.connection DEBUG close.complete
21:35:04,255 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:35:04,258 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee419890>
21:35:04,258 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:35:04,265 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee41ab10>
21:35:04,266 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:04,267 httpcore.http11 DEBUG send_request_headers.complete
21:35:04,267 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:04,267 httpcore.http11 DEBUG send_request_body.complete
21:35:04,268 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:04,499 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'00b46a41a3950624ce7f336b13a3fcb0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5507af3f4cc6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:04,506 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:35:04,507 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:04,509 httpcore.http11 DEBUG receive_response_body.complete
21:35:04,509 httpcore.http11 DEBUG response_closed.started
21:35:04,510 httpcore.http11 DEBUG response_closed.complete
21:35:04,510 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:35:04,525 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:04,528 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:07,929 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:07,934 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:35:07,939 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:07,941 httpcore.http11 DEBUG send_request_headers.complete
21:35:07,942 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:07,942 httpcore.http11 DEBUG send_request_body.complete
21:35:07,943 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:08,447 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:08 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'430'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b1044a78153689d781f70be414031dc3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a551eacac3061-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:08,451 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:35:08,452 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:09,635 httpcore.http11 DEBUG receive_response_body.complete
21:35:09,636 httpcore.http11 DEBUG response_closed.started
21:35:09,637 httpcore.http11 DEBUG response_closed.complete
21:35:09,639 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:35:09,711 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent10.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:35:22,282 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent10.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:35:22,289 httpcore.connection DEBUG close.started
21:35:22,290 httpcore.connection DEBUG close.complete
21:35:22,290 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:35:22,320 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40f510>
21:35:22,320 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:35:22,330 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40dad0>
21:35:22,331 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:22,333 httpcore.http11 DEBUG send_request_headers.complete
21:35:22,334 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:22,354 httpcore.http11 DEBUG send_request_body.complete
21:35:22,354 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:23,248 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:23 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b6c0cf91f03da1315c631d4f6a176b03'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5578992c4d07-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:23,253 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:35:23,254 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:23,256 httpcore.http11 DEBUG receive_response_body.complete
21:35:23,256 httpcore.http11 DEBUG response_closed.started
21:35:23,257 httpcore.http11 DEBUG response_closed.complete
21:35:23,258 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:35:23,259 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:35:23,288 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:35:23,291 httpcore.connection DEBUG close.started
21:35:23,291 httpcore.connection DEBUG close.complete
21:35:23,292 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:35:23,294 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fd210>
21:35:23,294 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:35:23,302 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fef10>
21:35:23,302 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:23,303 httpcore.http11 DEBUG send_request_headers.complete
21:35:23,304 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:23,304 httpcore.http11 DEBUG send_request_body.complete
21:35:23,304 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:23,600 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5f96571c49e06550c01c36898d7b6a53'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a557eab3a4d16-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:23,606 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:35:23,606 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:23,607 httpcore.http11 DEBUG receive_response_body.complete
21:35:23,607 httpcore.http11 DEBUG response_closed.started
21:35:23,608 httpcore.http11 DEBUG response_closed.complete
21:35:23,608 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:35:23,624 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:23,627 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:27,29 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:27,46 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:27,50 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:29,53 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:29,72 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:29,76 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:32,478 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:32,484 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:35:32,493 httpcore.connection DEBUG close.started
21:35:32,493 httpcore.connection DEBUG close.complete
21:35:32,494 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:35:32,497 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fca10>
21:35:32,497 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:35:32,502 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fd490>
21:35:32,503 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:32,504 httpcore.http11 DEBUG send_request_headers.complete
21:35:32,504 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:32,505 httpcore.http11 DEBUG send_request_body.complete
21:35:32,505 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:33,134 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:33 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'487'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2173c0dbf4b44bd0655f0cac65a97145'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a55b829b04d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:33,139 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:35:33,140 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:33,603 httpcore.http11 DEBUG receive_response_body.complete
21:35:33,603 httpcore.http11 DEBUG response_closed.started
21:35:33,604 httpcore.http11 DEBUG response_closed.complete
21:35:33,604 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:35:33,674 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent11.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:35:44,968 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent11.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:35:44,973 httpcore.connection DEBUG close.started
21:35:44,973 httpcore.connection DEBUG close.complete
21:35:44,974 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:35:44,976 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee409ed0>
21:35:44,977 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:35:44,984 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40b710>
21:35:44,985 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:44,986 httpcore.http11 DEBUG send_request_headers.complete
21:35:44,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:45,24 httpcore.http11 DEBUG send_request_body.complete
21:35:45,24 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:45,885 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'31'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'07d6caf40507f6c459c4aef1dafd0105'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a56062f604d12-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:45,889 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:35:45,890 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:45,890 httpcore.http11 DEBUG receive_response_body.complete
21:35:45,891 httpcore.http11 DEBUG response_closed.started
21:35:45,891 httpcore.http11 DEBUG response_closed.complete
21:35:45,892 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:35:45,892 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:35:45,923 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it below the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:35:45,928 httpcore.connection DEBUG close.started
21:35:45,929 httpcore.connection DEBUG close.complete
21:35:45,929 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:35:45,932 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40d950>
21:35:45,933 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:35:45,939 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40da90>
21:35:45,939 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:45,941 httpcore.http11 DEBUG send_request_headers.complete
21:35:45,941 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:45,942 httpcore.http11 DEBUG send_request_body.complete
21:35:45,943 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:46,178 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'124'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'53a2dbe0df4969f4d28805acc5f7b090'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a560c2bfb4cfc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:46,184 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:35:46,185 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:46,186 httpcore.http11 DEBUG receive_response_body.complete
21:35:46,187 httpcore.http11 DEBUG response_closed.started
21:35:46,187 httpcore.http11 DEBUG response_closed.complete
21:35:46,187 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:35:46,221 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it below the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:35:46,224 httpcore.connection DEBUG close.started
21:35:46,224 httpcore.connection DEBUG close.complete
21:35:46,225 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:35:46,227 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee41d8d0>
21:35:46,228 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e2690> server_hostname='api.openai.com' timeout=None
21:35:46,235 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee41f350>
21:35:46,235 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:46,237 httpcore.http11 DEBUG send_request_headers.complete
21:35:46,238 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:46,239 httpcore.http11 DEBUG send_request_body.complete
21:35:46,239 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:46,944 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'572'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1abf9c02ddab4e723e386f74273e16ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a560dfffc4cfc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:46,949 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:35:46,950 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:46,952 httpcore.http11 DEBUG receive_response_body.complete
21:35:46,953 httpcore.http11 DEBUG response_closed.started
21:35:46,953 httpcore.http11 DEBUG response_closed.complete
21:35:46,954 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:35:46,971 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:46,975 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:53,477 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:53,496 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:53,499 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:58,501 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:58,512 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:58,516 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:00,519 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:00,538 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:00,541 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:03,943 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:03,960 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:03,963 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:10,466 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:10,487 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:10,491 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:13,895 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:13,911 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:13,915 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:18,918 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:18,925 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:36:18,932 httpcore.connection DEBUG close.started
21:36:18,933 httpcore.connection DEBUG close.complete
21:36:18,934 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:36:18,937 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40b710>
21:36:18,937 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:36:18,943 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40a890>
21:36:18,944 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:18,945 httpcore.http11 DEBUG send_request_headers.complete
21:36:18,945 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:18,946 httpcore.http11 DEBUG send_request_body.complete
21:36:18,946 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:19,457 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'430'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ec526e8875cfa33ec31a60f78ba28e59'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a56da6c733010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:19,463 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:36:19,464 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:20,698 httpcore.http11 DEBUG receive_response_body.complete
21:36:20,698 httpcore.http11 DEBUG response_closed.started
21:36:20,698 httpcore.http11 DEBUG response_closed.complete
21:36:20,699 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:36:20,767 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent12.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:36:33,322 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent12.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:36:33,329 httpcore.connection DEBUG close.started
21:36:33,329 httpcore.connection DEBUG close.complete
21:36:33,330 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:36:33,357 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ca450>
21:36:33,357 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:36:33,364 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3c99d0>
21:36:33,364 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:33,366 httpcore.http11 DEBUG send_request_headers.complete
21:36:33,366 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:33,384 httpcore.http11 DEBUG send_request_body.complete
21:36:33,384 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:34,236 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'edfb1a3be5f3d68cbdcf55978f8f7e90'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a573489073b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:34,241 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:36:34,242 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:34,243 httpcore.http11 DEBUG receive_response_body.complete
21:36:34,244 httpcore.http11 DEBUG response_closed.started
21:36:34,245 httpcore.http11 DEBUG response_closed.complete
21:36:34,245 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:36:34,246 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:36:34,273 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove down.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:36:34,276 httpcore.connection DEBUG close.started
21:36:34,276 httpcore.connection DEBUG close.complete
21:36:34,277 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:36:34,279 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee610>
21:36:34,279 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:36:34,286 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3efa10>
21:36:34,287 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:34,288 httpcore.http11 DEBUG send_request_headers.complete
21:36:34,288 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:34,288 httpcore.http11 DEBUG send_request_body.complete
21:36:34,289 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:34,524 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a5b010a32bca11cb7b6ed7fe93faff26'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a573a48c24cec-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:34,529 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:36:34,530 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:34,530 httpcore.http11 DEBUG receive_response_body.complete
21:36:34,531 httpcore.http11 DEBUG response_closed.started
21:36:34,531 httpcore.http11 DEBUG response_closed.complete
21:36:34,531 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:36:34,567 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove down.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:36:34,570 httpcore.connection DEBUG close.started
21:36:34,571 httpcore.connection DEBUG close.complete
21:36:34,571 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:36:34,574 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fef10>
21:36:34,574 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:36:34,585 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ff690>
21:36:34,585 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:34,587 httpcore.http11 DEBUG send_request_headers.complete
21:36:34,588 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:34,589 httpcore.http11 DEBUG send_request_body.complete
21:36:34,589 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:34,831 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5e4b007dd747f812d0540e9816795bdb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a573c2fd14cd6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:34,836 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:36:34,837 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:34,838 httpcore.http11 DEBUG receive_response_body.complete
21:36:34,839 httpcore.http11 DEBUG response_closed.started
21:36:34,839 httpcore.http11 DEBUG response_closed.complete
21:36:34,840 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:36:34,856 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:34,860 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:38,263 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:38,271 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:36:38,278 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:38,279 httpcore.http11 DEBUG send_request_headers.complete
21:36:38,279 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:38,280 httpcore.http11 DEBUG send_request_body.complete
21:36:38,280 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:38,992 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'590'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd809338ee505bfc38db87201268fa95d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a57533e163b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:38,998 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:36:38,998 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:40,96 httpcore.http11 DEBUG receive_response_body.complete
21:36:40,97 httpcore.http11 DEBUG response_closed.started
21:36:40,98 httpcore.http11 DEBUG response_closed.complete
21:36:40,99 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:36:40,167 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent13.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:38:51,197 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:51,201 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,22 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,23 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,64 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,65 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,113 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,114 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,155 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,156 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,202 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,204 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,244 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,245 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,293 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,294 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,335 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,336 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:53,247 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:38:53,267 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:38:53,299 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce6f10>
21:38:53,300 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61d00> server_hostname='api.openai.com' timeout=5.0
21:38:53,307 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce7450>
21:38:53,308 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:38:53,311 httpcore.http11 DEBUG send_request_headers.complete
21:38:53,312 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:38:53,313 httpcore.http11 DEBUG send_request_body.complete
21:38:53,313 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:38:53,966 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:38:53 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'538'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1dc972a2a98cd7409685f2b1ba540fa3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XuR6dHiFWDet6yM8pNetMsJGLr3EEqb327OWzeMeUGg-1702262333-1-AbxsMkwu+SPwSzDya0nzRU3B9r9E4KzjTDia/PPTArPD/xe+6rUgZlK8A1r4iLBuzjVerTuM2Dn+H8m2a8D+dSc=; path=/; expires=Mon, 11-Dec-23 03:08:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NejP2LMGGfd9B2K0X.9E5eyEVgvg6HTdxtSQK_ZhtZA-1702262333959-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5a9f3fbc4cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:38:53,974 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:38:53,974 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:38:54,719 httpcore.http11 DEBUG receive_response_body.complete
21:38:54,720 httpcore.http11 DEBUG response_closed.started
21:38:54,720 httpcore.http11 DEBUG response_closed.complete
21:38:54,721 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:38:54,799 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:39:08,83 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:39:08,93 httpcore.connection DEBUG close.started
21:39:08,93 httpcore.connection DEBUG close.complete
21:39:08,94 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:39:08,97 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce7590>
21:39:08,97 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61d00> server_hostname='api.openai.com' timeout=5.0
21:39:08,103 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce7710>
21:39:08,104 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:08,105 httpcore.http11 DEBUG send_request_headers.complete
21:39:08,105 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:08,137 httpcore.http11 DEBUG send_request_body.complete
21:39:08,137 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:09,0 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:08 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'199d392ac5ab3e89a9ace3b4cbe883fd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5afbab7f4cf4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:09,6 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:39:09,7 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:09,8 httpcore.http11 DEBUG receive_response_body.complete
21:39:09,9 httpcore.http11 DEBUG response_closed.started
21:39:09,10 httpcore.http11 DEBUG response_closed.complete
21:39:09,10 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:39:09,10 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:39:09,43 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:39:09,55 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:39:09,57 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb37010>
21:39:09,57 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61eb0> server_hostname='api.openai.com' timeout=None
21:39:09,64 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82e733010>
21:39:09,64 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:09,66 httpcore.http11 DEBUG send_request_headers.complete
21:39:09,66 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:09,66 httpcore.http11 DEBUG send_request_body.complete
21:39:09,67 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:09,280 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2318b9f608f30d4add1820b0a10ab99a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=90hcpys9mXXA0VCT7iOFmpeByDIL84iovesQrz2SsU8-1702262349-1-AeVAMRtc38Lk3piszm8aXrmiaoFrLJ4x9rDJKCROhbRKHPzSyEVIXZpa8NpCOVwLmD2puetcUajSjUt0QmuFJf0=; path=/; expires=Mon, 11-Dec-23 03:09:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=7GfasFhw.AYzIxLcYviyAOt7v1Z.PFho0p_6E6OGGQk-1702262349276-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5b01acc26ac6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:09,288 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:39:09,289 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:09,292 httpcore.http11 DEBUG receive_response_body.complete
21:39:09,292 httpcore.http11 DEBUG response_closed.started
21:39:09,293 httpcore.http11 DEBUG response_closed.complete
21:39:09,293 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:39:09,326 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:39:09,337 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:39:09,355 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb47c50>
21:39:09,356 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd62690> server_hostname='api.openai.com' timeout=None
21:39:09,363 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb44250>
21:39:09,364 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:09,366 httpcore.http11 DEBUG send_request_headers.complete
21:39:09,366 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:09,367 httpcore.http11 DEBUG send_request_body.complete
21:39:09,367 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:10,482 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'864'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cfafc262672a5e510f39022200743952'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mUyF_fkF0Jc0av20NXdVp63D4TULpdBXMUJA6xuI3J0-1702262350-1-AZui/GQWY5MegJ4dLdTjtF47IUXSL5EoLkWPKNFSoY/7H1pfXTpVAzk5TbngxN4qYIBN64gcTnKG3z9abqH/sUM=; path=/; expires=Mon, 11-Dec-23 03:09:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=4WX_MZXtmGXxW0XzONPsoglFzezneXtl.zsSDErPJos-1702262350477-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5b038d214ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:10,488 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:39:10,488 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:10,490 httpcore.http11 DEBUG receive_response_body.complete
21:39:10,490 httpcore.http11 DEBUG response_closed.started
21:39:10,490 httpcore.http11 DEBUG response_closed.complete
21:39:10,491 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:39:10,509 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:10,513 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:17,21 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:17,40 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:17,44 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:22,46 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:22,64 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:22,67 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:24,69 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:24,85 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:24,88 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:27,490 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:27,509 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:27,512 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:34,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:34,30 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:34,33 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:37,837 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:37,856 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:37,860 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:41,663 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:41,671 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:39:41,676 httpcore.connection DEBUG close.started
21:39:41,677 httpcore.connection DEBUG close.complete
21:39:41,677 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:39:41,680 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce7710>
21:39:41,681 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61d00> server_hostname='api.openai.com' timeout=5.0
21:39:41,688 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb4c510>
21:39:41,688 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:41,690 httpcore.http11 DEBUG send_request_headers.complete
21:39:41,691 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:41,691 httpcore.http11 DEBUG send_request_body.complete
21:39:41,692 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:42,171 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'403'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6bfe35f6f56ccc230c806a4295e99005'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5bcd9a153068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:42,176 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:39:42,177 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:43,284 httpcore.http11 DEBUG receive_response_body.complete
21:39:43,285 httpcore.http11 DEBUG response_closed.started
21:39:43,285 httpcore.http11 DEBUG response_closed.complete
21:39:43,286 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:39:43,356 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:39:55,836 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:39:55,840 httpcore.connection DEBUG close.started
21:39:55,841 httpcore.connection DEBUG close.complete
21:39:55,841 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:39:55,870 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb72490>
21:39:55,871 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61d00> server_hostname='api.openai.com' timeout=5.0
21:39:55,879 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb72510>
21:39:55,879 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:55,881 httpcore.http11 DEBUG send_request_headers.complete
21:39:55,881 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:55,906 httpcore.http11 DEBUG send_request_body.complete
21:39:55,906 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:56,738 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:56 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'361'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'df08aec852f455457652db8b4eb8db4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5c264a9c4d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:56,744 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:39:56,745 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:56,746 httpcore.http11 DEBUG receive_response_body.complete
21:39:56,746 httpcore.http11 DEBUG response_closed.started
21:39:56,747 httpcore.http11 DEBUG response_closed.complete
21:39:56,747 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:39:56,748 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:39:56,778 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nUh, yes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:39:56,782 httpcore.connection DEBUG close.started
21:39:56,783 httpcore.connection DEBUG close.complete
21:39:56,783 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:39:56,786 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb36f10>
21:39:56,786 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61eb0> server_hostname='api.openai.com' timeout=None
21:39:56,793 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb37010>
21:39:56,793 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:56,794 httpcore.http11 DEBUG send_request_headers.complete
21:39:56,795 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:56,795 httpcore.http11 DEBUG send_request_body.complete
21:39:56,796 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:57,0 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'af27e90c57b6a2211563d1edadc9a063'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5c2bf9304d02-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:57,5 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:39:57,6 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:57,7 httpcore.http11 DEBUG receive_response_body.complete
21:39:57,7 httpcore.http11 DEBUG response_closed.started
21:39:57,8 httpcore.http11 DEBUG response_closed.complete
21:39:57,8 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:39:57,43 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nUh, yes.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:39:57,55 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:39:57,58 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb73850>
21:39:57,58 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd62210> server_hostname='api.openai.com' timeout=None
21:39:57,64 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb73390>
21:39:57,65 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:57,66 httpcore.http11 DEBUG send_request_headers.complete
21:39:57,66 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:57,67 httpcore.http11 DEBUG send_request_body.complete
21:39:57,67 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:57,947 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'789'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b345d98b80cc1650f8595ffc4c3d510a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jFc99JuO9cuXY1jcUCbH8jCC.5.EwfGf9wEEbzpuudc-1702262397-1-AeyJ+Awzw+WqleAHwfuU5KtRhXWf4o4yl3kYhHc1Jj9O7EI4ssvZ8B6xXDnI6yGJk5t9ISLE7Pvf0irsG1PhVp4=; path=/; expires=Mon, 11-Dec-23 03:09:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Vo5gG_cpdJPHtRa07q4sBVSx9YpxrecfYFLB7DDItM0-1702262397942-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5c2daca94d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:57,955 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:39:57,955 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:57,956 httpcore.http11 DEBUG receive_response_body.complete
21:39:57,956 httpcore.http11 DEBUG response_closed.started
21:39:57,957 httpcore.http11 DEBUG response_closed.complete
21:39:57,957 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:39:57,965 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Great! Let's keep going. Can you please move the next candle to the left a bit? Once you have placed all the candles, we can light them up and enjoy the cake!", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:39:57,968 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:57,970 httpcore.http11 DEBUG send_request_headers.complete
21:39:57,970 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:57,971 httpcore.http11 DEBUG send_request_body.complete
21:39:57,971 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:58,506 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'464'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6328283f5ca6d66553d96fe27c0b0441'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5c335a3e4d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:58,508 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:39:58,509 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:59,842 httpcore.http11 DEBUG receive_response_body.complete
21:39:59,843 httpcore.http11 DEBUG response_closed.started
21:39:59,843 httpcore.http11 DEBUG response_closed.complete
21:39:59,844 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:39:59,916 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:51:58,1 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,7 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:58,832 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,833 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:58,874 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,875 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:58,924 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,925 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:58,966 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,967 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:59,14 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:59,15 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:59,56 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:59,58 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:59,105 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:59,106 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:59,147 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:59,148 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:52:02,846 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:52:02,868 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:52:02,899 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f822535d0>
21:52:02,900 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:52:02,908 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82253ad0>
21:52:02,910 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:02,911 httpcore.http11 DEBUG send_request_headers.complete
21:52:02,912 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:02,912 httpcore.http11 DEBUG send_request_body.complete
21:52:02,913 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:03,371 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:03 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'82b4fb9c8fba4dd5fdbe104709699bb0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=P6KrdQzKvliYSRglOJr8gX6fxxW9tGLdkkz5edOY0YA-1702263123-1-AYx8U06QecceD/xcwaICNtoz4Q0UmRMF7QKCK4vZ10iB87En1bg/HWq88DEoQ9FK2sTgNf6K17QJvKoZYK+ovgc=; path=/; expires=Mon, 11-Dec-23 03:22:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=JHsJ792RKLrQjeQ9wwpCce66p7RUtapa15zzY3.wFv4-1702263123365-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6de638244cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:03,382 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:52:03,383 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:04,153 httpcore.http11 DEBUG receive_response_body.complete
21:52:04,154 httpcore.http11 DEBUG response_closed.started
21:52:04,154 httpcore.http11 DEBUG response_closed.complete
21:52:04,155 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:52:04,233 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:52:17,569 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:52:17,583 httpcore.connection DEBUG close.started
21:52:17,583 httpcore.connection DEBUG close.complete
21:52:17,584 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:52:17,586 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82253c50>
21:52:17,587 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:52:17,592 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82253dd0>
21:52:17,593 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:17,594 httpcore.http11 DEBUG send_request_headers.complete
21:52:17,594 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:17,645 httpcore.http11 DEBUG send_request_body.complete
21:52:17,645 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:18,623 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'454'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a42bed77301e1b3163a40b51236220ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6e41f9614ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:18,630 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:52:18,630 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:18,631 httpcore.http11 DEBUG receive_response_body.complete
21:52:18,632 httpcore.http11 DEBUG response_closed.started
21:52:18,632 httpcore.http11 DEBUG response_closed.complete
21:52:18,632 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:52:18,633 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:52:18,667 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:52:18,680 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:52:18,683 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b4110>
21:52:18,683 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9f40> server_hostname='api.openai.com' timeout=None
21:52:18,688 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b4050>
21:52:18,689 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:18,690 httpcore.http11 DEBUG send_request_headers.complete
21:52:18,690 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:18,691 httpcore.http11 DEBUG send_request_body.complete
21:52:18,691 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:18,912 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8b4bb834fc36ce0736c6003cd3d32245'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cO2zrtcI9AY7n4r_ddi6yBjlBxSBEw0WwOJlM.4B_kQ-1702263138-1-AY8B6FbYQcrUDsseRfPHxL0XAASiOFJQamejCcJ3OGcxyE6ozlZScIfgJK2AkiFDbnhyR4cFUdqloXBha63Akcs=; path=/; expires=Mon, 11-Dec-23 03:22:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rsB6OtRo2_8WCQFCh_8_VgXlYx9SbgY24KCOBqd6ZtY-1702263138909-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6e48d9f13b70-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:18,916 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:52:18,917 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:18,918 httpcore.http11 DEBUG receive_response_body.complete
21:52:18,918 httpcore.http11 DEBUG response_closed.started
21:52:18,918 httpcore.http11 DEBUG response_closed.complete
21:52:18,919 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:52:18,956 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:52:18,968 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:52:18,970 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f824ce950>
21:52:18,971 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822da720> server_hostname='api.openai.com' timeout=None
21:52:18,977 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b4710>
21:52:18,977 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:18,978 httpcore.http11 DEBUG send_request_headers.complete
21:52:18,979 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:18,979 httpcore.http11 DEBUG send_request_body.complete
21:52:18,979 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:19,898 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'824'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0e7af500c0107fb5de75d3d733bb4e6d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0DowzlPNPBv5cYaP49YTMy5VM6KuuzW7SFhMHNmiBD8-1702263139-1-Af0TaECuV53rU/pd7zDNTOmoW90Y0xlhGqqjoyXQXIwaJGLNgVzHL8ncYwkXurIX/EuyWxbjIATeef2syu9ubrs=; path=/; expires=Mon, 11-Dec-23 03:22:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LyRVuS8LgZV0vAklcHzFG0wT1K4_E4.pqR98RSmjR6c-1702263139892-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6e4a98304d1c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:19,904 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:52:19,904 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:19,905 httpcore.http11 DEBUG receive_response_body.complete
21:52:19,906 httpcore.http11 DEBUG response_closed.started
21:52:19,906 httpcore.http11 DEBUG response_closed.complete
21:52:19,907 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:52:19,926 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:19,930 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:26,439 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:26,454 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:26,457 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:31,459 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:31,476 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:31,480 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:33,482 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:33,500 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:33,504 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:36,906 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:36,924 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:36,927 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:43,429 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:43,446 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:43,449 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:47,652 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:47,670 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:47,674 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:51,878 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:51,885 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:52:51,889 httpcore.connection DEBUG close.started
21:52:51,889 httpcore.connection DEBUG close.complete
21:52:51,890 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:52:51,906 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82297890>
21:52:51,907 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:52:51,913 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82252d10>
21:52:51,914 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:51,915 httpcore.http11 DEBUG send_request_headers.complete
21:52:51,916 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:51,916 httpcore.http11 DEBUG send_request_body.complete
21:52:51,917 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:52,501 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'479'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'17d4e9efd68fdae53bb45f8a85b30ca0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6f18797c3061-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:52,506 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:52:52,507 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:53,532 httpcore.http11 DEBUG receive_response_body.complete
21:52:53,533 httpcore.http11 DEBUG response_closed.started
21:52:53,534 httpcore.http11 DEBUG response_closed.complete
21:52:53,535 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:52:53,606 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:53:06,47 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:53:06,53 httpcore.connection DEBUG close.started
21:53:06,53 httpcore.connection DEBUG close.complete
21:53:06,54 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:53:06,83 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e69d0>
21:53:06,84 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:53:06,90 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e6a50>
21:53:06,90 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:06,91 httpcore.http11 DEBUG send_request_headers.complete
21:53:06,92 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:06,110 httpcore.http11 DEBUG send_request_body.complete
21:53:06,111 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:08,724 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:08 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'2105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'10b7cceb9f9c067315bd990550767540'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6f711b044cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:08,730 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:53:08,731 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:08,733 httpcore.http11 DEBUG receive_response_body.complete
21:53:08,733 httpcore.http11 DEBUG response_closed.started
21:53:08,734 httpcore.http11 DEBUG response_closed.complete
21:53:08,735 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:53:08,736 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:53:08,769 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nyes\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:53:08,773 httpcore.connection DEBUG close.started
21:53:08,773 httpcore.connection DEBUG close.complete
21:53:08,774 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:53:08,776 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b42d0>
21:53:08,777 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9f40> server_hostname='api.openai.com' timeout=None
21:53:08,781 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b5910>
21:53:08,782 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:08,783 httpcore.http11 DEBUG send_request_headers.complete
21:53:08,783 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:08,784 httpcore.http11 DEBUG send_request_body.complete
21:53:08,784 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:09,10 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ebc3eb7e95ba56324b5f195243f29a65'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6f81e93a4d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:09,16 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:53:09,17 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:09,19 httpcore.http11 DEBUG receive_response_body.complete
21:53:09,20 httpcore.http11 DEBUG response_closed.started
21:53:09,21 httpcore.http11 DEBUG response_closed.complete
21:53:09,22 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:53:09,53 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nyes\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:53:09,65 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:53:09,67 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e6390>
21:53:09,67 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9eb0> server_hostname='api.openai.com' timeout=None
21:53:09,74 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e63d0>
21:53:09,75 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:09,76 httpcore.http11 DEBUG send_request_headers.complete
21:53:09,76 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:09,77 httpcore.http11 DEBUG send_request_body.complete
21:53:09,77 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:09,307 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b9d57e9d6c94d2696fa486722a373659'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0.iPAX6uAQlEBKSbn63aJjw41zUUOkb7HTrizuACkCQ-1702263189-1-AQC88FwN+ZgEFqdqqQQs8nyxWBQOFUKeauZv+weUFlXPlnNZUIP3nfvvteB3W/rWHLSYF7ZdCCttYoYi2fE/lRA=; path=/; expires=Mon, 11-Dec-23 03:23:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3h_dZbbOVQ8yydSMvYWyix02QkHRK7Txfo8hUfXXKvM-1702263189302-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6f83b8ba4cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:09,315 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:53:09,317 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:09,318 httpcore.http11 DEBUG receive_response_body.complete
21:53:09,319 httpcore.http11 DEBUG response_closed.started
21:53:09,319 httpcore.http11 DEBUG response_closed.complete
21:53:09,319 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:53:09,335 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:09,337 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:12,739 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:12,759 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:12,763 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:14,765 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:14,780 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:14,783 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:18,185 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:18,188 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:53:18,192 httpcore.connection DEBUG close.started
21:53:18,192 httpcore.connection DEBUG close.complete
21:53:18,193 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:53:18,195 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e6910>
21:53:18,195 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:53:18,204 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e72d0>
21:53:18,205 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:18,207 httpcore.http11 DEBUG send_request_headers.complete
21:53:18,208 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:18,209 httpcore.http11 DEBUG send_request_body.complete
21:53:18,209 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:18,632 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:18 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b226b0bc33058a34587563ddb626e1c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6fbccd684d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:18,637 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:53:18,638 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:19,32 httpcore.http11 DEBUG receive_response_body.complete
21:53:19,32 httpcore.http11 DEBUG response_closed.started
21:53:19,33 httpcore.http11 DEBUG response_closed.complete
21:53:19,34 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:53:19,103 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:53:30,235 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:53:30,242 httpcore.connection DEBUG close.started
21:53:30,242 httpcore.connection DEBUG close.complete
21:53:30,243 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:53:30,245 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820f2b10>
21:53:30,246 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:53:30,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820f2b90>
21:53:30,251 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:30,252 httpcore.http11 DEBUG send_request_headers.complete
21:53:30,253 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:30,285 httpcore.http11 DEBUG send_request_body.complete
21:53:30,285 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:32,58 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:32 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'34'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1338'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd24ebbf86bcb391ff1785ae38f5de664'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a70081be54cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:32,66 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:53:32,68 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:32,69 httpcore.http11 DEBUG receive_response_body.complete
21:53:32,70 httpcore.http11 DEBUG response_closed.started
21:53:32,70 httpcore.http11 DEBUG response_closed.complete
21:53:32,70 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:53:32,71 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:53:32,101 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the right of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:53:32,105 httpcore.connection DEBUG close.started
21:53:32,105 httpcore.connection DEBUG close.complete
21:53:32,105 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:53:32,109 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820fdc90>
21:53:32,110 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9f40> server_hostname='api.openai.com' timeout=None
21:53:32,119 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820fdd10>
21:53:32,120 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:32,122 httpcore.http11 DEBUG send_request_headers.complete
21:53:32,123 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:32,124 httpcore.http11 DEBUG send_request_body.complete
21:53:32,125 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:32,341 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1aebb77a97d07092fd5c0da1ad952b7c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7013c92c4cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:32,348 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:53:32,349 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:32,351 httpcore.http11 DEBUG receive_response_body.complete
21:53:32,351 httpcore.http11 DEBUG response_closed.started
21:53:32,352 httpcore.http11 DEBUG response_closed.complete
21:53:32,352 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:53:32,389 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the right of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:53:32,393 httpcore.connection DEBUG close.started
21:53:32,393 httpcore.connection DEBUG close.complete
21:53:32,393 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:53:32,396 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820f3bd0>
21:53:32,397 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822da720> server_hostname='api.openai.com' timeout=None
21:53:32,404 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820f1050>
21:53:32,405 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:32,409 httpcore.http11 DEBUG send_request_headers.complete
21:53:32,410 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:32,411 httpcore.http11 DEBUG send_request_body.complete
21:53:32,412 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:32,859 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'340'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c9c1c43cc80f07c79421cb8d1c1f1763'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a70158eaa3ba6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:32,863 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:53:32,863 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:32,865 httpcore.http11 DEBUG receive_response_body.complete
21:53:32,865 httpcore.http11 DEBUG response_closed.started
21:53:32,866 httpcore.http11 DEBUG response_closed.complete
21:53:32,866 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:53:32,884 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:32,887 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:39,389 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:39,401 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:39,404 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:44,406 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:44,424 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:44,427 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:46,429 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:46,445 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:46,448 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:49,850 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:49,868 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:49,871 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:56,373 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:56,391 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:56,394 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:54:00,995 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:54:01,8 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:54:01,11 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:14,590 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:14,593 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,401 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,402 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,440 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,441 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,483 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,483 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,520 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,521 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,560 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,561 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,598 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,599 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,640 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,641 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,678 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,679 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,720 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:57:15,732 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:57:15,761 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a4035d0>
21:57:15,762 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:57:15,770 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a34ea50>
21:57:15,771 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:57:15,773 httpcore.http11 DEBUG send_request_headers.complete
21:57:15,773 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:57:15,774 httpcore.http11 DEBUG send_request_body.complete
21:57:15,774 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:57:16,411 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:57:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'519'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f1ce11860ba68de5e081704ecf82e6e4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ndg69kOB50ZxPUxn1BYt3n65nOP2iLt.lENh6u.j6Uk-1702263436-1-Abh5gGukCJQETusdToU53VKAD96n9NOgIYmnkMI+ojrJuvsG5QqHMjdgIMAAY6MpCkZjRNqTvDeO0pDEyDpaiao=; path=/; expires=Mon, 11-Dec-23 03:27:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IOA2LXrmMO7l6PkuAL7mjfKZ7sIjN5iMKaH1c7aUjDM-1702263436408-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a75899cbc3035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:57:16,414 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:57:16,415 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:57:17,202 httpcore.http11 DEBUG receive_response_body.complete
21:57:17,203 httpcore.http11 DEBUG response_closed.started
21:57:17,203 httpcore.http11 DEBUG response_closed.complete
21:57:17,204 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:57:17,272 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:57:30,499 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:57:30,507 httpcore.connection DEBUG close.started
21:57:30,507 httpcore.connection DEBUG close.complete
21:57:30,508 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:57:30,510 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a34eb10>
21:57:30,510 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:57:30,531 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a34dd10>
21:57:30,531 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:57:30,532 httpcore.http11 DEBUG send_request_headers.complete
21:57:30,532 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:57:30,563 httpcore.http11 DEBUG send_request_body.complete
21:57:30,564 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:57:31,464 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:57:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'15'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0a29848a462e427a5f688e77d157bafb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a75e5dd7f305d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:57:31,466 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:57:31,466 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:57:31,467 httpcore.http11 DEBUG receive_response_body.complete
21:57:31,467 httpcore.http11 DEBUG response_closed.started
21:57:31,468 httpcore.http11 DEBUG response_closed.complete
21:57:31,468 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:57:31,469 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:57:31,488 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:57:31,497 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:57:31,500 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36fb10>
21:57:31,500 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:57:31,508 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36f9d0>
21:57:31,508 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:57:31,509 httpcore.http11 DEBUG send_request_headers.complete
21:57:31,509 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:57:31,509 httpcore.http11 DEBUG send_request_body.complete
21:57:31,509 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:57:31,745 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:57:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'137'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'627844504904c4467b2cb31cd91f26db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2KjFBAZXqgKLOkL5Lk47kkT3KEjXNlRSlUvTIkNHy.E-1702263451-1-ARmxaGckDa8eFLPLn8D/PNKgR2GL8+4omCE6Xw8IwP+HWdknWBGOz6M4h8m+3/qwlC2PxjFEdXKXrPV85U89ww8=; path=/; expires=Mon, 11-Dec-23 03:27:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=wHEX6G8xNelus3za7Vp74BZ41lYiywrqnWcD_HfSjdY-1702263451741-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a75ebeb454cf0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:57:31,747 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:57:31,748 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:57:31,748 httpcore.http11 DEBUG receive_response_body.complete
21:57:31,748 httpcore.http11 DEBUG response_closed.started
21:57:31,749 httpcore.http11 DEBUG response_closed.complete
21:57:31,749 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:57:31,771 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:57:31,782 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:57:31,784 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36d310>
21:57:31,785 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d2720> server_hostname='api.openai.com' timeout=None
21:57:31,792 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1af7d0>
21:57:31,792 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:57:31,793 httpcore.http11 DEBUG send_request_headers.complete
21:57:31,793 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:57:31,794 httpcore.http11 DEBUG send_request_body.complete
21:57:31,794 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:57:32,539 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:57:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'646'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6ded54cc55c5f7fe0fad4512927143d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=a7InAs3iQ7otjv1GmzQ1GPPiryFb.WUNL.8cpvXtOQs-1702263452-1-Ae5YpjM47Weka/UT1HkHcZ/ldbHmGLXznlkfw2VCaYPfesnOdEoIuDFDTk3FxKlVVG9O36c+aGvHLuDsDmgHX+A=; path=/; expires=Mon, 11-Dec-23 03:27:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rfIRbTn01r_yhnvGj7BcqYfZDLFfg0sT1beRxcSauWQ-1702263452535-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a75edb8704cc2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:57:32,543 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:57:32,543 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:57:32,545 httpcore.http11 DEBUG receive_response_body.complete
21:57:32,545 httpcore.http11 DEBUG response_closed.started
21:57:32,545 httpcore.http11 DEBUG response_closed.complete
21:57:32,546 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:57:32,558 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:32,615 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:39,122 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:39,134 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:39,137 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:44,138 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:44,150 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:44,153 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:46,154 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:46,164 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:46,167 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:49,568 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:49,582 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:49,586 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:56,88 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:56,100 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:56,105 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:00,306 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:00,317 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:00,321 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:04,522 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:04,526 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:58:04,532 httpcore.connection DEBUG close.started
21:58:04,532 httpcore.connection DEBUG close.complete
21:58:04,533 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:58:04,563 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a34dd10>
21:58:04,563 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:58:04,575 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1b0c50>
21:58:04,576 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:04,577 httpcore.http11 DEBUG send_request_headers.complete
21:58:04,577 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:04,578 httpcore.http11 DEBUG send_request_body.complete
21:58:04,578 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:05,103 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'456'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5ae27cc9f586b24a1da6293b5dc37b98'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a76ba98364ce3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:05,105 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:58:05,106 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:06,265 httpcore.http11 DEBUG receive_response_body.complete
21:58:06,266 httpcore.http11 DEBUG response_closed.started
21:58:06,266 httpcore.http11 DEBUG response_closed.complete
21:58:06,267 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:58:06,332 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:58:18,523 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:58:18,527 httpcore.connection DEBUG close.started
21:58:18,527 httpcore.connection DEBUG close.complete
21:58:18,527 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:58:18,544 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2090>
21:58:18,544 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:58:18,552 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2110>
21:58:18,553 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:18,554 httpcore.http11 DEBUG send_request_headers.complete
21:58:18,554 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:18,575 httpcore.http11 DEBUG send_request_body.complete
21:58:18,575 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:19,398 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:19 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'342'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd2aa20c3c92d9e6ca5311679a45183fb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7711f8aa4ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:19,400 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:58:19,400 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:19,401 httpcore.http11 DEBUG receive_response_body.complete
21:58:19,401 httpcore.http11 DEBUG response_closed.started
21:58:19,402 httpcore.http11 DEBUG response_closed.complete
21:58:19,402 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:58:19,402 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:58:19,418 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:58:19,420 httpcore.connection DEBUG close.started
21:58:19,420 httpcore.connection DEBUG close.complete
21:58:19,420 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:58:19,422 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36f9d0>
21:58:19,423 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:58:19,428 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36ff10>
21:58:19,429 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:19,429 httpcore.http11 DEBUG send_request_headers.complete
21:58:19,429 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:19,430 httpcore.http11 DEBUG send_request_body.complete
21:58:19,430 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:19,664 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'317396bb9f1094f115d2bd2da3089d52'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a77176b0a4cd8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:19,667 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:58:19,668 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:19,669 httpcore.http11 DEBUG receive_response_body.complete
21:58:19,669 httpcore.http11 DEBUG response_closed.started
21:58:19,670 httpcore.http11 DEBUG response_closed.complete
21:58:19,670 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:58:19,688 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:58:19,697 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:58:19,699 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c0b10>
21:58:19,699 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
21:58:19,706 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e3990>
21:58:19,706 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:19,707 httpcore.http11 DEBUG send_request_headers.complete
21:58:19,707 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:19,707 httpcore.http11 DEBUG send_request_body.complete
21:58:19,707 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:19,954 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'133'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'96a5881216ced1695c9c2aee4b2f4a00'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fG0b2xgR.ZvdstRZ906JhdQSVHxhMdqVGoWX6m5JC6c-1702263499-1-AebVGBxddOjME+V0rNzXhcmBNedNCM1EEq4ZJia68GvBgDDvW6lC1DfrednkYioLmr7wj6fcFEfuxdQIlQ8MXxk=; path=/; expires=Mon, 11-Dec-23 03:28:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=anZbBqxxIz2CNjCI1dgomFXJGgEKd3wdMQf2zGS8YyE-1702263499951-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a771929bc3b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:19,958 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:58:19,958 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:19,959 httpcore.http11 DEBUG receive_response_body.complete
21:58:19,959 httpcore.http11 DEBUG response_closed.started
21:58:19,960 httpcore.http11 DEBUG response_closed.complete
21:58:19,960 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:58:19,972 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:19,975 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:23,377 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:23,386 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:23,389 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:25,391 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:25,405 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:25,409 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:28,810 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:28,814 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:58:28,819 httpcore.connection DEBUG close.started
21:58:28,819 httpcore.connection DEBUG close.complete
21:58:28,820 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:58:28,822 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e1dd0>
21:58:28,822 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:58:28,829 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2210>
21:58:28,829 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:28,830 httpcore.http11 DEBUG send_request_headers.complete
21:58:28,830 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:28,830 httpcore.http11 DEBUG send_request_body.complete
21:58:28,830 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:29,288 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:29 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2dfe6be01f2dcda3d6b8c3411d703d11'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a77523d754cd4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:29,289 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:58:29,289 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:29,748 httpcore.http11 DEBUG receive_response_body.complete
21:58:29,749 httpcore.http11 DEBUG response_closed.started
21:58:29,749 httpcore.http11 DEBUG response_closed.complete
21:58:29,749 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:58:29,816 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:58:41,79 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:58:41,83 httpcore.connection DEBUG close.started
21:58:41,84 httpcore.connection DEBUG close.complete
21:58:41,84 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:58:41,86 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3d90>
21:58:41,86 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:58:41,91 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3e10>
21:58:41,92 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:41,92 httpcore.http11 DEBUG send_request_headers.complete
21:58:41,93 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:41,125 httpcore.http11 DEBUG send_request_body.complete
21:58:41,125 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:42,275 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:42 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'34'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'582'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3ac5a2cd023ca75edd046eaf23dc1419'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a779edf8d3b8e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:42,276 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:58:42,276 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:42,277 httpcore.http11 DEBUG receive_response_body.complete
21:58:42,277 httpcore.http11 DEBUG response_closed.started
21:58:42,277 httpcore.http11 DEBUG response_closed.complete
21:58:42,277 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:58:42,278 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:58:42,291 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the right of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:58:42,294 httpcore.connection DEBUG close.started
21:58:42,294 httpcore.connection DEBUG close.complete
21:58:42,295 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:58:42,297 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f6f90>
21:58:42,297 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:58:42,302 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f7090>
21:58:42,302 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:42,303 httpcore.http11 DEBUG send_request_headers.complete
21:58:42,303 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:42,303 httpcore.http11 DEBUG send_request_body.complete
21:58:42,303 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:42,507 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'90e9d702d9cb2c3911c399b8323c29b1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a77a66a073b70-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:42,510 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:58:42,511 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:42,513 httpcore.http11 DEBUG receive_response_body.complete
21:58:42,513 httpcore.http11 DEBUG response_closed.started
21:58:42,514 httpcore.http11 DEBUG response_closed.complete
21:58:42,514 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:58:42,531 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the right of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:58:42,533 httpcore.connection DEBUG close.started
21:58:42,533 httpcore.connection DEBUG close.complete
21:58:42,533 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:58:42,535 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c2850>
21:58:42,535 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d2720> server_hostname='api.openai.com' timeout=None
21:58:42,541 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c12d0>
21:58:42,541 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:42,542 httpcore.http11 DEBUG send_request_headers.complete
21:58:42,542 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:42,542 httpcore.http11 DEBUG send_request_body.complete
21:58:42,542 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:43,59 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'db455a1c801b9beaf4bb94dacbee96c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a77a7ed243035-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:43,62 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:58:43,62 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:43,64 httpcore.http11 DEBUG receive_response_body.complete
21:58:43,64 httpcore.http11 DEBUG response_closed.started
21:58:43,65 httpcore.http11 DEBUG response_closed.complete
21:58:43,65 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:58:43,76 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:43,80 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:49,582 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:49,595 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:49,598 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:54,599 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:54,610 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:54,614 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:56,615 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:56,628 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:56,630 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:00,32 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:00,38 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:00,41 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:06,542 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:06,554 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:06,558 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:11,160 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:11,171 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:11,174 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:15,377 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:15,381 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:59:15,386 httpcore.connection DEBUG close.started
21:59:15,387 httpcore.connection DEBUG close.complete
21:59:15,387 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:59:15,390 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3e10>
21:59:15,391 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:59:15,398 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3450>
21:59:15,399 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:15,400 httpcore.http11 DEBUG send_request_headers.complete
21:59:15,400 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:15,401 httpcore.http11 DEBUG send_request_body.complete
21:59:15,401 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:15,922 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'437'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8192910a1f2c550be1d0809d2ddd2afb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a78754c814ccc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:15,924 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:59:15,924 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:17,1 httpcore.http11 DEBUG receive_response_body.complete
21:59:17,1 httpcore.http11 DEBUG response_closed.started
21:59:17,1 httpcore.http11 DEBUG response_closed.complete
21:59:17,2 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:59:17,68 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:59:29,540 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:59:29,543 httpcore.connection DEBUG close.started
21:59:29,543 httpcore.connection DEBUG close.complete
21:59:29,544 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:59:29,574 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2350>
21:59:29,575 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:59:29,584 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2210>
21:59:29,585 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:29,586 httpcore.http11 DEBUG send_request_headers.complete
21:59:29,586 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:29,608 httpcore.http11 DEBUG send_request_body.complete
21:59:29,609 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:30,360 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'344'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'675dcc6f05db73d80c38be1e6bb1940e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a78cded834cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:30,363 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:59:30,364 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:30,364 httpcore.http11 DEBUG receive_response_body.complete
21:59:30,365 httpcore.http11 DEBUG response_closed.started
21:59:30,365 httpcore.http11 DEBUG response_closed.complete
21:59:30,366 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:59:30,367 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:59:30,382 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:59:30,384 httpcore.connection DEBUG close.started
21:59:30,384 httpcore.connection DEBUG close.complete
21:59:30,385 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:59:30,387 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f8dd0>
21:59:30,387 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:59:30,393 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f89d0>
21:59:30,393 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:30,394 httpcore.http11 DEBUG send_request_headers.complete
21:59:30,394 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:30,394 httpcore.http11 DEBUG send_request_body.complete
21:59:30,394 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:30,839 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'338'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e24dcbefd9699c05e9ceaab9d3fa945d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a78d2faf23b99-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:30,841 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:59:30,841 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:30,842 httpcore.http11 DEBUG receive_response_body.complete
21:59:30,842 httpcore.http11 DEBUG response_closed.started
21:59:30,843 httpcore.http11 DEBUG response_closed.complete
21:59:30,843 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:59:30,862 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:59:30,864 httpcore.connection DEBUG close.started
21:59:30,864 httpcore.connection DEBUG close.complete
21:59:30,864 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:59:30,867 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1fadd0>
21:59:30,867 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
21:59:30,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1fb510>
21:59:30,877 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:30,878 httpcore.http11 DEBUG send_request_headers.complete
21:59:30,878 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:30,878 httpcore.http11 DEBUG send_request_body.complete
21:59:30,878 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:31,111 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4414274a8f15797b3537b147d8d8103f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a78d5f9c94d07-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:31,114 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:59:31,115 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:31,116 httpcore.http11 DEBUG receive_response_body.complete
21:59:31,116 httpcore.http11 DEBUG response_closed.started
21:59:31,117 httpcore.http11 DEBUG response_closed.complete
21:59:31,117 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:59:31,127 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:31,130 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:34,531 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:34,544 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:34,550 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:36,552 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:36,562 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:36,566 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:39,968 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:39,972 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:59:39,975 httpcore.connection DEBUG close.started
21:59:39,975 httpcore.connection DEBUG close.complete
21:59:39,976 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:59:39,978 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1b2a50>
21:59:39,978 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:59:39,983 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1b0790>
21:59:39,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:39,984 httpcore.http11 DEBUG send_request_headers.complete
21:59:39,984 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:39,985 httpcore.http11 DEBUG send_request_body.complete
21:59:39,985 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:40,603 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'483'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c0219dafaf6238245cab860559ce3502'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a790eecb06ac7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:40,605 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:59:40,606 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:41,17 httpcore.http11 DEBUG receive_response_body.complete
21:59:41,17 httpcore.http11 DEBUG response_closed.started
21:59:41,17 httpcore.http11 DEBUG response_closed.complete
21:59:41,17 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:59:41,81 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:59:52,202 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:59:52,205 httpcore.connection DEBUG close.started
21:59:52,205 httpcore.connection DEBUG close.complete
21:59:52,205 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:59:52,208 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c1a90>
21:59:52,208 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:59:52,214 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3790>
21:59:52,214 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:52,215 httpcore.http11 DEBUG send_request_headers.complete
21:59:52,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:52,247 httpcore.http11 DEBUG send_request_body.complete
21:59:52,247 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:53,145 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:53 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a9ce07d4173d5825efb080f7aad5426d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a795b5d344cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:53,147 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:59:53,148 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:53,149 httpcore.http11 DEBUG receive_response_body.complete
21:59:53,149 httpcore.http11 DEBUG response_closed.started
21:59:53,149 httpcore.http11 DEBUG response_closed.complete
21:59:53,150 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:59:53,150 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:59:53,166 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nbelow the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:59:53,168 httpcore.connection DEBUG close.started
21:59:53,168 httpcore.connection DEBUG close.complete
21:59:53,168 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:59:53,171 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f8f10>
21:59:53,171 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:59:53,178 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1fa790>
21:59:53,179 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:53,180 httpcore.http11 DEBUG send_request_headers.complete
21:59:53,180 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:53,180 httpcore.http11 DEBUG send_request_body.complete
21:59:53,180 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:53,404 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'98'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'13b6273cefe5cfd96f100a264903fd5c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a79616fdb4d14-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:53,407 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:59:53,407 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:53,409 httpcore.http11 DEBUG receive_response_body.complete
21:59:53,409 httpcore.http11 DEBUG response_closed.started
21:59:53,409 httpcore.http11 DEBUG response_closed.complete
21:59:53,410 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:59:53,426 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nbelow the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:59:53,428 httpcore.connection DEBUG close.started
21:59:53,429 httpcore.connection DEBUG close.complete
21:59:53,429 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:59:53,431 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3f90>
21:59:53,431 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d2720> server_hostname='api.openai.com' timeout=None
21:59:53,437 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c0950>
21:59:53,437 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:53,437 httpcore.http11 DEBUG send_request_headers.complete
21:59:53,438 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:53,438 httpcore.http11 DEBUG send_request_body.complete
21:59:53,438 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:53,802 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'262'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f9ab5f5b319a21cda24cb2f380f3d6e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7962fbe14d13-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:53,806 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:59:53,807 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:53,809 httpcore.http11 DEBUG receive_response_body.complete
21:59:53,809 httpcore.http11 DEBUG response_closed.started
21:59:53,810 httpcore.http11 DEBUG response_closed.complete
21:59:53,810 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:59:53,820 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:53,823 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:00,324 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:00,339 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:00,342 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:05,343 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:05,352 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:05,356 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:07,358 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:07,371 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:07,374 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:10,776 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:10,787 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:10,791 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:17,293 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:17,304 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:17,308 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:20,309 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:20,321 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:20,324 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:23,725 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:23,729 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
22:00:23,734 httpcore.connection DEBUG close.started
22:00:23,734 httpcore.connection DEBUG close.complete
22:00:23,734 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:00:23,737 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a2041d0>
22:00:23,737 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:00:23,744 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a204d10>
22:00:23,745 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:23,745 httpcore.http11 DEBUG send_request_headers.complete
22:00:23,745 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:23,746 httpcore.http11 DEBUG send_request_body.complete
22:00:23,746 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:24,265 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:24 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'edd0fef1be48529d7e5ae3fde87c913c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a206bf14cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:24,267 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
22:00:24,268 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:25,300 httpcore.http11 DEBUG receive_response_body.complete
22:00:25,300 httpcore.http11 DEBUG response_closed.started
22:00:25,300 httpcore.http11 DEBUG response_closed.complete
22:00:25,301 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
22:00:25,367 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
22:00:37,614 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
22:00:37,617 httpcore.connection DEBUG close.started
22:00:37,617 httpcore.connection DEBUG close.complete
22:00:37,617 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:00:37,648 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a207790>
22:00:37,649 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:00:37,659 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a207810>
22:00:37,660 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:37,661 httpcore.http11 DEBUG send_request_headers.complete
22:00:37,662 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:37,682 httpcore.http11 DEBUG send_request_body.complete
22:00:37,683 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:38,580 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:38 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'369'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e5b456bdb14db0d2c31328c7777a512b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a77680a4d07-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:38,583 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
22:00:38,583 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:38,586 httpcore.http11 DEBUG receive_response_body.complete
22:00:38,586 httpcore.http11 DEBUG response_closed.started
22:00:38,586 httpcore.http11 DEBUG response_closed.complete
22:00:38,586 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
22:00:38,587 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
22:00:38,602 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nto the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:00:38,604 httpcore.connection DEBUG close.started
22:00:38,604 httpcore.connection DEBUG close.complete
22:00:38,605 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:00:38,607 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c2910>
22:00:38,607 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
22:00:38,612 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c05d0>
22:00:38,613 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:38,614 httpcore.http11 DEBUG send_request_headers.complete
22:00:38,614 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:38,615 httpcore.http11 DEBUG send_request_body.complete
22:00:38,615 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:38,891 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1230792f14dbd2fd7a17e941ae0258d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a7d5d4c305d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:38,894 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:00:38,895 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:38,896 httpcore.http11 DEBUG receive_response_body.complete
22:00:38,897 httpcore.http11 DEBUG response_closed.started
22:00:38,897 httpcore.http11 DEBUG response_closed.complete
22:00:38,898 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:00:38,914 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nto the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:00:38,916 httpcore.connection DEBUG close.started
22:00:38,916 httpcore.connection DEBUG close.complete
22:00:38,916 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:00:38,918 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1fa9d0>
22:00:38,918 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
22:00:38,926 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f8550>
22:00:38,926 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:38,927 httpcore.http11 DEBUG send_request_headers.complete
22:00:38,927 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:38,927 httpcore.http11 DEBUG send_request_body.complete
22:00:38,927 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:39,164 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ae414569c8140a3b51cbeb007d80a761'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a7f4ea13031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:39,166 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:00:39,166 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:39,167 httpcore.http11 DEBUG receive_response_body.complete
22:00:39,167 httpcore.http11 DEBUG response_closed.started
22:00:39,167 httpcore.http11 DEBUG response_closed.complete
22:00:39,167 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:00:39,178 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:39,181 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:42,583 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:42,587 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
22:00:42,591 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:42,592 httpcore.http11 DEBUG send_request_headers.complete
22:00:42,592 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:42,592 httpcore.http11 DEBUG send_request_body.complete
22:00:42,592 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:43,89 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:43 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'426'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6044a2f16c2b6bf36681cb2bd9ccec18'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a963a584d07-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:43,91 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
22:00:43,92 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:44,221 httpcore.http11 DEBUG receive_response_body.complete
22:00:44,222 httpcore.http11 DEBUG response_closed.started
22:00:44,222 httpcore.http11 DEBUG response_closed.complete
22:00:44,222 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
22:00:44,285 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
22:00:56,875 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
22:00:56,878 httpcore.connection DEBUG close.started
22:00:56,878 httpcore.connection DEBUG close.complete
22:00:56,879 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:00:56,881 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f5450>
22:00:56,881 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:00:56,887 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f61d0>
22:00:56,888 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:56,888 httpcore.http11 DEBUG send_request_headers.complete
22:00:56,888 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:56,909 httpcore.http11 DEBUG send_request_body.complete
22:00:56,909 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:57,691 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'344'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ddd2b51dfbd72575837eb7a3f014163f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7aef8ea94cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:57,693 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
22:00:57,693 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:57,694 httpcore.http11 DEBUG receive_response_body.complete
22:00:57,695 httpcore.http11 DEBUG response_closed.started
22:00:57,695 httpcore.http11 DEBUG response_closed.complete
22:00:57,695 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
22:00:57,696 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
22:00:57,709 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nTo the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:00:57,711 httpcore.connection DEBUG close.started
22:00:57,711 httpcore.connection DEBUG close.complete
22:00:57,711 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:00:57,714 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1b8410>
22:00:57,714 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
22:00:57,719 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e1390>
22:00:57,719 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:57,720 httpcore.http11 DEBUG send_request_headers.complete
22:00:57,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:57,720 httpcore.http11 DEBUG send_request_body.complete
22:00:57,720 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:58,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e60f46db2103230c8f837d68d0b972ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7af4c91b4d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:58,25 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:00:58,25 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:58,25 httpcore.http11 DEBUG receive_response_body.complete
22:00:58,26 httpcore.http11 DEBUG response_closed.started
22:00:58,26 httpcore.http11 DEBUG response_closed.complete
22:00:58,26 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:00:58,36 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:58,40 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:01,441 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:01:01,445 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
22:01:01,449 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:01,450 httpcore.http11 DEBUG send_request_headers.complete
22:01:01,451 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:01,451 httpcore.http11 DEBUG send_request_body.complete
22:01:01,451 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:01,980 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'443'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd8b3f8093c397f15ff9cb143ccced627'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7b0c1a0a4cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:01,982 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
22:01:01,983 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:03,200 httpcore.http11 DEBUG receive_response_body.complete
22:01:03,201 httpcore.http11 DEBUG response_closed.started
22:01:03,201 httpcore.http11 DEBUG response_closed.complete
22:01:03,202 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
22:01:03,264 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
22:01:15,634 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
22:01:15,638 httpcore.connection DEBUG close.started
22:01:15,639 httpcore.connection DEBUG close.complete
22:01:15,639 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:01:15,642 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f6b10>
22:01:15,642 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:01:15,649 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f4690>
22:01:15,650 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:15,650 httpcore.http11 DEBUG send_request_headers.complete
22:01:15,650 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:15,672 httpcore.http11 DEBUG send_request_body.complete
22:01:15,672 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:16,561 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:16 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a4028f338109d8ffdcb82053f51db6a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7b64de734d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:16,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
22:01:16,565 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:16,566 httpcore.http11 DEBUG receive_response_body.complete
22:01:16,566 httpcore.http11 DEBUG response_closed.started
22:01:16,567 httpcore.http11 DEBUG response_closed.complete
22:01:16,567 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
22:01:16,568 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
22:01:16,583 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nto the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:01:16,585 httpcore.connection DEBUG close.started
22:01:16,585 httpcore.connection DEBUG close.complete
22:01:16,585 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:01:16,587 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a206250>
22:01:16,588 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
22:01:16,593 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a205490>
22:01:16,594 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:16,594 httpcore.http11 DEBUG send_request_headers.complete
22:01:16,594 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:16,595 httpcore.http11 DEBUG send_request_body.complete
22:01:16,595 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:16,793 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e95469566d051818ccd8ad811375d7be'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7b6ab94d6ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:16,796 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:01:16,797 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:16,798 httpcore.http11 DEBUG receive_response_body.complete
22:01:16,799 httpcore.http11 DEBUG response_closed.started
22:01:16,799 httpcore.http11 DEBUG response_closed.complete
22:01:16,800 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:01:16,809 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:01:16,811 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:20,213 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:01:20,216 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
22:01:20,220 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:20,221 httpcore.http11 DEBUG send_request_headers.complete
22:01:20,221 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:20,222 httpcore.http11 DEBUG send_request_body.complete
22:01:20,222 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:20,792 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'65d55f779992c368bccec72354ecf507'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7b816c9b4d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:20,794 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
22:01:20,795 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:21,756 httpcore.http11 DEBUG receive_response_body.complete
22:01:21,756 httpcore.http11 DEBUG response_closed.started
22:01:21,756 httpcore.http11 DEBUG response_closed.complete
22:01:21,757 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
22:01:21,823 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
22:01:33,542 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
22:01:33,545 httpcore.connection DEBUG close.started
22:01:33,545 httpcore.connection DEBUG close.complete
22:01:33,546 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:01:33,548 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1af490>
22:01:33,548 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:01:33,553 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1af290>
22:01:33,553 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:33,554 httpcore.http11 DEBUG send_request_headers.complete
22:01:33,554 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:33,578 httpcore.http11 DEBUG send_request_body.complete
22:01:33,578 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:34,345 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b948e6590841875bd74618abf8661ac6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7bd4bbcd4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:34,347 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
22:01:34,348 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:34,348 httpcore.http11 DEBUG receive_response_body.complete
22:01:34,349 httpcore.http11 DEBUG response_closed.started
22:01:34,349 httpcore.http11 DEBUG response_closed.complete
22:01:34,349 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
22:01:34,350 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
22:01:34,365 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:01:34,367 httpcore.connection DEBUG close.started
22:01:34,367 httpcore.connection DEBUG close.complete
22:01:34,367 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:01:34,369 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a208750>
22:01:34,370 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
22:01:34,379 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a208050>
22:01:34,379 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:34,380 httpcore.http11 DEBUG send_request_headers.complete
22:01:34,380 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:34,380 httpcore.http11 DEBUG send_request_body.complete
22:01:34,381 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:34,585 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cc1b179c51f2ba70dd7738729755c5fd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7bd9e9864cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:34,587 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:01:34,587 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:34,588 httpcore.http11 DEBUG receive_response_body.complete
22:01:34,589 httpcore.http11 DEBUG response_closed.started
22:01:34,589 httpcore.http11 DEBUG response_closed.complete
22:01:34,590 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:01:34,599 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:01:34,603 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:38,4 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:01:38,17 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:01:38,20 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:40,21 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:01:40,35 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:01:40,39 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:43,440 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:34:48,544 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:34:48,547 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:34:49,372 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:34:49,373 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:34:49,415 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:34:49,416 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:34:49,464 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:34:49,465 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:34:49,506 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:34:49,507 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:34:49,554 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:34:49,555 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:34:49,614 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:34:49,615 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:34:49,669 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:34:49,670 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:34:49,710 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:34:49,711 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:35:19,136 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Steph. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:35:19,158 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:35:19,188 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2d4415f5d0>
17:35:19,188 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2d441e9e20> server_hostname='api.openai.com' timeout=5.0
17:35:19,197 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2d4415fa50>
17:35:19,198 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:35:19,200 httpcore.http11 DEBUG send_request_headers.complete
17:35:19,200 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:35:19,201 httpcore.http11 DEBUG send_request_body.complete
17:35:19,201 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:35:19,674 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:35:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'420c6a8b6b0fc4b3aef928374e6f554f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7U.MqS_EHBAZhC4pbx0y8Dv3mekGTrNm9foRD21LTsQ-1702334119-1-AeVWQBwO0vzeYudCmezS4UgrCbNPYfGmALIomRh/KVWG0scpa8JQgkKGFUMhM8VR/SAqSsBCDHXVZ6ZGMrfAHyI=; path=/; expires=Mon, 11-Dec-23 23:05:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=QJm3Y6JHmCOvsASqOFCx4xSjkwW0wTNy5vhhm0lysrc-1702334119668-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834133350a073b87-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:35:19,685 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:35:19,686 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:35:20,493 httpcore.http11 DEBUG receive_response_body.complete
17:35:20,494 httpcore.http11 DEBUG response_closed.started
17:35:20,495 httpcore.http11 DEBUG response_closed.complete
17:35:20,496 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:35:20,580 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:35:33,826 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:35:33,837 httpcore.connection DEBUG close.started
17:35:33,838 httpcore.connection DEBUG close.complete
17:35:33,838 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:35:33,840 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2d4415fa50>
17:35:33,841 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2d441e9e20> server_hostname='api.openai.com' timeout=5.0
17:35:33,848 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2d4415f950>
17:35:33,848 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:35:33,849 httpcore.http11 DEBUG send_request_headers.complete
17:35:33,850 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:35:33,884 httpcore.http11 DEBUG send_request_body.complete
17:35:33,885 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:35:34,372 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Mon, 11 Dec 2023 22:35:34 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'301'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'f2840e6472476b13a524b252d8dde7f0'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834133909de46ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:35:34,377 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 401 Unauthorized"
17:35:34,378 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:35:34,379 httpcore.http11 DEBUG receive_response_body.complete
17:35:34,380 httpcore.http11 DEBUG response_closed.started
17:35:34,380 httpcore.http11 DEBUG response_closed.complete
17:35:34,381 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "401 Unauthorized"
17:36:34,723 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:36:34,728 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:36:35,540 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:36:35,541 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:36:35,586 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:36:35,586 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:36:35,629 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:36:35,629 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:36:35,667 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:36:35,668 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:36:35,706 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:36:35,707 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:36:35,745 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:36:35,746 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:36:35,786 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:36:35,787 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:36:35,824 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:36:35,824 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:36:35,865 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Steph. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:36:35,878 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:36:35,913 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210abe190>
17:36:35,913 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:36:35,921 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210abe710>
17:36:35,922 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:36:35,924 httpcore.http11 DEBUG send_request_headers.complete
17:36:35,924 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:36:35,925 httpcore.http11 DEBUG send_request_body.complete
17:36:35,925 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:36:36,640 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:36:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'510'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'33d24c871a4f80f57869f353e260da71'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=N8ZA6Qe4IAL7KrN.s0grgbVeoN6HUmcIyFlmOogHAus-1702334196-1-AXdYOL+k4i8iSx3lekhobzTLNa5o/CFgrV/EYFosFxT8rW9mY0Gw5BfZj5K0f5FTQDMLYE25oUlaN5/udZCoOQY=; path=/; expires=Mon, 11-Dec-23 23:06:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BZXPaIe5QR8AFH.Sy6Jz1dEO6xgjJWv5QEucK3Oe3GY-1702334196635-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834135148c9c4cd0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:36:36,647 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:36:36,648 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:36:37,395 httpcore.http11 DEBUG receive_response_body.complete
17:36:37,396 httpcore.http11 DEBUG response_closed.started
17:36:37,396 httpcore.http11 DEBUG response_closed.complete
17:36:37,397 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:36:37,481 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:36:50,735 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:36:50,743 httpcore.connection DEBUG close.started
17:36:50,743 httpcore.connection DEBUG close.complete
17:36:50,744 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:36:50,746 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210abe710>
17:36:50,746 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:36:50,756 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210abda50>
17:36:50,756 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:36:50,757 httpcore.http11 DEBUG send_request_headers.complete
17:36:50,757 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:36:50,790 httpcore.http11 DEBUG send_request_body.complete
17:36:50,791 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:36:53,103 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:36:53 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1673'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ef5bc60565454bdd65931c4597292e3d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834135713bfe6ac5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:36:53,106 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:36:53,106 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:36:53,107 httpcore.http11 DEBUG receive_response_body.complete
17:36:53,107 httpcore.http11 DEBUG response_closed.started
17:36:53,107 httpcore.http11 DEBUG response_closed.complete
17:36:53,107 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:36:53,108 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:36:53,128 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Steph. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nTop right corner.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:36:53,136 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:36:53,139 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210918110>
17:36:53,139 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45fd0> server_hostname='api.openai.com' timeout=None
17:36:53,156 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb2109180d0>
17:36:53,157 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:36:53,157 httpcore.http11 DEBUG send_request_headers.complete
17:36:53,158 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:36:53,158 httpcore.http11 DEBUG send_request_body.complete
17:36:53,158 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:36:53,373 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:36:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd711982e9e03a84ece677e5167ac4f6a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hO7zGeFQm5uWcSggFpAKvaWWXog_8VjHRQ4THmigdU4-1702334213-1-AadVdXC2h8YoGBcpygFyLdH6HdwfCc2K2OOQqrUt6BIVBxZEaR6+Mchb9HOGF5dJdSnTAf5dK7FOB+nyfQg8N6o=; path=/; expires=Mon, 11-Dec-23 23:06:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=mB4Gti5p9fD0tiVRfTsVVeDxv.09AJEP5zgDrINiSFA-1702334213369-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834135803cc24ce0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:36:53,375 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:36:53,375 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:36:53,376 httpcore.http11 DEBUG receive_response_body.complete
17:36:53,376 httpcore.http11 DEBUG response_closed.started
17:36:53,376 httpcore.http11 DEBUG response_closed.complete
17:36:53,376 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:36:53,391 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nHi, Steph. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nTop right corner.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:36:53,402 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:36:53,404 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210919250>
17:36:53,404 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b467b0> server_hostname='api.openai.com' timeout=None
17:36:53,409 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb2109186d0>
17:36:53,409 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:36:53,409 httpcore.http11 DEBUG send_request_headers.complete
17:36:53,410 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:36:53,410 httpcore.http11 DEBUG send_request_body.complete
17:36:53,410 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:36:54,271 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:36:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'772'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'855b0c4f6858b1bb0e22ca03adf8a5fe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yVLZMp7P0VrqpiLO4msGHoVFBeafqatWlLDoLr8VaPc-1702334214-1-ATuL/pktvp6Xx9qJ97j7Sb/GH1ACkXIr6XCseY3DrE4e1/c6BaWk2qSDOnb0A4wQCCcqzqhyINntG740okEA8Ow=; path=/; expires=Mon, 11-Dec-23 23:06:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=GvqfHKeFQ_85uX.FDnku3b7e0ZzH9g_9BsfHcf.7B5M-1702334214268-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413581dd8e6ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:36:54,275 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:36:54,275 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:36:54,276 httpcore.http11 DEBUG receive_response_body.complete
17:36:54,277 httpcore.http11 DEBUG response_closed.started
17:36:54,277 httpcore.http11 DEBUG response_closed.complete
17:36:54,277 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:36:54,495 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:36:54,500 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:37:01,6 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:37:01,21 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:37:01,25 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:37:06,27 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:37:06,40 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:37:06,43 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:37:08,44 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:37:08,58 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:37:08,62 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:37:11,463 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:37:11,474 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:37:11,477 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:37:17,979 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:37:17,989 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:37:17,992 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:37:22,593 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:37:22,606 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:37:22,608 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:37:27,610 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:37:27,613 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:37:27,617 httpcore.connection DEBUG close.started
17:37:27,618 httpcore.connection DEBUG close.complete
17:37:27,618 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:37:27,621 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210abda50>
17:37:27,621 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:37:27,628 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210947f90>
17:37:27,628 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:37:27,629 httpcore.http11 DEBUG send_request_headers.complete
17:37:27,629 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:37:27,630 httpcore.http11 DEBUG send_request_body.complete
17:37:27,630 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:37:28,267 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:37:28 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'526'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3a861fe09408a201eafc0ee5082d1748'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413657bc394cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:37:28,269 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:37:28,270 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:37:29,321 httpcore.http11 DEBUG receive_response_body.complete
17:37:29,322 httpcore.http11 DEBUG response_closed.started
17:37:29,322 httpcore.http11 DEBUG response_closed.complete
17:37:29,322 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:37:29,384 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:37:41,830 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:37:41,834 httpcore.connection DEBUG close.started
17:37:41,834 httpcore.connection DEBUG close.complete
17:37:41,835 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:37:41,865 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094ddd0>
17:37:41,866 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:37:41,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094de50>
17:37:41,876 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:37:41,878 httpcore.http11 DEBUG send_request_headers.complete
17:37:41,878 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:37:41,896 httpcore.http11 DEBUG send_request_body.complete
17:37:41,896 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:37:42,652 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:37:42 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'345'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cded3549abb03587f00fadd128518c7e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834136b0bfca4d1e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:37:42,654 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:37:42,654 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:37:42,655 httpcore.http11 DEBUG receive_response_body.complete
17:37:42,655 httpcore.http11 DEBUG response_closed.started
17:37:42,656 httpcore.http11 DEBUG response_closed.complete
17:37:42,656 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:37:42,656 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:37:42,678 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:37:42,680 httpcore.connection DEBUG close.started
17:37:42,680 httpcore.connection DEBUG close.complete
17:37:42,680 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:37:42,683 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb2109180d0>
17:37:42,683 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45fd0> server_hostname='api.openai.com' timeout=None
17:37:42,688 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210918150>
17:37:42,689 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:37:42,689 httpcore.http11 DEBUG send_request_headers.complete
17:37:42,690 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:37:42,690 httpcore.http11 DEBUG send_request_body.complete
17:37:42,690 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:37:42,891 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:37:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'472524ed0a2039ab17dcbbdacd7c9445'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834136b5db504cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:37:42,894 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:37:42,894 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:37:42,895 httpcore.http11 DEBUG receive_response_body.complete
17:37:42,896 httpcore.http11 DEBUG response_closed.started
17:37:42,896 httpcore.http11 DEBUG response_closed.complete
17:37:42,896 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:37:42,915 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:37:42,924 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:37:42,927 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094c4d0>
17:37:42,927 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:37:42,935 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094e590>
17:37:42,935 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:37:42,936 httpcore.http11 DEBUG send_request_headers.complete
17:37:42,936 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:37:42,937 httpcore.http11 DEBUG send_request_body.complete
17:37:42,937 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:37:43,146 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:37:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9a54413c37a5c0992f86cb6ad6a1ce6f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=I6tCcBTp3MI66N7WJRnPEzGMjxHyxYp7pqmFjNImhIA-1702334263-1-AS2mFR/ssTzZ4H1lwkgj2J5sGG6cg7+FMfM5r2gcEbtqI/plzYtzUinjVz45k5qkRF10MkRuiQOi98xzHTjroGA=; path=/; expires=Mon, 11-Dec-23 23:07:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=v_8BgnH60mTevX.9f4GpY8fHWwDhNKlvjgm2A8bz7EM-1702334263142-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834136b75cb53bab-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:37:43,150 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:37:43,151 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:37:43,152 httpcore.http11 DEBUG receive_response_body.complete
17:37:43,153 httpcore.http11 DEBUG response_closed.started
17:37:43,153 httpcore.http11 DEBUG response_closed.complete
17:37:43,154 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:37:43,164 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:37:43,166 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:37:46,568 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:37:46,572 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:37:46,578 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:37:46,578 httpcore.http11 DEBUG send_request_headers.complete
17:37:46,579 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:37:46,579 httpcore.http11 DEBUG send_request_body.complete
17:37:46,579 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:37:47,95 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:37:47 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'422'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'806b95d4301b9e0bb3afc48a593663e2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834136ce1f0d4d1e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:37:47,97 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:37:47,98 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:37:48,244 httpcore.http11 DEBUG receive_response_body.complete
17:37:48,245 httpcore.http11 DEBUG response_closed.started
17:37:48,245 httpcore.http11 DEBUG response_closed.complete
17:37:48,246 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:37:48,316 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:38:00,888 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:38:00,891 httpcore.connection DEBUG close.started
17:38:00,891 httpcore.connection DEBUG close.complete
17:38:00,892 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:38:00,894 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210959b90>
17:38:00,894 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:38:00,900 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210959c10>
17:38:00,900 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:00,900 httpcore.http11 DEBUG send_request_headers.complete
17:38:00,901 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:00,923 httpcore.http11 DEBUG send_request_body.complete
17:38:00,924 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:01,781 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:01 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'369'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0b2411df337ee8eeb2e3f4aec0132242'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413727af994cd2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:01,783 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:38:01,784 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:01,785 httpcore.http11 DEBUG receive_response_body.complete
17:38:01,785 httpcore.http11 DEBUG response_closed.started
17:38:01,785 httpcore.http11 DEBUG response_closed.complete
17:38:01,786 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:38:01,786 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:38:01,800 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:38:01,802 httpcore.connection DEBUG close.started
17:38:01,802 httpcore.connection DEBUG close.complete
17:38:01,802 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:38:01,804 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964d10>
17:38:01,804 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:38:01,811 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964e10>
17:38:01,812 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:01,812 httpcore.http11 DEBUG send_request_headers.complete
17:38:01,812 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:01,813 httpcore.http11 DEBUG send_request_body.complete
17:38:01,813 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:02,21 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2887656463b28dcef17ff01c73bc866f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341372d5bb03059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:02,24 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:38:02,24 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:02,26 httpcore.http11 DEBUG receive_response_body.complete
17:38:02,26 httpcore.http11 DEBUG response_closed.started
17:38:02,26 httpcore.http11 DEBUG response_closed.complete
17:38:02,26 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:38:02,39 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:38:02,43 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:38:05,446 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:38:05,460 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:38:05,468 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:38:07,470 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:38:07,481 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:38:07,485 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:38:10,886 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:38:10,891 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:38:10,895 httpcore.connection DEBUG close.started
17:38:10,896 httpcore.connection DEBUG close.complete
17:38:10,896 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:38:10,899 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210959950>
17:38:10,900 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:38:10,906 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21095a110>
17:38:10,907 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:10,907 httpcore.http11 DEBUG send_request_headers.complete
17:38:10,907 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:10,908 httpcore.http11 DEBUG send_request_body.complete
17:38:10,908 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:11,396 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:11 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'406'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9c7d2e37737ee7874182a0f3f455efd1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834137662d1a4cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:11,398 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:38:11,399 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:11,878 httpcore.http11 DEBUG receive_response_body.complete
17:38:11,879 httpcore.http11 DEBUG response_closed.started
17:38:11,879 httpcore.http11 DEBUG response_closed.complete
17:38:11,879 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:38:11,949 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:38:23,142 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:38:23,145 httpcore.connection DEBUG close.started
17:38:23,146 httpcore.connection DEBUG close.complete
17:38:23,146 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:38:23,148 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094ecd0>
17:38:23,149 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:38:23,156 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094fbd0>
17:38:23,157 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:23,157 httpcore.http11 DEBUG send_request_headers.complete
17:38:23,158 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:23,186 httpcore.http11 DEBUG send_request_body.complete
17:38:23,186 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:29,980 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:29 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'29'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'6360'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0eafa47d208a51b504e811348d80a529'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834137b2be8b4cf3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:29,983 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:38:29,983 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:29,984 httpcore.http11 DEBUG receive_response_body.complete
17:38:29,984 httpcore.http11 DEBUG response_closed.started
17:38:29,985 httpcore.http11 DEBUG response_closed.complete
17:38:29,985 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:38:29,986 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:38:30,4 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nin the middle of the square.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:38:30,6 httpcore.connection DEBUG close.started
17:38:30,7 httpcore.connection DEBUG close.complete
17:38:30,7 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:38:30,9 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210918ad0>
17:38:30,10 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45fd0> server_hostname='api.openai.com' timeout=None
17:38:30,15 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210918210>
17:38:30,15 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:30,15 httpcore.http11 DEBUG send_request_headers.complete
17:38:30,15 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:30,16 httpcore.http11 DEBUG send_request_body.complete
17:38:30,16 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:30,322 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b056f2c98020fbbefc07d43c3b22a3cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834137dd9d4a4ce4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:30,325 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:38:30,326 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:30,326 httpcore.http11 DEBUG receive_response_body.complete
17:38:30,327 httpcore.http11 DEBUG response_closed.started
17:38:30,327 httpcore.http11 DEBUG response_closed.complete
17:38:30,327 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:38:30,346 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nin the middle of the square.\n\n'''\nRedirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:38:30,355 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:38:30,357 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210966750>
17:38:30,358 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b46330> server_hostname='api.openai.com' timeout=None
17:38:30,363 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964fd0>
17:38:30,363 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:30,364 httpcore.http11 DEBUG send_request_headers.complete
17:38:30,364 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:30,364 httpcore.http11 DEBUG send_request_body.complete
17:38:30,364 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:31,305 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'851'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'babf3f2cdb0220dff2bded0d94897934'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9BeWZdgetcN7igS2_MZzLugmlRPuQKtT4RvyoZOCW9k-1702334311-1-AX3ODyqjJE0RHhbazcJMEt2+KppEOmddqeT7P/tEfyn9GS2m/dICAahQ4OTeOH2G/BsdKL9pofrZakNIUnn4wFw=; path=/; expires=Mon, 11-Dec-23 23:08:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=YKZaqw0QGsxcKHqaadCzCR2qOViPVe6qzNsczX5fa2w-1702334311301-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834137dfcb593b6f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:31,309 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:38:31,310 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:31,310 httpcore.http11 DEBUG receive_response_body.complete
17:38:31,311 httpcore.http11 DEBUG response_closed.started
17:38:31,311 httpcore.http11 DEBUG response_closed.complete
17:38:31,311 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:38:31,315 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'I understand that you want me to place the second candle in the middle of the square. Could you please tell me exactly where on the cake I should place it? I need more specific instructions to complete this task.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:38:31,318 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:31,319 httpcore.http11 DEBUG send_request_headers.complete
17:38:31,320 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:31,320 httpcore.http11 DEBUG send_request_body.complete
17:38:31,320 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:32,91 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:32 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'653'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fb4a225bfeaeb227276662ad8a1325bf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834137e5cd724cf3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:32,93 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:38:32,94 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:34,43 httpcore.http11 DEBUG receive_response_body.complete
17:38:34,44 httpcore.http11 DEBUG response_closed.started
17:38:34,44 httpcore.http11 DEBUG response_closed.complete
17:38:34,45 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:38:34,118 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:38:56,383 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:38:56,386 httpcore.connection DEBUG close.started
17:38:56,387 httpcore.connection DEBUG close.complete
17:38:56,387 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:38:56,390 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096dd50>
17:38:56,390 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:38:56,397 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096ddd0>
17:38:56,397 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:56,398 httpcore.http11 DEBUG send_request_headers.complete
17:38:56,398 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:56,415 httpcore.http11 DEBUG send_request_body.complete
17:38:56,416 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:57,598 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'10'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'393'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cf30fd3d3ae746a8d5a895758ec514a9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834138827e9d3b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:57,599 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:38:57,600 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:57,600 httpcore.http11 DEBUG receive_response_body.complete
17:38:57,601 httpcore.http11 DEBUG response_closed.started
17:38:57,601 httpcore.http11 DEBUG response_closed.complete
17:38:57,601 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:38:57,601 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:38:57,616 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI understand that you want me to place the second candle in the middle of the square. Could you please tell me exactly where on the cake I should place it? I need more specific instructions to complete this task.\n'''\nAnd the human answered\n'''\nTss! Tss!\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:38:57,618 httpcore.connection DEBUG close.started
17:38:57,618 httpcore.connection DEBUG close.complete
17:38:57,619 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:38:57,622 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210967090>
17:38:57,622 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45fd0> server_hostname='api.openai.com' timeout=None
17:38:57,634 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964750>
17:38:57,635 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:57,635 httpcore.http11 DEBUG send_request_headers.complete
17:38:57,636 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:57,636 httpcore.http11 DEBUG send_request_body.complete
17:38:57,636 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:57,876 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'132'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4197baa02197e620c0cc7d80084f27d3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341388a386c4cf4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:57,878 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:38:57,879 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:57,880 httpcore.http11 DEBUG receive_response_body.complete
17:38:57,881 httpcore.http11 DEBUG response_closed.started
17:38:57,881 httpcore.http11 DEBUG response_closed.complete
17:38:57,882 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:38:57,899 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nI understand that you want me to place the second candle in the middle of the square. Could you please tell me exactly where on the cake I should place it? I need more specific instructions to complete this task.\n'''\nAnd the human answered\n'''\nTss! Tss!\n\n'''\nRedirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:38:57,901 httpcore.connection DEBUG close.started
17:38:57,901 httpcore.connection DEBUG close.complete
17:38:57,901 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:38:57,910 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964fd0>
17:38:57,910 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b46330> server_hostname='api.openai.com' timeout=None
17:38:57,931 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210966990>
17:38:57,932 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:57,933 httpcore.http11 DEBUG send_request_headers.complete
17:38:57,933 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:57,934 httpcore.http11 DEBUG send_request_body.complete
17:38:57,934 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:59,186 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1147'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1060b2ee7ca28d6b7bba47419f303c65'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341388c18843b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:59,188 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:38:59,188 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:59,189 httpcore.http11 DEBUG receive_response_body.complete
17:38:59,189 httpcore.http11 DEBUG response_closed.started
17:38:59,189 httpcore.http11 DEBUG response_closed.complete
17:38:59,190 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:38:59,195 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I'm sorry, I didn't understand what you said. Could you please provide me with more specific instructions on where to place the second candle? I need to know the exact coordinates on the cake so I can complete the task. Thank you for your help.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:38:59,197 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:59,198 httpcore.http11 DEBUG send_request_headers.complete
17:38:59,198 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:59,199 httpcore.http11 DEBUG send_request_body.complete
17:38:59,199 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:59,794 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:38:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'518'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4d4ed892208b27eb43db6a95dcc0abe1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413893fa453b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:59,796 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:38:59,797 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:01,929 httpcore.http11 DEBUG receive_response_body.complete
17:39:01,930 httpcore.http11 DEBUG response_closed.started
17:39:01,930 httpcore.http11 DEBUG response_closed.complete
17:39:01,931 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:39:01,999 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:39:25,88 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:39:25,91 httpcore.connection DEBUG close.started
17:39:25,91 httpcore.connection DEBUG close.complete
17:39:25,91 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:39:25,123 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096d990>
17:39:25,123 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:39:25,130 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096ce10>
17:39:25,131 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:25,132 httpcore.http11 DEBUG send_request_headers.complete
17:39:25,132 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:25,161 httpcore.http11 DEBUG send_request_body.complete
17:39:25,161 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:25,994 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:39:25 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'30'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'381'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1d34ca6ddb43e9170aec2bd209271a3b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834139361c083b6f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:25,996 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:39:25,997 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:25,998 httpcore.http11 DEBUG receive_response_body.complete
17:39:25,998 httpcore.http11 DEBUG response_closed.started
17:39:25,998 httpcore.http11 DEBUG response_closed.complete
17:39:25,999 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:39:25,999 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:39:26,18 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI'm sorry, I didn't understand what you said. Could you please provide me with more specific instructions on where to place the second candle? I need to know the exact coordinates on the cake so I can complete the task. Thank you for your help.\n'''\nAnd the human answered\n'''\nCan you put it at zero, zero?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:39:26,21 httpcore.connection DEBUG close.started
17:39:26,21 httpcore.connection DEBUG close.complete
17:39:26,21 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:39:26,24 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210974dd0>
17:39:26,24 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45fd0> server_hostname='api.openai.com' timeout=None
17:39:26,32 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210974990>
17:39:26,32 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:26,34 httpcore.http11 DEBUG send_request_headers.complete
17:39:26,34 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:26,34 httpcore.http11 DEBUG send_request_body.complete
17:39:26,35 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:26,315 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:39:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ef71e4318c13175c41bc0cd8afe93c87'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341393bba5c4cc6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:26,317 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:39:26,317 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:26,318 httpcore.http11 DEBUG receive_response_body.complete
17:39:26,318 httpcore.http11 DEBUG response_closed.started
17:39:26,319 httpcore.http11 DEBUG response_closed.complete
17:39:26,319 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:39:26,337 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nI'm sorry, I didn't understand what you said. Could you please provide me with more specific instructions on where to place the second candle? I need to know the exact coordinates on the cake so I can complete the task. Thank you for your help.\n'''\nAnd the human answered\n'''\nCan you put it at zero, zero?\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:39:26,339 httpcore.connection DEBUG close.started
17:39:26,339 httpcore.connection DEBUG close.complete
17:39:26,339 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:39:26,342 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb2109186d0>
17:39:26,342 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b467b0> server_hostname='api.openai.com' timeout=None
17:39:26,350 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb2109190d0>
17:39:26,350 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:26,351 httpcore.http11 DEBUG send_request_headers.complete
17:39:26,351 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:26,351 httpcore.http11 DEBUG send_request_body.complete
17:39:26,351 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:26,958 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:39:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9d03240165536f4b227e585a57758c79'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341393dbb9c4cf0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:26,961 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:39:26,961 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:26,962 httpcore.http11 DEBUG receive_response_body.complete
17:39:26,963 httpcore.http11 DEBUG response_closed.started
17:39:26,963 httpcore.http11 DEBUG response_closed.complete
17:39:26,964 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:39:27,85 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:27,88 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:33,589 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:33,599 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:33,603 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:38,604 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:38,615 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:38,619 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:40,621 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:40,634 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:40,637 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:44,39 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:44,50 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:44,53 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:50,554 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:50,568 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:50,570 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:54,372 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:54,386 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:54,389 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:57,790 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:57,794 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:39:57,799 httpcore.connection DEBUG close.started
17:39:57,799 httpcore.connection DEBUG close.complete
17:39:57,800 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:39:57,802 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096e090>
17:39:57,803 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:39:57,809 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096ddd0>
17:39:57,810 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:57,811 httpcore.http11 DEBUG send_request_headers.complete
17:39:57,811 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:57,812 httpcore.http11 DEBUG send_request_body.complete
17:39:57,812 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:58,508 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:39:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'572'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bfe7aaca69bd00aab38846905b8e6ceb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413a025ffb6ac5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:58,510 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:39:58,511 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:59,417 httpcore.http11 DEBUG receive_response_body.complete
17:39:59,417 httpcore.http11 DEBUG response_closed.started
17:39:59,418 httpcore.http11 DEBUG response_closed.complete
17:39:59,418 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:39:59,484 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:40:11,728 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:40:11,731 httpcore.connection DEBUG close.started
17:40:11,731 httpcore.connection DEBUG close.complete
17:40:11,731 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:40:11,734 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210ad3490>
17:40:11,734 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:40:11,741 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210ab3f50>
17:40:11,741 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:11,742 httpcore.http11 DEBUG send_request_headers.complete
17:40:11,742 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:11,764 httpcore.http11 DEBUG send_request_body.complete
17:40:11,764 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:12,535 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:12 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'8'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'338'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8bca921989fcba7454e92498d9b9be86'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413a596a396ac5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:12,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:40:12,538 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:12,539 httpcore.http11 DEBUG receive_response_body.complete
17:40:12,539 httpcore.http11 DEBUG response_closed.started
17:40:12,540 httpcore.http11 DEBUG response_closed.complete
17:40:12,540 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:40:12,541 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:40:12,555 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nmove up\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:40:12,557 httpcore.connection DEBUG close.started
17:40:12,557 httpcore.connection DEBUG close.complete
17:40:12,558 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:40:12,560 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964190>
17:40:12,560 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45fd0> server_hostname='api.openai.com' timeout=None
17:40:12,568 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210967a10>
17:40:12,569 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:12,570 httpcore.http11 DEBUG send_request_headers.complete
17:40:12,570 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:12,571 httpcore.http11 DEBUG send_request_body.complete
17:40:12,571 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:12,785 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8f01b023102f92a53659c0ecbd3617fc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413a5e9bcf4ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:12,788 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:40:12,788 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:12,789 httpcore.http11 DEBUG receive_response_body.complete
17:40:12,790 httpcore.http11 DEBUG response_closed.started
17:40:12,790 httpcore.http11 DEBUG response_closed.complete
17:40:12,790 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:40:12,807 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nmove up\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:40:12,809 httpcore.connection DEBUG close.started
17:40:12,810 httpcore.connection DEBUG close.complete
17:40:12,810 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:40:12,812 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964650>
17:40:12,812 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:40:12,819 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964f10>
17:40:12,819 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:12,820 httpcore.http11 DEBUG send_request_headers.complete
17:40:12,820 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:12,820 httpcore.http11 DEBUG send_request_body.complete
17:40:12,820 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:13,25 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1920dd6a938d7a9a6938e9b4cb977a7c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413a60282e4ce2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:13,26 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:40:13,27 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:13,28 httpcore.http11 DEBUG receive_response_body.complete
17:40:13,28 httpcore.http11 DEBUG response_closed.started
17:40:13,28 httpcore.http11 DEBUG response_closed.complete
17:40:13,29 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:40:13,44 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:40:13,48 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:40:16,450 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:40:16,454 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:40:16,458 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:16,458 httpcore.http11 DEBUG send_request_headers.complete
17:40:16,458 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:16,459 httpcore.http11 DEBUG send_request_body.complete
17:40:16,459 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:16,955 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'422'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'830fc9ded64b2fe6795ee3ad125d5ffd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413a76ddd76ac5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:16,958 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:40:16,958 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:18,65 httpcore.http11 DEBUG receive_response_body.complete
17:40:18,66 httpcore.http11 DEBUG response_closed.started
17:40:18,66 httpcore.http11 DEBUG response_closed.complete
17:40:18,67 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:40:18,132 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:40:30,652 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:40:30,656 httpcore.connection DEBUG close.started
17:40:30,656 httpcore.connection DEBUG close.complete
17:40:30,656 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:40:30,685 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096d590>
17:40:30,686 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:40:30,694 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096d1d0>
17:40:30,694 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:30,696 httpcore.http11 DEBUG send_request_headers.complete
17:40:30,696 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:30,719 httpcore.http11 DEBUG send_request_body.complete
17:40:30,720 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:31,687 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'513'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'36471205a428e0e9e560f6e44849fc22'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413acfd8f64ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:31,690 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:40:31,690 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:31,691 httpcore.http11 DEBUG receive_response_body.complete
17:40:31,692 httpcore.http11 DEBUG response_closed.started
17:40:31,692 httpcore.http11 DEBUG response_closed.complete
17:40:31,692 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:40:31,693 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:40:31,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:40:31,709 httpcore.connection DEBUG close.started
17:40:31,709 httpcore.connection DEBUG close.complete
17:40:31,709 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:40:31,712 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094fc90>
17:40:31,712 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:40:31,717 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094c390>
17:40:31,717 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:31,718 httpcore.http11 DEBUG send_request_headers.complete
17:40:31,718 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:31,718 httpcore.http11 DEBUG send_request_body.complete
17:40:31,718 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:31,963 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'288d5bcbe5aacd8da205fee86b4bfaf3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413ad63ce94d0d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:31,966 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:40:31,966 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:31,967 httpcore.http11 DEBUG receive_response_body.complete
17:40:31,968 httpcore.http11 DEBUG response_closed.started
17:40:31,968 httpcore.http11 DEBUG response_closed.complete
17:40:31,968 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:40:31,981 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:40:31,983 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:40:35,385 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:40:35,388 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:40:35,393 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:35,394 httpcore.http11 DEBUG send_request_headers.complete
17:40:35,394 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:35,395 httpcore.http11 DEBUG send_request_body.complete
17:40:35,395 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:35,886 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'420'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'412232dc58b2a0977926473c88e1559f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413aed3b974ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:35,889 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:40:35,889 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:37,198 httpcore.http11 DEBUG receive_response_body.complete
17:40:37,198 httpcore.http11 DEBUG response_closed.started
17:40:37,199 httpcore.http11 DEBUG response_closed.complete
17:40:37,199 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:40:37,263 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:40:49,831 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:40:49,833 httpcore.connection DEBUG close.started
17:40:49,833 httpcore.connection DEBUG close.complete
17:40:49,834 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:40:49,836 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210976cd0>
17:40:49,836 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:40:49,841 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210976dd0>
17:40:49,841 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:49,842 httpcore.http11 DEBUG send_request_headers.complete
17:40:49,842 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:49,869 httpcore.http11 DEBUG send_request_body.complete
17:40:49,869 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:50,563 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:50 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'411'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e61afc3ffe8fcb00d561af9836813107'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413b478c5d4cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:50,565 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:40:50,566 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:50,566 httpcore.http11 DEBUG receive_response_body.complete
17:40:50,567 httpcore.http11 DEBUG response_closed.started
17:40:50,567 httpcore.http11 DEBUG response_closed.complete
17:40:50,567 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:40:50,568 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:40:50,582 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:40:50,584 httpcore.connection DEBUG close.started
17:40:50,584 httpcore.connection DEBUG close.complete
17:40:50,584 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:40:50,587 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210971550>
17:40:50,587 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:40:50,594 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210971490>
17:40:50,595 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:50,595 httpcore.http11 DEBUG send_request_headers.complete
17:40:50,596 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:50,596 httpcore.http11 DEBUG send_request_body.complete
17:40:50,596 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:50,836 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8ad29996b17ddd6519a8a8e6492a8bb1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413b4c3d6c4cf9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:50,839 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:40:50,840 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:50,841 httpcore.http11 DEBUG receive_response_body.complete
17:40:50,842 httpcore.http11 DEBUG response_closed.started
17:40:50,842 httpcore.http11 DEBUG response_closed.complete
17:40:50,842 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:40:50,851 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:40:50,855 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:40:54,257 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:40:54,258 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:40:54,260 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:54,261 httpcore.http11 DEBUG send_request_headers.complete
17:40:54,261 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:54,261 httpcore.http11 DEBUG send_request_body.complete
17:40:54,261 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:54,793 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:40:54 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'459'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b17eaa35fd9a544b153c3698731cfbdf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413b632eed4cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:54,795 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:40:54,796 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:55,981 httpcore.http11 DEBUG receive_response_body.complete
17:40:55,982 httpcore.http11 DEBUG response_closed.started
17:40:55,982 httpcore.http11 DEBUG response_closed.complete
17:40:55,983 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:40:56,49 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:41:08,538 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph9.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:41:08,541 httpcore.connection DEBUG close.started
17:41:08,541 httpcore.connection DEBUG close.complete
17:41:08,541 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:41:08,544 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210926210>
17:41:08,544 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:41:08,552 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210967990>
17:41:08,552 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:08,552 httpcore.http11 DEBUG send_request_headers.complete
17:41:08,553 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:08,574 httpcore.http11 DEBUG send_request_body.complete
17:41:08,574 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:09,397 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:41:09 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'439'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'80fba69ea1d8d064645f16245a6ecbb2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413bbc7c8e4d10-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:09,398 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:41:09,399 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:09,399 httpcore.http11 DEBUG receive_response_body.complete
17:41:09,399 httpcore.http11 DEBUG response_closed.started
17:41:09,400 httpcore.http11 DEBUG response_closed.complete
17:41:09,400 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:41:09,400 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:41:09,415 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nThank you very much for joining us.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:41:09,417 httpcore.connection DEBUG close.started
17:41:09,417 httpcore.connection DEBUG close.complete
17:41:09,417 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:41:09,419 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094cd90>
17:41:09,420 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:41:09,427 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094cbd0>
17:41:09,428 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:09,428 httpcore.http11 DEBUG send_request_headers.complete
17:41:09,428 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:09,428 httpcore.http11 DEBUG send_request_body.complete
17:41:09,429 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:09,766 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:41:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'190'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3556b512cfd55298fb95c656e6bdeb66'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413bc1ec364d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:09,769 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:41:09,770 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:09,771 httpcore.http11 DEBUG receive_response_body.complete
17:41:09,771 httpcore.http11 DEBUG response_closed.started
17:41:09,772 httpcore.http11 DEBUG response_closed.complete
17:41:09,772 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:41:09,777 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:41:09,782 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:09,784 httpcore.http11 DEBUG send_request_headers.complete
17:41:09,784 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:09,784 httpcore.http11 DEBUG send_request_body.complete
17:41:09,785 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:10,449 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:41:10 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'543'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a0bc1d91198a2a68fed56e3240fcc9b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413bc42a614d10-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:10,451 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:41:10,451 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:11,590 httpcore.http11 DEBUG receive_response_body.complete
17:41:11,591 httpcore.http11 DEBUG response_closed.started
17:41:11,591 httpcore.http11 DEBUG response_closed.complete
17:41:11,592 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:41:11,658 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph10.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:41:24,212 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph10.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:41:24,215 httpcore.connection DEBUG close.started
17:41:24,215 httpcore.connection DEBUG close.complete
17:41:24,216 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:41:24,218 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21095bd50>
17:41:24,219 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:41:24,227 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21095be10>
17:41:24,227 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:24,228 httpcore.http11 DEBUG send_request_headers.complete
17:41:24,228 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:24,249 httpcore.http11 DEBUG send_request_body.complete
17:41:24,250 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:25,90 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:41:25 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'401'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1b24a5976a1c65ad451874ffe153bc28'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413c1e6d794d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:25,92 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:41:25,92 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:25,93 httpcore.http11 DEBUG receive_response_body.complete
17:41:25,94 httpcore.http11 DEBUG response_closed.started
17:41:25,94 httpcore.http11 DEBUG response_closed.complete
17:41:25,94 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:41:25,95 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:41:25,111 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nyes\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:41:25,114 httpcore.connection DEBUG close.started
17:41:25,114 httpcore.connection DEBUG close.complete
17:41:25,114 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:41:25,117 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210980190>
17:41:25,117 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:41:25,132 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210980590>
17:41:25,132 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:25,133 httpcore.http11 DEBUG send_request_headers.complete
17:41:25,134 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:25,134 httpcore.http11 DEBUG send_request_body.complete
17:41:25,134 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:25,341 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:41:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0f7084fd16e2ccfde11ba9dcba9b45d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413c241a1e4cd8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:25,344 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:41:25,344 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:25,346 httpcore.http11 DEBUG receive_response_body.complete
17:41:25,346 httpcore.http11 DEBUG response_closed.started
17:41:25,346 httpcore.http11 DEBUG response_closed.complete
17:41:25,346 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:41:25,356 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:41:25,360 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:41:28,761 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:41:28,773 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:41:28,776 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:41:30,777 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:41:30,789 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:41:30,792 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:41:34,194 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:41:34,197 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:41:34,200 httpcore.connection DEBUG close.started
17:41:34,201 httpcore.connection DEBUG close.complete
17:41:34,201 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:41:34,205 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096e490>
17:41:34,205 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:41:34,213 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096d7d0>
17:41:34,213 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:34,213 httpcore.http11 DEBUG send_request_headers.complete
17:41:34,214 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:34,214 httpcore.http11 DEBUG send_request_body.complete
17:41:34,214 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:34,650 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:41:34 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'423d924c8ab79e59223c94640a2233ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413c5cdb503b9f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:34,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:41:34,652 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:35,64 httpcore.http11 DEBUG receive_response_body.complete
17:41:35,65 httpcore.http11 DEBUG response_closed.started
17:41:35,65 httpcore.http11 DEBUG response_closed.complete
17:41:35,65 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:41:35,129 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph11.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:41:46,409 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph11.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:41:46,411 httpcore.connection DEBUG close.started
17:41:46,412 httpcore.connection DEBUG close.complete
17:41:46,412 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:41:46,441 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210958610>
17:41:46,442 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:41:46,447 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210959410>
17:41:46,448 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:46,449 httpcore.http11 DEBUG send_request_headers.complete
17:41:46,449 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:46,479 httpcore.http11 DEBUG send_request_body.complete
17:41:46,480 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:47,298 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:41:47 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'357'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1e1d7112807a432b51211a46b229e32e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413ca94a573b99-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:47,299 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:41:47,299 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:47,300 httpcore.http11 DEBUG receive_response_body.complete
17:41:47,300 httpcore.http11 DEBUG response_closed.started
17:41:47,300 httpcore.http11 DEBUG response_closed.complete
17:41:47,301 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:41:47,301 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:41:47,316 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nBOTTOM LEFT CORNER\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:41:47,318 httpcore.connection DEBUG close.started
17:41:47,318 httpcore.connection DEBUG close.complete
17:41:47,318 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:41:47,321 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210965550>
17:41:47,321 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45fd0> server_hostname='api.openai.com' timeout=None
17:41:47,329 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964190>
17:41:47,329 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:47,331 httpcore.http11 DEBUG send_request_headers.complete
17:41:47,331 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:47,332 httpcore.http11 DEBUG send_request_body.complete
17:41:47,332 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:47,582 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:41:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c305367cb10fdd0069479f2ffa71437a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413caedc424cf3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:47,585 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:41:47,585 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:47,586 httpcore.http11 DEBUG receive_response_body.complete
17:41:47,587 httpcore.http11 DEBUG response_closed.started
17:41:47,587 httpcore.http11 DEBUG response_closed.complete
17:41:47,588 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:41:47,603 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nBOTTOM LEFT CORNER\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:41:47,604 httpcore.connection DEBUG close.started
17:41:47,605 httpcore.connection DEBUG close.complete
17:41:47,605 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:41:47,608 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210919210>
17:41:47,608 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b467b0> server_hostname='api.openai.com' timeout=None
17:41:47,614 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210919310>
17:41:47,614 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:47,615 httpcore.http11 DEBUG send_request_headers.complete
17:41:47,615 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:47,615 httpcore.http11 DEBUG send_request_body.complete
17:41:47,615 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:48,72 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:41:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fe0e61636b31ad3e7c30f47c16b5e69b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413cb09b3c4cde-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:48,74 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:41:48,75 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:48,76 httpcore.http11 DEBUG receive_response_body.complete
17:41:48,77 httpcore.http11 DEBUG response_closed.started
17:41:48,77 httpcore.http11 DEBUG response_closed.complete
17:41:48,77 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:41:48,234 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:41:48,237 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:41:54,738 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:41:54,748 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:41:54,752 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:41:59,753 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:41:59,764 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:41:59,767 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:01,769 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:01,780 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:01,783 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:05,184 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:05,197 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:05,200 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:11,701 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:11,717 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:11,720 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:15,521 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:15,533 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:15,539 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:20,940 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:20,942 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:42:20,944 httpcore.connection DEBUG close.started
17:42:20,945 httpcore.connection DEBUG close.complete
17:42:20,945 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:42:20,947 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210958a90>
17:42:20,947 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:42:20,953 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb2109596d0>
17:42:20,954 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:20,954 httpcore.http11 DEBUG send_request_headers.complete
17:42:20,955 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:20,955 httpcore.http11 DEBUG send_request_body.complete
17:42:20,955 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:21,449 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:42:21 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'413'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ea87994c7bbe8ecb51944be705e52a08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413d80fff23071-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:21,451 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:42:21,452 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:22,698 httpcore.http11 DEBUG receive_response_body.complete
17:42:22,698 httpcore.http11 DEBUG response_closed.started
17:42:22,698 httpcore.http11 DEBUG response_closed.complete
17:42:22,699 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:42:22,768 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph12.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:42:34,899 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph12.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:42:34,901 httpcore.connection DEBUG close.started
17:42:34,902 httpcore.connection DEBUG close.complete
17:42:34,902 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:42:34,904 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210983b10>
17:42:34,904 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:42:34,909 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210983b90>
17:42:34,909 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:34,910 httpcore.http11 DEBUG send_request_headers.complete
17:42:34,910 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:34,927 httpcore.http11 DEBUG send_request_body.complete
17:42:34,927 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:35,790 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:42:35 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'402'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2362ac66658bf2b50f70b7f49df023b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413dd83bfd3021-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:35,792 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:42:35,793 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:35,794 httpcore.http11 DEBUG receive_response_body.complete
17:42:35,794 httpcore.http11 DEBUG response_closed.started
17:42:35,794 httpcore.http11 DEBUG response_closed.complete
17:42:35,795 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:42:35,795 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:42:35,811 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove down. A lot.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:42:35,813 httpcore.connection DEBUG close.started
17:42:35,813 httpcore.connection DEBUG close.complete
17:42:35,813 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:42:35,816 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210964190>
17:42:35,816 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45fd0> server_hostname='api.openai.com' timeout=None
17:42:35,821 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210967b10>
17:42:35,821 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:35,822 httpcore.http11 DEBUG send_request_headers.complete
17:42:35,822 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:35,822 httpcore.http11 DEBUG send_request_body.complete
17:42:35,823 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:36,34 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:42:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'114'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'223d59472a78dcfaaac1b0baf78c8fcf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413ddde9064cda-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:36,36 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:42:36,37 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:36,37 httpcore.http11 DEBUG receive_response_body.complete
17:42:36,38 httpcore.http11 DEBUG response_closed.started
17:42:36,38 httpcore.http11 DEBUG response_closed.complete
17:42:36,38 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:42:36,54 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove down. A lot.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:42:36,56 httpcore.connection DEBUG close.started
17:42:36,56 httpcore.connection DEBUG close.complete
17:42:36,57 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:42:36,59 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210982950>
17:42:36,59 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:42:36,64 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210982850>
17:42:36,64 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:36,65 httpcore.http11 DEBUG send_request_headers.complete
17:42:36,65 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:36,65 httpcore.http11 DEBUG send_request_body.complete
17:42:36,65 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:36,270 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:42:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'61751d1215f0d0a41fef9b7432ed942b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413ddf6ac74ced-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:36,273 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:42:36,274 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:36,275 httpcore.http11 DEBUG receive_response_body.complete
17:42:36,275 httpcore.http11 DEBUG response_closed.started
17:42:36,275 httpcore.http11 DEBUG response_closed.complete
17:42:36,276 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:42:36,286 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:36,289 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:39,691 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:39,694 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:42:39,698 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:39,699 httpcore.http11 DEBUG send_request_headers.complete
17:42:39,700 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:39,700 httpcore.http11 DEBUG send_request_body.complete
17:42:39,701 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:40,380 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:42:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'560'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4b67276028c26fe9ab1c64bf000ecf9e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413df628c73021-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:40,382 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:42:40,383 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:41,213 httpcore.http11 DEBUG receive_response_body.complete
17:42:41,214 httpcore.http11 DEBUG response_closed.started
17:42:41,214 httpcore.http11 DEBUG response_closed.complete
17:42:41,214 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:42:41,282 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph13.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:42:53,675 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph13.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:42:53,679 httpcore.connection DEBUG close.started
17:42:53,679 httpcore.connection DEBUG close.complete
17:42:53,680 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:42:53,709 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210983150>
17:42:53,709 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:42:53,717 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096e690>
17:42:53,718 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:53,719 httpcore.http11 DEBUG send_request_headers.complete
17:42:53,719 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:53,744 httpcore.http11 DEBUG send_request_body.complete
17:42:53,744 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:55,408 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:42:55 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1139'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5e80261872d2469e8ea7f718848aefe4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413e4dc8a24d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:55,410 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:42:55,411 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:55,411 httpcore.http11 DEBUG receive_response_body.complete
17:42:55,412 httpcore.http11 DEBUG response_closed.started
17:42:55,412 httpcore.http11 DEBUG response_closed.complete
17:42:55,413 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:42:55,413 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:42:55,426 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:42:55,428 httpcore.connection DEBUG close.started
17:42:55,428 httpcore.connection DEBUG close.complete
17:42:55,429 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:42:55,431 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21098a450>
17:42:55,431 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:42:55,436 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210988750>
17:42:55,436 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:55,437 httpcore.http11 DEBUG send_request_headers.complete
17:42:55,437 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:55,437 httpcore.http11 DEBUG send_request_body.complete
17:42:55,437 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:55,662 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:42:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9ce3d361971e59dd5ffd93bff8d97c3c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413e5879a54cf4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:55,664 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:42:55,665 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:55,666 httpcore.http11 DEBUG receive_response_body.complete
17:42:55,667 httpcore.http11 DEBUG response_closed.started
17:42:55,667 httpcore.http11 DEBUG response_closed.complete
17:42:55,667 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:42:55,674 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:42:55,676 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:55,677 httpcore.http11 DEBUG send_request_headers.complete
17:42:55,677 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:55,677 httpcore.http11 DEBUG send_request_body.complete
17:42:55,678 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:56,194 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:42:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'439'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9257908d738162eafc9f42034c88f2e2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413e59f8704d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:56,196 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:42:56,197 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:57,406 httpcore.http11 DEBUG receive_response_body.complete
17:42:57,406 httpcore.http11 DEBUG response_closed.started
17:42:57,407 httpcore.http11 DEBUG response_closed.complete
17:42:57,407 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:42:57,476 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph14.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:43:10,79 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph14.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:43:10,82 httpcore.connection DEBUG close.started
17:43:10,82 httpcore.connection DEBUG close.complete
17:43:10,83 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:43:10,85 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21098bb10>
17:43:10,85 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:43:10,90 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21098bb90>
17:43:10,91 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:10,91 httpcore.http11 DEBUG send_request_headers.complete
17:43:10,92 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:10,113 httpcore.http11 DEBUG send_request_body.complete
17:43:10,113 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:11,593 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:43:11 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'727'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5f710bc98a759f9336dba3b1bd633950'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413eb41eff3b6f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:11,596 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:43:11,596 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:11,597 httpcore.http11 DEBUG receive_response_body.complete
17:43:11,597 httpcore.http11 DEBUG response_closed.started
17:43:11,598 httpcore.http11 DEBUG response_closed.complete
17:43:11,598 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:43:11,598 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:43:11,614 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nThank you for watching!\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:43:11,617 httpcore.connection DEBUG close.started
17:43:11,617 httpcore.connection DEBUG close.complete
17:43:11,617 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:43:11,620 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210988750>
17:43:11,620 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:43:11,626 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21098a490>
17:43:11,626 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:11,626 httpcore.http11 DEBUG send_request_headers.complete
17:43:11,627 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:11,627 httpcore.http11 DEBUG send_request_body.complete
17:43:11,627 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:11,865 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:43:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'133'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2a596961c068978d0cbced7ea00f41fc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413ebda9d44d1c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:11,867 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:43:11,868 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:11,869 httpcore.http11 DEBUG receive_response_body.complete
17:43:11,869 httpcore.http11 DEBUG response_closed.started
17:43:11,869 httpcore.http11 DEBUG response_closed.complete
17:43:11,870 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:43:11,874 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:43:11,877 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:11,877 httpcore.http11 DEBUG send_request_headers.complete
17:43:11,877 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:11,878 httpcore.http11 DEBUG send_request_body.complete
17:43:11,878 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:12,380 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:43:12 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'423'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'32a57152ce4e1dff1973f79bde191f84'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413ebf3c493b6f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:12,382 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:43:12,382 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:13,354 httpcore.http11 DEBUG receive_response_body.complete
17:43:13,355 httpcore.http11 DEBUG response_closed.started
17:43:13,355 httpcore.http11 DEBUG response_closed.complete
17:43:13,356 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:43:13,423 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph15.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:43:25,952 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph15.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:43:25,956 httpcore.connection DEBUG close.started
17:43:25,956 httpcore.connection DEBUG close.complete
17:43:25,957 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:43:25,959 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21095bcd0>
17:43:25,960 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:43:25,965 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21096d8d0>
17:43:25,966 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:25,966 httpcore.http11 DEBUG send_request_headers.complete
17:43:25,966 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:25,985 httpcore.http11 DEBUG send_request_body.complete
17:43:25,985 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:26,851 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:43:26 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'367'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bf4e3db979b1e646150e52578774c7af'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413f174d353068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:26,853 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:43:26,854 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:26,855 httpcore.http11 DEBUG receive_response_body.complete
17:43:26,855 httpcore.http11 DEBUG response_closed.started
17:43:26,856 httpcore.http11 DEBUG response_closed.complete
17:43:26,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:43:26,857 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:43:26,871 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove down.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:43:26,873 httpcore.connection DEBUG close.started
17:43:26,874 httpcore.connection DEBUG close.complete
17:43:26,874 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:43:26,877 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb210958a90>
17:43:26,877 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:43:26,884 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb2109597d0>
17:43:26,885 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:26,885 httpcore.http11 DEBUG send_request_headers.complete
17:43:26,886 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:26,886 httpcore.http11 DEBUG send_request_body.complete
17:43:26,886 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:27,169 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:43:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4caa15b7e1e26b84f04d35c82115e20a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413f1d0af83031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:27,173 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:43:27,174 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:27,175 httpcore.http11 DEBUG receive_response_body.complete
17:43:27,176 httpcore.http11 DEBUG response_closed.started
17:43:27,176 httpcore.http11 DEBUG response_closed.complete
17:43:27,177 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:43:27,185 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:27,188 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:30,590 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:30,594 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:43:30,600 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:30,601 httpcore.http11 DEBUG send_request_headers.complete
17:43:30,601 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:30,602 httpcore.http11 DEBUG send_request_body.complete
17:43:30,602 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:31,112 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:43:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'444'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1d27a800cb7a95d16178f402ccb4debb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413f3449da3068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:31,114 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:43:31,115 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:32,163 httpcore.http11 DEBUG receive_response_body.complete
17:43:32,164 httpcore.http11 DEBUG response_closed.started
17:43:32,164 httpcore.http11 DEBUG response_closed.complete
17:43:32,164 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:43:32,233 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Steph16.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:43:44,702 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Steph16.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:43:44,705 httpcore.connection DEBUG close.started
17:43:44,705 httpcore.connection DEBUG close.complete
17:43:44,705 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:43:44,708 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21098d090>
17:43:44,708 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45e20> server_hostname='api.openai.com' timeout=5.0
17:43:44,718 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21098c950>
17:43:44,719 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:44,720 httpcore.http11 DEBUG send_request_headers.complete
17:43:44,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:44,742 httpcore.http11 DEBUG send_request_body.complete
17:43:44,742 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:45,580 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:43:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'385'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'75c84a2faedf77aef629a7dc0b46b6ed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413f8c88804cc9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:45,582 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:43:45,583 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:45,584 httpcore.http11 DEBUG receive_response_body.complete
17:43:45,584 httpcore.http11 DEBUG response_closed.started
17:43:45,584 httpcore.http11 DEBUG response_closed.complete
17:43:45,585 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:43:45,585 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:43:45,598 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:43:45,600 httpcore.connection DEBUG close.started
17:43:45,600 httpcore.connection DEBUG close.complete
17:43:45,601 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:43:45,603 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094d1d0>
17:43:45,603 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb210b45f40> server_hostname='api.openai.com' timeout=None
17:43:45,609 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb21094fc90>
17:43:45,609 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:45,610 httpcore.http11 DEBUG send_request_headers.complete
17:43:45,610 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:45,610 httpcore.http11 DEBUG send_request_body.complete
17:43:45,610 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:45,848 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 22:43:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8f9beb727732ad6e48754830ed18492d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83413f9218ca4ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:45,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:43:45,852 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:45,853 httpcore.http11 DEBUG receive_response_body.complete
17:43:45,853 httpcore.http11 DEBUG response_closed.started
17:43:45,853 httpcore.http11 DEBUG response_closed.complete
17:43:45,854 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:43:45,865 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:45,868 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:49,270 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:49,283 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:49,286 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:51,288 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:51,303 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:51,306 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:54,708 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:02:40,895 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:02:40,898 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:02:41,718 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:02:41,720 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:02:41,788 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:02:41,790 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:02:41,842 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:02:41,843 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:02:41,891 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:02:41,892 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:02:41,952 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:02:41,953 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:02:41,998 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:02:41,999 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:02:42,49 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:02:42,50 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:02:42,93 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:02:42,94 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:05:39,599 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Jo. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:05:39,617 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:05:39,648 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805b04210>
18:05:39,648 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fde20> server_hostname='api.openai.com' timeout=5.0
18:05:39,656 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805873d50>
18:05:39,657 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:05:39,659 httpcore.http11 DEBUG send_request_headers.complete
18:05:39,659 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:05:39,660 httpcore.http11 DEBUG send_request_body.complete
18:05:39,660 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:05:40,136 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:05:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ec6055d5a01c02f3130a1b38335f8ba5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2JpZ1FYlqslRf1QsLE7Rm0K5v45ctxg6WElxVpTMAfs-1702335940-1-AaevIGScxTuoQW/ltAhQdY+Jh0pPHdTSDWJMIRWt2x/2zNS94NeHUQGubwpQ/u9+Jz3jR0ExaIiLo07qDDU0Ol8=; path=/; expires=Mon, 11-Dec-23 23:35:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=.XLZiwIXeBxKxqU3vwGY6al66EahGvYAKmEa.4pBCz4-1702335940130-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83415fa6d91d3b9f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:05:40,144 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:05:40,144 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:05:41,64 httpcore.http11 DEBUG receive_response_body.complete
18:05:41,65 httpcore.http11 DEBUG response_closed.started
18:05:41,65 httpcore.http11 DEBUG response_closed.complete
18:05:41,66 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:05:41,148 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:05:54,250 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:05:54,261 httpcore.connection DEBUG close.started
18:05:54,262 httpcore.connection DEBUG close.complete
18:05:54,262 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:05:54,265 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805873d50>
18:05:54,265 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fde20> server_hostname='api.openai.com' timeout=5.0
18:05:54,271 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805873750>
18:05:54,271 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:05:54,272 httpcore.http11 DEBUG send_request_headers.complete
18:05:54,273 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:05:54,306 httpcore.http11 DEBUG send_request_body.complete
18:05:54,306 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:05:55,89 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:05:55 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9d862b19b4a1a5d153cd1417218683e7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416002388a4cc8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:05:55,92 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:05:55,93 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:05:55,94 httpcore.http11 DEBUG receive_response_body.complete
18:05:55,95 httpcore.http11 DEBUG response_closed.started
18:05:55,95 httpcore.http11 DEBUG response_closed.complete
18:05:55,96 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:05:55,97 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:05:55,133 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Jo. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nUh, you should place the first candle in the middle of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:05:55,145 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:05:55,147 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8058c8c10>
18:05:55,147 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fdfd0> server_hostname='api.openai.com' timeout=None
18:05:55,153 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8058c8bd0>
18:05:55,153 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:05:55,154 httpcore.http11 DEBUG send_request_headers.complete
18:05:55,155 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:05:55,155 httpcore.http11 DEBUG send_request_body.complete
18:05:55,155 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:05:55,400 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:05:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'155'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c06dd84947bf2d3eaeb2b18176798959'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qjwWfoZIEjzJcAnp0A47NFJvS2ojJRa4a9GZuF52Z7o-1702335955-1-Aa754zUhZiQYuFi11tLB/zjehVIiaTv8lHr0Gbwx1gBt8cCqKiSqSozp0htrxiCjpJChSh3PIJcyaT4qkA/vK4A=; path=/; expires=Mon, 11-Dec-23 23:35:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=7fnecU_5.kouz874n82h0idbW3HFNwbg_dO02_fbWr4-1702335955395-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416007ba14305d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:05:55,409 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:05:55,410 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:05:55,411 httpcore.http11 DEBUG receive_response_body.complete
18:05:55,412 httpcore.http11 DEBUG response_closed.started
18:05:55,412 httpcore.http11 DEBUG response_closed.complete
18:05:55,412 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:05:55,451 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nHi, Jo. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nUh, you should place the first candle in the middle of the cake.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:05:55,464 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:05:55,466 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8058c99d0>
18:05:55,467 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fe7b0> server_hostname='api.openai.com' timeout=None
18:05:55,474 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8058c8150>
18:05:55,475 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:05:55,476 httpcore.http11 DEBUG send_request_headers.complete
18:05:55,477 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:05:55,477 httpcore.http11 DEBUG send_request_body.complete
18:05:55,478 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:05:56,440 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:05:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'847'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e413164854c9ef53a6330248c162dc08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lw_k8jGPSMRM4UQLWK462Br2ccgS7KSedvhf_5xON6k-1702335956-1-AfEPnavOswX+KlcfXsMv+Px2nwDDoL4bF0bTf3yrJ0GfHT1cp9GxRPN/enXRpPSmzDsVzEZPupQjqGM2AeZb3MA=; path=/; expires=Mon, 11-Dec-23 23:35:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fSooWwhDdzjzot4g6nCVSrX2yc05QVNA8EMhG9Fyqc4-1702335956436-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416009be634cd6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:05:56,447 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:05:56,448 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:05:56,449 httpcore.http11 DEBUG receive_response_body.complete
18:05:56,450 httpcore.http11 DEBUG response_closed.started
18:05:56,450 httpcore.http11 DEBUG response_closed.complete
18:05:56,451 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:05:56,474 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:05:56,479 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:02,987 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:03,0 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:06:03,3 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:08,5 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:08,23 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:06:08,26 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:10,28 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:10,45 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:06:10,49 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:13,451 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:13,464 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:06:13,468 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:19,970 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:19,988 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:06:19,992 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:24,194 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:24,216 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:06:24,219 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:28,421 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:28,428 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:06:28,435 httpcore.connection DEBUG close.started
18:06:28,436 httpcore.connection DEBUG close.complete
18:06:28,436 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:06:28,439 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805873750>
18:06:28,440 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fde20> server_hostname='api.openai.com' timeout=5.0
18:06:28,447 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8056e6150>
18:06:28,447 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:28,448 httpcore.http11 DEBUG send_request_headers.complete
18:06:28,448 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:28,449 httpcore.http11 DEBUG send_request_body.complete
18:06:28,449 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:28,993 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:06:28 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'432'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'985b5c532fc9c14c34989bd2b68bb5b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834160d7c9b94cd6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:28,998 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:06:28,999 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:30,175 httpcore.http11 DEBUG receive_response_body.complete
18:06:30,176 httpcore.http11 DEBUG response_closed.started
18:06:30,177 httpcore.http11 DEBUG response_closed.complete
18:06:30,178 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:30,245 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:06:42,600 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:06:42,605 httpcore.connection DEBUG close.started
18:06:42,605 httpcore.connection DEBUG close.complete
18:06:42,606 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:06:42,633 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8057061d0>
18:06:42,633 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fde20> server_hostname='api.openai.com' timeout=5.0
18:06:42,642 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805706250>
18:06:42,643 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:42,645 httpcore.http11 DEBUG send_request_headers.complete
18:06:42,645 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:42,661 httpcore.http11 DEBUG send_request_body.complete
18:06:42,661 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:43,318 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:06:43 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'305'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb4d8a869e1c164198c7b47b6946bb00'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834161308c45305d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:43,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:06:43,324 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:43,325 httpcore.http11 DEBUG receive_response_body.complete
18:06:43,326 httpcore.http11 DEBUG response_closed.started
18:06:43,326 httpcore.http11 DEBUG response_closed.complete
18:06:43,327 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:06:43,327 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:06:43,360 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:06:43,363 httpcore.connection DEBUG close.started
18:06:43,364 httpcore.connection DEBUG close.complete
18:06:43,364 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:06:43,366 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8058c8190>
18:06:43,366 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fdfd0> server_hostname='api.openai.com' timeout=None
18:06:43,373 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8058bd350>
18:06:43,373 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:43,374 httpcore.http11 DEBUG send_request_headers.complete
18:06:43,375 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:43,375 httpcore.http11 DEBUG send_request_body.complete
18:06:43,376 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:43,605 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:06:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'124'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'afaf6f3ca8f86f8477fd37694a78654a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416135197e4d02-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:43,612 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:06:43,613 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:43,614 httpcore.http11 DEBUG receive_response_body.complete
18:06:43,615 httpcore.http11 DEBUG response_closed.started
18:06:43,615 httpcore.http11 DEBUG response_closed.complete
18:06:43,616 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:06:43,653 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:06:43,664 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:06:43,667 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805707910>
18:06:43,667 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fdf40> server_hostname='api.openai.com' timeout=None
18:06:43,677 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8057078d0>
18:06:43,678 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:43,680 httpcore.http11 DEBUG send_request_headers.complete
18:06:43,681 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:43,682 httpcore.http11 DEBUG send_request_body.complete
18:06:43,682 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:43,897 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:06:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'15cac734080948cddd39943b8b1cee19'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JOq0sARFwSoX4_xx9NNFLP5COEux0FvILDmXbGsljKA-1702336003-1-AWZ4wcKpjS9LXZl+8IunpJMTaxDV269DTp0CycAQVrsOi2uuxbu60wleA+4KFnUu9K5y5vOpLvuRvugZNU6Z7D0=; path=/; expires=Mon, 11-Dec-23 23:36:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1fN2cHAJk.xhcTl2H.tW0BTwWEFECfmuE0trdhuxm5g-1702336003891-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341613708773008-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:43,902 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:06:43,903 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:43,904 httpcore.http11 DEBUG receive_response_body.complete
18:06:43,904 httpcore.http11 DEBUG response_closed.started
18:06:43,904 httpcore.http11 DEBUG response_closed.complete
18:06:43,905 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:06:43,922 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:06:43,925 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:47,328 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:47,346 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:06:47,349 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:49,351 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:49,363 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:06:49,367 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:06:52,769 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:06:52,775 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:06:52,780 httpcore.connection DEBUG close.started
18:06:52,780 httpcore.connection DEBUG close.complete
18:06:52,781 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:06:52,789 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805706050>
18:06:52,790 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fde20> server_hostname='api.openai.com' timeout=5.0
18:06:52,796 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805707f10>
18:06:52,796 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:52,797 httpcore.http11 DEBUG send_request_headers.complete
18:06:52,798 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:52,798 httpcore.http11 DEBUG send_request_body.complete
18:06:52,798 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:53,231 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:06:53 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'357'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'65f09ebed4dce04b75d5ebfa2c43f222'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341616ffbe2304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:53,236 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:06:53,237 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:53,709 httpcore.http11 DEBUG receive_response_body.complete
18:06:53,710 httpcore.http11 DEBUG response_closed.started
18:06:53,710 httpcore.http11 DEBUG response_closed.complete
18:06:53,711 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:53,780 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:07:05,127 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:07:05,133 httpcore.connection DEBUG close.started
18:07:05,134 httpcore.connection DEBUG close.complete
18:07:05,134 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:07:05,136 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805712350>
18:07:05,137 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fde20> server_hostname='api.openai.com' timeout=5.0
18:07:05,143 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8057123d0>
18:07:05,144 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:07:05,145 httpcore.http11 DEBUG send_request_headers.complete
18:07:05,145 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:07:05,176 httpcore.http11 DEBUG send_request_body.complete
18:07:05,176 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:07:06,320 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:07:06 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'449'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'134e7ce0087ed6dd19115894c04a3779'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834161bd2ac13b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:07:06,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:07:06,325 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:07:06,327 httpcore.http11 DEBUG receive_response_body.complete
18:07:06,327 httpcore.http11 DEBUG response_closed.started
18:07:06,328 httpcore.http11 DEBUG response_closed.complete
18:07:06,328 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:07:06,329 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:07:06,360 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nYou should put the second candle at the top of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:07:06,363 httpcore.connection DEBUG close.started
18:07:06,364 httpcore.connection DEBUG close.complete
18:07:06,364 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:07:06,366 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd80571d610>
18:07:06,367 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fdfd0> server_hostname='api.openai.com' timeout=None
18:07:06,373 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd80571d690>
18:07:06,373 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:07:06,374 httpcore.http11 DEBUG send_request_headers.complete
18:07:06,374 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:07:06,375 httpcore.http11 DEBUG send_request_body.complete
18:07:06,375 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:07:06,577 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:07:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1274f7e0b72d1595d0b92c47a71ce906'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834161c4d9203008-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:07:06,582 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:07:06,583 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:07:06,584 httpcore.http11 DEBUG receive_response_body.complete
18:07:06,584 httpcore.http11 DEBUG response_closed.started
18:07:06,585 httpcore.http11 DEBUG response_closed.complete
18:07:06,585 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:07:06,619 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nYou should put the second candle at the top of the cake.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:07:06,622 httpcore.connection DEBUG close.started
18:07:06,623 httpcore.connection DEBUG close.complete
18:07:06,623 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:07:06,626 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd805704150>
18:07:06,626 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd8058fe7b0> server_hostname='api.openai.com' timeout=None
18:07:06,632 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd8057062d0>
18:07:06,632 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:07:06,633 httpcore.http11 DEBUG send_request_headers.complete
18:07:06,633 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:07:06,634 httpcore.http11 DEBUG send_request_body.complete
18:07:06,634 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:07:07,141 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:07:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'413'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7af36f08febffeb8349d35d508c57a7c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834161c67ebf4cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:07:07,148 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:07:07,149 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:07:07,150 httpcore.http11 DEBUG receive_response_body.complete
18:07:07,150 httpcore.http11 DEBUG response_closed.started
18:07:07,151 httpcore.http11 DEBUG response_closed.complete
18:07:07,151 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:07:07,474 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:07:07,479 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:07:13,981 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:07:13,998 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:07:14,2 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:07:19,3 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:07:19,19 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:07:19,21 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:07:21,23 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:07:21,41 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:07:21,44 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:07:24,445 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:07:24,459 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:07:24,462 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:07:30,963 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:07:30,977 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:07:30,980 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:44,324 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:08:44,328 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:08:45,141 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:08:45,142 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:08:45,183 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:08:45,184 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:08:45,231 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:08:45,232 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:08:45,272 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:08:45,273 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:08:45,315 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:08:45,316 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:08:45,358 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:08:45,358 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:08:45,403 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:08:45,404 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:08:45,447 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:08:45,448 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:08:45,493 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Jo. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:08:45,507 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:08:45,538 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275362290>
18:08:45,539 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:08:45,547 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275362810>
18:08:45,548 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:45,550 httpcore.http11 DEBUG send_request_headers.complete
18:08:45,551 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:45,552 httpcore.http11 DEBUG send_request_body.complete
18:08:45,552 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:46,1 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:08:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'48c527d3503bc543e471a29b556751dd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bPEOF7eKAEeKfla.9.1n5bZFs6VOnhHRrOgoh.qI5sQ-1702336125-1-Ad4Mj7T25jCqIjHCgkrNZkXsO+xwB7UoBCfBvn4s5FEFOFDVKbkgjnCY9e7kl/79wm8BOlfNjhLlOWMzd3IyBtM=; path=/; expires=Mon, 11-Dec-23 23:38:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=5BxuJNblyr.XoxXZrlltMDm94Vghf689jejf3IqFjHM-1702336125997-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416430b98d3b94-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:46,4 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:08:46,4 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:46,723 httpcore.http11 DEBUG receive_response_body.complete
18:08:46,724 httpcore.http11 DEBUG response_closed.started
18:08:46,724 httpcore.http11 DEBUG response_closed.complete
18:08:46,725 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:08:46,797 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:08:59,895 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:08:59,904 httpcore.connection DEBUG close.started
18:08:59,905 httpcore.connection DEBUG close.complete
18:08:59,905 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:08:59,907 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275362950>
18:08:59,908 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:08:59,912 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275361a90>
18:08:59,912 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:59,913 httpcore.http11 DEBUG send_request_headers.complete
18:08:59,913 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:59,945 httpcore.http11 DEBUG send_request_body.complete
18:08:59,945 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:00,932 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:09:00 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'457'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fa6e541665540da9b4ee92e422fe9fe7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341648a7a714ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:00,934 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:09:00,935 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:00,936 httpcore.http11 DEBUG receive_response_body.complete
18:09:00,937 httpcore.http11 DEBUG response_closed.started
18:09:00,937 httpcore.http11 DEBUG response_closed.complete
18:09:00,938 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:09:00,938 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:09:00,955 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Jo. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nYou should place the first candle in the middle of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:00,964 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:09:00,967 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751b7c50>
18:09:00,967 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9fd0> server_hostname='api.openai.com' timeout=None
18:09:00,975 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751b7f10>
18:09:00,975 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:00,976 httpcore.http11 DEBUG send_request_headers.complete
18:09:00,977 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:00,978 httpcore.http11 DEBUG send_request_body.complete
18:09:00,978 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:01,190 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:09:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'124'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'095e0595f57abecb1a1689a59dd8fb99'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ZUxJTJEHI4ZhtCXKxl0offgYfnw0nEPLctHBzZxGChE-1702336141-1-AT/jYmektLSMca9L1G1qC41Nb5DYyfhUFMlTeQXBogBACVKv+qF98n17aC0+K6JuKmk2TbhapLTlLR6VP+oFoJ8=; path=/; expires=Mon, 11-Dec-23 23:39:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=dOIO3oBVF3LCnNK70wvEhktmMdQ8XT26UKsuuiC6hoA-1702336141187-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341649119516ac9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:01,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:01,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:01,195 httpcore.http11 DEBUG receive_response_body.complete
18:09:01,195 httpcore.http11 DEBUG response_closed.started
18:09:01,195 httpcore.http11 DEBUG response_closed.complete
18:09:01,196 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:01,216 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Jo. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nYou should place the first candle in the middle of the cake.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:01,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:09:01,226 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751c0910>
18:09:01,226 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753ea7b0> server_hostname='api.openai.com' timeout=None
18:09:01,232 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751c0d90>
18:09:01,232 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:01,233 httpcore.http11 DEBUG send_request_headers.complete
18:09:01,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:01,234 httpcore.http11 DEBUG send_request_body.complete
18:09:01,234 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:02,283 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:09:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'951'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2b813f5a4bc9205e2a51420259e337bc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ikPqAyZ1AIY0og5iX_IxCetMsCFFBDAR1QRYqP5nBnY-1702336142-1-Abb/W9OH4E/kBjkfryMprrmP5rTwdScxRhwEKQJvJJqiut9CxS6rEPSbcxQ7TZ/V0n3YDRt11OQAl/pR2ger8+Y=; path=/; expires=Mon, 11-Dec-23 23:39:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rdYaBFkZ6ZWFo2dJ9dZ4Lly9gTNwax8Pggp34j_7098-1702336142279-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416492bb434d06-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:02,286 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:02,287 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:02,287 httpcore.http11 DEBUG receive_response_body.complete
18:09:02,288 httpcore.http11 DEBUG response_closed.started
18:09:02,288 httpcore.http11 DEBUG response_closed.complete
18:09:02,288 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:02,302 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:02,305 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:08,810 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:08,820 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:08,824 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:13,826 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:13,839 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:13,843 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:15,844 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:15,856 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:15,860 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:19,262 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:19,276 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:19,279 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:25,780 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:25,796 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:25,799 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:29,600 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:29,612 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:29,615 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:33,417 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:33,420 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:09:33,426 httpcore.connection DEBUG close.started
18:09:33,426 httpcore.connection DEBUG close.complete
18:09:33,426 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:09:33,429 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275361a90>
18:09:33,429 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:09:33,434 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751cdc50>
18:09:33,435 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:33,435 httpcore.http11 DEBUG send_request_headers.complete
18:09:33,436 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:33,436 httpcore.http11 DEBUG send_request_body.complete
18:09:33,436 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:34,109 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:09:34 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'547'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'702e9ed1741bce5a53e15070a9b17eba'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341655bf8ea4ce8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:34,111 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:09:34,111 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:34,835 httpcore.http11 DEBUG receive_response_body.complete
18:09:34,836 httpcore.http11 DEBUG response_closed.started
18:09:34,836 httpcore.http11 DEBUG response_closed.complete
18:09:34,837 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:09:34,903 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:09:47,216 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:09:47,221 httpcore.connection DEBUG close.started
18:09:47,222 httpcore.connection DEBUG close.complete
18:09:47,222 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:09:47,265 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751f2010>
18:09:47,266 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:09:47,272 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751f1210>
18:09:47,272 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:47,274 httpcore.http11 DEBUG send_request_headers.complete
18:09:47,274 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:47,300 httpcore.http11 DEBUG send_request_body.complete
18:09:47,300 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:48,99 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:09:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'40b601ce809f5db9cadc4371cc00042e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834165b279754d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:48,102 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:09:48,102 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:48,103 httpcore.http11 DEBUG receive_response_body.complete
18:09:48,103 httpcore.http11 DEBUG response_closed.started
18:09:48,103 httpcore.http11 DEBUG response_closed.complete
18:09:48,103 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:09:48,104 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:09:48,119 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:48,121 httpcore.connection DEBUG close.started
18:09:48,121 httpcore.connection DEBUG close.complete
18:09:48,121 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:09:48,124 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751b7f10>
18:09:48,124 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9fd0> server_hostname='api.openai.com' timeout=None
18:09:48,130 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751b4590>
18:09:48,130 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:48,131 httpcore.http11 DEBUG send_request_headers.complete
18:09:48,131 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:48,132 httpcore.http11 DEBUG send_request_body.complete
18:09:48,132 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:48,341 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:09:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1b104e153c24fc0f7f72d7586c132b13'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834165b7d95c4cc9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:48,344 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:48,345 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:48,346 httpcore.http11 DEBUG receive_response_body.complete
18:09:48,346 httpcore.http11 DEBUG response_closed.started
18:09:48,347 httpcore.http11 DEBUG response_closed.complete
18:09:48,347 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:48,362 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:48,370 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:09:48,373 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751f3390>
18:09:48,373 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9f40> server_hostname='api.openai.com' timeout=None
18:09:48,378 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751f1f10>
18:09:48,378 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:48,379 httpcore.http11 DEBUG send_request_headers.complete
18:09:48,379 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:48,379 httpcore.http11 DEBUG send_request_body.complete
18:09:48,380 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:48,575 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:09:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dd8945718fe0937cad680a31bf965a3e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=KOxm1.mk2BUSn4yKFhu9cW4g2UfaLmwZ14stKZNBDVI-1702336188-1-AYpTWb35TRO175j97/DDJkhot+5N/CNvJlhQgFeaac8ZWTxKdMkXoYimVdYMsQWII4GWahkhPLUSrwECWMb/dOs=; path=/; expires=Mon, 11-Dec-23 23:39:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=wfK_DpbkEgfHDmOKss0jST0bZnFcfgLaFr746YAGR.0-1702336188572-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834165b95dff4cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:48,577 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:48,577 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:48,578 httpcore.http11 DEBUG receive_response_body.complete
18:09:48,578 httpcore.http11 DEBUG response_closed.started
18:09:48,579 httpcore.http11 DEBUG response_closed.complete
18:09:48,579 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:48,588 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:48,591 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:51,992 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:51,996 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:09:52,0 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:52,1 httpcore.http11 DEBUG send_request_headers.complete
18:09:52,2 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:52,2 httpcore.http11 DEBUG send_request_body.complete
18:09:52,2 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:52,505 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:09:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'426'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'98a0bb5008d7cec3b48f2086f911082f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834165d00e384d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:52,506 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:09:52,507 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:53,531 httpcore.http11 DEBUG receive_response_body.complete
18:09:53,531 httpcore.http11 DEBUG response_closed.started
18:09:53,531 httpcore.http11 DEBUG response_closed.complete
18:09:53,532 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:09:53,600 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:10:06,79 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:10:06,83 httpcore.connection DEBUG close.started
18:10:06,83 httpcore.connection DEBUG close.complete
18:10:06,83 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:10:06,85 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751fde50>
18:10:06,86 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:10:06,91 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751fded0>
18:10:06,92 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:06,93 httpcore.http11 DEBUG send_request_headers.complete
18:10:06,93 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:06,115 httpcore.http11 DEBUG send_request_body.complete
18:10:06,115 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:06,894 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:10:06 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'323'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e4ca46c2c4c70900d9bfbd5f266b6324'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834166281b2c4cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:06,896 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:10:06,897 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:06,898 httpcore.http11 DEBUG receive_response_body.complete
18:10:06,898 httpcore.http11 DEBUG response_closed.started
18:10:06,899 httpcore.http11 DEBUG response_closed.complete
18:10:06,899 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:10:06,900 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:10:06,915 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nVAP.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:10:06,917 httpcore.connection DEBUG close.started
18:10:06,917 httpcore.connection DEBUG close.complete
18:10:06,918 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:10:06,920 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275209010>
18:10:06,920 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9f40> server_hostname='api.openai.com' timeout=None
18:10:06,928 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275209110>
18:10:06,928 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:06,928 httpcore.http11 DEBUG send_request_headers.complete
18:10:06,929 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:06,929 httpcore.http11 DEBUG send_request_body.complete
18:10:06,929 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:07,200 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:10:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'169'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7078b398bd158317f041e215ba69240b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341662d4dfd4ce4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:07,202 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:10:07,203 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:07,204 httpcore.http11 DEBUG receive_response_body.complete
18:10:07,204 httpcore.http11 DEBUG response_closed.started
18:10:07,204 httpcore.http11 DEBUG response_closed.complete
18:10:07,204 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:10:07,210 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:10:07,212 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:07,213 httpcore.http11 DEBUG send_request_headers.complete
18:10:07,213 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:07,213 httpcore.http11 DEBUG send_request_body.complete
18:10:07,213 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:07,890 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:10:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'564'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3b882693f72412dddc5b946d8339f6bf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341662f18864cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:07,892 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:10:07,893 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:08,944 httpcore.http11 DEBUG receive_response_body.complete
18:10:08,945 httpcore.http11 DEBUG response_closed.started
18:10:08,945 httpcore.http11 DEBUG response_closed.complete
18:10:08,947 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:10:09,17 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:10:21,172 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:10:21,178 httpcore.connection DEBUG close.started
18:10:21,178 httpcore.connection DEBUG close.complete
18:10:21,178 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:10:21,180 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751c7410>
18:10:21,181 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:10:21,186 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751c5810>
18:10:21,186 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:21,187 httpcore.http11 DEBUG send_request_headers.complete
18:10:21,187 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:21,204 httpcore.http11 DEBUG send_request_body.complete
18:10:21,204 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:21,981 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:10:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'378'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'dce5aeac6f77dee8bb107d5d5ea4b92e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834166866a3a4cc9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:21,983 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:10:21,983 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:21,984 httpcore.http11 DEBUG receive_response_body.complete
18:10:21,984 httpcore.http11 DEBUG response_closed.started
18:10:21,984 httpcore.http11 DEBUG response_closed.complete
18:10:21,985 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:10:21,985 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:10:22,2 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:10:22,4 httpcore.connection DEBUG close.started
18:10:22,5 httpcore.connection DEBUG close.complete
18:10:22,5 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:10:22,7 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751f0ad0>
18:10:22,7 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9f40> server_hostname='api.openai.com' timeout=None
18:10:22,14 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751f3dd0>
18:10:22,14 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:22,15 httpcore.http11 DEBUG send_request_headers.complete
18:10:22,15 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:22,15 httpcore.http11 DEBUG send_request_body.complete
18:10:22,15 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:22,232 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:10:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4da3ee10c6fee8ca016decd53eed2163'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341668b9c543b81-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:22,235 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:10:22,235 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:22,237 httpcore.http11 DEBUG receive_response_body.complete
18:10:22,237 httpcore.http11 DEBUG response_closed.started
18:10:22,237 httpcore.http11 DEBUG response_closed.complete
18:10:22,238 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:10:22,248 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:10:22,252 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:10:25,654 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:10:25,657 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:10:25,661 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:25,662 httpcore.http11 DEBUG send_request_headers.complete
18:10:25,662 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:25,662 httpcore.http11 DEBUG send_request_body.complete
18:10:25,663 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:26,179 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:10:26 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'438'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7a4204c9358b014ad2ae6c738ed1e4ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834166a26a674cc9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:26,181 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:10:26,182 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:27,116 httpcore.http11 DEBUG receive_response_body.complete
18:10:27,116 httpcore.http11 DEBUG response_closed.started
18:10:27,117 httpcore.http11 DEBUG response_closed.complete
18:10:27,117 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:10:27,187 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:10:39,485 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:10:39,487 httpcore.connection DEBUG close.started
18:10:39,487 httpcore.connection DEBUG close.complete
18:10:39,488 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:10:39,490 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe27520a950>
18:10:39,490 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:10:39,496 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe27520ac90>
18:10:39,496 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:39,497 httpcore.http11 DEBUG send_request_headers.complete
18:10:39,497 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:39,516 httpcore.http11 DEBUG send_request_body.complete
18:10:39,516 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:40,269 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:10:40 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'328'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9ef5cf9f4ca4ef47926be8bd003474f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834166f8de793061-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:40,271 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:10:40,271 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:40,272 httpcore.http11 DEBUG receive_response_body.complete
18:10:40,272 httpcore.http11 DEBUG response_closed.started
18:10:40,272 httpcore.http11 DEBUG response_closed.complete
18:10:40,273 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:10:40,273 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:10:40,289 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:10:40,291 httpcore.connection DEBUG close.started
18:10:40,291 httpcore.connection DEBUG close.complete
18:10:40,292 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:10:40,308 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275205dd0>
18:10:40,308 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9f40> server_hostname='api.openai.com' timeout=None
18:10:40,315 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275205ed0>
18:10:40,316 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:40,317 httpcore.http11 DEBUG send_request_headers.complete
18:10:40,317 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:40,317 httpcore.http11 DEBUG send_request_body.complete
18:10:40,317 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:40,530 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:10:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a48376a99f01bc7c7546791357062395'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834166fdf8a93031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:40,532 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:10:40,532 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:40,533 httpcore.http11 DEBUG receive_response_body.complete
18:10:40,533 httpcore.http11 DEBUG response_closed.started
18:10:40,533 httpcore.http11 DEBUG response_closed.complete
18:10:40,533 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:10:40,542 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:10:40,545 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:10:43,946 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:10:43,959 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:10:43,963 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:10:45,965 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:10:45,979 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:10:45,982 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:10:49,383 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:10:49,388 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:10:49,391 httpcore.connection DEBUG close.started
18:10:49,392 httpcore.connection DEBUG close.complete
18:10:49,392 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:10:49,422 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275209910>
18:10:49,423 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:10:49,431 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2752089d0>
18:10:49,432 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:49,433 httpcore.http11 DEBUG send_request_headers.complete
18:10:49,433 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:49,434 httpcore.http11 DEBUG send_request_body.complete
18:10:49,434 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:50,33 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:10:50 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'486'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'375c4392abb083387b70de525f97e9df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416736fa314d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:50,35 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:10:50,36 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:50,395 httpcore.http11 DEBUG receive_response_body.complete
18:10:50,396 httpcore.http11 DEBUG response_closed.started
18:10:50,396 httpcore.http11 DEBUG response_closed.complete
18:10:50,397 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:10:50,465 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:11:01,531 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:11:01,534 httpcore.connection DEBUG close.started
18:11:01,534 httpcore.connection DEBUG close.complete
18:11:01,534 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:11:01,537 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751f08d0>
18:11:01,537 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:11:01,542 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751f16d0>
18:11:01,542 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:11:01,543 httpcore.http11 DEBUG send_request_headers.complete
18:11:01,543 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:11:01,572 httpcore.http11 DEBUG send_request_body.complete
18:11:01,572 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:11:02,588 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:11:02 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'522'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6a55b478b442d4c3b666ebdeabb52877'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416782af32300c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:11:02,590 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:11:02,591 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:11:02,592 httpcore.http11 DEBUG receive_response_body.complete
18:11:02,592 httpcore.http11 DEBUG response_closed.started
18:11:02,593 httpcore.http11 DEBUG response_closed.complete
18:11:02,593 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:11:02,594 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:11:02,610 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nYou should place the second candle at the top left corner of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:11:02,612 httpcore.connection DEBUG close.started
18:11:02,613 httpcore.connection DEBUG close.complete
18:11:02,613 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:11:02,616 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751b4590>
18:11:02,616 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9fd0> server_hostname='api.openai.com' timeout=None
18:11:02,621 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751c5390>
18:11:02,621 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:11:02,621 httpcore.http11 DEBUG send_request_headers.complete
18:11:02,622 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:11:02,622 httpcore.http11 DEBUG send_request_body.complete
18:11:02,622 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:11:02,839 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:11:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'053b3fc1b23435ec1e987cab031ead1d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834167896db14ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:11:02,841 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:11:02,841 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:11:02,842 httpcore.http11 DEBUG receive_response_body.complete
18:11:02,842 httpcore.http11 DEBUG response_closed.started
18:11:02,842 httpcore.http11 DEBUG response_closed.complete
18:11:02,842 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:11:02,857 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nYou should place the second candle at the top left corner of the cake.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:11:02,859 httpcore.connection DEBUG close.started
18:11:02,859 httpcore.connection DEBUG close.complete
18:11:02,860 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:11:02,862 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751c3350>
18:11:02,862 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753ea7b0> server_hostname='api.openai.com' timeout=None
18:11:02,866 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2751fe010>
18:11:02,867 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:11:02,867 httpcore.http11 DEBUG send_request_headers.complete
18:11:02,867 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:11:02,868 httpcore.http11 DEBUG send_request_body.complete
18:11:02,868 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:11:03,682 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:11:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'716'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'250326eb1156af1c7ef035d18b3b54ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341678aefaf4cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:11:03,685 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:11:03,685 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:11:03,686 httpcore.http11 DEBUG receive_response_body.complete
18:11:03,686 httpcore.http11 DEBUG response_closed.started
18:11:03,686 httpcore.http11 DEBUG response_closed.complete
18:11:03,687 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:11:03,868 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:11:03,869 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:11:10,371 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:11:10,381 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:11:10,384 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:11:15,385 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:11:15,396 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:11:15,400 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:11:17,401 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:11:17,412 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:11:17,415 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:11:20,817 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:11:20,828 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:11:20,831 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:11:27,333 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:11:27,345 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:11:27,348 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:11:31,150 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:11:31,163 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:11:31,165 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:11:34,967 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:11:34,971 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:11:34,975 httpcore.connection DEBUG close.started
18:11:34,976 httpcore.connection DEBUG close.complete
18:11:34,976 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:11:34,978 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2752054d0>
18:11:34,979 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe2753e9e20> server_hostname='api.openai.com' timeout=5.0
18:11:34,984 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe275205e50>
18:11:34,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:11:34,985 httpcore.http11 DEBUG send_request_headers.complete
18:11:34,985 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:11:34,985 httpcore.http11 DEBUG send_request_body.complete
18:11:34,985 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:11:35,482 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:11:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ff379e3c2ce9da12103778d3c13dd3e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416853afe23b94-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:11:35,483 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:11:35,484 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:11:36,582 httpcore.http11 DEBUG receive_response_body.complete
18:11:36,582 httpcore.http11 DEBUG response_closed.started
18:11:36,583 httpcore.http11 DEBUG response_closed.complete
18:11:36,583 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:11:36,644 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:14:55,913 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:55,918 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:56,720 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:56,721 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:56,762 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:56,763 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:56,805 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:56,806 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:56,843 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:56,844 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:56,884 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:56,884 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:56,924 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:56,925 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:56,966 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:56,967 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:57,3 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:57,4 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:57,45 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Jo. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:14:57,58 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:14:57,88 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d62a650>
18:14:57,88 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:14:57,97 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1a6190>
18:14:57,98 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:57,100 httpcore.http11 DEBUG send_request_headers.complete
18:14:57,100 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:57,100 httpcore.http11 DEBUG send_request_body.complete
18:14:57,101 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:57,724 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:14:57 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'512'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'42db32d5b05eb27bec775d610866ef8a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=oez2Xnfo.HMA1MwpxYC7BSVnGeDxTuohoIJQ4T0RnZs-1702336497-1-Aad6GVb7klGkUtXKiee/udDJP4C3aJH0enH6gJFF6BWSr2OF+wwGqw/U0IfPkX/hRtWgTmVUHRAggxxxAhUkK+A=; path=/; expires=Mon, 11-Dec-23 23:44:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=6fSCbkYGAnQKcJ9hiMrllR7Nho9dNi_28VuGrdvbk3w-1702336497719-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416d42e8224cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:57,729 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:14:57,730 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:58,391 httpcore.http11 DEBUG receive_response_body.complete
18:14:58,392 httpcore.http11 DEBUG response_closed.started
18:14:58,392 httpcore.http11 DEBUG response_closed.complete
18:14:58,393 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:14:58,467 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:15:11,331 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:15:11,337 httpcore.connection DEBUG close.started
18:15:11,337 httpcore.connection DEBUG close.complete
18:15:11,337 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:15:11,340 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1a6650>
18:15:11,340 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:15:11,346 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1c8250>
18:15:11,346 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:11,347 httpcore.http11 DEBUG send_request_headers.complete
18:15:11,347 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:11,410 httpcore.http11 DEBUG send_request_body.complete
18:15:11,411 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:12,386 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:15:12 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'445'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2646f1c905bdbb8de8faca04e1f12988'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416d9bec134cf5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:12,388 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:15:12,389 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:12,390 httpcore.http11 DEBUG receive_response_body.complete
18:15:12,390 httpcore.http11 DEBUG response_closed.started
18:15:12,391 httpcore.http11 DEBUG response_closed.complete
18:15:12,391 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:15:12,392 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:15:12,410 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Jo. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nYou should place the first candle in the middle of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:15:12,418 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:15:12,421 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1f4210>
18:15:12,421 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42dfd0> server_hostname='api.openai.com' timeout=None
18:15:12,428 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1f4150>
18:15:12,428 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:12,429 httpcore.http11 DEBUG send_request_headers.complete
18:15:12,430 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:12,430 httpcore.http11 DEBUG send_request_body.complete
18:15:12,430 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:12,650 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:15:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'32095c88f7327d810c7c1ba6f08634ba'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ehKkn.BhNTbFUIMHdaPqIJ2mJCbqLU_NBHl3xDsQGKQ-1702336512-1-AUsB3MR4GvmAt7hcC5wpkIpH1NIu8WCz3UrNwHQDhUCeTBPUv05hEMiiLRCfu4uJB4tuyuacyvD9rjNqPb5q6N0=; path=/; expires=Mon, 11-Dec-23 23:45:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LxDqolwf33DjI7z4tDjavA.F5NgeowSiM9UKHrfNLV4-1702336512646-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416da2b8be4cde-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:12,652 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:15:12,652 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:12,653 httpcore.http11 DEBUG receive_response_body.complete
18:15:12,653 httpcore.http11 DEBUG response_closed.started
18:15:12,653 httpcore.http11 DEBUG response_closed.complete
18:15:12,654 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:15:12,670 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Jo. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nYou should place the first candle in the middle of the cake.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:15:12,681 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:15:12,684 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d200b50>
18:15:12,684 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42e7b0> server_hostname='api.openai.com' timeout=None
18:15:12,691 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d201250>
18:15:12,691 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:12,692 httpcore.http11 DEBUG send_request_headers.complete
18:15:12,692 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:12,693 httpcore.http11 DEBUG send_request_body.complete
18:15:12,693 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:13,629 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:15:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'823'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9e064313d95a818684434e6abd2954ec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6ckL5sCRs9zXrrCD5RQhLbDWFsf4emkE58HhXq1hNso-1702336513-1-AaHJDEl4iDFQU8zfbip1ZqffK/TWVYBfBsQiTo/DWkn3aiood9W+jXyXpwCj2Za7rNSlfyy/0y9ES70kWs517v8=; path=/; expires=Mon, 11-Dec-23 23:45:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=digvo.EvPNptj7SGyrQNCyK4f0FedMV9OqABgfsivnU-1702336513624-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416da45c7b4d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:13,634 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:15:13,635 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:13,637 httpcore.http11 DEBUG receive_response_body.complete
18:15:13,637 httpcore.http11 DEBUG response_closed.started
18:15:13,638 httpcore.http11 DEBUG response_closed.complete
18:15:13,638 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:15:13,654 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:15:13,707 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:15:20,214 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:15:20,226 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:15:20,231 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:15:25,234 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:15:25,247 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:15:25,250 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:15:27,251 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:15:27,266 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:15:27,270 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:15:30,673 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:15:30,685 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:15:30,688 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:15:37,189 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:15:37,201 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:15:37,205 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:15:41,6 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:15:41,19 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:15:41,23 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:15:44,825 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:15:44,829 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:15:44,832 httpcore.connection DEBUG close.started
18:15:44,832 httpcore.connection DEBUG close.complete
18:15:44,833 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:15:44,851 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1c8250>
18:15:44,851 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:15:44,860 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1a59d0>
18:15:44,860 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:44,861 httpcore.http11 DEBUG send_request_headers.complete
18:15:44,862 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:44,862 httpcore.http11 DEBUG send_request_body.complete
18:15:44,862 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:45,583 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:15:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'580'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b337eef60eba47ee4a34086dc3883093'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416e6d69c04cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:45,584 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:15:45,585 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:46,641 httpcore.http11 DEBUG receive_response_body.complete
18:15:46,642 httpcore.http11 DEBUG response_closed.started
18:15:46,642 httpcore.http11 DEBUG response_closed.complete
18:15:46,643 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:15:46,708 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:15:59,57 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:15:59,59 httpcore.connection DEBUG close.started
18:15:59,60 httpcore.connection DEBUG close.complete
18:15:59,60 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:15:59,91 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d235c90>
18:15:59,91 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:15:59,99 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d235d10>
18:15:59,99 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:59,101 httpcore.http11 DEBUG send_request_headers.complete
18:15:59,101 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:59,129 httpcore.http11 DEBUG send_request_body.complete
18:15:59,130 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:59,932 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:15:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'383'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e1e207a1afc5ebf4acf1c7ec5f879ef3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416ec66f234cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:59,935 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:15:59,935 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:59,936 httpcore.http11 DEBUG receive_response_body.complete
18:15:59,937 httpcore.http11 DEBUG response_closed.started
18:15:59,937 httpcore.http11 DEBUG response_closed.complete
18:15:59,937 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:15:59,938 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:15:59,953 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:15:59,955 httpcore.connection DEBUG close.started
18:15:59,955 httpcore.connection DEBUG close.complete
18:15:59,955 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:15:59,958 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1f4150>
18:15:59,959 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42dfd0> server_hostname='api.openai.com' timeout=None
18:15:59,964 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1f4250>
18:15:59,964 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:59,965 httpcore.http11 DEBUG send_request_headers.complete
18:15:59,965 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:59,965 httpcore.http11 DEBUG send_request_body.complete
18:15:59,965 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:00,215 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5a28bc05024573e976a5da43e91de946'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416ecbcdca4d06-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:00,218 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:16:00,219 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:00,219 httpcore.http11 DEBUG receive_response_body.complete
18:16:00,219 httpcore.http11 DEBUG response_closed.started
18:16:00,220 httpcore.http11 DEBUG response_closed.complete
18:16:00,220 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:16:00,235 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:16:00,245 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:16:00,247 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d235d50>
18:16:00,247 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42df40> server_hostname='api.openai.com' timeout=None
18:16:00,252 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d236990>
18:16:00,252 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:00,253 httpcore.http11 DEBUG send_request_headers.complete
18:16:00,253 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:00,253 httpcore.http11 DEBUG send_request_body.complete
18:16:00,253 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:00,498 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'144'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5c64bc5a81eed57f18573e92bd0a0145'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ku8oP6qEdNZm.X88bM9sRk4CHZBcIfXMxIPr1Y5Nqjo-1702336560-1-ARrb36j/85Joopu1pKNHwfOoJVFCrmAEhLjQbOmb5x6yCXZNl/3IA1yRWaSarRRT2qAhMMc4jxf2ZVknxnq3hzg=; path=/; expires=Mon, 11-Dec-23 23:46:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qnSc3GvpZK5KXyiEozln1ZVL94Ra1DxlmZZdjOyF1K4-1702336560495-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416ecd9f724d0e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:00,500 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:16:00,500 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:00,501 httpcore.http11 DEBUG receive_response_body.complete
18:16:00,501 httpcore.http11 DEBUG response_closed.started
18:16:00,502 httpcore.http11 DEBUG response_closed.complete
18:16:00,502 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:16:00,512 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:16:00,515 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:16:03,917 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:16:03,920 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:16:03,925 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:03,926 httpcore.http11 DEBUG send_request_headers.complete
18:16:03,926 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:03,926 httpcore.http11 DEBUG send_request_body.complete
18:16:03,926 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:04,445 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:04 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bfee440243efbae8d2f865792aec9f37'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416ee48ed54cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:04,447 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:16:04,448 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:05,669 httpcore.http11 DEBUG receive_response_body.complete
18:16:05,670 httpcore.http11 DEBUG response_closed.started
18:16:05,670 httpcore.http11 DEBUG response_closed.complete
18:16:05,671 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:16:05,744 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:16:18,304 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:16:18,307 httpcore.connection DEBUG close.started
18:16:18,308 httpcore.connection DEBUG close.complete
18:16:18,308 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:16:18,311 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d03dc10>
18:16:18,311 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:16:18,320 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d03dc90>
18:16:18,320 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:18,321 httpcore.http11 DEBUG send_request_headers.complete
18:16:18,321 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:18,348 httpcore.http11 DEBUG send_request_body.complete
18:16:18,348 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:19,208 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:19 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'370'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0ef8f020840b0f7dcc7a60528028ae91'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416f3e898b4cde-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:19,210 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:16:19,211 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:19,211 httpcore.http11 DEBUG receive_response_body.complete
18:16:19,212 httpcore.http11 DEBUG response_closed.started
18:16:19,212 httpcore.http11 DEBUG response_closed.complete
18:16:19,213 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:16:19,213 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:16:19,228 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:16:19,230 httpcore.connection DEBUG close.started
18:16:19,230 httpcore.connection DEBUG close.complete
18:16:19,230 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:16:19,233 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d048e90>
18:16:19,233 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42df40> server_hostname='api.openai.com' timeout=None
18:16:19,242 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d048f10>
18:16:19,243 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:19,244 httpcore.http11 DEBUG send_request_headers.complete
18:16:19,244 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:19,244 httpcore.http11 DEBUG send_request_body.complete
18:16:19,244 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:19,478 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'edc11639291f88638fa8971e6c7631b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416f4448334cff-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:19,480 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:16:19,481 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:19,482 httpcore.http11 DEBUG receive_response_body.complete
18:16:19,483 httpcore.http11 DEBUG response_closed.started
18:16:19,483 httpcore.http11 DEBUG response_closed.complete
18:16:19,483 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:16:19,495 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:16:19,499 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:16:22,900 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:16:22,904 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:16:22,909 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:22,910 httpcore.http11 DEBUG send_request_headers.complete
18:16:22,910 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:22,910 httpcore.http11 DEBUG send_request_body.complete
18:16:22,910 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:23,435 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'450'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'75b5cb43522046513b6bed3681fa4ec1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416f5b3b8d4cde-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:23,437 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:16:23,438 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:24,426 httpcore.http11 DEBUG receive_response_body.complete
18:16:24,426 httpcore.http11 DEBUG response_closed.started
18:16:24,427 httpcore.http11 DEBUG response_closed.complete
18:16:24,427 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:16:24,492 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:16:36,731 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:16:36,734 httpcore.connection DEBUG close.started
18:16:36,734 httpcore.connection DEBUG close.complete
18:16:36,734 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:16:36,737 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d234710>
18:16:36,737 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:16:36,743 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d236d90>
18:16:36,743 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:36,744 httpcore.http11 DEBUG send_request_headers.complete
18:16:36,744 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:36,755 httpcore.http11 DEBUG send_request_body.complete
18:16:36,755 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:37,568 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'439'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8a852e1a385a191e379c170f56383471'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416fb1ae5f4cf4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:37,570 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:16:37,571 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:37,572 httpcore.http11 DEBUG receive_response_body.complete
18:16:37,572 httpcore.http11 DEBUG response_closed.started
18:16:37,572 httpcore.http11 DEBUG response_closed.complete
18:16:37,573 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:16:37,573 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:16:37,588 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:16:37,590 httpcore.connection DEBUG close.started
18:16:37,590 httpcore.connection DEBUG close.complete
18:16:37,590 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:16:37,592 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d237b10>
18:16:37,593 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42df40> server_hostname='api.openai.com' timeout=None
18:16:37,599 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d236e10>
18:16:37,599 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:37,600 httpcore.http11 DEBUG send_request_headers.complete
18:16:37,600 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:37,600 httpcore.http11 DEBUG send_request_body.complete
18:16:37,600 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:37,820 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'124'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fc1201a1c7f8fd7f92d52bf875cc856e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416fb70e8b4d1d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:37,822 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:16:37,822 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:37,823 httpcore.http11 DEBUG receive_response_body.complete
18:16:37,823 httpcore.http11 DEBUG response_closed.started
18:16:37,823 httpcore.http11 DEBUG response_closed.complete
18:16:37,823 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:16:37,832 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:16:37,836 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:16:41,238 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:16:41,253 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:16:41,256 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:16:43,257 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:16:43,265 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:16:43,270 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:16:46,673 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:16:46,677 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:16:46,681 httpcore.connection DEBUG close.started
18:16:46,681 httpcore.connection DEBUG close.complete
18:16:46,682 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:16:46,684 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d234a10>
18:16:46,684 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:16:46,692 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d2347d0>
18:16:46,693 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:46,693 httpcore.http11 DEBUG send_request_headers.complete
18:16:46,693 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:46,694 httpcore.http11 DEBUG send_request_body.complete
18:16:46,694 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:47,141 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:47 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1b93932d770ec52e2a6b8c6b6cc1a1df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83416fefde0b4cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:47,142 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:16:47,143 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:47,469 httpcore.http11 DEBUG receive_response_body.complete
18:16:47,469 httpcore.http11 DEBUG response_closed.started
18:16:47,470 httpcore.http11 DEBUG response_closed.complete
18:16:47,470 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:16:47,540 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:16:58,402 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:16:58,405 httpcore.connection DEBUG close.started
18:16:58,406 httpcore.connection DEBUG close.complete
18:16:58,406 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:16:58,408 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d04b150>
18:16:58,408 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:16:58,416 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d04b1d0>
18:16:58,416 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:58,416 httpcore.http11 DEBUG send_request_headers.complete
18:16:58,417 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:58,441 httpcore.http11 DEBUG send_request_body.complete
18:16:58,441 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:59,357 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7b51cb32d2eaf70e680a18ff7ca0f424'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834170391ca64cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:59,359 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:16:59,360 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:59,361 httpcore.http11 DEBUG receive_response_body.complete
18:16:59,361 httpcore.http11 DEBUG response_closed.started
18:16:59,362 httpcore.http11 DEBUG response_closed.complete
18:16:59,362 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:16:59,362 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:16:59,378 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPlace the second candle at the top left corner of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:16:59,381 httpcore.connection DEBUG close.started
18:16:59,381 httpcore.connection DEBUG close.complete
18:16:59,381 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:16:59,412 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1f4290>
18:16:59,412 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42dfd0> server_hostname='api.openai.com' timeout=None
18:16:59,420 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1f7790>
18:16:59,421 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:59,422 httpcore.http11 DEBUG send_request_headers.complete
18:16:59,423 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:59,424 httpcore.http11 DEBUG send_request_body.complete
18:16:59,424 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:16:59,661 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:16:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'140'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'afe37977ad47dd8defd2688432982608'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341703f6ad74d0b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:16:59,663 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:16:59,664 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:16:59,665 httpcore.http11 DEBUG receive_response_body.complete
18:16:59,666 httpcore.http11 DEBUG response_closed.started
18:16:59,666 httpcore.http11 DEBUG response_closed.complete
18:16:59,667 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:16:59,697 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPlace the second candle at the top left corner of the cake.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:16:59,699 httpcore.connection DEBUG close.started
18:16:59,700 httpcore.connection DEBUG close.complete
18:16:59,700 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:16:59,702 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d20b7d0>
18:16:59,703 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42e7b0> server_hostname='api.openai.com' timeout=None
18:16:59,708 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d201250>
18:16:59,709 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:16:59,709 httpcore.http11 DEBUG send_request_headers.complete
18:16:59,710 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:16:59,710 httpcore.http11 DEBUG send_request_body.complete
18:16:59,710 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:17:00,414 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:17:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'488'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7f0ad70ecd4dca82108cc21cb63ef981'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341704139094ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:17:00,416 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:17:00,417 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:17:00,418 httpcore.http11 DEBUG receive_response_body.complete
18:17:00,418 httpcore.http11 DEBUG response_closed.started
18:17:00,418 httpcore.http11 DEBUG response_closed.complete
18:17:00,419 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:17:00,606 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:17:00,609 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:17:07,110 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:17:07,121 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:17:07,125 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:17:12,126 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:17:12,135 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:17:12,138 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:17:14,140 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:17:14,155 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:17:14,159 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:17:17,560 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:17:17,570 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:17:17,574 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:17:24,76 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:17:24,90 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:17:24,97 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:17:27,899 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:17:27,910 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:17:27,913 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:17:32,515 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:17:32,517 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:17:32,519 httpcore.connection DEBUG close.started
18:17:32,520 httpcore.connection DEBUG close.complete
18:17:32,521 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:17:32,524 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d049510>
18:17:32,524 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:17:32,534 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d04bcd0>
18:17:32,534 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:17:32,535 httpcore.http11 DEBUG send_request_headers.complete
18:17:32,535 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:17:32,535 httpcore.http11 DEBUG send_request_body.complete
18:17:32,535 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:17:33,191 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:17:33 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'537'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a881e89882d77509441db87bc72fd04a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341710e5d504d10-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:17:33,192 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:17:33,193 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:17:34,383 httpcore.http11 DEBUG receive_response_body.complete
18:17:34,383 httpcore.http11 DEBUG response_closed.started
18:17:34,384 httpcore.http11 DEBUG response_closed.complete
18:17:34,384 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:17:34,452 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:17:46,850 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:17:46,854 httpcore.connection DEBUG close.started
18:17:46,854 httpcore.connection DEBUG close.complete
18:17:46,854 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:17:46,862 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d03f450>
18:17:46,862 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:17:46,872 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d03da10>
18:17:46,872 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:17:46,874 httpcore.http11 DEBUG send_request_headers.complete
18:17:46,874 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:17:46,895 httpcore.http11 DEBUG send_request_body.complete
18:17:46,895 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:17:47,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:17:47 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'439'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bb844042fce1a5a64a7655851a9dcc16'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83417167ff744cce-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:17:47,858 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:17:47,858 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:17:47,859 httpcore.http11 DEBUG receive_response_body.complete
18:17:47,859 httpcore.http11 DEBUG response_closed.started
18:17:47,860 httpcore.http11 DEBUG response_closed.complete
18:17:47,860 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:17:47,861 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:17:47,877 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the left.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:17:47,879 httpcore.connection DEBUG close.started
18:17:47,880 httpcore.connection DEBUG close.complete
18:17:47,880 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:17:47,882 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d052ad0>
18:17:47,882 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42dfd0> server_hostname='api.openai.com' timeout=None
18:17:47,889 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d050450>
18:17:47,890 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:17:47,890 httpcore.http11 DEBUG send_request_headers.complete
18:17:47,891 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:17:47,891 httpcore.http11 DEBUG send_request_body.complete
18:17:47,891 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:17:48,121 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:17:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3f5025b87aec8a1b6664a4cedd8190c0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341716e5f4c4d19-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:17:48,123 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:17:48,124 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:17:48,125 httpcore.http11 DEBUG receive_response_body.complete
18:17:48,126 httpcore.http11 DEBUG response_closed.started
18:17:48,126 httpcore.http11 DEBUG response_closed.complete
18:17:48,126 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:17:48,144 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the left.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:17:48,146 httpcore.connection DEBUG close.started
18:17:48,147 httpcore.connection DEBUG close.complete
18:17:48,147 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:17:48,149 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d237a10>
18:17:48,149 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42df40> server_hostname='api.openai.com' timeout=None
18:17:48,158 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d237990>
18:17:48,158 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:17:48,159 httpcore.http11 DEBUG send_request_headers.complete
18:17:48,159 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:17:48,159 httpcore.http11 DEBUG send_request_body.complete
18:17:48,160 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:17:48,387 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:17:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a8a52b39e2120b216ddf700d59be281c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341716ffe014d0e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:17:48,389 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:17:48,390 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:17:48,390 httpcore.http11 DEBUG receive_response_body.complete
18:17:48,391 httpcore.http11 DEBUG response_closed.started
18:17:48,391 httpcore.http11 DEBUG response_closed.complete
18:17:48,391 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:17:48,404 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:17:48,408 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:17:51,810 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:17:51,812 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:17:51,816 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:17:51,818 httpcore.http11 DEBUG send_request_headers.complete
18:17:51,818 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:17:51,819 httpcore.http11 DEBUG send_request_body.complete
18:17:51,819 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:17:52,331 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:17:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'440'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'881f873aaa6f58bc3dc2b734fdd5180a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83417186dedc4cce-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:17:52,333 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:17:52,333 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:17:53,524 httpcore.http11 DEBUG receive_response_body.complete
18:17:53,524 httpcore.http11 DEBUG response_closed.started
18:17:53,525 httpcore.http11 DEBUG response_closed.complete
18:17:53,525 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:17:53,592 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:18:06,5 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:18:06,8 httpcore.connection DEBUG close.started
18:18:06,8 httpcore.connection DEBUG close.complete
18:18:06,8 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:06,37 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d20a0d0>
18:18:06,37 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:18:06,44 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d2098d0>
18:18:06,44 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:06,46 httpcore.http11 DEBUG send_request_headers.complete
18:18:06,46 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:06,69 httpcore.http11 DEBUG send_request_body.complete
18:18:06,69 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:06,866 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:18:06 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'342'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'15bc5c3f0789bbdeb55b2d0875db3e4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834171dfcfe63b9a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:06,868 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:18:06,869 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:06,869 httpcore.http11 DEBUG receive_response_body.complete
18:18:06,870 httpcore.http11 DEBUG response_closed.started
18:18:06,870 httpcore.http11 DEBUG response_closed.complete
18:18:06,870 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:18:06,871 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:18:06,887 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:18:06,889 httpcore.connection DEBUG close.started
18:18:06,889 httpcore.connection DEBUG close.complete
18:18:06,890 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:18:06,892 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d03f350>
18:18:06,892 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42df40> server_hostname='api.openai.com' timeout=None
18:18:06,897 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d03f250>
18:18:06,897 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:06,898 httpcore.http11 DEBUG send_request_headers.complete
18:18:06,898 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:06,898 httpcore.http11 DEBUG send_request_body.complete
18:18:06,898 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:07,106 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:18:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c339752e639d0c2739d5320552247124'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834171e51db13031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:07,108 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:18:07,108 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:07,109 httpcore.http11 DEBUG receive_response_body.complete
18:18:07,109 httpcore.http11 DEBUG response_closed.started
18:18:07,109 httpcore.http11 DEBUG response_closed.complete
18:18:07,110 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:18:07,122 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:18:07,126 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:18:10,527 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:18:10,531 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:18:10,536 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:10,537 httpcore.http11 DEBUG send_request_headers.complete
18:18:10,537 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:10,538 httpcore.http11 DEBUG send_request_body.complete
18:18:10,539 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:11,631 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:18:11 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'975'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'230db664b9de72bec26e4e8cb560ab46'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834171fbda6b3b9a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:11,633 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:18:11,634 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:12,609 httpcore.http11 DEBUG receive_response_body.complete
18:18:12,610 httpcore.http11 DEBUG response_closed.started
18:18:12,610 httpcore.http11 DEBUG response_closed.complete
18:18:12,611 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:18:12,679 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:18:25,60 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:18:25,63 httpcore.connection DEBUG close.started
18:18:25,64 httpcore.connection DEBUG close.complete
18:18:25,64 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:25,66 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d049750>
18:18:25,67 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:18:25,72 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d049b90>
18:18:25,72 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:25,73 httpcore.http11 DEBUG send_request_headers.complete
18:18:25,73 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:25,92 httpcore.http11 DEBUG send_request_body.complete
18:18:25,92 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:27,112 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:18:27 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'70e8fe264a6fcd6e4f0314844f75c954'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83417256ba774cd0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:27,114 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:18:27,115 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:27,115 httpcore.http11 DEBUG receive_response_body.complete
18:18:27,116 httpcore.http11 DEBUG response_closed.started
18:18:27,116 httpcore.http11 DEBUG response_closed.complete
18:18:27,116 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:18:27,117 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:18:27,132 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:18:27,136 httpcore.connection DEBUG close.started
18:18:27,136 httpcore.connection DEBUG close.complete
18:18:27,136 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:18:27,138 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d0597d0>
18:18:27,139 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42df40> server_hostname='api.openai.com' timeout=None
18:18:27,148 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d058090>
18:18:27,149 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:27,149 httpcore.http11 DEBUG send_request_headers.complete
18:18:27,149 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:27,150 httpcore.http11 DEBUG send_request_body.complete
18:18:27,150 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:27,334 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:18:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'69'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'86240bd9880e5c9f8192742c9bd2553f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83417263bac34ce7-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:27,337 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:18:27,338 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:27,339 httpcore.http11 DEBUG receive_response_body.complete
18:18:27,340 httpcore.http11 DEBUG response_closed.started
18:18:27,340 httpcore.http11 DEBUG response_closed.complete
18:18:27,341 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:18:27,350 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:18:27,353 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:18:30,755 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:18:30,767 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:18:30,771 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:18:32,773 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:18:32,784 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:18:32,787 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:18:36,189 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:18:36,192 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:18:36,197 httpcore.connection DEBUG close.started
18:18:36,198 httpcore.connection DEBUG close.complete
18:18:36,198 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:36,200 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d04ba90>
18:18:36,201 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:18:36,208 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d04bcd0>
18:18:36,208 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:36,209 httpcore.http11 DEBUG send_request_headers.complete
18:18:36,209 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:36,209 httpcore.http11 DEBUG send_request_body.complete
18:18:36,210 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:36,683 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:18:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e88dc8a99db9646865d3d891a9f64737'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341729c5f514ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:36,685 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:18:36,685 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:37,105 httpcore.http11 DEBUG receive_response_body.complete
18:18:37,105 httpcore.http11 DEBUG response_closed.started
18:18:37,106 httpcore.http11 DEBUG response_closed.complete
18:18:37,106 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:18:37,178 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:18:48,401 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:18:48,404 httpcore.connection DEBUG close.started
18:18:48,405 httpcore.connection DEBUG close.complete
18:18:48,405 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:48,407 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d20a010>
18:18:48,408 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:18:48,414 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d209e10>
18:18:48,414 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:48,415 httpcore.http11 DEBUG send_request_headers.complete
18:18:48,415 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:48,442 httpcore.http11 DEBUG send_request_body.complete
18:18:48,442 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:49,395 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:18:49 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'433'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2a513fe3508f52c949e81fab4837237e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834172e89f596ac7-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:49,397 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:18:49,398 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:49,399 httpcore.http11 DEBUG receive_response_body.complete
18:18:49,399 httpcore.http11 DEBUG response_closed.started
18:18:49,400 httpcore.http11 DEBUG response_closed.complete
18:18:49,400 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:18:49,401 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:18:49,418 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nYou should place the third candle in the bottom right corner of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:18:49,421 httpcore.connection DEBUG close.started
18:18:49,421 httpcore.connection DEBUG close.complete
18:18:49,421 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:18:49,424 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d03d3d0>
18:18:49,424 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42dfd0> server_hostname='api.openai.com' timeout=None
18:18:49,431 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d03f650>
18:18:49,431 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:49,432 httpcore.http11 DEBUG send_request_headers.complete
18:18:49,432 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:49,432 httpcore.http11 DEBUG send_request_body.complete
18:18:49,433 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:49,717 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:18:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'133'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0e9e0d3d99756bdfafcf1b8170c82428'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834172eeff424d1d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:49,720 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:18:49,720 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:49,721 httpcore.http11 DEBUG receive_response_body.complete
18:18:49,721 httpcore.http11 DEBUG response_closed.started
18:18:49,722 httpcore.http11 DEBUG response_closed.complete
18:18:49,722 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:18:49,737 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nYou should place the third candle in the bottom right corner of the cake.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:18:49,739 httpcore.connection DEBUG close.started
18:18:49,740 httpcore.connection DEBUG close.complete
18:18:49,740 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:18:49,751 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d203090>
18:18:49,752 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42e7b0> server_hostname='api.openai.com' timeout=None
18:18:49,757 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d200b10>
18:18:49,757 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:49,758 httpcore.http11 DEBUG send_request_headers.complete
18:18:49,758 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:49,759 httpcore.http11 DEBUG send_request_body.complete
18:18:49,759 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:50,578 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:18:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'675'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9e87719d69c1f7c1340e70db5869e146'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834172f0f9ef6aca-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:50,581 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:18:50,582 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:50,583 httpcore.http11 DEBUG receive_response_body.complete
18:18:50,583 httpcore.http11 DEBUG response_closed.started
18:18:50,584 httpcore.http11 DEBUG response_closed.complete
18:18:50,584 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:18:50,595 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:18:50,599 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:18:57,101 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:18:57,113 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:18:57,117 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:19:02,118 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:19:02,131 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:19:02,134 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:19:04,136 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:19:04,146 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:19:04,149 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:19:07,551 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:19:07,566 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:19:07,569 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:19:14,70 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:19:14,87 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:19:14,90 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:19:17,892 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:19:17,903 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:19:17,907 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:19:21,709 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:19:21,713 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:19:21,718 httpcore.connection DEBUG close.started
18:19:21,718 httpcore.connection DEBUG close.complete
18:19:21,719 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:19:21,749 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d1f4210>
18:19:21,750 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:19:21,757 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d053a50>
18:19:21,758 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:19:21,759 httpcore.http11 DEBUG send_request_headers.complete
18:19:21,759 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:19:21,760 httpcore.http11 DEBUG send_request_body.complete
18:19:21,760 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:19:22,416 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:19:22 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'528'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c186f8fbcecc2c484e33027ac03af06e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834173b8f9fe3ba0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:19:22,418 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:19:22,419 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:19:23,510 httpcore.http11 DEBUG receive_response_body.complete
18:19:23,510 httpcore.http11 DEBUG response_closed.started
18:19:23,511 httpcore.http11 DEBUG response_closed.complete
18:19:23,511 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:19:23,583 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:19:36,84 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo9.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:19:36,86 httpcore.connection DEBUG close.started
18:19:36,87 httpcore.connection DEBUG close.complete
18:19:36,87 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:19:36,89 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d058e50>
18:19:36,89 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:19:36,96 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d059a10>
18:19:36,96 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:19:36,97 httpcore.http11 DEBUG send_request_headers.complete
18:19:36,97 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:19:36,115 httpcore.http11 DEBUG send_request_body.complete
18:19:36,116 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:19:36,856 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:19:36 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'23'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3faee8e2d9ecf074a133d9055432b714'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834174129abb4d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:19:36,859 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:19:36,860 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:19:36,860 httpcore.http11 DEBUG receive_response_body.complete
18:19:36,861 httpcore.http11 DEBUG response_closed.started
18:19:36,861 httpcore.http11 DEBUG response_closed.complete
18:19:36,862 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:19:36,862 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:19:36,879 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nOh, move to the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:19:36,881 httpcore.connection DEBUG close.started
18:19:36,882 httpcore.connection DEBUG close.complete
18:19:36,882 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:19:36,884 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d051390>
18:19:36,884 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42dfd0> server_hostname='api.openai.com' timeout=None
18:19:36,891 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d052d10>
18:19:36,891 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:19:36,892 httpcore.http11 DEBUG send_request_headers.complete
18:19:36,892 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:19:36,892 httpcore.http11 DEBUG send_request_body.complete
18:19:36,892 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:19:37,393 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:19:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'407'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4de42337375c08688421a68dec1ebc85'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83417417999b6aca-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:19:37,396 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:19:37,397 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:19:37,398 httpcore.http11 DEBUG receive_response_body.complete
18:19:37,398 httpcore.http11 DEBUG response_closed.started
18:19:37,398 httpcore.http11 DEBUG response_closed.complete
18:19:37,398 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:19:37,414 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nOh, move to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:19:37,416 httpcore.connection DEBUG close.started
18:19:37,417 httpcore.connection DEBUG close.complete
18:19:37,417 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:19:37,419 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d05a750>
18:19:37,419 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42df40> server_hostname='api.openai.com' timeout=None
18:19:37,427 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d058790>
18:19:37,428 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:19:37,428 httpcore.http11 DEBUG send_request_headers.complete
18:19:37,428 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:19:37,429 httpcore.http11 DEBUG send_request_body.complete
18:19:37,429 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:19:37,628 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:19:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8312a6dcec3e04ec51bd811c3d7f700a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341741aedae4d17-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:19:37,630 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:19:37,631 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:19:37,631 httpcore.http11 DEBUG receive_response_body.complete
18:19:37,632 httpcore.http11 DEBUG response_closed.started
18:19:37,632 httpcore.http11 DEBUG response_closed.complete
18:19:37,632 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:19:37,641 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:19:37,644 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:19:41,46 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:19:41,49 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:19:41,54 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:19:41,54 httpcore.http11 DEBUG send_request_headers.complete
18:19:41,54 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:19:41,55 httpcore.http11 DEBUG send_request_body.complete
18:19:41,55 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:19:41,609 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:19:41 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'477'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a96442708d21f7c1ff80c138f027cc8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83417431994e4d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:19:41,611 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:19:41,612 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:19:42,741 httpcore.http11 DEBUG receive_response_body.complete
18:19:42,742 httpcore.http11 DEBUG response_closed.started
18:19:42,742 httpcore.http11 DEBUG response_closed.complete
18:19:42,743 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:19:42,818 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo10.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:19:55,289 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo10.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:19:55,292 httpcore.connection DEBUG close.started
18:19:55,292 httpcore.connection DEBUG close.complete
18:19:55,292 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:19:55,294 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d20a650>
18:19:55,294 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:19:55,302 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d20add0>
18:19:55,303 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:19:55,303 httpcore.http11 DEBUG send_request_headers.complete
18:19:55,303 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:19:55,326 httpcore.http11 DEBUG send_request_body.complete
18:19:55,327 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:19:56,60 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:19:56 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'341'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'30510ad627c17b74fc899c52c5e5885f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341748aacb13b99-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:19:56,62 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:19:56,62 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:19:56,63 httpcore.http11 DEBUG receive_response_body.complete
18:19:56,63 httpcore.http11 DEBUG response_closed.started
18:19:56,63 httpcore.http11 DEBUG response_closed.complete
18:19:56,64 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:19:56,64 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:19:56,78 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:19:56,80 httpcore.connection DEBUG close.started
18:19:56,81 httpcore.connection DEBUG close.complete
18:19:56,81 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:19:56,83 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d0605d0>
18:19:56,83 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42df40> server_hostname='api.openai.com' timeout=None
18:19:56,92 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d060550>
18:19:56,92 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:19:56,93 httpcore.http11 DEBUG send_request_headers.complete
18:19:56,93 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:19:56,93 httpcore.http11 DEBUG send_request_body.complete
18:19:56,93 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:19:56,304 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:19:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6c1b387d260cbc61c4a3f42fab6cb8b6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341748f9e434cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:19:56,306 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:19:56,307 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:19:56,308 httpcore.http11 DEBUG receive_response_body.complete
18:19:56,308 httpcore.http11 DEBUG response_closed.started
18:19:56,309 httpcore.http11 DEBUG response_closed.complete
18:19:56,309 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:19:56,321 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:19:56,325 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:19:59,727 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:19:59,731 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:19:59,736 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:19:59,737 httpcore.http11 DEBUG send_request_headers.complete
18:19:59,738 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:19:59,738 httpcore.http11 DEBUG send_request_body.complete
18:19:59,739 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:20:00,394 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:20:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'538'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ca409f21976e1a2f6e02edb4877e6903'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834174a65cd63b99-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:20:00,397 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:20:00,398 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:20:01,576 httpcore.http11 DEBUG receive_response_body.complete
18:20:01,577 httpcore.http11 DEBUG response_closed.started
18:20:01,577 httpcore.http11 DEBUG response_closed.complete
18:20:01,577 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:20:01,647 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Jo11.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:20:14,155 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Jo11.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:20:14,158 httpcore.connection DEBUG close.started
18:20:14,159 httpcore.connection DEBUG close.complete
18:20:14,159 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:20:14,162 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d062710>
18:20:14,163 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42de20> server_hostname='api.openai.com' timeout=5.0
18:20:14,170 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d062790>
18:20:14,170 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:20:14,171 httpcore.http11 DEBUG send_request_headers.complete
18:20:14,171 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:20:14,199 httpcore.http11 DEBUG send_request_body.complete
18:20:14,200 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:20:14,999 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:20:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'17c13194dfeca889afb01176ffe4fdc6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834175009f544d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:20:15,1 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:20:15,1 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:20:15,2 httpcore.http11 DEBUG receive_response_body.complete
18:20:15,2 httpcore.http11 DEBUG response_closed.started
18:20:15,3 httpcore.http11 DEBUG response_closed.complete
18:20:15,3 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:20:15,4 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:20:15,21 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:20:15,23 httpcore.connection DEBUG close.started
18:20:15,23 httpcore.connection DEBUG close.complete
18:20:15,23 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:20:15,26 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d237a50>
18:20:15,26 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fee4d42df40> server_hostname='api.openai.com' timeout=None
18:20:15,35 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fee4d236fd0>
18:20:15,36 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:20:15,37 httpcore.http11 DEBUG send_request_headers.complete
18:20:15,37 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:20:15,38 httpcore.http11 DEBUG send_request_body.complete
18:20:15,38 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:20:15,269 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:20:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'131'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'16f6534f47ed8be45d66699c31bf7d67'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83417505fd764cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:20:15,272 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:20:15,273 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:20:15,274 httpcore.http11 DEBUG receive_response_body.complete
18:20:15,275 httpcore.http11 DEBUG response_closed.started
18:20:15,275 httpcore.http11 DEBUG response_closed.complete
18:20:15,276 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:20:15,288 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:20:15,291 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:20:18,693 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:20:18,704 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:20:18,707 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:20:20,709 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:20:20,722 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:20:20,726 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:20:24,128 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:49:27,523 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:27,525 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,313 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,315 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,351 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,352 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,387 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,388 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,421 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,422 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,455 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,456 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,488 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,489 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,522 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,523 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,555 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,556 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,589 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, test_user. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:49:28,598 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:49:28,629 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81a9e5d0>
18:49:28,629 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:49:28,636 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81a9f1d0>
18:49:28,637 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:28,637 httpcore.http11 DEBUG send_request_headers.complete
18:49:28,637 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:28,638 httpcore.http11 DEBUG send_request_body.complete
18:49:28,638 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:29,115 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:49:29 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'398'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e240a3eed46adc01cde43999e8e0c1c4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=arfkGhltjmGWhfWZrcOSlP6w.Shgxef5RxnYkCQ6Vz0-1702338569-1-AaKoVWsEYYCzWkxWvdj1yytguMsiwYpDGKcSGMTc3JLdA2NMjf7LlnI0TOTbNVXWYzCIKhyAYUE9nBAtjwIamy8=; path=/; expires=Tue, 12-Dec-23 00:19:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=FOa_IRqzQYfZ9ey6leijMUYeodJMeinYy3FkYZPTvWk-1702338569112-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83419fd5fd253074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:29,117 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:49:29,117 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:29,973 httpcore.http11 DEBUG receive_response_body.complete
18:49:29,973 httpcore.http11 DEBUG response_closed.started
18:49:29,973 httpcore.http11 DEBUG response_closed.complete
18:49:29,974 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:49:30,41 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/test_user0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:49:43,576 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/test_user0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:49:43,582 httpcore.connection DEBUG close.started
18:49:43,582 httpcore.connection DEBUG close.complete
18:49:43,582 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:49:43,584 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81a9e590>
18:49:43,584 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:49:43,591 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81d726d0>
18:49:43,591 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:43,591 httpcore.http11 DEBUG send_request_headers.complete
18:49:43,592 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:43,618 httpcore.http11 DEBUG send_request_body.complete
18:49:43,618 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:44,616 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:49:44 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'47'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'493'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b609a708d84168c6cb2eaf4d3d2b55be'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a0337a9e4cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:44,617 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:49:44,617 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:44,617 httpcore.http11 DEBUG receive_response_body.complete
18:49:44,617 httpcore.http11 DEBUG response_closed.started
18:49:44,618 httpcore.http11 DEBUG response_closed.complete
18:49:44,618 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:49:44,618 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:49:44,628 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, test_user. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nUh, in the middle. Oops, there's nothing here.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:49:44,635 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:49:44,637 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818b15d0>
18:49:44,637 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7bf0> server_hostname='api.openai.com' timeout=None
18:49:44,643 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818c9c90>
18:49:44,643 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:44,644 httpcore.http11 DEBUG send_request_headers.complete
18:49:44,644 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:44,644 httpcore.http11 DEBUG send_request_body.complete
18:49:44,644 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:44,865 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:49:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'126'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'bb16aef467172c5d859c0401e0a8c722'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=w2o.vR.45LnGi0SNiOkxjEen0QzfRINLslZMRLebpcA-1702338584-1-AfbhZZHRfbv9fkCUQ4Co/wPeCSS3i1aX9W62hff4OK6DihCqAtBhh0pWSnjV1y8eOM3r6GlEcsyHgxN0dFpcObA=; path=/; expires=Tue, 12-Dec-23 00:19:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=f5XWLsxKOHalkq1JIVmF_2DdV2TEteL79jDl2BKnSGA-1702338584863-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a03a0cde3ba0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:44,866 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:49:44,867 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:44,867 httpcore.http11 DEBUG receive_response_body.complete
18:49:44,867 httpcore.http11 DEBUG response_closed.started
18:49:44,867 httpcore.http11 DEBUG response_closed.complete
18:49:44,868 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:44,878 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nHi, test_user. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nUh, in the middle. Oops, there's nothing here.\n\n'''\nRedirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:49:44,885 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:49:44,887 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818de610>
18:49:44,887 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81b74290> server_hostname='api.openai.com' timeout=None
18:49:44,893 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818de690>
18:49:44,893 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:44,894 httpcore.http11 DEBUG send_request_headers.complete
18:49:44,894 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:44,894 httpcore.http11 DEBUG send_request_body.complete
18:49:44,894 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:45,786 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:49:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'789'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5476ef0c43465527cc8a2f1385c0f2eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=J7DfH4CEpnlWC2o0zQu0CNp6FpD3uAXmdSA3sh1X37c-1702338585-1-AbK0MeAgMWnpqXbzfCSNqhVzLuQV/cefSibupF63wEbwo4yYqsC+r4n23RrelwsPBqKA8pk2UA7lN0G1nw4DL2U=; path=/; expires=Tue, 12-Dec-23 00:19:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=TnIIeDUyv3BjMuDoG9BWDbv5YM03UgVeRgDoh99PY2E-1702338585784-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a03b9d353045-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:45,788 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:49:45,788 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:45,788 httpcore.http11 DEBUG receive_response_body.complete
18:49:45,788 httpcore.http11 DEBUG response_closed.started
18:49:45,789 httpcore.http11 DEBUG response_closed.complete
18:49:45,789 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:45,792 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "\nNo problem! Let's try again. Where would you like me to place the first candle? Please point to the spot on the cake where you would like me to place it. I'm ready when you are!", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:49:45,794 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:45,794 httpcore.http11 DEBUG send_request_headers.complete
18:49:45,795 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:45,795 httpcore.http11 DEBUG send_request_body.complete
18:49:45,795 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:46,335 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:49:46 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'470'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f85194fcc1ee82e9fa1b4c706c93a9e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a0413c764cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:46,335 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:49:46,336 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:48,157 httpcore.http11 DEBUG receive_response_body.complete
18:49:48,158 httpcore.http11 DEBUG response_closed.started
18:49:48,158 httpcore.http11 DEBUG response_closed.complete
18:49:48,158 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:49:48,229 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/test_user1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:50:07,338 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/test_user1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:50:07,339 httpcore.connection DEBUG close.started
18:50:07,340 httpcore.connection DEBUG close.complete
18:50:07,340 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:07,342 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81a9fdd0>
18:50:07,342 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:50:07,350 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81a9f950>
18:50:07,350 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:07,350 httpcore.http11 DEBUG send_request_headers.complete
18:50:07,350 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:07,387 httpcore.http11 DEBUG send_request_body.complete
18:50:07,387 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:08,572 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:50:08 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'745'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f563d94e7ec6c6e986154809cefb28b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a0c7fad74cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:08,572 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:50:08,572 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:08,573 httpcore.http11 DEBUG receive_response_body.complete
18:50:08,573 httpcore.http11 DEBUG response_closed.started
18:50:08,573 httpcore.http11 DEBUG response_closed.complete
18:50:08,573 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:50:08,573 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:50:08,577 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\n\nNo problem! Let's try again. Where would you like me to place the first candle? Please point to the spot on the cake where you would like me to place it. I'm ready when you are!\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:50:08,578 httpcore.connection DEBUG close.started
18:50:08,579 httpcore.connection DEBUG close.complete
18:50:08,579 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:50:08,581 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818c8f90>
18:50:08,581 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7bf0> server_hostname='api.openai.com' timeout=None
18:50:08,587 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818c9b90>
18:50:08,587 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:08,588 httpcore.http11 DEBUG send_request_headers.complete
18:50:08,588 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:08,588 httpcore.http11 DEBUG send_request_body.complete
18:50:08,588 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:08,753 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:50:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'73'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e39abe09d5c8960c57ea502efcc8be64'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a0cfae753b82-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:08,754 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:50:08,754 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:08,755 httpcore.http11 DEBUG receive_response_body.complete
18:50:08,755 httpcore.http11 DEBUG response_closed.started
18:50:08,755 httpcore.http11 DEBUG response_closed.complete
18:50:08,755 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:50:08,765 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\n\nNo problem! Let's try again. Where would you like me to place the first candle? Please point to the spot on the cake where you would like me to place it. I'm ready when you are!\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:50:08,772 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:50:08,775 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818e6e50>
18:50:08,775 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81b74680> server_hostname='api.openai.com' timeout=None
18:50:08,782 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818e6d10>
18:50:08,782 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:08,783 httpcore.http11 DEBUG send_request_headers.complete
18:50:08,783 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:08,783 httpcore.http11 DEBUG send_request_body.complete
18:50:08,783 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:09,698 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:50:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'813'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3f7e28cda43937c4cdbba283cfaf7be3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Y57WeJ178.5z3QJigO5koffcY_BjxmZ7_qRkeXh7uxA-1702338609-1-AanxoUuYd77Y/HeoQqvzrcKs+ShI9jGdjhBQEjWNknS0/W/m7wtiyngelwInwOEIEs2AIxg2EiSlrQX1eAXG7tQ=; path=/; expires=Tue, 12-Dec-23 00:20:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=His4b2g5N.RjOpmO7EtpvvVRbING.qrkyTza6OPhnK0-1702338609696-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a0d0e88b4ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:09,699 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:50:09,700 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:09,700 httpcore.http11 DEBUG receive_response_body.complete
18:50:09,700 httpcore.http11 DEBUG response_closed.started
18:50:09,701 httpcore.http11 DEBUG response_closed.complete
18:50:09,701 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:50:09,706 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:09,708 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:16,211 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:16,214 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:16,218 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:21,219 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:21,222 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:21,225 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:23,226 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:23,228 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:23,230 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:26,638 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:26,640 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:26,643 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:33,144 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:33,147 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:33,150 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:37,351 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:37,353 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:37,356 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:41,557 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:41,558 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:50:41,560 httpcore.connection DEBUG close.started
18:50:41,560 httpcore.connection DEBUG close.complete
18:50:41,561 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:41,601 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81904f90>
18:50:41,602 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:50:41,607 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c819050d0>
18:50:41,607 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:41,607 httpcore.http11 DEBUG send_request_headers.complete
18:50:41,607 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:41,607 httpcore.http11 DEBUG send_request_body.complete
18:50:41,608 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:42,293 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:50:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'559'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3c216f27633c8e93603c303f90257f5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a19e0c124cef-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:42,294 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:50:42,294 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:43,372 httpcore.http11 DEBUG receive_response_body.complete
18:50:43,372 httpcore.http11 DEBUG response_closed.started
18:50:43,372 httpcore.http11 DEBUG response_closed.complete
18:50:43,372 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:50:43,442 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/test_user2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:50:55,422 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/test_user2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:50:55,423 httpcore.connection DEBUG close.started
18:50:55,423 httpcore.connection DEBUG close.complete
18:50:55,424 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:55,426 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818e7250>
18:50:55,426 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:50:55,430 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818e7050>
18:50:55,430 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:55,431 httpcore.http11 DEBUG send_request_headers.complete
18:50:55,431 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:55,448 httpcore.http11 DEBUG send_request_body.complete
18:50:55,448 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:56,590 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:50:56 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'391'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2f4c1359211a0b6fd4dc6ee2dd9565ba'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a1f478524d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:56,590 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:50:56,590 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:56,591 httpcore.http11 DEBUG receive_response_body.complete
18:50:56,591 httpcore.http11 DEBUG response_closed.started
18:50:56,591 httpcore.http11 DEBUG response_closed.complete
18:50:56,591 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:50:56,591 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:50:56,599 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:50:56,600 httpcore.connection DEBUG close.started
18:50:56,600 httpcore.connection DEBUG close.complete
18:50:56,600 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:50:56,602 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81a9da50>
18:50:56,602 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7bf0> server_hostname='api.openai.com' timeout=None
18:50:56,612 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818c9b90>
18:50:56,612 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:56,612 httpcore.http11 DEBUG send_request_headers.complete
18:50:56,613 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:56,613 httpcore.http11 DEBUG send_request_body.complete
18:50:56,613 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:56,814 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:50:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'059b83457f6d61b11a5789977f2b9be2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a1fbd9324cf0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:56,815 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:50:56,815 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:56,815 httpcore.http11 DEBUG receive_response_body.complete
18:50:56,815 httpcore.http11 DEBUG response_closed.started
18:50:56,815 httpcore.http11 DEBUG response_closed.complete
18:50:56,816 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:50:56,823 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:50:56,829 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:50:56,832 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c819050d0>
18:50:56,832 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7d10> server_hostname='api.openai.com' timeout=None
18:50:56,838 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c819063d0>
18:50:56,838 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:56,838 httpcore.http11 DEBUG send_request_headers.complete
18:50:56,838 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:56,838 httpcore.http11 DEBUG send_request_body.complete
18:50:56,839 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:57,75 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:50:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'136'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8638435d7753dc5f85432a7346019397'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LOHkjsinnMWyVlY9FWrsYA196CN0tdr7BzM6VGQatIQ-1702338657-1-AVWTL9NXZxcYRQsPcTj5s6Wo4qDbibNDrajEeV8zfWgej5BbGJRo7EHP4n+HrwcK7cblA2+WHZrQkJyFrW7l6pU=; path=/; expires=Tue, 12-Dec-23 00:20:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=eRwpssnGUEz.z0y7gpxH.hBQf1fYAEroK7PIdYmre3I-1702338657072-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a1fd3fee4d0d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:57,76 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:50:57,76 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:57,76 httpcore.http11 DEBUG receive_response_body.complete
18:50:57,77 httpcore.http11 DEBUG response_closed.started
18:50:57,77 httpcore.http11 DEBUG response_closed.complete
18:50:57,77 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:50:57,82 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:57,85 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:00,486 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:00,489 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:51:00,492 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:02,493 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:02,496 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:51:02,497 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:05,898 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:05,900 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:51:05,901 httpcore.connection DEBUG close.started
18:51:05,901 httpcore.connection DEBUG close.complete
18:51:05,902 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:05,904 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81906550>
18:51:05,905 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:51:05,911 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81907550>
18:51:05,911 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:05,911 httpcore.http11 DEBUG send_request_headers.complete
18:51:05,912 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:05,912 httpcore.http11 DEBUG send_request_body.complete
18:51:05,912 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:06,368 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:51:06 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3473ac5617d89209bfa6babb2d0aa2bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a235f95f4ce2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:06,368 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:51:06,369 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:06,776 httpcore.http11 DEBUG receive_response_body.complete
18:51:06,776 httpcore.http11 DEBUG response_closed.started
18:51:06,776 httpcore.http11 DEBUG response_closed.complete
18:51:06,776 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:51:06,846 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/test_user3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:51:17,774 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/test_user3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:51:17,776 httpcore.connection DEBUG close.started
18:51:17,776 httpcore.connection DEBUG close.complete
18:51:17,776 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:17,779 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81909190>
18:51:17,779 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:51:17,787 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81909150>
18:51:17,787 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:17,787 httpcore.http11 DEBUG send_request_headers.complete
18:51:17,787 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:17,815 httpcore.http11 DEBUG send_request_body.complete
18:51:17,815 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:18,989 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:51:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'32'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'417'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c93ff7a2bb49fbfd5e902d3ba410bcad'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a2802af54cee-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:18,990 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:51:18,990 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:18,990 httpcore.http11 DEBUG receive_response_body.complete
18:51:18,990 httpcore.http11 DEBUG response_closed.started
18:51:18,990 httpcore.http11 DEBUG response_closed.complete
18:51:18,990 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:51:18,990 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:51:18,994 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the left of the first candle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:18,996 httpcore.connection DEBUG close.started
18:51:18,996 httpcore.connection DEBUG close.complete
18:51:18,996 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:18,998 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81907690>
18:51:18,998 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7bf0> server_hostname='api.openai.com' timeout=None
18:51:19,4 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81907810>
18:51:19,5 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:19,5 httpcore.http11 DEBUG send_request_headers.complete
18:51:19,5 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:19,5 httpcore.http11 DEBUG send_request_body.complete
18:51:19,5 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:19,201 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:51:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'46f36a3942c4eb5bf4dca1e13fbf979a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a287ce264cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:19,202 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:19,202 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:19,202 httpcore.http11 DEBUG receive_response_body.complete
18:51:19,202 httpcore.http11 DEBUG response_closed.started
18:51:19,202 httpcore.http11 DEBUG response_closed.complete
18:51:19,202 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:51:19,212 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the left of the first candle\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:19,213 httpcore.connection DEBUG close.started
18:51:19,213 httpcore.connection DEBUG close.complete
18:51:19,213 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:19,216 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81a9c650>
18:51:19,216 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81b74680> server_hostname='api.openai.com' timeout=None
18:51:19,222 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81a9d990>
18:51:19,222 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:19,222 httpcore.http11 DEBUG send_request_headers.complete
18:51:19,222 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:19,222 httpcore.http11 DEBUG send_request_body.complete
18:51:19,222 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:19,578 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:51:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'259'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'57c78304ae39cde86b4538fdafedff35'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a2892be84d06-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:19,578 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:19,579 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:19,579 httpcore.http11 DEBUG receive_response_body.complete
18:51:19,579 httpcore.http11 DEBUG response_closed.started
18:51:19,579 httpcore.http11 DEBUG response_closed.complete
18:51:19,579 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:51:19,584 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:51:19,587 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:26,88 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:26,91 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:51:26,94 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:31,95 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:31,97 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:51:31,99 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:33,100 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:33,102 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:51:33,105 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:36,506 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:36,508 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:51:36,511 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:43,12 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:43,16 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:51:43,20 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:46,21 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:46,23 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:51:46,26 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:51:51,27 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:51:51,28 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:51:51,30 httpcore.connection DEBUG close.started
18:51:51,30 httpcore.connection DEBUG close.complete
18:51:51,31 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:51,59 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81906890>
18:51:51,60 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:51:51,67 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81907090>
18:51:51,67 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:51,68 httpcore.http11 DEBUG send_request_headers.complete
18:51:51,68 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:51,68 httpcore.http11 DEBUG send_request_body.complete
18:51:51,68 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:51,599 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:51:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'26bedc315094c3eb60d7b4d2157c4d69'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a35029e13031-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:51,599 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:51:51,600 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:52,574 httpcore.http11 DEBUG receive_response_body.complete
18:51:52,574 httpcore.http11 DEBUG response_closed.started
18:51:52,574 httpcore.http11 DEBUG response_closed.complete
18:51:52,575 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:51:52,642 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/test_user4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:52:05,116 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/test_user4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:52:05,117 httpcore.connection DEBUG close.started
18:52:05,118 httpcore.connection DEBUG close.complete
18:52:05,118 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:52:05,120 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818e6590>
18:52:05,121 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:52:05,127 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818e5a90>
18:52:05,128 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:05,128 httpcore.http11 DEBUG send_request_headers.complete
18:52:05,128 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:05,149 httpcore.http11 DEBUG send_request_body.complete
18:52:05,149 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:06,37 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:06 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'450'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a8cf5d130ac8dd04105c12bbcee8bd77'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a3a80b1d4cfe-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:06,38 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:52:06,38 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:06,38 httpcore.http11 DEBUG receive_response_body.complete
18:52:06,38 httpcore.http11 DEBUG response_closed.started
18:52:06,38 httpcore.http11 DEBUG response_closed.complete
18:52:06,39 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:52:06,39 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:52:06,44 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes. Obviously, yes, so it gets through that quickly.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:06,44 httpcore.connection DEBUG close.started
18:52:06,45 httpcore.connection DEBUG close.complete
18:52:06,45 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:06,47 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c8190bfd0>
18:52:06,47 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7bf0> server_hostname='api.openai.com' timeout=None
18:52:06,52 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c8190bf50>
18:52:06,53 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:06,53 httpcore.http11 DEBUG send_request_headers.complete
18:52:06,53 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:06,53 httpcore.http11 DEBUG send_request_body.complete
18:52:06,53 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:06,302 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'124'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0dfe0364643653ce30e5d2a785c11f58'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a3addb624cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:06,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:06,303 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:06,304 httpcore.http11 DEBUG receive_response_body.complete
18:52:06,304 httpcore.http11 DEBUG response_closed.started
18:52:06,304 httpcore.http11 DEBUG response_closed.complete
18:52:06,304 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:06,314 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes. Obviously, yes, so it gets through that quickly.\n\n'''\nRedirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:06,315 httpcore.connection DEBUG close.started
18:52:06,315 httpcore.connection DEBUG close.complete
18:52:06,315 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:06,317 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818dd990>
18:52:06,317 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81b74290> server_hostname='api.openai.com' timeout=None
18:52:06,328 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818dc090>
18:52:06,328 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:06,328 httpcore.http11 DEBUG send_request_headers.complete
18:52:06,329 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:06,329 httpcore.http11 DEBUG send_request_body.complete
18:52:06,329 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:07,526 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1059'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'918615e52e1b303fdeb087adda2d1553'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a3af8ce44ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:07,527 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:07,527 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:07,527 httpcore.http11 DEBUG receive_response_body.complete
18:52:07,528 httpcore.http11 DEBUG response_closed.started
18:52:07,528 httpcore.http11 DEBUG response_closed.complete
18:52:07,528 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:07,532 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "\nI understand that this is a good location. Let's continue with the task of placing the candles. Please tell me which direction you would like me to move the candle in. You can say either left, right, up, or down.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:52:07,533 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:07,533 httpcore.http11 DEBUG send_request_headers.complete
18:52:07,533 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:07,534 httpcore.http11 DEBUG send_request_body.complete
18:52:07,534 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:08,161 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:08 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'488'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'39b859862cca22375af258cced6dab6e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a3b71a1f4cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:08,162 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:52:08,162 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:10,434 httpcore.http11 DEBUG receive_response_body.complete
18:52:10,434 httpcore.http11 DEBUG response_closed.started
18:52:10,435 httpcore.http11 DEBUG response_closed.complete
18:52:10,435 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:52:10,497 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/test_user5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:52:29,359 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/test_user5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:52:29,360 httpcore.connection DEBUG close.started
18:52:29,360 httpcore.connection DEBUG close.complete
18:52:29,361 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:52:29,363 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818e7cd0>
18:52:29,363 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:52:29,371 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c818e6f90>
18:52:29,371 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:29,372 httpcore.http11 DEBUG send_request_headers.complete
18:52:29,372 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:29,391 httpcore.http11 DEBUG send_request_body.complete
18:52:29,391 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:30,361 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'17'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'485'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5f939d38a8c0265fbd65e1f4f87713eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a43f9f573b82-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:30,362 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:52:30,362 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:30,362 httpcore.http11 DEBUG receive_response_body.complete
18:52:30,362 httpcore.http11 DEBUG response_closed.started
18:52:30,363 httpcore.http11 DEBUG response_closed.complete
18:52:30,363 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:52:30,363 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:52:30,369 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\n\nI understand that this is a good location. Let's continue with the task of placing the candles. Please tell me which direction you would like me to move the candle in. You can say either left, right, up, or down.\n'''\nAnd the human answered\n'''\nhear that uh yes\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:30,370 httpcore.connection DEBUG close.started
18:52:30,370 httpcore.connection DEBUG close.complete
18:52:30,371 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:30,373 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c8190b190>
18:52:30,373 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7bf0> server_hostname='api.openai.com' timeout=None
18:52:30,380 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c819098d0>
18:52:30,381 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:30,381 httpcore.http11 DEBUG send_request_headers.complete
18:52:30,381 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:30,382 httpcore.http11 DEBUG send_request_body.complete
18:52:30,382 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:30,607 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'129'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd7e82b83f95a246ed80a2551d5f7e002'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a445ebc24cc3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:30,608 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:30,608 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:30,608 httpcore.http11 DEBUG receive_response_body.complete
18:52:30,608 httpcore.http11 DEBUG response_closed.started
18:52:30,609 httpcore.http11 DEBUG response_closed.complete
18:52:30,609 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:30,616 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\n\nI understand that this is a good location. Let's continue with the task of placing the candles. Please tell me which direction you would like me to move the candle in. You can say either left, right, up, or down.\n'''\nAnd the human answered\n'''\nhear that uh yes\n\n'''\nRedirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:30,617 httpcore.connection DEBUG close.started
18:52:30,618 httpcore.connection DEBUG close.complete
18:52:30,618 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:30,620 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81906510>
18:52:30,620 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81b74290> server_hostname='api.openai.com' timeout=None
18:52:30,628 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81905d50>
18:52:30,629 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:30,629 httpcore.http11 DEBUG send_request_headers.complete
18:52:30,629 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:30,629 httpcore.http11 DEBUG send_request_body.complete
18:52:30,630 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:31,650 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'923'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6274899482b65e538cf2e5c409b3a08e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a44769c33ba0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:31,650 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:31,651 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:31,651 httpcore.http11 DEBUG receive_response_body.complete
18:52:31,651 httpcore.http11 DEBUG response_closed.started
18:52:31,652 httpcore.http11 DEBUG response_closed.complete
18:52:31,652 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:31,655 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I'm sorry, I didn't understand your response. Could you please tell me which direction you would like me to move the candle in? You can say either left, right, up, or down. That way, I can help you place the candles on the cake.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:52:31,656 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:31,656 httpcore.http11 DEBUG send_request_headers.complete
18:52:31,657 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:31,657 httpcore.http11 DEBUG send_request_body.complete
18:52:31,657 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:32,409 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:32 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'647'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0dce5d83ec620a4289e420f3f23f729f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a44ddd493b82-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:32,410 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:52:32,410 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:34,343 httpcore.http11 DEBUG receive_response_body.complete
18:52:34,343 httpcore.http11 DEBUG response_closed.started
18:52:34,343 httpcore.http11 DEBUG response_closed.complete
18:52:34,344 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:52:34,411 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/test_user6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:52:53,396 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/test_user6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:52:53,398 httpcore.connection DEBUG close.started
18:52:53,398 httpcore.connection DEBUG close.complete
18:52:53,398 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:52:53,428 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c8191c690>
18:52:53,428 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7c80> server_hostname='api.openai.com' timeout=5.0
18:52:53,435 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c8191c210>
18:52:53,435 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:53,435 httpcore.http11 DEBUG send_request_headers.complete
18:52:53,435 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:53,454 httpcore.http11 DEBUG send_request_body.complete
18:52:53,455 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:54,510 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:54 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'692'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'068df38bc57b02636d1eaf58a227d4c6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a4d5fbaa4ce4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:54,511 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:52:54,511 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:54,511 httpcore.http11 DEBUG receive_response_body.complete
18:52:54,511 httpcore.http11 DEBUG response_closed.started
18:52:54,512 httpcore.http11 DEBUG response_closed.complete
18:52:54,512 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:52:54,512 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:52:54,519 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI'm sorry, I didn't understand your response. Could you please tell me which direction you would like me to move the candle in? You can say either left, right, up, or down. That way, I can help you place the candles on the cake.\n'''\nAnd the human answered\n'''\ndown you know yeah\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:54,520 httpcore.connection DEBUG close.started
18:52:54,520 httpcore.connection DEBUG close.complete
18:52:54,520 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:54,522 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81908e50>
18:52:54,523 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81ca7bf0> server_hostname='api.openai.com' timeout=None
18:52:54,528 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81908710>
18:52:54,528 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:54,528 httpcore.http11 DEBUG send_request_headers.complete
18:52:54,528 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:54,528 httpcore.http11 DEBUG send_request_body.complete
18:52:54,529 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:54,737 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9c1066e60b3c631e91493c1a4370f96c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a4dcca973b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:54,738 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:54,738 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:54,738 httpcore.http11 DEBUG receive_response_body.complete
18:52:54,738 httpcore.http11 DEBUG response_closed.started
18:52:54,739 httpcore.http11 DEBUG response_closed.complete
18:52:54,739 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:54,744 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nI'm sorry, I didn't understand your response. Could you please tell me which direction you would like me to move the candle in? You can say either left, right, up, or down. That way, I can help you place the candles on the cake.\n'''\nAnd the human answered\n'''\ndown you know yeah\n\n'''\nRedirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:54,745 httpcore.connection DEBUG close.started
18:52:54,745 httpcore.connection DEBUG close.complete
18:52:54,745 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:54,748 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81906d90>
18:52:54,748 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0c81b74290> server_hostname='api.openai.com' timeout=None
18:52:54,757 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0c81905b10>
18:52:54,757 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:54,758 httpcore.http11 DEBUG send_request_headers.complete
18:52:54,758 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:54,758 httpcore.http11 DEBUG send_request_body.complete
18:52:54,758 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:55,991 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 23:52:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1135'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0907693464b7065692ffb6086657d718'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8341a4de3a5c4ce2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:55,992 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:55,992 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:55,993 httpcore.http11 DEBUG receive_response_body.complete
18:52:55,993 httpcore.http11 DEBUG response_closed.started
18:52:55,993 httpcore.http11 DEBUG response_closed.complete
18:52:55,993 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:55,996 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I'm sorry, I didn't understand what you said. Could you please tell me which direction you would like me to move the candle in? You can say either left, right, up, or down. That way, I can help you place the candles on the cake.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:52:55,998 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:55,998 httpcore.http11 DEBUG send_request_headers.complete
18:52:55,999 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:55,999 httpcore.http11 DEBUG send_request_body.complete
18:52:55,999 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:56,327 httpcore.http11 DEBUG receive_response_headers.failed exception=KeyboardInterrupt()
18:52:56,328 httpcore.http11 DEBUG response_closed.started
18:52:56,328 httpcore.http11 DEBUG response_closed.complete
12:40:26,881 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
12:40:26,885 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
12:40:27,708 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
12:40:27,709 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
12:40:27,752 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
12:40:27,753 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
12:40:27,800 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
12:40:27,801 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
12:40:27,841 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
12:40:27,842 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
12:40:27,890 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
12:40:27,891 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
12:40:27,933 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
12:40:27,934 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
12:40:27,981 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
12:40:27,982 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
12:40:28,26 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
12:40:28,27 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
12:41:38,683 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Emeka. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:41:38,708 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:41:38,740 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02628cbd90>
12:41:38,741 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:41:38,748 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026264f790>
12:41:38,750 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:41:38,751 httpcore.http11 DEBUG send_request_headers.complete
12:41:38,751 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:41:38,751 httpcore.http11 DEBUG send_request_body.complete
12:41:38,752 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:41:39,471 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:41:39 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'526'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'23a11a75c8bad5191ec7fb16ea4e7e5f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WdwxZO_0puv1GP3h4xFnldBm_VimkUyRljXynELFJj8-1702402899-1-Adud6wXmkFiNl+w7p+dpiOqB3j1DIBDRLg/9Fx5gf7CdZYhJ3IpwoC/oSijJX5pNid+wREOEwPPrpQ8EMMkAUyQ=; path=/; expires=Tue, 12-Dec-23 18:11:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=xuMIS7UeNp4OcGgXGgbkCQj22A7JbSfw263OjTh6ukA-1702402899463-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c2653fbe3021-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:41:39,479 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:41:39,480 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:41:40,194 httpcore.http11 DEBUG receive_response_body.complete
12:41:40,194 httpcore.http11 DEBUG response_closed.started
12:41:40,195 httpcore.http11 DEBUG response_closed.complete
12:41:40,195 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:41:40,280 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:41:53,625 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:41:53,636 httpcore.connection DEBUG close.started
12:41:53,637 httpcore.connection DEBUG close.complete
12:41:53,637 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:41:53,640 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026264f790>
12:41:53,640 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:41:53,646 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026264f150>
12:41:53,647 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:41:53,648 httpcore.http11 DEBUG send_request_headers.complete
12:41:53,648 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:41:53,686 httpcore.http11 DEBUG send_request_body.complete
12:41:53,687 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:41:54,652 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:41:54 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'416'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'80100a31d68e24f3471ab74b4faebaff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c2c2490c4ce0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:41:54,657 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:41:54,658 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:41:54,661 httpcore.http11 DEBUG receive_response_body.complete
12:41:54,661 httpcore.http11 DEBUG response_closed.started
12:41:54,662 httpcore.http11 DEBUG response_closed.complete
12:41:54,662 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:41:54,663 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:41:54,699 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Emeka. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPlace the first candle a few inches to the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:41:54,710 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:41:54,713 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624aca90>
12:41:54,713 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9fd0> server_hostname='api.openai.com' timeout=None
12:41:54,718 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624aca50>
12:41:54,719 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:41:54,720 httpcore.http11 DEBUG send_request_headers.complete
12:41:54,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:41:54,721 httpcore.http11 DEBUG send_request_body.complete
12:41:54,721 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:41:54,980 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:41:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'579a019f1414b09e0e01c35931b20ab8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FDh_LK3jEp5Pdkn3Wqljbm2x619YpZlOdrwFD8kVHdw-1702402914-1-AY6Wb7xSOVLvEleThXmUh6lu04SeB4xAoQ4yjxPvjH5a40bwrBZuJJ7EkJl9nyEJFZusGSMDc/x6l7ZxLDhYaGk=; path=/; expires=Tue, 12-Dec-23 18:11:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=MrPZwUV1IBHxlfHs6d.kNzX9J5mOqQ3fh1xpoWuoa90-1702402914975-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c2c90e8d3b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:41:54,988 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:41:54,989 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:41:54,991 httpcore.http11 DEBUG receive_response_body.complete
12:41:54,991 httpcore.http11 DEBUG response_closed.started
12:41:54,992 httpcore.http11 DEBUG response_closed.complete
12:41:54,993 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:41:55,28 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nHi, Emeka. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPlace the first candle a few inches to the right.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:41:55,40 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:41:55,43 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ad590>
12:41:55,43 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626da7b0> server_hostname='api.openai.com' timeout=None
12:41:55,49 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ae750>
12:41:55,50 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:41:55,51 httpcore.http11 DEBUG send_request_headers.complete
12:41:55,51 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:41:55,52 httpcore.http11 DEBUG send_request_body.complete
12:41:55,52 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:41:55,634 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:41:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'89cd36312398c8dcf6bd5cf32951f19d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=gIsonj.OEg3oBb.a9d_UnZ2no_4xlUWDWO99qQ4L6CI-1702402915-1-AQZQZio/0Y+/BC7Lp/T7WoJTG/h3DEnOTMAM5mEGVuisyI17IrAmt/ebakgymXNB3J8krGWxvp9NuUaeG/bOfGI=; path=/; expires=Tue, 12-Dec-23 18:11:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=8cnt5RFHs55l6jLdTx.oRi9vC2V.HpIlqXruWD.6eYU-1702402915629-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c2cb1e343b7c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:41:55,642 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:41:55,642 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:41:55,643 httpcore.http11 DEBUG receive_response_body.complete
12:41:55,644 httpcore.http11 DEBUG response_closed.started
12:41:55,644 httpcore.http11 DEBUG response_closed.complete
12:41:55,644 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:41:55,664 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:41:55,670 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:42:02,178 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:42:02,193 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:42:02,207 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:42:07,209 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:42:07,227 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:42:07,231 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:42:09,233 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:42:09,258 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:42:09,264 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:42:12,666 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:42:12,682 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:42:12,685 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:42:19,187 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:42:19,208 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:42:19,213 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:42:22,216 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:42:22,236 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:42:22,243 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:42:26,446 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:42:26,454 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:42:26,460 httpcore.connection DEBUG close.started
12:42:26,460 httpcore.connection DEBUG close.complete
12:42:26,460 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:42:26,463 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262645610>
12:42:26,463 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:42:26,473 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624c1550>
12:42:26,473 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:42:26,475 httpcore.http11 DEBUG send_request_headers.complete
12:42:26,475 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:42:26,476 httpcore.http11 DEBUG send_request_body.complete
12:42:26,476 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:42:27,165 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:42:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'569'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'98e6f7a2b93055d267f36bd91877ee73'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c38f79064cf8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:42:27,170 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:42:27,170 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:42:28,284 httpcore.http11 DEBUG receive_response_body.complete
12:42:28,285 httpcore.http11 DEBUG response_closed.started
12:42:28,286 httpcore.http11 DEBUG response_closed.complete
12:42:28,287 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:42:28,356 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:42:40,782 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:42:40,789 httpcore.connection DEBUG close.started
12:42:40,789 httpcore.connection DEBUG close.complete
12:42:40,790 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:42:40,819 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624e2110>
12:42:40,820 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:42:40,827 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624e1610>
12:42:40,828 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:42:40,830 httpcore.http11 DEBUG send_request_headers.complete
12:42:40,831 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:42:40,859 httpcore.http11 DEBUG send_request_body.complete
12:42:40,859 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:42:41,657 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:42:41 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'23'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'360'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f56c4b72414a266196489b4d256d6f32'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c3e938ca4d08-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:42:41,662 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:42:41,664 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:42:41,665 httpcore.http11 DEBUG receive_response_body.complete
12:42:41,666 httpcore.http11 DEBUG response_closed.started
12:42:41,667 httpcore.http11 DEBUG response_closed.complete
12:42:41,668 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:42:41,669 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:42:41,698 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nNo, move to the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:42:41,702 httpcore.connection DEBUG close.started
12:42:41,702 httpcore.connection DEBUG close.complete
12:42:41,702 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:42:41,705 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624aca50>
12:42:41,706 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9fd0> server_hostname='api.openai.com' timeout=None
12:42:41,711 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ac350>
12:42:41,711 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:42:41,712 httpcore.http11 DEBUG send_request_headers.complete
12:42:41,712 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:42:41,713 httpcore.http11 DEBUG send_request_body.complete
12:42:41,713 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:42:41,936 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:42:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'132'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b078701a0ecb84578e7160f8c4d86df3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c3eebab34cda-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:42:41,940 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:42:41,940 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:42:41,942 httpcore.http11 DEBUG receive_response_body.complete
12:42:41,942 httpcore.http11 DEBUG response_closed.started
12:42:41,942 httpcore.http11 DEBUG response_closed.complete
12:42:41,943 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:42:41,976 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nNo, move to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:42:41,992 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:42:41,995 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624e19d0>
12:42:41,996 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:42:42,3 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624e1c50>
12:42:42,4 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:42:42,5 httpcore.http11 DEBUG send_request_headers.complete
12:42:42,5 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:42:42,6 httpcore.http11 DEBUG send_request_body.complete
12:42:42,6 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:42:42,265 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:42:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'131'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'45c08aa6e4bcabfac5c21d9ecca63623'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EypWO0YLwza2.LKEzYjZWralAfKKerkKmqkXsoad3.w-1702402962-1-Ae7NcTDt6WZ+MrZfktQNNHn25t+KXt3A8I0WUNFRd7MDKZquAuvBz97Fwy2ZxU60/y5ixL5tLhLkj3gPPrymnT0=; path=/; expires=Tue, 12-Dec-23 18:12:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=N_MIniLaxr.mLOCDr5ZQmIVKj.DOX8BPEU3CsHaBlxE-1702402962261-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c3f08b534d07-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:42:42,269 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:42:42,270 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:42:42,271 httpcore.http11 DEBUG receive_response_body.complete
12:42:42,272 httpcore.http11 DEBUG response_closed.started
12:42:42,272 httpcore.http11 DEBUG response_closed.complete
12:42:42,273 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:42:42,280 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:42:42,284 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:42:42,285 httpcore.http11 DEBUG send_request_headers.complete
12:42:42,286 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:42:42,286 httpcore.http11 DEBUG send_request_body.complete
12:42:42,287 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:42:42,777 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:42:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'416'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0c342242d66e3c8651dc232384144c5b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c3f24cdd4d08-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:42:42,784 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:42:42,785 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:42:43,958 httpcore.http11 DEBUG receive_response_body.complete
12:42:43,958 httpcore.http11 DEBUG response_closed.started
12:42:43,959 httpcore.http11 DEBUG response_closed.complete
12:42:43,959 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:42:44,24 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:42:56,442 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:42:56,447 httpcore.connection DEBUG close.started
12:42:56,448 httpcore.connection DEBUG close.complete
12:42:56,448 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:42:56,452 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624edf90>
12:42:56,452 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:42:56,461 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ee010>
12:42:56,462 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:42:56,463 httpcore.http11 DEBUG send_request_headers.complete
12:42:56,463 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:42:56,492 httpcore.http11 DEBUG send_request_body.complete
12:42:56,492 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:42:57,378 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:42:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'396'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e45e72e6403302cc0b5e4e7e51b20cec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c44ae85f4ce9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:42:57,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:42:57,384 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:42:57,386 httpcore.http11 DEBUG receive_response_body.complete
12:42:57,387 httpcore.http11 DEBUG response_closed.started
12:42:57,387 httpcore.http11 DEBUG response_closed.complete
12:42:57,388 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:42:57,389 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:42:57,417 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:42:57,420 httpcore.connection DEBUG close.started
12:42:57,420 httpcore.connection DEBUG close.complete
12:42:57,421 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:42:57,423 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f5210>
12:42:57,424 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:42:57,431 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f5290>
12:42:57,432 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:42:57,433 httpcore.http11 DEBUG send_request_headers.complete
12:42:57,433 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:42:57,433 httpcore.http11 DEBUG send_request_body.complete
12:42:57,434 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:42:57,654 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:42:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e2a038fdc355451af1e6e52951ef17b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c450fb5b4ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:42:57,661 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:42:57,662 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:42:57,663 httpcore.http11 DEBUG receive_response_body.complete
12:42:57,663 httpcore.http11 DEBUG response_closed.started
12:42:57,664 httpcore.http11 DEBUG response_closed.complete
12:42:57,664 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:42:57,680 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:42:57,684 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:43:01,86 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:43:01,91 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:43:01,100 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:01,101 httpcore.http11 DEBUG send_request_headers.complete
12:43:01,101 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:01,102 httpcore.http11 DEBUG send_request_body.complete
12:43:01,102 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:01,648 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'441'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b836f14086b6a0e46ff0411a000aa1c7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c467ebec4ce9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:01,654 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:43:01,656 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:02,748 httpcore.http11 DEBUG receive_response_body.complete
12:43:02,749 httpcore.http11 DEBUG response_closed.started
12:43:02,750 httpcore.http11 DEBUG response_closed.complete
12:43:02,751 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:43:02,815 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:43:15,167 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:43:15,172 httpcore.connection DEBUG close.started
12:43:15,172 httpcore.connection DEBUG close.complete
12:43:15,173 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:43:15,175 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ec690>
12:43:15,176 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:43:15,182 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ed690>
12:43:15,182 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:15,183 httpcore.http11 DEBUG send_request_headers.complete
12:43:15,184 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:15,201 httpcore.http11 DEBUG send_request_body.complete
12:43:15,202 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:16,78 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:16 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'370'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'91da51a8fd75c07d24baafc7c32f44f8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c4bfe8d54d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:16,84 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:43:16,85 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:16,86 httpcore.http11 DEBUG receive_response_body.complete
12:43:16,86 httpcore.http11 DEBUG response_closed.started
12:43:16,87 httpcore.http11 DEBUG response_closed.complete
12:43:16,87 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:43:16,87 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:43:16,115 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:43:16,118 httpcore.connection DEBUG close.started
12:43:16,119 httpcore.connection DEBUG close.complete
12:43:16,119 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:43:16,122 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ac1d0>
12:43:16,122 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:43:16,127 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624e0510>
12:43:16,128 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:16,129 httpcore.http11 DEBUG send_request_headers.complete
12:43:16,129 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:16,130 httpcore.http11 DEBUG send_request_body.complete
12:43:16,130 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:16,342 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'14511f180c9670db0183d76cb47f4981'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c4c5ccc94cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:16,349 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:43:16,350 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:16,354 httpcore.http11 DEBUG receive_response_body.complete
12:43:16,354 httpcore.http11 DEBUG response_closed.started
12:43:16,354 httpcore.http11 DEBUG response_closed.complete
12:43:16,355 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:43:16,370 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:43:16,375 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:43:19,777 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:43:19,783 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:43:19,790 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:19,791 httpcore.http11 DEBUG send_request_headers.complete
12:43:19,791 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:19,792 httpcore.http11 DEBUG send_request_body.complete
12:43:19,792 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:20,291 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9790f937494a186286fb2f64e9c272c3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c4dcbd984d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:20,296 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:43:20,298 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:21,405 httpcore.http11 DEBUG receive_response_body.complete
12:43:21,406 httpcore.http11 DEBUG response_closed.started
12:43:21,407 httpcore.http11 DEBUG response_closed.complete
12:43:21,408 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:43:21,478 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:43:33,999 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:43:34,4 httpcore.connection DEBUG close.started
12:43:34,5 httpcore.connection DEBUG close.complete
12:43:34,5 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:43:34,8 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f6e90>
12:43:34,8 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:43:34,14 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f6f10>
12:43:34,15 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:34,16 httpcore.http11 DEBUG send_request_headers.complete
12:43:34,16 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:34,44 httpcore.http11 DEBUG send_request_body.complete
12:43:34,44 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:34,831 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'391'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e1a913f6e24f163011a41712aa3417a9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c535991d4cd4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:34,834 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:43:34,835 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:34,836 httpcore.http11 DEBUG receive_response_body.complete
12:43:34,836 httpcore.http11 DEBUG response_closed.started
12:43:34,837 httpcore.http11 DEBUG response_closed.complete
12:43:34,837 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:43:34,838 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:43:34,872 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:43:34,875 httpcore.connection DEBUG close.started
12:43:34,875 httpcore.connection DEBUG close.complete
12:43:34,876 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:43:34,879 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fe110>
12:43:34,879 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:43:34,884 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fe190>
12:43:34,884 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:34,885 httpcore.http11 DEBUG send_request_headers.complete
12:43:34,885 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:34,886 httpcore.http11 DEBUG send_request_body.complete
12:43:34,886 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:35,40 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'68'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e7402e2d3021484c258c713207625111'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c53b0ea94cf0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:35,45 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:43:35,46 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:35,48 httpcore.http11 DEBUG receive_response_body.complete
12:43:35,48 httpcore.http11 DEBUG response_closed.started
12:43:35,49 httpcore.http11 DEBUG response_closed.complete
12:43:35,50 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:43:35,69 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:43:35,72 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:43:38,475 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:43:38,486 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:43:38,489 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:38,491 httpcore.http11 DEBUG send_request_headers.complete
12:43:38,491 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:38,492 httpcore.http11 DEBUG send_request_body.complete
12:43:38,492 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:39,28 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:39 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'431'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'712d0be07a46b2cad2fda47a25c2518e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c5519c3a4cd4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:39,33 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:43:39,34 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:40,199 httpcore.http11 DEBUG receive_response_body.complete
12:43:40,200 httpcore.http11 DEBUG response_closed.started
12:43:40,201 httpcore.http11 DEBUG response_closed.complete
12:43:40,202 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:43:40,272 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:43:52,825 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:43:52,832 httpcore.connection DEBUG close.started
12:43:52,832 httpcore.connection DEBUG close.complete
12:43:52,833 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:43:52,862 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f7590>
12:43:52,862 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:43:52,873 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f7110>
12:43:52,874 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:52,876 httpcore.http11 DEBUG send_request_headers.complete
12:43:52,876 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:52,903 httpcore.http11 DEBUG send_request_body.complete
12:43:52,903 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:54,98 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:54 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'408'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd8e7c9706d257a136f60abcf0b0c49bf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c5ab7d0c4cd5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:54,102 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:43:54,103 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:54,104 httpcore.http11 DEBUG receive_response_body.complete
12:43:54,105 httpcore.http11 DEBUG response_closed.started
12:43:54,105 httpcore.http11 DEBUG response_closed.complete
12:43:54,106 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:43:54,107 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:43:54,136 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:43:54,139 httpcore.connection DEBUG close.started
12:43:54,140 httpcore.connection DEBUG close.complete
12:43:54,140 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:43:54,143 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624eca10>
12:43:54,143 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:43:54,149 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624eebd0>
12:43:54,149 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:54,150 httpcore.http11 DEBUG send_request_headers.complete
12:43:54,150 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:54,151 httpcore.http11 DEBUG send_request_body.complete
12:43:54,151 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:54,295 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'53'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cb61575a9405eb00007d89437bdbb140'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c5b379384cdb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:54,302 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:43:54,302 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:54,303 httpcore.http11 DEBUG receive_response_body.complete
12:43:54,303 httpcore.http11 DEBUG response_closed.started
12:43:54,304 httpcore.http11 DEBUG response_closed.complete
12:43:54,304 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:43:54,319 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:43:54,323 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:43:57,725 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:43:57,731 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:43:57,737 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:43:57,740 httpcore.http11 DEBUG send_request_headers.complete
12:43:57,741 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:43:57,742 httpcore.http11 DEBUG send_request_body.complete
12:43:57,742 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:43:58,267 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:43:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'453'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3625d3984d762705639c7f2c9839caf2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c5c9ec704cd5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:43:58,271 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:43:58,272 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:43:59,457 httpcore.http11 DEBUG receive_response_body.complete
12:43:59,458 httpcore.http11 DEBUG response_closed.started
12:43:59,459 httpcore.http11 DEBUG response_closed.complete
12:43:59,460 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:43:59,525 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:44:12,112 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:44:12,117 httpcore.connection DEBUG close.started
12:44:12,117 httpcore.connection DEBUG close.complete
12:44:12,118 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:44:12,120 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fe450>
12:44:12,120 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:44:12,130 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fd6d0>
12:44:12,130 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:44:12,131 httpcore.http11 DEBUG send_request_headers.complete
12:44:12,132 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:44:12,154 httpcore.http11 DEBUG send_request_body.complete
12:44:12,154 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:44:15,737 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:44:15 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'3057'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'728526c99a7e8803ad61a3c04befd4c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c623d8af4d02-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:44:15,742 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:44:15,743 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:44:15,744 httpcore.http11 DEBUG receive_response_body.complete
12:44:15,745 httpcore.http11 DEBUG response_closed.started
12:44:15,745 httpcore.http11 DEBUG response_closed.complete
12:44:15,746 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:44:15,747 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:44:15,776 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:44:15,779 httpcore.connection DEBUG close.started
12:44:15,780 httpcore.connection DEBUG close.complete
12:44:15,780 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:44:15,783 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262509850>
12:44:15,783 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:44:15,788 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02625092d0>
12:44:15,789 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:44:15,790 httpcore.http11 DEBUG send_request_headers.complete
12:44:15,790 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:44:15,791 httpcore.http11 DEBUG send_request_body.complete
12:44:15,791 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:44:16,3 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:44:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3b6d1912ab3bbcb65cae1d2141e0be7e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c63abdf34d1c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:44:16,9 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:44:16,10 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:44:16,12 httpcore.http11 DEBUG receive_response_body.complete
12:44:16,12 httpcore.http11 DEBUG response_closed.started
12:44:16,13 httpcore.http11 DEBUG response_closed.complete
12:44:16,13 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:44:16,29 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:44:16,33 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:44:19,435 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:44:19,450 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:44:19,454 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:44:21,456 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:44:21,468 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:44:21,472 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:44:24,874 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:44:24,881 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:44:24,885 httpcore.connection DEBUG close.started
12:44:24,886 httpcore.connection DEBUG close.complete
12:44:24,886 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:44:24,888 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262644b50>
12:44:24,889 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:44:24,893 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262644ed0>
12:44:24,894 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:44:24,895 httpcore.http11 DEBUG send_request_headers.complete
12:44:24,895 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:44:24,896 httpcore.http11 DEBUG send_request_body.complete
12:44:24,897 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:44:25,329 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:44:25 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'359'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ce74611e12d153f8fa783ab47f757a43'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c6739a42305d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:44:25,334 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:44:25,335 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:44:25,715 httpcore.http11 DEBUG receive_response_body.complete
12:44:25,716 httpcore.http11 DEBUG response_closed.started
12:44:25,716 httpcore.http11 DEBUG response_closed.complete
12:44:25,717 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:44:25,788 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:44:37,26 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:44:37,30 httpcore.connection DEBUG close.started
12:44:37,31 httpcore.connection DEBUG close.complete
12:44:37,31 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:44:37,34 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624bb0d0>
12:44:37,34 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:44:37,41 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624bb090>
12:44:37,41 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:44:37,42 httpcore.http11 DEBUG send_request_headers.complete
12:44:37,42 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:44:37,117 httpcore.http11 DEBUG send_request_body.complete
12:44:37,118 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:44:38,102 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:44:38 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'40'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'399'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4fc3824862df360e04dcc9a2297aa1ee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c6bf8b994d10-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:44:38,107 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:44:38,108 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:44:38,109 httpcore.http11 DEBUG receive_response_body.complete
12:44:38,110 httpcore.http11 DEBUG response_closed.started
12:44:38,110 httpcore.http11 DEBUG response_closed.complete
12:44:38,111 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:44:38,111 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:44:38,140 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPlace the candle somewhere on the left.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:44:38,143 httpcore.connection DEBUG close.started
12:44:38,144 httpcore.connection DEBUG close.complete
12:44:38,144 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:44:38,147 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ac350>
12:44:38,147 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9fd0> server_hostname='api.openai.com' timeout=None
12:44:38,153 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624acbd0>
12:44:38,153 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:44:38,154 httpcore.http11 DEBUG send_request_headers.complete
12:44:38,155 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:44:38,155 httpcore.http11 DEBUG send_request_body.complete
12:44:38,155 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:44:38,371 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:44:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'01305027bbc7cc405dafb025bfa433d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c6c67a1a4ce3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:44:38,376 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:44:38,377 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:44:38,378 httpcore.http11 DEBUG receive_response_body.complete
12:44:38,379 httpcore.http11 DEBUG response_closed.started
12:44:38,379 httpcore.http11 DEBUG response_closed.complete
12:44:38,380 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:44:38,414 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPlace the candle somewhere on the left.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:44:38,418 httpcore.connection DEBUG close.started
12:44:38,418 httpcore.connection DEBUG close.complete
12:44:38,419 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:44:38,421 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ae750>
12:44:38,422 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626da7b0> server_hostname='api.openai.com' timeout=None
12:44:38,428 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ad750>
12:44:38,428 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:44:38,429 httpcore.http11 DEBUG send_request_headers.complete
12:44:38,430 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:44:38,430 httpcore.http11 DEBUG send_request_body.complete
12:44:38,431 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:44:39,154 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:44:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'521'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'984f47588fdb3b0b8de31b3b20b676f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c6c83eb54ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:44:39,158 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:44:39,159 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:44:39,161 httpcore.http11 DEBUG receive_response_body.complete
12:44:39,161 httpcore.http11 DEBUG response_closed.started
12:44:39,162 httpcore.http11 DEBUG response_closed.complete
12:44:39,162 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:44:39,361 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:44:39,368 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:44:45,870 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:44:45,888 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:44:45,893 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:44:50,897 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:44:50,917 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:44:50,920 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:44:52,922 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:44:52,941 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:44:52,946 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:44:56,348 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:44:56,365 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:44:56,369 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:45:02,871 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:45:02,890 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:45:02,896 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:45:07,99 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:45:07,116 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:45:07,120 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:45:10,122 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:45:10,129 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:45:10,134 httpcore.connection DEBUG close.started
12:45:10,135 httpcore.connection DEBUG close.complete
12:45:10,135 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:45:10,183 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624eff90>
12:45:10,184 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:45:10,192 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ec090>
12:45:10,193 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:45:10,196 httpcore.http11 DEBUG send_request_headers.complete
12:45:10,196 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:45:10,198 httpcore.http11 DEBUG send_request_body.complete
12:45:10,198 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:45:10,865 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:45:10 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'551'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3e8acd345abd0a1a74991aabaf794150'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c78ebdd23049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:45:10,870 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:45:10,871 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:45:11,873 httpcore.http11 DEBUG receive_response_body.complete
12:45:11,874 httpcore.http11 DEBUG response_closed.started
12:45:11,875 httpcore.http11 DEBUG response_closed.complete
12:45:11,876 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:45:11,946 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:45:24,285 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:45:24,291 httpcore.connection DEBUG close.started
12:45:24,292 httpcore.connection DEBUG close.complete
12:45:24,292 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:45:24,294 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f7bd0>
12:45:24,295 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:45:24,301 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f4290>
12:45:24,302 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:45:24,303 httpcore.http11 DEBUG send_request_headers.complete
12:45:24,303 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:45:24,328 httpcore.http11 DEBUG send_request_body.complete
12:45:24,329 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:45:25,266 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:45:25 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'401'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b66c3763762e325d4a05012f35716072'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c7e6e9a73031-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:45:25,273 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:45:25,274 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:45:25,276 httpcore.http11 DEBUG receive_response_body.complete
12:45:25,277 httpcore.http11 DEBUG response_closed.started
12:45:25,277 httpcore.http11 DEBUG response_closed.complete
12:45:25,278 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:45:25,278 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:45:25,311 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the left.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:45:25,315 httpcore.connection DEBUG close.started
12:45:25,316 httpcore.connection DEBUG close.complete
12:45:25,316 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:45:25,319 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f6c50>
12:45:25,320 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9fd0> server_hostname='api.openai.com' timeout=None
12:45:25,327 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f7150>
12:45:25,328 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:45:25,330 httpcore.http11 DEBUG send_request_headers.complete
12:45:25,330 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:45:25,331 httpcore.http11 DEBUG send_request_body.complete
12:45:25,332 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:45:25,533 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:45:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3b1f355edee742dde8fb15e7535d0971'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c7ed5aa44cd9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:45:25,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:45:25,538 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:45:25,539 httpcore.http11 DEBUG receive_response_body.complete
12:45:25,540 httpcore.http11 DEBUG response_closed.started
12:45:25,540 httpcore.http11 DEBUG response_closed.complete
12:45:25,541 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:45:25,574 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the left.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:45:25,577 httpcore.connection DEBUG close.started
12:45:25,577 httpcore.connection DEBUG close.complete
12:45:25,578 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:45:25,582 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ff1d0>
12:45:25,582 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:45:25,592 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ff4d0>
12:45:25,592 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:45:25,593 httpcore.http11 DEBUG send_request_headers.complete
12:45:25,593 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:45:25,594 httpcore.http11 DEBUG send_request_body.complete
12:45:25,594 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:45:25,814 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:45:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0087b17329fa37c2b1db0ad31db5b3c6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c7eefdbf4cf0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:45:25,821 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:45:25,822 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:45:25,824 httpcore.http11 DEBUG receive_response_body.complete
12:45:25,825 httpcore.http11 DEBUG response_closed.started
12:45:25,825 httpcore.http11 DEBUG response_closed.complete
12:45:25,826 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:45:25,841 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:45:25,845 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:45:29,247 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:45:29,254 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:45:29,261 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:45:29,262 httpcore.http11 DEBUG send_request_headers.complete
12:45:29,262 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:45:29,263 httpcore.http11 DEBUG send_request_body.complete
12:45:29,263 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:45:29,949 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:45:29 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'571'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a6163357f3c0c245cb5881e602bf891a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c805e8f13031-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:45:29,954 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:45:29,955 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:45:31,20 httpcore.http11 DEBUG receive_response_body.complete
12:45:31,21 httpcore.http11 DEBUG response_closed.started
12:45:31,22 httpcore.http11 DEBUG response_closed.complete
12:45:31,23 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:45:31,93 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:45:43,692 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka9.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:45:43,697 httpcore.connection DEBUG close.started
12:45:43,698 httpcore.connection DEBUG close.complete
12:45:43,698 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:45:43,701 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fe210>
12:45:43,702 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:45:43,707 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fe2d0>
12:45:43,708 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:45:43,709 httpcore.http11 DEBUG send_request_headers.complete
12:45:43,710 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:45:43,734 httpcore.http11 DEBUG send_request_body.complete
12:45:43,735 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:45:44,560 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:45:44 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'401'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8e8950103d790c698c17d1c6debb7d42'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c8602a814cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:45:44,566 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:45:44,567 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:45:44,569 httpcore.http11 DEBUG receive_response_body.complete
12:45:44,569 httpcore.http11 DEBUG response_closed.started
12:45:44,570 httpcore.http11 DEBUG response_closed.complete
12:45:44,570 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:45:44,571 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:45:44,601 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:45:44,608 httpcore.connection DEBUG close.started
12:45:44,609 httpcore.connection DEBUG close.complete
12:45:44,609 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:45:44,614 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262509f90>
12:45:44,615 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:45:44,622 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026250a2d0>
12:45:44,622 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:45:44,623 httpcore.http11 DEBUG send_request_headers.complete
12:45:44,623 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:45:44,624 httpcore.http11 DEBUG send_request_body.complete
12:45:44,624 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:45:44,786 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:45:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'59'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e3ee52b90257f43420d643ceece1c7bc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c865e9013b99-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:45:44,791 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:45:44,792 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:45:44,793 httpcore.http11 DEBUG receive_response_body.complete
12:45:44,794 httpcore.http11 DEBUG response_closed.started
12:45:44,794 httpcore.http11 DEBUG response_closed.complete
12:45:44,795 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:45:44,812 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:45:44,816 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:45:48,218 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:45:48,236 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:45:48,239 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:45:50,242 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:45:50,260 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:45:50,264 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:45:53,666 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:45:53,674 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:45:53,677 httpcore.connection DEBUG close.started
12:45:53,678 httpcore.connection DEBUG close.complete
12:45:53,678 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:45:53,681 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262509010>
12:45:53,682 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:45:53,691 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026264d810>
12:45:53,692 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:45:53,693 httpcore.http11 DEBUG send_request_headers.complete
12:45:53,693 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:45:53,694 httpcore.http11 DEBUG send_request_body.complete
12:45:53,694 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:45:54,138 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:45:54 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'342'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'511ca2fd774568b6c21d55ec51aa259a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c89e99264d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:45:54,144 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:45:54,145 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:45:54,575 httpcore.http11 DEBUG receive_response_body.complete
12:45:54,577 httpcore.http11 DEBUG response_closed.started
12:45:54,578 httpcore.http11 DEBUG response_closed.complete
12:45:54,579 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:45:54,648 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka10.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:46:05,899 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka10.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:46:05,905 httpcore.connection DEBUG close.started
12:46:05,905 httpcore.connection DEBUG close.complete
12:46:05,906 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:46:05,908 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f84d0>
12:46:05,909 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:46:05,914 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f8f50>
12:46:05,914 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:46:05,916 httpcore.http11 DEBUG send_request_headers.complete
12:46:05,916 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:46:05,948 httpcore.http11 DEBUG send_request_body.complete
12:46:05,949 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:46:06,981 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:46:06 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'41'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'404'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e00ecb01783798480b4809b9f6ef3e89'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c8eafa1f4cc3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:46:06,983 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:46:06,984 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:46:06,985 httpcore.http11 DEBUG receive_response_body.complete
12:46:06,986 httpcore.http11 DEBUG response_closed.started
12:46:06,987 httpcore.http11 DEBUG response_closed.complete
12:46:06,988 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:46:06,989 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:46:07,22 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPlace the third candle somewhere on top.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:46:07,25 httpcore.connection DEBUG close.started
12:46:07,26 httpcore.connection DEBUG close.complete
12:46:07,26 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:46:07,28 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624e0b50>
12:46:07,29 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9fd0> server_hostname='api.openai.com' timeout=None
12:46:07,34 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624e1d10>
12:46:07,34 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:46:07,35 httpcore.http11 DEBUG send_request_headers.complete
12:46:07,35 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:46:07,36 httpcore.http11 DEBUG send_request_body.complete
12:46:07,36 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:46:07,232 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:46:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'97'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'942b4a03c39241622c84bf40908b4ee6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c8f1fe504cf3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:46:07,235 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:46:07,236 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:46:07,237 httpcore.http11 DEBUG receive_response_body.complete
12:46:07,238 httpcore.http11 DEBUG response_closed.started
12:46:07,238 httpcore.http11 DEBUG response_closed.complete
12:46:07,239 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:46:07,279 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPlace the third candle somewhere on top.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:46:07,282 httpcore.connection DEBUG close.started
12:46:07,283 httpcore.connection DEBUG close.complete
12:46:07,283 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:46:07,286 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ad6d0>
12:46:07,286 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626da7b0> server_hostname='api.openai.com' timeout=None
12:46:07,294 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ad610>
12:46:07,295 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:46:07,296 httpcore.http11 DEBUG send_request_headers.complete
12:46:07,296 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:46:07,297 httpcore.http11 DEBUG send_request_body.complete
12:46:07,297 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:46:07,748 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:46:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'321'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b2b1fa9432ebf32bb00ea26d159a1365'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c8f39a4c4cd8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:46:07,755 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:46:07,756 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:46:07,758 httpcore.http11 DEBUG receive_response_body.complete
12:46:07,758 httpcore.http11 DEBUG response_closed.started
12:46:07,758 httpcore.http11 DEBUG response_closed.complete
12:46:07,759 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:46:07,971 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:46:07,975 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:46:14,477 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:46:14,497 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:46:14,502 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:46:19,504 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:46:19,524 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:46:19,529 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:46:21,532 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:46:21,549 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:46:21,553 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:46:24,955 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:46:24,976 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:46:24,980 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:46:31,482 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:46:31,499 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:46:31,503 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:46:36,506 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:46:36,525 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:46:36,530 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:46:41,933 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:46:41,939 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:46:41,947 httpcore.connection DEBUG close.started
12:46:41,947 httpcore.connection DEBUG close.complete
12:46:41,948 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:46:41,979 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026250a090>
12:46:41,980 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:46:41,987 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262509dd0>
12:46:41,988 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:46:41,990 httpcore.http11 DEBUG send_request_headers.complete
12:46:41,991 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:46:41,992 httpcore.http11 DEBUG send_request_body.complete
12:46:41,992 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:46:42,527 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:46:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'440'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4395de5821f7d7e1022435faf709e6fa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347c9cc7f024ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:46:42,531 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:46:42,532 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:46:43,801 httpcore.http11 DEBUG receive_response_body.complete
12:46:43,802 httpcore.http11 DEBUG response_closed.started
12:46:43,803 httpcore.http11 DEBUG response_closed.complete
12:46:43,804 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:46:43,875 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka11.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:46:56,357 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka11.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:46:56,362 httpcore.connection DEBUG close.started
12:46:56,363 httpcore.connection DEBUG close.complete
12:46:56,363 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:46:56,366 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f4990>
12:46:56,366 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:46:56,375 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f48d0>
12:46:56,375 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:46:56,377 httpcore.http11 DEBUG send_request_headers.complete
12:46:56,377 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:46:56,401 httpcore.http11 DEBUG send_request_body.complete
12:46:56,402 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:46:57,545 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:46:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'10'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'681'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fc2cec0a6862714b9008486d657d0b67'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347ca265cef3061-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:46:57,550 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:46:57,551 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:46:57,552 httpcore.http11 DEBUG receive_response_body.complete
12:46:57,552 httpcore.http11 DEBUG response_closed.started
12:46:57,553 httpcore.http11 DEBUG response_closed.complete
12:46:57,553 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:46:57,554 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:46:57,586 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nmove down\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:46:57,590 httpcore.connection DEBUG close.started
12:46:57,590 httpcore.connection DEBUG close.complete
12:46:57,591 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:46:57,593 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f9890>
12:46:57,594 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9fd0> server_hostname='api.openai.com' timeout=None
12:46:57,603 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f8510>
12:46:57,604 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:46:57,605 httpcore.http11 DEBUG send_request_headers.complete
12:46:57,605 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:46:57,606 httpcore.http11 DEBUG send_request_body.complete
12:46:57,606 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:46:57,961 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:46:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dd1078d040ec9cedadcd37cbee19cd80'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347ca2e0de73021-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:46:57,967 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:46:57,968 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:46:57,970 httpcore.http11 DEBUG receive_response_body.complete
12:46:57,970 httpcore.http11 DEBUG response_closed.started
12:46:57,971 httpcore.http11 DEBUG response_closed.complete
12:46:57,972 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:46:58,6 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nmove down\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:46:58,10 httpcore.connection DEBUG close.started
12:46:58,10 httpcore.connection DEBUG close.complete
12:46:58,11 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:46:58,13 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f6410>
12:46:58,14 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:46:58,19 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f7090>
12:46:58,20 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:46:58,21 httpcore.http11 DEBUG send_request_headers.complete
12:46:58,21 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:46:58,22 httpcore.http11 DEBUG send_request_body.complete
12:46:58,22 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:46:58,259 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:46:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'137'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'18ebbf3e09498fc2aa7cc17b97fa84e0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347ca30ae064cf4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:46:58,265 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:46:58,265 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:46:58,267 httpcore.http11 DEBUG receive_response_body.complete
12:46:58,268 httpcore.http11 DEBUG response_closed.started
12:46:58,268 httpcore.http11 DEBUG response_closed.complete
12:46:58,269 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:46:58,288 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:46:58,292 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:47:01,694 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:47:01,701 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:47:01,706 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:01,708 httpcore.http11 DEBUG send_request_headers.complete
12:47:01,708 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:01,709 httpcore.http11 DEBUG send_request_body.complete
12:47:01,709 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:02,403 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:02 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'572'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9c49d64d8ca9772358a1f92ea8da3140'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347ca47a96f3061-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:02,407 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:47:02,408 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:03,391 httpcore.http11 DEBUG receive_response_body.complete
12:47:03,392 httpcore.http11 DEBUG response_closed.started
12:47:03,393 httpcore.http11 DEBUG response_closed.complete
12:47:03,393 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:47:03,465 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka12.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:47:15,817 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka12.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:47:15,822 httpcore.connection DEBUG close.started
12:47:15,822 httpcore.connection DEBUG close.complete
12:47:15,823 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:47:15,826 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fca90>
12:47:15,826 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:47:15,835 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fed50>
12:47:15,835 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:15,837 httpcore.http11 DEBUG send_request_headers.complete
12:47:15,837 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:15,864 httpcore.http11 DEBUG send_request_body.complete
12:47:15,864 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:16,641 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:16 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'360'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4f79f0e8cb08a49024fce8aeb6e34d1f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347ca9ffa194ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:16,646 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:47:16,647 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:16,648 httpcore.http11 DEBUG receive_response_body.complete
12:47:16,649 httpcore.http11 DEBUG response_closed.started
12:47:16,650 httpcore.http11 DEBUG response_closed.complete
12:47:16,651 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:47:16,652 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:47:16,680 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove to the left.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:47:16,684 httpcore.connection DEBUG close.started
12:47:16,684 httpcore.connection DEBUG close.complete
12:47:16,685 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:47:16,687 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026250af10>
12:47:16,688 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:47:16,693 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026250a310>
12:47:16,694 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:16,695 httpcore.http11 DEBUG send_request_headers.complete
12:47:16,695 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:16,696 httpcore.http11 DEBUG send_request_body.complete
12:47:16,696 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:16,962 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'142'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'936337324a4562f6147cff420633f803'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347caa55f4c4d1e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:16,969 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:47:16,970 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:16,970 httpcore.http11 DEBUG receive_response_body.complete
12:47:16,971 httpcore.http11 DEBUG response_closed.started
12:47:16,971 httpcore.http11 DEBUG response_closed.complete
12:47:16,971 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:47:16,987 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:47:16,991 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:47:20,394 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:47:20,400 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:47:20,407 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:20,408 httpcore.http11 DEBUG send_request_headers.complete
12:47:20,409 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:20,409 httpcore.http11 DEBUG send_request_body.complete
12:47:20,410 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:20,983 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'468'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ed2ec25df7bb0b51a9e3f4fda1bef385'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cabc8d9c4ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:20,989 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:47:20,990 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:22,205 httpcore.http11 DEBUG receive_response_body.complete
12:47:22,205 httpcore.http11 DEBUG response_closed.started
12:47:22,206 httpcore.http11 DEBUG response_closed.complete
12:47:22,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:47:22,281 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka13.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:47:34,829 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka13.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:47:34,835 httpcore.connection DEBUG close.started
12:47:34,836 httpcore.connection DEBUG close.complete
12:47:34,836 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:47:34,839 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f8c50>
12:47:34,839 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:47:34,846 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fa8d0>
12:47:34,847 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:34,849 httpcore.http11 DEBUG send_request_headers.complete
12:47:34,850 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:34,876 httpcore.http11 DEBUG send_request_body.complete
12:47:34,877 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:35,640 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:35 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'347'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'33c584d451816b2fbdcf25b574546c53'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cb16cbb74cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:35,645 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:47:35,646 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:35,646 httpcore.http11 DEBUG receive_response_body.complete
12:47:35,647 httpcore.http11 DEBUG response_closed.started
12:47:35,647 httpcore.http11 DEBUG response_closed.complete
12:47:35,647 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:47:35,648 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:47:35,676 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nThank you for watching!\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:47:35,680 httpcore.connection DEBUG close.started
12:47:35,680 httpcore.connection DEBUG close.complete
12:47:35,681 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:47:35,683 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262515610>
12:47:35,683 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:47:35,689 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02625151d0>
12:47:35,689 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:35,690 httpcore.http11 DEBUG send_request_headers.complete
12:47:35,690 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:35,691 httpcore.http11 DEBUG send_request_body.complete
12:47:35,691 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:35,918 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c54f89a4e8cd330467a29c53fc129ec8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cb1c1bbc3b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:35,923 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:47:35,923 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:35,925 httpcore.http11 DEBUG receive_response_body.complete
12:47:35,925 httpcore.http11 DEBUG response_closed.started
12:47:35,925 httpcore.http11 DEBUG response_closed.complete
12:47:35,926 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:47:35,935 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:47:35,939 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:35,940 httpcore.http11 DEBUG send_request_headers.complete
12:47:35,940 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:35,940 httpcore.http11 DEBUG send_request_body.complete
12:47:35,941 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:36,457 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'429'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e9619c0d3aee87e689fb4b92d9b42913'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cb1dab2c4cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:36,461 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:47:36,462 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:37,671 httpcore.http11 DEBUG receive_response_body.complete
12:47:37,672 httpcore.http11 DEBUG response_closed.started
12:47:37,672 httpcore.http11 DEBUG response_closed.complete
12:47:37,673 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:47:37,744 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka14.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:47:50,238 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka14.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:47:50,244 httpcore.connection DEBUG close.started
12:47:50,244 httpcore.connection DEBUG close.complete
12:47:50,245 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:47:50,263 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fd950>
12:47:50,263 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:47:50,272 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fc5d0>
12:47:50,273 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:50,275 httpcore.http11 DEBUG send_request_headers.complete
12:47:50,275 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:50,295 httpcore.http11 DEBUG send_request_body.complete
12:47:50,295 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:51,896 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:51 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'6'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1052'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ed8b12889b94740a296d1fc72d5c0e24'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cb773fbf3b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:51,900 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:47:51,901 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:51,902 httpcore.http11 DEBUG receive_response_body.complete
12:47:51,903 httpcore.http11 DEBUG response_closed.started
12:47:51,903 httpcore.http11 DEBUG response_closed.complete
12:47:51,904 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:47:51,905 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:47:51,935 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nleft.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:47:51,938 httpcore.connection DEBUG close.started
12:47:51,938 httpcore.connection DEBUG close.complete
12:47:51,939 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:47:51,941 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fb890>
12:47:51,942 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:47:51,947 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f8110>
12:47:51,948 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:51,949 httpcore.http11 DEBUG send_request_headers.complete
12:47:51,949 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:51,950 httpcore.http11 DEBUG send_request_body.complete
12:47:51,950 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:52,953 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3f79f8ad3d2649a99abe36bb65377c03'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cb81aa724ccf-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:52,958 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:47:52,959 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:52,960 httpcore.http11 DEBUG receive_response_body.complete
12:47:52,960 httpcore.http11 DEBUG response_closed.started
12:47:52,960 httpcore.http11 DEBUG response_closed.complete
12:47:52,961 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:47:52,978 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:47:52,982 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:47:56,384 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:47:56,389 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:47:56,394 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:47:56,396 httpcore.http11 DEBUG send_request_headers.complete
12:47:56,396 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:47:56,396 httpcore.http11 DEBUG send_request_body.complete
12:47:56,397 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:47:57,93 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:47:57 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'571'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1ec4ee3254d68cf2424e98191c01d040'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cb9d7cc13b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:47:57,98 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:47:57,99 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:47:58,175 httpcore.http11 DEBUG receive_response_body.complete
12:47:58,176 httpcore.http11 DEBUG response_closed.started
12:47:58,177 httpcore.http11 DEBUG response_closed.complete
12:47:58,178 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:47:58,251 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka15.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:48:10,613 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka15.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:48:10,619 httpcore.connection DEBUG close.started
12:48:10,620 httpcore.connection DEBUG close.complete
12:48:10,620 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:48:10,623 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f8f90>
12:48:10,623 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:48:10,629 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f8dd0>
12:48:10,630 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:48:10,632 httpcore.http11 DEBUG send_request_headers.complete
12:48:10,632 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:48:10,663 httpcore.http11 DEBUG send_request_body.complete
12:48:10,663 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:48:11,834 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:48:11 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'378'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7bc5293b2ba52ff195558e5c0a933ff9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cbf67e2d6ac5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:48:11,836 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:48:11,837 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:48:11,837 httpcore.http11 DEBUG receive_response_body.complete
12:48:11,838 httpcore.http11 DEBUG response_closed.started
12:48:11,838 httpcore.http11 DEBUG response_closed.complete
12:48:11,838 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:48:11,839 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:48:11,868 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove to the left.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:48:11,872 httpcore.connection DEBUG close.started
12:48:11,872 httpcore.connection DEBUG close.complete
12:48:11,873 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:48:11,875 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262516e10>
12:48:11,875 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:48:11,880 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0262515e10>
12:48:11,880 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:48:11,881 httpcore.http11 DEBUG send_request_headers.complete
12:48:11,882 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:48:11,882 httpcore.http11 DEBUG send_request_body.complete
12:48:11,882 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:48:12,88 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:48:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'86471deaf206f71f6e974c842e1973b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cbfe4d783b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:48:12,95 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:48:12,96 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:48:12,98 httpcore.http11 DEBUG receive_response_body.complete
12:48:12,99 httpcore.http11 DEBUG response_closed.started
12:48:12,99 httpcore.http11 DEBUG response_closed.complete
12:48:12,100 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:48:12,117 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:48:12,120 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:48:15,521 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:48:15,525 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:48:15,530 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:48:15,531 httpcore.http11 DEBUG send_request_headers.complete
12:48:15,532 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:48:15,532 httpcore.http11 DEBUG send_request_body.complete
12:48:15,532 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:48:16,26 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:48:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'425'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6c0b9fb1b4b2bb084287604989f2e281'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cc151c526ac5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:48:16,31 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:48:16,32 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:48:17,37 httpcore.http11 DEBUG receive_response_body.complete
12:48:17,38 httpcore.http11 DEBUG response_closed.started
12:48:17,38 httpcore.http11 DEBUG response_closed.complete
12:48:17,39 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:48:17,110 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka16.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:48:29,668 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka16.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:48:29,675 httpcore.connection DEBUG close.started
12:48:29,675 httpcore.connection DEBUG close.complete
12:48:29,676 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:48:29,678 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fdad0>
12:48:29,678 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:48:29,685 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fe0d0>
12:48:29,686 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:48:29,687 httpcore.http11 DEBUG send_request_headers.complete
12:48:29,687 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:48:29,708 httpcore.http11 DEBUG send_request_body.complete
12:48:29,708 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:48:30,467 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:48:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'383'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd9a63e1a7def4f028f9ab442a9c740aa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cc6d89a93074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:48:30,472 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:48:30,473 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:48:30,474 httpcore.http11 DEBUG receive_response_body.complete
12:48:30,475 httpcore.http11 DEBUG response_closed.started
12:48:30,476 httpcore.http11 DEBUG response_closed.complete
12:48:30,477 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:48:30,477 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:48:30,505 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nI don't know.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:48:30,509 httpcore.connection DEBUG close.started
12:48:30,509 httpcore.connection DEBUG close.complete
12:48:30,509 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:48:30,512 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fa350>
12:48:30,512 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:48:30,517 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f9790>
12:48:30,517 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:48:30,518 httpcore.http11 DEBUG send_request_headers.complete
12:48:30,519 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:48:30,519 httpcore.http11 DEBUG send_request_body.complete
12:48:30,519 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:48:30,768 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:48:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'114'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'847466da54583d460fa3a8b20d3e6a0b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cc72b8a53045-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:48:30,774 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:48:30,775 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:48:30,777 httpcore.http11 DEBUG receive_response_body.complete
12:48:30,778 httpcore.http11 DEBUG response_closed.started
12:48:30,779 httpcore.http11 DEBUG response_closed.complete
12:48:30,780 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:48:30,788 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:48:30,791 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:48:30,792 httpcore.http11 DEBUG send_request_headers.complete
12:48:30,793 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:48:30,793 httpcore.http11 DEBUG send_request_body.complete
12:48:30,793 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:48:31,486 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:48:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'575'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7e5e5182644648e419d8e1a1de634ed2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cc747b273074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:48:31,491 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:48:31,492 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:48:32,559 httpcore.http11 DEBUG receive_response_body.complete
12:48:32,560 httpcore.http11 DEBUG response_closed.started
12:48:32,561 httpcore.http11 DEBUG response_closed.complete
12:48:32,562 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:48:32,628 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka17.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:48:45,89 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka17.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:48:45,94 httpcore.connection DEBUG close.started
12:48:45,94 httpcore.connection DEBUG close.complete
12:48:45,95 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:48:45,98 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624afc50>
12:48:45,98 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:48:45,105 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624afad0>
12:48:45,106 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:48:45,107 httpcore.http11 DEBUG send_request_headers.complete
12:48:45,108 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:48:45,149 httpcore.http11 DEBUG send_request_body.complete
12:48:45,150 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:48:47,45 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:48:47 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1138'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b6438cf13772b63b5cf873578c2d7f1f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cccde95e4cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:48:47,48 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:48:47,49 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:48:47,50 httpcore.http11 DEBUG receive_response_body.complete
12:48:47,51 httpcore.http11 DEBUG response_closed.started
12:48:47,51 httpcore.http11 DEBUG response_closed.complete
12:48:47,52 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:48:47,52 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:48:47,81 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove down.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:48:47,84 httpcore.connection DEBUG close.started
12:48:47,85 httpcore.connection DEBUG close.complete
12:48:47,85 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:48:47,88 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026251c6d0>
12:48:47,88 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:48:47,93 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f026251c610>
12:48:47,93 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:48:47,94 httpcore.http11 DEBUG send_request_headers.complete
12:48:47,94 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:48:47,95 httpcore.http11 DEBUG send_request_body.complete
12:48:47,95 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:48:47,333 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:48:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'57838273ed230047ba225f9860ae5d12'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347ccda5aa74d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:48:47,340 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:48:47,341 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:48:47,341 httpcore.http11 DEBUG receive_response_body.complete
12:48:47,342 httpcore.http11 DEBUG response_closed.started
12:48:47,342 httpcore.http11 DEBUG response_closed.complete
12:48:47,343 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:48:47,358 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:48:47,362 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:48:50,764 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:48:50,770 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
12:48:50,775 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:48:50,776 httpcore.http11 DEBUG send_request_headers.complete
12:48:50,777 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:48:50,777 httpcore.http11 DEBUG send_request_body.complete
12:48:50,778 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:48:51,263 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:48:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'408'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'68980a2b946278e0c3ceb1c4d883e8ef'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347ccf15f644cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:48:51,268 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
12:48:51,269 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:48:52,357 httpcore.http11 DEBUG receive_response_body.complete
12:48:52,358 httpcore.http11 DEBUG response_closed.started
12:48:52,359 httpcore.http11 DEBUG response_closed.complete
12:48:52,360 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
12:48:52,431 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Emeka18.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
12:49:05,25 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Emeka18.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
12:49:05,30 httpcore.connection DEBUG close.started
12:49:05,30 httpcore.connection DEBUG close.complete
12:49:05,31 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
12:49:05,62 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ffb50>
12:49:05,63 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9e20> server_hostname='api.openai.com' timeout=5.0
12:49:05,70 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624ed690>
12:49:05,71 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:49:05,73 httpcore.http11 DEBUG send_request_headers.complete
12:49:05,74 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:49:05,98 httpcore.http11 DEBUG send_request_body.complete
12:49:05,99 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:49:05,934 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:49:05 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'69ca5347217e7ea359b488451be34856'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cd4ab8104cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:49:05,938 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
12:49:05,939 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:49:05,940 httpcore.http11 DEBUG receive_response_body.complete
12:49:05,941 httpcore.http11 DEBUG response_closed.started
12:49:05,942 httpcore.http11 DEBUG response_closed.complete
12:49:05,942 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
12:49:05,943 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
12:49:05,972 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
12:49:05,975 httpcore.connection DEBUG close.started
12:49:05,976 httpcore.connection DEBUG close.complete
12:49:05,976 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
12:49:05,980 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624fb690>
12:49:05,980 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f02626d9f40> server_hostname='api.openai.com' timeout=None
12:49:05,988 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f02624f9050>
12:49:05,988 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
12:49:05,989 httpcore.http11 DEBUG send_request_headers.complete
12:49:05,989 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
12:49:05,990 httpcore.http11 DEBUG send_request_body.complete
12:49:05,990 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
12:49:06,207 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 17:49:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e1053f8d8578718095a4f43d4d775015'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8347cd506d1c4d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
12:49:06,214 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
12:49:06,215 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
12:49:06,217 httpcore.http11 DEBUG receive_response_body.complete
12:49:06,218 httpcore.http11 DEBUG response_closed.started
12:49:06,218 httpcore.http11 DEBUG response_closed.complete
12:49:06,218 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
12:49:06,233 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:49:06,237 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:49:09,639 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:49:09,661 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:49:09,665 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:49:11,668 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
12:49:11,690 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
12:49:11,696 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
12:49:15,98 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:47:59,721 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
14:47:59,725 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
14:48:00,549 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
14:48:00,550 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
14:48:00,592 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
14:48:00,593 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
14:48:00,645 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
14:48:00,646 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
14:48:00,691 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
14:48:00,692 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
14:48:00,748 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
14:48:00,749 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
14:48:00,794 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
14:48:00,795 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
14:48:00,851 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
14:48:00,852 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
14:48:00,899 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
14:48:00,901 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
14:49:13,350 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Sarah. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:49:13,373 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:49:13,411 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac55c7a50>
14:49:13,411 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:49:13,427 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac55c7f50>
14:49:13,428 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:49:13,432 httpcore.http11 DEBUG send_request_headers.complete
14:49:13,433 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:49:13,434 httpcore.http11 DEBUG send_request_body.complete
14:49:13,435 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:49:13,985 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:49:13 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'393'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7f05174d042b8f7cacd539c870cf7077'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=s9C682aCDo9l.Iwgh8.0UEnvmBLQfXNeFT9ioGcmzCw-1702410553-1-AZVMGrgz4bwuSoA4SV611jk671Dbtz+fcdAcVpDf2fVApEHXBhjevMTg8uKdIK60EwNfQG6ykx/LFaKi9HiJT9Y=; path=/; expires=Tue, 12-Dec-23 20:19:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=tMB6D7Zsx_R7a6k8121xGlY2lhvzBeGYSzTWqUCWXHE-1702410553979-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487d46fa173b9a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:49:13,993 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:49:13,994 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:49:14,675 httpcore.http11 DEBUG receive_response_body.complete
14:49:14,676 httpcore.http11 DEBUG response_closed.started
14:49:14,677 httpcore.http11 DEBUG response_closed.complete
14:49:14,679 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:49:14,756 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:49:27,941 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:49:27,952 httpcore.connection DEBUG close.started
14:49:27,953 httpcore.connection DEBUG close.complete
14:49:27,953 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:49:27,955 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac55c7f50>
14:49:27,956 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:49:27,962 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac55dc410>
14:49:27,963 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:49:27,964 httpcore.http11 DEBUG send_request_headers.complete
14:49:27,964 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:49:27,996 httpcore.http11 DEBUG send_request_body.complete
14:49:27,996 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:49:28,790 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:49:28 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'446'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5799658caeaa1eea75ca3fb3a2c56980'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487da1c8463045-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:49:28,793 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:49:28,794 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:49:28,796 httpcore.http11 DEBUG receive_response_body.complete
14:49:28,796 httpcore.http11 DEBUG response_closed.started
14:49:28,797 httpcore.http11 DEBUG response_closed.complete
14:49:28,797 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:49:28,798 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:49:28,833 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Sarah. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nCan you put the first candle in the very center of the cake?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:49:28,847 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:49:28,849 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5424cd0>
14:49:28,850 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652060> server_hostname='api.openai.com' timeout=None
14:49:28,858 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5424c90>
14:49:28,858 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:49:28,860 httpcore.http11 DEBUG send_request_headers.complete
14:49:28,860 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:49:28,861 httpcore.http11 DEBUG send_request_body.complete
14:49:28,861 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:49:29,70 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:49:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'255bacb02fff6a5a419b19e3a8078c5d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=iTBkRNC4XXX10hgZvhQHCZeBiyg7V4TTt47_.aAUA5g-1702410569-1-AflcckLqeXrqAWE28Hk7qOVwPbc42Ygawy3TrD8XA7nQR2uRb695p3jLfukxzmgeRL9A3cY0hC8hL6fajAaerM4=; path=/; expires=Tue, 12-Dec-23 20:19:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=a3dethv9KkZbxQ6BVLmSE6B4CtuJ8Zk.VNZ36B7t7NE-1702410569066-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487da76bdb3b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:49:29,78 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:49:29,78 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:49:29,79 httpcore.http11 DEBUG receive_response_body.complete
14:49:29,79 httpcore.http11 DEBUG response_closed.started
14:49:29,80 httpcore.http11 DEBUG response_closed.complete
14:49:29,80 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:49:29,117 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it somewhere on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nHi, Sarah. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nCan you put the first candle in the very center of the cake?\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:49:29,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:49:29,132 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac55ec3d0>
14:49:29,132 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652840> server_hostname='api.openai.com' timeout=None
14:49:29,137 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5433c10>
14:49:29,138 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:49:29,139 httpcore.http11 DEBUG send_request_headers.complete
14:49:29,139 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:49:29,140 httpcore.http11 DEBUG send_request_body.complete
14:49:29,140 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:49:30,103 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:49:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'846'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a2e66b77b18f1527e2958240edfd3d49'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=nBUmt9_n3KIacGMQnvw0EzXB__srjNZkf810g7CueIU-1702410570-1-AYgeKlYBm4sgEurdxbQMrgvOBoNBdyqBDU8NTVkAJXK0PCkzP3+T6+UIrtzCbKHNnNtBRzjeEdM6aofRmsg+ZiA=; path=/; expires=Tue, 12-Dec-23 20:19:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=p2HGDL8v3IA2.EPKHesg1VEdd1BX8XEfaOz8HFLXkY8-1702410570099-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487da9198d4cd9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:49:30,113 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:49:30,114 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:49:30,116 httpcore.http11 DEBUG receive_response_body.complete
14:49:30,117 httpcore.http11 DEBUG response_closed.started
14:49:30,117 httpcore.http11 DEBUG response_closed.complete
14:49:30,118 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:49:30,136 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:49:30,140 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:49:36,648 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:49:36,662 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:49:36,667 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:49:41,671 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:49:41,692 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:49:41,695 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:49:43,697 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:49:43,716 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:49:43,720 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:49:47,122 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:49:47,147 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:49:47,152 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:49:53,655 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:49:53,671 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:49:53,676 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:49:57,879 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:49:57,899 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:49:57,903 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:50:02,105 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:50:02,114 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:50:02,122 httpcore.connection DEBUG close.started
14:50:02,122 httpcore.connection DEBUG close.complete
14:50:02,123 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:50:02,126 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac55bcf50>
14:50:02,126 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:50:02,134 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac55dc150>
14:50:02,134 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:02,135 httpcore.http11 DEBUG send_request_headers.complete
14:50:02,135 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:02,136 httpcore.http11 DEBUG send_request_body.complete
14:50:02,136 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:02,659 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:02 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'431'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e20fbe6b9ebf79fca9b7eb6d0988aa80'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487e775def4ce8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:02,663 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:50:02,664 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:03,733 httpcore.http11 DEBUG receive_response_body.complete
14:50:03,734 httpcore.http11 DEBUG response_closed.started
14:50:03,735 httpcore.http11 DEBUG response_closed.complete
14:50:03,736 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:50:03,806 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:50:16,159 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:50:16,167 httpcore.connection DEBUG close.started
14:50:16,167 httpcore.connection DEBUG close.complete
14:50:16,168 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:50:16,208 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545a090>
14:50:16,208 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:50:16,218 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545a110>
14:50:16,219 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:16,221 httpcore.http11 DEBUG send_request_headers.complete
14:50:16,221 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:16,243 httpcore.http11 DEBUG send_request_body.complete
14:50:16,243 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:16,954 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:16 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'32'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'380'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0048b939efc4bc7b622518cbcca09ae0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487ecf6bee4cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:16,960 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:50:16,961 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:16,962 httpcore.http11 DEBUG receive_response_body.complete
14:50:16,963 httpcore.http11 DEBUG response_closed.started
14:50:16,964 httpcore.http11 DEBUG response_closed.complete
14:50:16,965 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:50:16,966 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:50:16,998 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nCan you move a little bit down?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:50:17,2 httpcore.connection DEBUG close.started
14:50:17,2 httpcore.connection DEBUG close.complete
14:50:17,3 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:50:17,5 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5424450>
14:50:17,6 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652060> server_hostname='api.openai.com' timeout=None
14:50:17,17 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5424b10>
14:50:17,18 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:17,18 httpcore.http11 DEBUG send_request_headers.complete
14:50:17,19 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:17,19 httpcore.http11 DEBUG send_request_body.complete
14:50:17,19 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:17,216 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'99'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'be1eb0499ee00cb0ad4ee25cb5643c1a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487ed45c8d4cc9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:17,222 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:50:17,224 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:17,226 httpcore.http11 DEBUG receive_response_body.complete
14:50:17,226 httpcore.http11 DEBUG response_closed.started
14:50:17,227 httpcore.http11 DEBUG response_closed.complete
14:50:17,228 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:50:17,262 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nCan you move a little bit down?\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:50:17,277 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:50:17,280 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545b5d0>
14:50:17,280 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651fd0> server_hostname='api.openai.com' timeout=None
14:50:17,287 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545b590>
14:50:17,288 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:17,289 httpcore.http11 DEBUG send_request_headers.complete
14:50:17,290 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:17,290 httpcore.http11 DEBUG send_request_body.complete
14:50:17,291 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:17,525 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c2bd392328df8999bfb02dba8c657a1b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zYVaF5d1OMGUmSU0.XWlLxeIL7P0AUEs4FzmodkuEwc-1702410617-1-AfiY8AG4QtGdKrQuH2FD47KEShfSZQLphjMw9AYcFbQmzb6TTfQJsadosyb/G70AnkCRBNcH/W4bMCMrQB47XsE=; path=/; expires=Tue, 12-Dec-23 20:20:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=n0kU4ELhSV8PWcSO1fjkd8GnYLBp2w510S.QG5VJ7K4-1702410617520-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487ed61f664cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:17,532 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:50:17,534 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:17,536 httpcore.http11 DEBUG receive_response_body.complete
14:50:17,536 httpcore.http11 DEBUG response_closed.started
14:50:17,537 httpcore.http11 DEBUG response_closed.complete
14:50:17,538 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:50:17,553 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:50:17,557 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:50:20,960 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:50:20,967 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:50:20,974 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:20,975 httpcore.http11 DEBUG send_request_headers.complete
14:50:20,976 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:20,976 httpcore.http11 DEBUG send_request_body.complete
14:50:20,976 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:21,485 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:21 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'425'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ba0785960e0b154da3a0ac71311e612b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487eed1b144cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:21,490 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:50:21,491 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:22,580 httpcore.http11 DEBUG receive_response_body.complete
14:50:22,581 httpcore.http11 DEBUG response_closed.started
14:50:22,582 httpcore.http11 DEBUG response_closed.complete
14:50:22,583 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:50:22,644 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:50:35,51 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:50:35,59 httpcore.connection DEBUG close.started
14:50:35,60 httpcore.connection DEBUG close.complete
14:50:35,61 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:50:35,63 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5466010>
14:50:35,64 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:50:35,78 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5466090>
14:50:35,78 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:35,80 httpcore.http11 DEBUG send_request_headers.complete
14:50:35,81 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:35,106 httpcore.http11 DEBUG send_request_body.complete
14:50:35,106 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:38,167 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:38 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'2693'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9c625e5efbdfa80c594ed1c01bfacc3c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487f454c2f3068-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:38,174 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:50:38,176 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:38,178 httpcore.http11 DEBUG receive_response_body.complete
14:50:38,178 httpcore.http11 DEBUG response_closed.started
14:50:38,179 httpcore.http11 DEBUG response_closed.complete
14:50:38,179 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:50:38,180 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:50:38,210 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nand bear policy in the future, we've gone too far. I think was not infection. So, I really like the workout that I had in the morning which was going to be addictive. You know, I was following my doctor around and it looked like my body was changing, so it just seemed to be voltage growing and I can do all the work,\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:50:38,214 httpcore.connection DEBUG close.started
14:50:38,214 httpcore.connection DEBUG close.complete
14:50:38,215 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:50:38,217 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546d290>
14:50:38,218 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651fd0> server_hostname='api.openai.com' timeout=None
14:50:38,227 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546d310>
14:50:38,228 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:38,229 httpcore.http11 DEBUG send_request_headers.complete
14:50:38,229 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:38,231 httpcore.http11 DEBUG send_request_body.complete
14:50:38,231 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:38,483 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'135'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6bf400d05be8d37c2c96e1fd869c6d84'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487f58ecd24cf6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:38,489 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:50:38,490 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:38,491 httpcore.http11 DEBUG receive_response_body.complete
14:50:38,492 httpcore.http11 DEBUG response_closed.started
14:50:38,492 httpcore.http11 DEBUG response_closed.complete
14:50:38,492 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:50:38,500 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:50:38,504 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:38,505 httpcore.http11 DEBUG send_request_headers.complete
14:50:38,505 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:38,506 httpcore.http11 DEBUG send_request_body.complete
14:50:38,506 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:39,26 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:39 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'426'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4245d4c3b64ec9dc6d4e96b18e53166a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487f5aa8b43068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:39,31 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:50:39,32 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:40,138 httpcore.http11 DEBUG receive_response_body.complete
14:50:40,140 httpcore.http11 DEBUG response_closed.started
14:50:40,140 httpcore.http11 DEBUG response_closed.complete
14:50:40,141 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:50:40,215 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:50:52,788 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:50:52,792 httpcore.connection DEBUG close.started
14:50:52,792 httpcore.connection DEBUG close.complete
14:50:52,793 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:50:52,796 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5458890>
14:50:52,796 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:50:52,803 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5464fd0>
14:50:52,803 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:52,804 httpcore.http11 DEBUG send_request_headers.complete
14:50:52,804 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:52,827 httpcore.http11 DEBUG send_request_body.complete
14:50:52,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:53,893 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:53 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'6'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fbe2ae824622e68e1c0bbf7bfe7e66c4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487fb40a014cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:53,898 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:50:53,899 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:53,901 httpcore.http11 DEBUG receive_response_body.complete
14:50:53,901 httpcore.http11 DEBUG response_closed.started
14:50:53,902 httpcore.http11 DEBUG response_closed.complete
14:50:53,903 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:50:53,904 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:50:53,933 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nTsss.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:50:53,936 httpcore.connection DEBUG close.started
14:50:53,937 httpcore.connection DEBUG close.complete
14:50:53,937 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:50:53,940 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac54590d0>
14:50:53,940 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651fd0> server_hostname='api.openai.com' timeout=None
14:50:53,946 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5458e10>
14:50:53,946 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:53,948 httpcore.http11 DEBUG send_request_headers.complete
14:50:53,948 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:53,948 httpcore.http11 DEBUG send_request_body.complete
14:50:53,949 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:54,165 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'de0d32e760abd91ff5b3f8eff63ef444'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487fbb2c984cf6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:54,171 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:50:54,172 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:54,174 httpcore.http11 DEBUG receive_response_body.complete
14:50:54,174 httpcore.http11 DEBUG response_closed.started
14:50:54,175 httpcore.http11 DEBUG response_closed.complete
14:50:54,175 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:50:54,182 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:50:54,186 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:50:54,187 httpcore.http11 DEBUG send_request_headers.complete
14:50:54,187 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:50:54,188 httpcore.http11 DEBUG send_request_body.complete
14:50:54,188 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:50:54,935 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:50:54 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'429'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'03e3d0090937c8263ecc01b1f87d892e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83487fbcad694cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:50:54,940 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:50:54,941 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:50:55,954 httpcore.http11 DEBUG receive_response_body.complete
14:50:55,955 httpcore.http11 DEBUG response_closed.started
14:50:55,956 httpcore.http11 DEBUG response_closed.complete
14:50:55,957 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:50:56,26 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:51:08,504 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:51:08,509 httpcore.connection DEBUG close.started
14:51:08,509 httpcore.connection DEBUG close.complete
14:51:08,510 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:51:08,512 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546ee90>
14:51:08,512 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:51:08,518 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546dd90>
14:51:08,519 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:51:08,520 httpcore.http11 DEBUG send_request_headers.complete
14:51:08,520 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:51:08,583 httpcore.http11 DEBUG send_request_body.complete
14:51:08,584 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:51:09,645 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:51:09 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b2048e2eef7a64f23b6a7c10b9b8a871'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348801649943bab-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:51:09,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:51:09,652 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:51:09,653 httpcore.http11 DEBUG receive_response_body.complete
14:51:09,654 httpcore.http11 DEBUG response_closed.started
14:51:09,654 httpcore.http11 DEBUG response_closed.complete
14:51:09,654 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:51:09,655 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:51:09,686 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nyes\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:51:09,689 httpcore.connection DEBUG close.started
14:51:09,689 httpcore.connection DEBUG close.complete
14:51:09,690 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:51:09,692 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac547a110>
14:51:09,692 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651fd0> server_hostname='api.openai.com' timeout=None
14:51:09,700 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac547a190>
14:51:09,700 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:51:09,701 httpcore.http11 DEBUG send_request_headers.complete
14:51:09,701 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:51:09,702 httpcore.http11 DEBUG send_request_body.complete
14:51:09,702 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:51:10,46 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:51:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7fbefb1ae4085bbe9883b76a345e45a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348801da8084ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:51:10,53 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:51:10,54 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:51:10,55 httpcore.http11 DEBUG receive_response_body.complete
14:51:10,56 httpcore.http11 DEBUG response_closed.started
14:51:10,56 httpcore.http11 DEBUG response_closed.complete
14:51:10,56 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:51:10,74 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:51:10,79 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:51:13,481 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:51:13,498 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:51:13,501 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:51:15,503 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:51:15,520 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:51:15,525 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:51:18,928 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:51:18,938 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:51:18,941 httpcore.connection DEBUG close.started
14:51:18,942 httpcore.connection DEBUG close.complete
14:51:18,943 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:51:18,972 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546fb10>
14:51:18,973 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:51:18,982 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546fcd0>
14:51:18,982 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:51:18,984 httpcore.http11 DEBUG send_request_headers.complete
14:51:18,984 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:51:18,985 httpcore.http11 DEBUG send_request_body.complete
14:51:18,986 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:51:19,430 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:51:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8e74fb0b01cc3f80fded5a4cad481666'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83488057aba53074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:51:19,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:51:19,436 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:51:19,845 httpcore.http11 DEBUG receive_response_body.complete
14:51:19,846 httpcore.http11 DEBUG response_closed.started
14:51:19,847 httpcore.http11 DEBUG response_closed.complete
14:51:19,847 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:51:19,912 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:51:30,830 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:51:30,836 httpcore.connection DEBUG close.started
14:51:30,837 httpcore.connection DEBUG close.complete
14:51:30,837 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:51:30,840 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545b450>
14:51:30,840 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:51:30,848 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545a1d0>
14:51:30,848 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:51:30,850 httpcore.http11 DEBUG send_request_headers.complete
14:51:30,850 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:51:30,887 httpcore.http11 DEBUG send_request_body.complete
14:51:30,888 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:51:31,797 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:51:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'457'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a9141c28b10f3308834d3934418934a5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834880a1db324cda-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:51:31,802 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:51:31,803 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:51:31,804 httpcore.http11 DEBUG receive_response_body.complete
14:51:31,804 httpcore.http11 DEBUG response_closed.started
14:51:31,805 httpcore.http11 DEBUG response_closed.complete
14:51:31,805 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:51:31,806 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:51:31,837 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nCan you please put the second candle to the upper left quadrant?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:51:31,841 httpcore.connection DEBUG close.started
14:51:31,841 httpcore.connection DEBUG close.complete
14:51:31,842 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:51:31,844 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5424b10>
14:51:31,844 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652060> server_hostname='api.openai.com' timeout=None
14:51:31,849 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5424d10>
14:51:31,850 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:51:31,851 httpcore.http11 DEBUG send_request_headers.complete
14:51:31,851 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:51:31,852 httpcore.http11 DEBUG send_request_body.complete
14:51:31,852 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:51:32,47 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:51:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'102'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3d5f024767a73b7df0e9cb904c6cc326'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834880a818163059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:51:32,57 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:51:32,58 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:51:32,59 httpcore.http11 DEBUG receive_response_body.complete
14:51:32,59 httpcore.http11 DEBUG response_closed.started
14:51:32,59 httpcore.http11 DEBUG response_closed.complete
14:51:32,60 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:51:32,95 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it somewhere on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nCan you please put the second candle to the upper left quadrant?\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:51:32,98 httpcore.connection DEBUG close.started
14:51:32,99 httpcore.connection DEBUG close.complete
14:51:32,99 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:51:32,103 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5433c10>
14:51:32,103 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652840> server_hostname='api.openai.com' timeout=None
14:51:32,108 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5433e90>
14:51:32,109 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:51:32,110 httpcore.http11 DEBUG send_request_headers.complete
14:51:32,110 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:51:32,110 httpcore.http11 DEBUG send_request_body.complete
14:51:32,111 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:51:32,791 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:51:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'582'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8b44118c3bdee11e081d1e2644972335'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834880a9b9b14cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:51:32,796 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:51:32,797 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:51:32,798 httpcore.http11 DEBUG receive_response_body.complete
14:51:32,798 httpcore.http11 DEBUG response_closed.started
14:51:32,799 httpcore.http11 DEBUG response_closed.complete
14:51:32,799 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:51:33,45 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:51:33,48 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:51:39,550 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:51:39,569 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:51:39,574 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:51:44,576 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:51:44,594 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:51:44,600 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:51:46,602 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:51:46,619 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:51:46,622 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:51:50,27 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:51:50,45 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:51:50,49 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:51:56,551 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:51:56,569 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:51:56,573 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:52:00,775 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:52:00,793 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:52:00,796 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:52:04,598 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:52:04,603 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:52:04,607 httpcore.connection DEBUG close.started
14:52:04,607 httpcore.connection DEBUG close.complete
14:52:04,608 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:52:04,611 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac547b390>
14:52:04,611 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:52:04,617 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac54791d0>
14:52:04,617 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:52:04,618 httpcore.http11 DEBUG send_request_headers.complete
14:52:04,619 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:52:04,619 httpcore.http11 DEBUG send_request_body.complete
14:52:04,620 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:52:05,143 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:52:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'446'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a805b946b3a9f659645fb682084c274f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83488174dfe54d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:52:05,148 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:52:05,149 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:52:06,262 httpcore.http11 DEBUG receive_response_body.complete
14:52:06,263 httpcore.http11 DEBUG response_closed.started
14:52:06,263 httpcore.http11 DEBUG response_closed.complete
14:52:06,263 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:52:06,334 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:52:18,696 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:52:18,700 httpcore.connection DEBUG close.started
14:52:18,701 httpcore.connection DEBUG close.complete
14:52:18,701 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:52:18,704 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac54755d0>
14:52:18,704 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:52:18,710 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5475650>
14:52:18,710 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:52:18,711 httpcore.http11 DEBUG send_request_headers.complete
14:52:18,711 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:52:18,736 httpcore.http11 DEBUG send_request_body.complete
14:52:18,737 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:52:19,913 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:52:19 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'515'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f507d79960dae16c127141d22b6a9df0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834881ccfefe4cc2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:52:19,921 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:52:19,922 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:52:19,924 httpcore.http11 DEBUG receive_response_body.complete
14:52:19,924 httpcore.http11 DEBUG response_closed.started
14:52:19,925 httpcore.http11 DEBUG response_closed.complete
14:52:19,925 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:52:19,926 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:52:19,959 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nIs this the problem that he has? No, but it's going to be on top of that.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:52:19,963 httpcore.connection DEBUG close.started
14:52:19,964 httpcore.connection DEBUG close.complete
14:52:19,964 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:52:19,993 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545b890>
14:52:19,994 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652060> server_hostname='api.openai.com' timeout=None
14:52:20,4 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545ba50>
14:52:20,4 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:52:20,6 httpcore.http11 DEBUG send_request_headers.complete
14:52:20,6 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:52:20,7 httpcore.http11 DEBUG send_request_body.complete
14:52:20,7 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:52:20,296 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:52:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3fb73e624fe5eb21a803e678f0d4511d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834881d50baa4d18-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:52:20,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:52:20,303 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:52:20,304 httpcore.http11 DEBUG receive_response_body.complete
14:52:20,305 httpcore.http11 DEBUG response_closed.started
14:52:20,305 httpcore.http11 DEBUG response_closed.complete
14:52:20,305 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:52:20,340 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nIs this the problem that he has? No, but it's going to be on top of that.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:52:20,352 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:52:20,355 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac547b490>
14:52:20,355 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac56523c0> server_hostname='api.openai.com' timeout=None
14:52:20,363 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac547bf50>
14:52:20,364 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:52:20,365 httpcore.http11 DEBUG send_request_headers.complete
14:52:20,365 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:52:20,366 httpcore.http11 DEBUG send_request_body.complete
14:52:20,367 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:52:21,969 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:52:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1513'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7f5ca2a8bc8f6f1a88caeca6533a620c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jzTUBD4NbZrt6JkQc_nFTCv_krthudCTurENo13e9Q8-1702410741-1-AdLi3TCrdHdIHn29GqvwxAlU0YQXpQ/h0TRbchXo1x1ocH9mtOsjV9nSD94DBhUgbN9hTh8JpfPwEhB4EYGZJWM=; path=/; expires=Tue, 12-Dec-23 20:22:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pUJzLZOFhtQ4975PchHSUATArSWwGG2ApTMdGz0g.A4-1702410741964-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834881d74ed33059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:52:21,976 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:52:21,977 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:52:21,979 httpcore.http11 DEBUG receive_response_body.complete
14:52:21,979 httpcore.http11 DEBUG response_closed.started
14:52:21,980 httpcore.http11 DEBUG response_closed.complete
14:52:21,981 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:52:21,988 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I understand that this is not the problem you are trying to solve. Let's focus on the task at hand - placing the candles on the cake. Can you tell me if this is a good location for the candles? You can say either yes, no, or move to the left, to the right, move up or move down.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:52:21,992 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:52:21,993 httpcore.http11 DEBUG send_request_headers.complete
14:52:21,993 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:52:21,994 httpcore.http11 DEBUG send_request_body.complete
14:52:21,994 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:52:22,650 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:52:22 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'549'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b154e9e67fb7e4b9a91070b54d4c4dae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834881e17b3f4cc2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:52:22,655 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:52:22,656 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:52:25,115 httpcore.http11 DEBUG receive_response_body.complete
14:52:25,116 httpcore.http11 DEBUG response_closed.started
14:52:25,116 httpcore.http11 DEBUG response_closed.complete
14:52:25,117 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:52:25,190 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:52:47,978 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:52:47,982 httpcore.connection DEBUG close.started
14:52:47,982 httpcore.connection DEBUG close.complete
14:52:47,983 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:52:47,986 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5466b90>
14:52:47,986 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:52:47,991 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5467ed0>
14:52:47,992 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:52:47,993 httpcore.http11 DEBUG send_request_headers.complete
14:52:47,993 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:52:48,14 httpcore.http11 DEBUG send_request_body.complete
14:52:48,14 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:52:48,757 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:52:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'17'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c08d5a132c0ad5ff9241de59b8ab08c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83488283fab54cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:52:48,761 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:52:48,762 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:52:48,763 httpcore.http11 DEBUG receive_response_body.complete
14:52:48,763 httpcore.http11 DEBUG response_closed.started
14:52:48,764 httpcore.http11 DEBUG response_closed.complete
14:52:48,764 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:52:48,765 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:52:48,797 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI understand that this is not the problem you are trying to solve. Let's focus on the task at hand - placing the candles on the cake. Can you tell me if this is a good location for the candles? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up, please.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:52:48,801 httpcore.connection DEBUG close.started
14:52:48,801 httpcore.connection DEBUG close.complete
14:52:48,802 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:52:48,804 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546c410>
14:52:48,804 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652060> server_hostname='api.openai.com' timeout=None
14:52:48,811 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546de90>
14:52:48,812 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:52:48,813 httpcore.http11 DEBUG send_request_headers.complete
14:52:48,813 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:52:48,813 httpcore.http11 DEBUG send_request_body.complete
14:52:48,814 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:52:49,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:52:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4fde1fbf86d7cf647849be9edd270856'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834882891b514d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:52:49,26 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:52:49,26 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:52:49,27 httpcore.http11 DEBUG receive_response_body.complete
14:52:49,28 httpcore.http11 DEBUG response_closed.started
14:52:49,28 httpcore.http11 DEBUG response_closed.complete
14:52:49,28 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:52:49,60 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI understand that this is not the problem you are trying to solve. Let's focus on the task at hand - placing the candles on the cake. Can you tell me if this is a good location for the candles? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up, please.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:52:49,63 httpcore.connection DEBUG close.started
14:52:49,64 httpcore.connection DEBUG close.complete
14:52:49,64 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:52:49,67 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5467110>
14:52:49,67 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651fd0> server_hostname='api.openai.com' timeout=None
14:52:49,75 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5464890>
14:52:49,75 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:52:49,76 httpcore.http11 DEBUG send_request_headers.complete
14:52:49,76 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:52:49,77 httpcore.http11 DEBUG send_request_body.complete
14:52:49,77 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:52:49,296 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:52:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'41486d2e12e7d57d0ad74b0ddbaeae43'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348828abed03ba0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:52:49,302 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:52:49,302 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:52:49,303 httpcore.http11 DEBUG receive_response_body.complete
14:52:49,304 httpcore.http11 DEBUG response_closed.started
14:52:49,304 httpcore.http11 DEBUG response_closed.complete
14:52:49,305 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:52:49,321 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:52:49,325 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:52:52,728 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:52:52,735 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:52:52,742 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:52:52,743 httpcore.http11 DEBUG send_request_headers.complete
14:52:52,743 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:52:52,744 httpcore.http11 DEBUG send_request_body.complete
14:52:52,744 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:52:53,249 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:52:53 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'407'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c7a206a8f1461e8ec692cbc064bb9c0f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834882a1ae994cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:52:53,252 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:52:53,253 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:52:54,555 httpcore.http11 DEBUG receive_response_body.complete
14:52:54,556 httpcore.http11 DEBUG response_closed.started
14:52:54,557 httpcore.http11 DEBUG response_closed.complete
14:52:54,557 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:52:54,629 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:53:07,126 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:53:07,132 httpcore.connection DEBUG close.started
14:53:07,132 httpcore.connection DEBUG close.complete
14:53:07,133 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:53:07,135 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546e6d0>
14:53:07,136 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:53:07,142 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546ff90>
14:53:07,143 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:53:07,144 httpcore.http11 DEBUG send_request_headers.complete
14:53:07,144 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:53:07,169 httpcore.http11 DEBUG send_request_body.complete
14:53:07,170 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:53:07,995 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:53:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'372'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'64b99272466ce943cc051238e436a9d6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834882fba8b06ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:53:08,0 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:53:08,1 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:53:08,3 httpcore.http11 DEBUG receive_response_body.complete
14:53:08,3 httpcore.http11 DEBUG response_closed.started
14:53:08,4 httpcore.http11 DEBUG response_closed.complete
14:53:08,5 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:53:08,6 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:53:08,36 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove left, please.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:53:08,39 httpcore.connection DEBUG close.started
14:53:08,39 httpcore.connection DEBUG close.complete
14:53:08,40 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:53:08,42 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5459ed0>
14:53:08,43 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651fd0> server_hostname='api.openai.com' timeout=None
14:53:08,48 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545bd10>
14:53:08,48 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:53:08,49 httpcore.http11 DEBUG send_request_headers.complete
14:53:08,50 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:53:08,50 httpcore.http11 DEBUG send_request_body.complete
14:53:08,50 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:53:08,312 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:53:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9fe42e4f900a340566a53e7bc6eeeb87'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348830159e34cf9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:53:08,318 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:53:08,319 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:53:08,320 httpcore.http11 DEBUG receive_response_body.complete
14:53:08,320 httpcore.http11 DEBUG response_closed.started
14:53:08,320 httpcore.http11 DEBUG response_closed.complete
14:53:08,321 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:53:08,338 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:53:08,342 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:53:11,744 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:53:11,751 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:53:11,756 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:53:11,757 httpcore.http11 DEBUG send_request_headers.complete
14:53:11,758 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:53:11,758 httpcore.http11 DEBUG send_request_body.complete
14:53:11,758 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:53:12,461 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:53:12 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'574'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9e64ae6bb30e80beab299fdba37871e2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834883187d426ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:53:12,466 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:53:12,467 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:53:13,540 httpcore.http11 DEBUG receive_response_body.complete
14:53:13,541 httpcore.http11 DEBUG response_closed.started
14:53:13,542 httpcore.http11 DEBUG response_closed.complete
14:53:13,543 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:53:13,612 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:53:26,241 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah9.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:53:26,246 httpcore.connection DEBUG close.started
14:53:26,247 httpcore.connection DEBUG close.complete
14:53:26,248 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:53:26,276 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5474390>
14:53:26,277 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:53:26,283 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac54768d0>
14:53:26,283 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:53:26,285 httpcore.http11 DEBUG send_request_headers.complete
14:53:26,285 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:53:26,308 httpcore.http11 DEBUG send_request_body.complete
14:53:26,309 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:53:26,957 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:53:26 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'329'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c98f1a2943778cd1c53d4ccac563040b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834883734cc14d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:53:26,962 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:53:26,962 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:53:26,963 httpcore.http11 DEBUG receive_response_body.complete
14:53:26,963 httpcore.http11 DEBUG response_closed.started
14:53:26,964 httpcore.http11 DEBUG response_closed.complete
14:53:26,964 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:53:26,965 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:53:26,994 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:53:26,997 httpcore.connection DEBUG close.started
14:53:26,998 httpcore.connection DEBUG close.complete
14:53:26,998 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:53:27,1 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5485350>
14:53:27,1 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651fd0> server_hostname='api.openai.com' timeout=None
14:53:27,7 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5485210>
14:53:27,7 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:53:27,8 httpcore.http11 DEBUG send_request_headers.complete
14:53:27,9 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:53:27,9 httpcore.http11 DEBUG send_request_body.complete
14:53:27,9 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:53:27,233 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:53:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'132'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd77d955350c37af30a4f9bd55685b88b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83488377cbed4cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:53:27,240 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:53:27,241 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:53:27,243 httpcore.http11 DEBUG receive_response_body.complete
14:53:27,244 httpcore.http11 DEBUG response_closed.started
14:53:27,245 httpcore.http11 DEBUG response_closed.complete
14:53:27,245 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:53:27,261 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:53:27,266 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:53:30,669 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:53:30,687 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:53:30,692 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:53:32,694 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:53:32,710 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:53:32,716 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:53:36,119 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:53:36,127 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:53:36,135 httpcore.connection DEBUG close.started
14:53:36,136 httpcore.connection DEBUG close.complete
14:53:36,136 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:53:36,139 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5474450>
14:53:36,139 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:53:36,145 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5475f50>
14:53:36,145 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:53:36,147 httpcore.http11 DEBUG send_request_headers.complete
14:53:36,147 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:53:36,148 httpcore.http11 DEBUG send_request_body.complete
14:53:36,148 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:53:36,765 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:53:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'484'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6c382bd9ac40d325f8f6eca21f39b826'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834883b0ed4f3049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:53:36,770 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:53:36,770 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:53:37,139 httpcore.http11 DEBUG receive_response_body.complete
14:53:37,140 httpcore.http11 DEBUG response_closed.started
14:53:37,141 httpcore.http11 DEBUG response_closed.complete
14:53:37,142 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:53:37,213 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah10.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:53:48,463 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah10.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:53:48,468 httpcore.connection DEBUG close.started
14:53:48,469 httpcore.connection DEBUG close.complete
14:53:48,469 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:53:48,472 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545ac10>
14:53:48,472 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:53:48,478 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac545b710>
14:53:48,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:53:48,480 httpcore.http11 DEBUG send_request_headers.complete
14:53:48,480 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:53:48,516 httpcore.http11 DEBUG send_request_body.complete
14:53:48,517 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:53:49,444 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:53:49 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'450'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'783c76940dbcfcf50651d6860a057172'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834883fe0a154d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:53:49,449 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:53:49,450 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:53:49,452 httpcore.http11 DEBUG receive_response_body.complete
14:53:49,453 httpcore.http11 DEBUG response_closed.started
14:53:49,454 httpcore.http11 DEBUG response_closed.complete
14:53:49,454 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:53:49,455 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:53:49,484 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nCan you place the third candle to the lower left quadrant?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:53:49,490 httpcore.connection DEBUG close.started
14:53:49,491 httpcore.connection DEBUG close.complete
14:53:49,492 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:53:49,494 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546de90>
14:53:49,494 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652060> server_hostname='api.openai.com' timeout=None
14:53:49,500 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546d8d0>
14:53:49,500 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:53:49,501 httpcore.http11 DEBUG send_request_headers.complete
14:53:49,502 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:53:49,502 httpcore.http11 DEBUG send_request_body.complete
14:53:49,502 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:53:49,726 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:53:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd667663ab411b1baac407602b64da242'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834884046ec73b8e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:53:49,732 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:53:49,733 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:53:49,735 httpcore.http11 DEBUG receive_response_body.complete
14:53:49,736 httpcore.http11 DEBUG response_closed.started
14:53:49,736 httpcore.http11 DEBUG response_closed.complete
14:53:49,737 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:53:49,771 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it somewhere on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == y0 - 1\nlambda x1, x0: x1==x0                                                \n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nCan you place the third candle to the lower left quadrant?\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:53:49,774 httpcore.connection DEBUG close.started
14:53:49,774 httpcore.connection DEBUG close.complete
14:53:49,775 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:53:49,778 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5479150>
14:53:49,779 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652840> server_hostname='api.openai.com' timeout=None
14:53:49,789 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5433f50>
14:53:49,790 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:53:49,792 httpcore.http11 DEBUG send_request_headers.complete
14:53:49,792 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:53:49,794 httpcore.http11 DEBUG send_request_body.complete
14:53:49,794 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:53:50,398 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:53:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'483'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c85bf6642b87de0ba91e265936b914b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83488406399e4ce9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:53:50,406 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:53:50,407 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:53:50,409 httpcore.http11 DEBUG receive_response_body.complete
14:53:50,410 httpcore.http11 DEBUG response_closed.started
14:53:50,410 httpcore.http11 DEBUG response_closed.complete
14:53:50,410 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:53:50,742 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:53:50,746 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:53:57,249 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:53:57,268 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:53:57,272 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:54:02,274 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:54:02,288 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:54:02,292 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:54:04,295 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:54:04,313 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:54:04,317 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:54:07,719 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:54:07,737 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:54:07,740 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:54:14,242 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:54:14,263 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:54:14,267 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:54:18,471 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:54:18,490 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:54:18,495 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:54:21,497 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:54:21,502 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:54:21,508 httpcore.connection DEBUG close.started
14:54:21,509 httpcore.connection DEBUG close.complete
14:54:21,510 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:54:21,526 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546e210>
14:54:21,527 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:54:21,533 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546f4d0>
14:54:21,534 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:54:21,536 httpcore.http11 DEBUG send_request_headers.complete
14:54:21,537 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:54:21,538 httpcore.http11 DEBUG send_request_body.complete
14:54:21,538 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:54:22,203 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:54:22 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'552'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f5a79975d03b3d41317757d6d7e4bacf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834884cc9dd63074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:54:22,209 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:54:22,210 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:54:23,160 httpcore.http11 DEBUG receive_response_body.complete
14:54:23,161 httpcore.http11 DEBUG response_closed.started
14:54:23,161 httpcore.http11 DEBUG response_closed.complete
14:54:23,162 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:54:23,235 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah11.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:54:35,675 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah11.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:54:35,679 httpcore.connection DEBUG close.started
14:54:35,680 httpcore.connection DEBUG close.complete
14:54:35,680 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:54:35,710 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5485c10>
14:54:35,710 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:54:35,718 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5485690>
14:54:35,719 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:54:35,721 httpcore.http11 DEBUG send_request_headers.complete
14:54:35,722 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:54:35,750 httpcore.http11 DEBUG send_request_body.complete
14:54:35,751 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:54:36,488 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:54:36 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cc9a60b3bc3a73a32ecdad79bcd20814'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834885254a854d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:54:36,491 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:54:36,491 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:54:36,492 httpcore.http11 DEBUG receive_response_body.complete
14:54:36,492 httpcore.http11 DEBUG response_closed.started
14:54:36,493 httpcore.http11 DEBUG response_closed.complete
14:54:36,493 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:54:36,494 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:54:36,526 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the left.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:54:36,529 httpcore.connection DEBUG close.started
14:54:36,530 httpcore.connection DEBUG close.complete
14:54:36,530 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:54:36,532 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546fc90>
14:54:36,533 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5652060> server_hostname='api.openai.com' timeout=None
14:54:36,540 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac546f3d0>
14:54:36,540 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:54:36,542 httpcore.http11 DEBUG send_request_headers.complete
14:54:36,542 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:54:36,542 httpcore.http11 DEBUG send_request_body.complete
14:54:36,543 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:54:36,746 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:54:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1b428584287db8cee12642ef669e18a4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348852a6df04cd9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:54:36,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:54:36,752 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:54:36,753 httpcore.http11 DEBUG receive_response_body.complete
14:54:36,754 httpcore.http11 DEBUG response_closed.started
14:54:36,754 httpcore.http11 DEBUG response_closed.complete
14:54:36,755 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:54:36,787 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the left.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:54:36,790 httpcore.connection DEBUG close.started
14:54:36,791 httpcore.connection DEBUG close.complete
14:54:36,791 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:54:36,794 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5464850>
14:54:36,794 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651fd0> server_hostname='api.openai.com' timeout=None
14:54:36,799 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5466c90>
14:54:36,799 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:54:36,800 httpcore.http11 DEBUG send_request_headers.complete
14:54:36,800 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:54:36,801 httpcore.http11 DEBUG send_request_body.complete
14:54:36,801 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:54:37,15 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:54:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a9c1ac9b464d358e40cd1be37d93fd87'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348852c0fb24d0b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:54:37,22 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:54:37,22 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:54:37,23 httpcore.http11 DEBUG receive_response_body.complete
14:54:37,24 httpcore.http11 DEBUG response_closed.started
14:54:37,24 httpcore.http11 DEBUG response_closed.complete
14:54:37,24 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:54:37,40 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:54:37,43 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:54:40,445 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:54:40,455 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
14:54:40,460 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:54:40,461 httpcore.http11 DEBUG send_request_headers.complete
14:54:40,461 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:54:40,462 httpcore.http11 DEBUG send_request_body.complete
14:54:40,462 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:54:40,949 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:54:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd5350722fa4029a71d7c519e4e954488'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83488542e9114d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:54:40,954 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
14:54:40,954 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:54:41,897 httpcore.http11 DEBUG receive_response_body.complete
14:54:41,898 httpcore.http11 DEBUG response_closed.started
14:54:41,899 httpcore.http11 DEBUG response_closed.complete
14:54:41,900 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
14:54:41,970 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Sarah12.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
14:54:54,428 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Sarah12.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
14:54:54,433 httpcore.connection DEBUG close.started
14:54:54,433 httpcore.connection DEBUG close.complete
14:54:54,434 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
14:54:54,436 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5474690>
14:54:54,437 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651eb0> server_hostname='api.openai.com' timeout=5.0
14:54:54,443 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac5475b10>
14:54:54,443 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:54:54,444 httpcore.http11 DEBUG send_request_headers.complete
14:54:54,445 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:54:54,468 httpcore.http11 DEBUG send_request_body.complete
14:54:54,468 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:54:55,163 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:54:55 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'287'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fe4ec1f05f2b6b54a7f4d236eddfb7e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348859a4d1c4d0c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:54:55,167 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
14:54:55,168 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:54:55,169 httpcore.http11 DEBUG receive_response_body.complete
14:54:55,169 httpcore.http11 DEBUG response_closed.started
14:54:55,170 httpcore.http11 DEBUG response_closed.complete
14:54:55,170 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
14:54:55,171 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
14:54:55,202 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
14:54:55,205 httpcore.connection DEBUG close.started
14:54:55,206 httpcore.connection DEBUG close.complete
14:54:55,206 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
14:54:55,209 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac54869d0>
14:54:55,209 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0ac5651fd0> server_hostname='api.openai.com' timeout=None
14:54:55,214 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0ac54872d0>
14:54:55,215 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
14:54:55,216 httpcore.http11 DEBUG send_request_headers.complete
14:54:55,216 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
14:54:55,217 httpcore.http11 DEBUG send_request_body.complete
14:54:55,217 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
14:54:55,436 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 19:54:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5393f8c0953db16f040b169f37417534'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348859f1f334ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
14:54:55,442 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
14:54:55,443 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
14:54:55,444 httpcore.http11 DEBUG receive_response_body.complete
14:54:55,444 httpcore.http11 DEBUG response_closed.started
14:54:55,444 httpcore.http11 DEBUG response_closed.complete
14:54:55,445 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
14:54:55,461 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:54:55,465 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:54:58,868 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:54:58,886 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:54:58,890 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:55:00,893 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
14:55:00,913 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
14:55:00,916 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
14:55:04,318 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:33:48,871 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
15:33:48,874 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
15:33:49,705 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
15:33:49,706 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
15:33:49,749 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
15:33:49,750 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
15:33:49,798 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
15:33:49,799 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
15:33:49,840 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
15:33:49,841 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
15:33:49,888 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
15:33:49,889 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
15:33:49,933 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
15:33:49,934 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
15:33:49,981 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
15:33:49,982 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
15:33:50,23 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
15:33:50,24 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
15:34:07,778 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Mitchell. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:34:07,795 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:34:07,814 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61aac8290>
15:34:07,815 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:34:07,822 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a7e0c50>
15:34:07,823 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:34:07,825 httpcore.http11 DEBUG send_request_headers.complete
15:34:07,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:34:07,826 httpcore.http11 DEBUG send_request_body.complete
15:34:07,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:34:08,321 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:34:08 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'393'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'dc3d8ec128ee2cc42a7fd6cdbde53b41'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=NdZdYFcyiIc9kQJ89FQw2grbf2navjBIzPI12hIot9M-1702413248-1-AeH0sVbxWTE39gSXKiw336MSHQ/4jucmhZi3J7ScsT0NOB87NnO6g/xcNr+Mv579ePmoYgcTR6nt7dpDlB+jtic=; path=/; expires=Tue, 12-Dec-23 21:04:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Rzr1WEHBZ.0hS36oupowNbaeZlMTofTIE4dylgPEhlg-1702413248316-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348bf0ee9da4d02-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:34:08,326 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:34:08,326 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:34:09,56 httpcore.http11 DEBUG receive_response_body.complete
15:34:09,57 httpcore.http11 DEBUG response_closed.started
15:34:09,58 httpcore.http11 DEBUG response_closed.complete
15:34:09,59 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:34:09,148 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:34:22,471 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:34:22,481 httpcore.connection DEBUG close.started
15:34:22,482 httpcore.connection DEBUG close.complete
15:34:22,482 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:34:22,485 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a717a10>
15:34:22,485 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:34:22,492 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a716f10>
15:34:22,492 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:34:22,493 httpcore.http11 DEBUG send_request_headers.complete
15:34:22,494 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:34:22,535 httpcore.http11 DEBUG send_request_body.complete
15:34:22,535 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:34:23,449 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:34:23 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f7a4d940ef719ac8578fe9be58672262'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348bf6a9cd74d17-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:34:23,454 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:34:23,455 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:34:23,456 httpcore.http11 DEBUG receive_response_body.complete
15:34:23,456 httpcore.http11 DEBUG response_closed.started
15:34:23,456 httpcore.http11 DEBUG response_closed.complete
15:34:23,457 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:34:23,457 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:34:23,492 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Mitchell. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:34:23,504 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:34:24,513 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a578110>
15:34:24,514 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e060> server_hostname='api.openai.com' timeout=None
15:34:24,523 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5780d0>
15:34:24,524 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:34:24,526 httpcore.http11 DEBUG send_request_headers.complete
15:34:24,526 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:34:24,527 httpcore.http11 DEBUG send_request_body.complete
15:34:24,528 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:34:24,715 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:34:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'96'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'697499cb0bdd5d3dd0d0a6623da99dfb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dHJN2OI8B5LTq_w5UMBcRE9CqUJBMfbDUa7jnWZ9oYs-1702413264-1-AWPG3whTvufsQnaIkQ8LxM/1FsSo1w4stVYjSzmcPhXsir5Znyjm1MlBj9tzw+c0+L8PWvMtAAfIcdU/Fy74UPw=; path=/; expires=Tue, 12-Dec-23 21:04:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=AuUDeMum6aUffhd.02FXJ1ZdQH6Ava5KXS4i3K4fsMA-1702413264710-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348bf774dee4cf9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:34:24,723 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:34:24,724 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:34:24,726 httpcore.http11 DEBUG receive_response_body.complete
15:34:24,726 httpcore.http11 DEBUG response_closed.started
15:34:24,727 httpcore.http11 DEBUG response_closed.complete
15:34:24,728 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:34:24,763 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\n                                               \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                                                                             \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n                                               \nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0\n                                               \nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2                                    \n\nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 < surface_height // 2                                    \n                                                                                                                                       \nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:34:24,775 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:34:24,777 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a579d10>
15:34:24,778 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e840> server_hostname='api.openai.com' timeout=None
15:34:24,786 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a580fd0>
15:34:24,786 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:34:24,787 httpcore.http11 DEBUG send_request_headers.complete
15:34:24,788 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:34:24,788 httpcore.http11 DEBUG send_request_body.complete
15:34:24,788 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:34:25,456 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:34:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'558'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c03e308c8ddd9ba7eb3090266ff1280d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=B0U5s7k2IT8y6c42raRpEJRhe868PuALOqY8oPr5bnw-1702413265-1-AZSesj8B1Lj2luMM3xznecaipC6GZHsPEmY0vkMdaEO9FGsUPnEwqsbZJzgNZT4x8FnCrmx9lyA3CQPa+XWqiug=; path=/; expires=Tue, 12-Dec-23 21:04:25 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NCgR9qZeLfGouj9CVbQfBgVbFHk3JWGaLV4hNIP5qRg-1702413265452-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348bf78ec653bac-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:34:25,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:34:25,460 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:34:25,461 httpcore.http11 DEBUG receive_response_body.complete
15:34:25,461 httpcore.http11 DEBUG response_closed.started
15:34:25,461 httpcore.http11 DEBUG response_closed.complete
15:34:25,462 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:34:25,480 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:34:25,484 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:34:31,989 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:34:32,2 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:34:32,6 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:34:37,8 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:34:37,27 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:34:37,31 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:34:39,32 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:34:39,47 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:34:39,51 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:34:42,453 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:34:42,472 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:34:42,475 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:34:48,978 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:34:48,994 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:34:48,997 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:34:52,399 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:34:52,416 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:34:52,421 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:34:55,824 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:34:55,828 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:34:55,832 httpcore.connection DEBUG close.started
15:34:55,833 httpcore.connection DEBUG close.complete
15:34:55,834 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:34:55,836 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a716f10>
15:34:55,836 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:34:55,843 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58ae50>
15:34:55,844 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:34:55,846 httpcore.http11 DEBUG send_request_headers.complete
15:34:55,847 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:34:55,848 httpcore.http11 DEBUG send_request_body.complete
15:34:55,848 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:34:56,543 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:34:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'574'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9788be3e89bf9fe6ef0c101ff231ba32'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c03b0f696ac5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:34:56,549 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:34:56,550 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:34:57,428 httpcore.http11 DEBUG receive_response_body.complete
15:34:57,429 httpcore.http11 DEBUG response_closed.started
15:34:57,430 httpcore.http11 DEBUG response_closed.complete
15:34:57,431 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:34:57,507 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:35:09,775 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:35:09,783 httpcore.connection DEBUG close.started
15:35:09,784 httpcore.connection DEBUG close.complete
15:35:09,784 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:35:09,816 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5aa8d0>
15:35:09,817 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:35:09,824 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5aa950>
15:35:09,824 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:35:09,826 httpcore.http11 DEBUG send_request_headers.complete
15:35:09,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:35:09,850 httpcore.http11 DEBUG send_request_body.complete
15:35:09,851 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:35:10,666 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:35:10 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b0ab47d898178a22bbd3200898e8ecd3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c09269a34d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:35:10,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:35:10,671 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:35:10,672 httpcore.http11 DEBUG receive_response_body.complete
15:35:10,673 httpcore.http11 DEBUG response_closed.started
15:35:10,673 httpcore.http11 DEBUG response_closed.complete
15:35:10,674 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:35:10,674 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:35:10,722 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:35:10,729 httpcore.connection DEBUG close.started
15:35:10,729 httpcore.connection DEBUG close.complete
15:35:10,730 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:35:10,734 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a578190>
15:35:10,735 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e060> server_hostname='api.openai.com' timeout=None
15:35:10,744 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a579e90>
15:35:10,745 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:35:10,748 httpcore.http11 DEBUG send_request_headers.complete
15:35:10,748 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:35:10,749 httpcore.http11 DEBUG send_request_body.complete
15:35:10,749 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:35:10,966 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:35:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'99'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'01f9a129bb55739c24fe6eab7256292c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c0982c724ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:35:10,969 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:35:10,970 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:35:10,971 httpcore.http11 DEBUG receive_response_body.complete
15:35:10,972 httpcore.http11 DEBUG response_closed.started
15:35:10,972 httpcore.http11 DEBUG response_closed.complete
15:35:10,973 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:35:11,7 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:35:11,15 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:35:11,17 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5ab890>
15:35:11,18 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79dfd0> server_hostname='api.openai.com' timeout=None
15:35:11,24 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5ab910>
15:35:11,24 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:35:11,25 httpcore.http11 DEBUG send_request_headers.complete
15:35:11,25 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:35:11,26 httpcore.http11 DEBUG send_request_body.complete
15:35:11,26 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:35:11,280 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:35:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'991643a6ea5ad5a076929eb112629764'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=UJQAthTy9P5C54AJCt8JaR81wX529H6kbzlovQeBuEc-1702413311-1-Ac4OkIrjp1TFC+uJgcCqKGvlfh0hm1QOKpsYmkz/vhuA949RKTX+NB88U145RO5HzHi6j4xtXaI0M2IhCiS58UQ=; path=/; expires=Tue, 12-Dec-23 21:05:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pTz0kq6h11hG87Q9a9egsoZkAM6iSzkStlMkxLELGiQ-1702413311274-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c099e8df4cff-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:35:11,289 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:35:11,290 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:35:11,290 httpcore.http11 DEBUG receive_response_body.complete
15:35:11,291 httpcore.http11 DEBUG response_closed.started
15:35:11,291 httpcore.http11 DEBUG response_closed.complete
15:35:11,291 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:35:11,307 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:35:11,311 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:35:14,714 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:35:14,733 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:35:14,736 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:35:16,738 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:35:16,752 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:35:16,755 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:35:20,157 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:35:20,165 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:35:20,171 httpcore.connection DEBUG close.started
15:35:20,172 httpcore.connection DEBUG close.complete
15:35:20,172 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:35:20,175 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5aa690>
15:35:20,176 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:35:20,184 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5ab690>
15:35:20,185 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:35:20,187 httpcore.http11 DEBUG send_request_headers.complete
15:35:20,187 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:35:20,188 httpcore.http11 DEBUG send_request_body.complete
15:35:20,188 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:35:20,649 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:35:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'351'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e9fc70a601934358a2a27452182e50d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c0d32a924cf3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:35:20,655 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:35:20,656 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:35:21,44 httpcore.http11 DEBUG receive_response_body.complete
15:35:21,45 httpcore.http11 DEBUG response_closed.started
15:35:21,46 httpcore.http11 DEBUG response_closed.complete
15:35:21,46 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:35:21,123 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:35:31,836 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:35:31,840 httpcore.connection DEBUG close.started
15:35:31,841 httpcore.connection DEBUG close.complete
15:35:31,841 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:35:31,844 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58e7d0>
15:35:31,844 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:35:31,850 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58e850>
15:35:31,851 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:35:31,852 httpcore.http11 DEBUG send_request_headers.complete
15:35:31,852 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:35:31,872 httpcore.http11 DEBUG send_request_body.complete
15:35:31,873 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:35:32,763 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:35:32 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'12'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'405'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8874ade58cd480a7de7673355efb43ee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c11c1b0d3ba0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:35:32,768 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:35:32,769 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:35:32,771 httpcore.http11 DEBUG receive_response_body.complete
15:35:32,772 httpcore.http11 DEBUG response_closed.started
15:35:32,772 httpcore.http11 DEBUG response_closed.complete
15:35:32,773 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:35:32,774 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:35:32,802 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\non the edge\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:35:32,805 httpcore.connection DEBUG close.started
15:35:32,806 httpcore.connection DEBUG close.complete
15:35:32,806 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:35:32,809 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c19d0>
15:35:32,809 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e060> server_hostname='api.openai.com' timeout=None
15:35:32,814 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c1a50>
15:35:32,814 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:35:32,815 httpcore.http11 DEBUG send_request_headers.complete
15:35:32,815 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:35:32,816 httpcore.http11 DEBUG send_request_body.complete
15:35:32,816 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:35:33,34 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:35:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'88591050604eb64fd7beff3e67de089d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c1221e194cf4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:35:33,38 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:35:33,39 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:35:33,41 httpcore.http11 DEBUG receive_response_body.complete
15:35:33,41 httpcore.http11 DEBUG response_closed.started
15:35:33,42 httpcore.http11 DEBUG response_closed.complete
15:35:33,43 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:35:33,86 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\n                                               \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                                                                             \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n                                               \nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0\n                                               \nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2                                    \n\nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 < surface_height // 2                                    \n                                                                                                                                       \nAnd the human answered\n'''\non the edge\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:35:33,90 httpcore.connection DEBUG close.started
15:35:33,90 httpcore.connection DEBUG close.complete
15:35:33,91 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:35:33,93 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58da10>
15:35:33,93 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e840> server_hostname='api.openai.com' timeout=None
15:35:33,100 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58cc10>
15:35:33,101 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:35:33,104 httpcore.http11 DEBUG send_request_headers.complete
15:35:33,104 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:35:33,106 httpcore.http11 DEBUG send_request_body.complete
15:35:33,106 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:35:33,817 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:35:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'614'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd6aafd485f876f5ff934986745a79483'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c123e8ed6ac8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:35:33,822 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:35:33,823 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:35:33,824 httpcore.http11 DEBUG receive_response_body.complete
15:35:33,825 httpcore.http11 DEBUG response_closed.started
15:35:33,825 httpcore.http11 DEBUG response_closed.complete
15:35:33,826 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:35:34,415 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:35:34,420 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:35:40,923 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:35:40,944 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:35:40,948 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:35:45,951 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:35:45,971 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:35:45,975 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:35:47,977 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:35:47,996 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:35:47,999 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:35:51,402 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:35:51,418 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:35:51,423 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:35:57,926 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:35:57,946 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:35:57,950 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:36:02,154 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:36:02,166 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:36:02,169 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:36:05,570 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:36:05,577 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:36:05,584 httpcore.connection DEBUG close.started
15:36:05,584 httpcore.connection DEBUG close.complete
15:36:05,585 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:36:05,588 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58e750>
15:36:05,589 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:36:05,595 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58df50>
15:36:05,595 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:05,596 httpcore.http11 DEBUG send_request_headers.complete
15:36:05,597 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:05,597 httpcore.http11 DEBUG send_request_body.complete
15:36:05,598 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:06,112 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:06 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'67e59476448d0beaa0b86ee49a29f8d3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c1eefb594cd6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:06,117 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:36:06,118 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:07,339 httpcore.http11 DEBUG receive_response_body.complete
15:36:07,340 httpcore.http11 DEBUG response_closed.started
15:36:07,341 httpcore.http11 DEBUG response_closed.complete
15:36:07,342 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:36:07,414 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:36:19,934 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:36:19,942 httpcore.connection DEBUG close.started
15:36:19,943 httpcore.connection DEBUG close.complete
15:36:19,943 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:36:19,973 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5a9ad0>
15:36:19,974 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:36:19,983 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5a9310>
15:36:19,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:19,986 httpcore.http11 DEBUG send_request_headers.complete
15:36:19,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:20,8 httpcore.http11 DEBUG send_request_body.complete
15:36:20,8 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:21,24 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'8'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'727'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5693816988a72d597a3f0ec17be099a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c248e9326ac6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:21,30 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:36:21,31 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:21,32 httpcore.http11 DEBUG receive_response_body.complete
15:36:21,33 httpcore.http11 DEBUG response_closed.started
15:36:21,34 httpcore.http11 DEBUG response_closed.complete
15:36:21,35 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:36:21,36 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:36:21,65 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove up\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:36:21,69 httpcore.connection DEBUG close.started
15:36:21,69 httpcore.connection DEBUG close.complete
15:36:21,70 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:36:21,72 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c39d0>
15:36:21,72 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e060> server_hostname='api.openai.com' timeout=None
15:36:21,80 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c3a10>
15:36:21,80 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:21,81 httpcore.http11 DEBUG send_request_headers.complete
15:36:21,81 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:21,82 httpcore.http11 DEBUG send_request_body.complete
15:36:21,82 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:21,279 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'102'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'75294087e3ed2434f78b5ced18c540ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c24fc9f44d19-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:21,284 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:36:21,285 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:21,287 httpcore.http11 DEBUG receive_response_body.complete
15:36:21,287 httpcore.http11 DEBUG response_closed.started
15:36:21,288 httpcore.http11 DEBUG response_closed.complete
15:36:21,288 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:36:21,323 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove up\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:36:21,326 httpcore.connection DEBUG close.started
15:36:21,326 httpcore.connection DEBUG close.complete
15:36:21,327 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:36:21,329 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5ab910>
15:36:21,329 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79dfd0> server_hostname='api.openai.com' timeout=None
15:36:21,336 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5a9850>
15:36:21,337 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:21,338 httpcore.http11 DEBUG send_request_headers.complete
15:36:21,338 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:21,339 httpcore.http11 DEBUG send_request_body.complete
15:36:21,339 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:21,543 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'92'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1de985c1011e7870ec9cc37d6152ec0f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c2515c453031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:21,550 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:36:21,550 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:21,551 httpcore.http11 DEBUG receive_response_body.complete
15:36:21,552 httpcore.http11 DEBUG response_closed.started
15:36:21,552 httpcore.http11 DEBUG response_closed.complete
15:36:21,553 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:36:21,568 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:36:21,572 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:36:24,974 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:36:24,981 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:36:24,987 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:24,988 httpcore.http11 DEBUG send_request_headers.complete
15:36:24,988 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:24,989 httpcore.http11 DEBUG send_request_body.complete
15:36:24,989 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:25,506 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:25 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb0e61b415745126f733cf7c22519f81'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c2682a9d6ac6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:25,509 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:36:25,509 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:26,645 httpcore.http11 DEBUG receive_response_body.complete
15:36:26,646 httpcore.http11 DEBUG response_closed.started
15:36:26,647 httpcore.http11 DEBUG response_closed.complete
15:36:26,649 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:36:26,724 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:36:39,309 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:36:39,315 httpcore.connection DEBUG close.started
15:36:39,315 httpcore.connection DEBUG close.complete
15:36:39,316 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:36:39,319 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5abe50>
15:36:39,319 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:36:39,326 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5aaf90>
15:36:39,327 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:39,328 httpcore.http11 DEBUG send_request_headers.complete
15:36:39,329 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:39,353 httpcore.http11 DEBUG send_request_body.complete
15:36:39,354 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:40,219 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:40 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'350'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'56a78a9b8f9f8c496da936b33859e403'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c2c1ca134cd0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:40,224 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:36:40,225 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:40,226 httpcore.http11 DEBUG receive_response_body.complete
15:36:40,227 httpcore.http11 DEBUG response_closed.started
15:36:40,228 httpcore.http11 DEBUG response_closed.complete
15:36:40,229 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:36:40,230 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:36:40,258 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nThank you for watching!\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:36:40,262 httpcore.connection DEBUG close.started
15:36:40,262 httpcore.connection DEBUG close.complete
15:36:40,263 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:36:40,265 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58da50>
15:36:40,265 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79dfd0> server_hostname='api.openai.com' timeout=None
15:36:40,272 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58db50>
15:36:40,272 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:40,273 httpcore.http11 DEBUG send_request_headers.complete
15:36:40,273 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:40,274 httpcore.http11 DEBUG send_request_body.complete
15:36:40,274 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:40,510 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e8bfbd411e392eb0fd464fee631be81e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c2c7b8513059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:40,517 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:36:40,518 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:40,520 httpcore.http11 DEBUG receive_response_body.complete
15:36:40,521 httpcore.http11 DEBUG response_closed.started
15:36:40,521 httpcore.http11 DEBUG response_closed.complete
15:36:40,522 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:36:40,531 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:36:40,534 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:40,536 httpcore.http11 DEBUG send_request_headers.complete
15:36:40,536 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:40,536 httpcore.http11 DEBUG send_request_body.complete
15:36:40,537 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:41,57 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:41 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2c47007699a6fcdd99c8b304913c6871'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c2c95a074cd0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:41,62 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:36:41,63 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:42,268 httpcore.http11 DEBUG receive_response_body.complete
15:36:42,269 httpcore.http11 DEBUG response_closed.started
15:36:42,270 httpcore.http11 DEBUG response_closed.complete
15:36:42,271 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:36:42,338 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:36:54,939 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:36:54,944 httpcore.connection DEBUG close.started
15:36:54,945 httpcore.connection DEBUG close.complete
15:36:54,945 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:36:54,948 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5cb890>
15:36:54,949 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:36:54,955 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5cb910>
15:36:54,955 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:54,956 httpcore.http11 DEBUG send_request_headers.complete
15:36:54,957 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:54,980 httpcore.http11 DEBUG send_request_body.complete
15:36:54,980 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:55,846 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:55 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4228a8bf9b6d58108a0b3b0ed4a5aa13'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c3237c7f4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:55,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:36:55,852 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:55,853 httpcore.http11 DEBUG receive_response_body.complete
15:36:55,854 httpcore.http11 DEBUG response_closed.started
15:36:55,854 httpcore.http11 DEBUG response_closed.complete
15:36:55,855 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:36:55,855 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:36:55,884 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nto the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:36:55,887 httpcore.connection DEBUG close.started
15:36:55,888 httpcore.connection DEBUG close.complete
15:36:55,888 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:36:55,890 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d2bd0>
15:36:55,891 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79dfd0> server_hostname='api.openai.com' timeout=None
15:36:55,896 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d2c50>
15:36:55,896 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:55,897 httpcore.http11 DEBUG send_request_headers.complete
15:36:55,898 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:55,899 httpcore.http11 DEBUG send_request_body.complete
15:36:55,899 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:36:56,124 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:36:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fff8a263b6b26cc5f0f8abd879716a72'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c3295d146aca-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:36:56,130 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:36:56,131 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:36:56,132 httpcore.http11 DEBUG receive_response_body.complete
15:36:56,132 httpcore.http11 DEBUG response_closed.started
15:36:56,132 httpcore.http11 DEBUG response_closed.complete
15:36:56,133 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:36:56,149 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:36:56,153 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:36:59,555 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:36:59,561 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:36:59,570 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:36:59,571 httpcore.http11 DEBUG send_request_headers.complete
15:36:59,572 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:36:59,572 httpcore.http11 DEBUG send_request_body.complete
15:36:59,572 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:00,71 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e079196a93a378a924fcb5c618d4ccbc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c3405fb04cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:00,76 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:37:00,77 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:01,311 httpcore.http11 DEBUG receive_response_body.complete
15:37:01,312 httpcore.http11 DEBUG response_closed.started
15:37:01,313 httpcore.http11 DEBUG response_closed.complete
15:37:01,314 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:37:01,388 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:37:13,778 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:37:13,786 httpcore.connection DEBUG close.started
15:37:13,787 httpcore.connection DEBUG close.complete
15:37:13,787 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:37:13,790 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c8350>
15:37:13,790 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:37:13,799 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c8450>
15:37:13,800 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:13,801 httpcore.http11 DEBUG send_request_headers.complete
15:37:13,802 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:13,819 httpcore.http11 DEBUG send_request_body.complete
15:37:13,820 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:14,801 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'379'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c727af7cb845c090a1bd801373ab061b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c3994e774ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:14,806 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:37:14,807 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:14,809 httpcore.http11 DEBUG receive_response_body.complete
15:37:14,810 httpcore.http11 DEBUG response_closed.started
15:37:14,810 httpcore.http11 DEBUG response_closed.complete
15:37:14,811 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:37:14,812 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:37:14,840 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:37:14,843 httpcore.connection DEBUG close.started
15:37:14,844 httpcore.connection DEBUG close.complete
15:37:14,844 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:37:14,847 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5aa350>
15:37:14,847 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79dfd0> server_hostname='api.openai.com' timeout=None
15:37:14,854 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5ab050>
15:37:14,855 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:14,855 httpcore.http11 DEBUG send_request_headers.complete
15:37:14,856 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:14,856 httpcore.http11 DEBUG send_request_body.complete
15:37:14,856 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:15,93 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7ea82adacfbfc7faec7ad4275e327765'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c39fda004ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:15,98 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:37:15,99 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:15,100 httpcore.http11 DEBUG receive_response_body.complete
15:37:15,100 httpcore.http11 DEBUG response_closed.started
15:37:15,101 httpcore.http11 DEBUG response_closed.complete
15:37:15,101 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:37:15,118 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:37:15,121 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:37:18,531 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:37:18,538 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:37:18,546 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:18,547 httpcore.http11 DEBUG send_request_headers.complete
15:37:18,548 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:18,548 httpcore.http11 DEBUG send_request_body.complete
15:37:18,549 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:19,295 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'566'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'aca0e0233b3625592d543198dd3a0a0d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c3b6efea4ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:19,299 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:37:19,300 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:20,470 httpcore.http11 DEBUG receive_response_body.complete
15:37:20,470 httpcore.http11 DEBUG response_closed.started
15:37:20,471 httpcore.http11 DEBUG response_closed.complete
15:37:20,472 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:37:20,547 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:37:33,102 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:37:33,107 httpcore.connection DEBUG close.started
15:37:33,108 httpcore.connection DEBUG close.complete
15:37:33,108 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:37:33,138 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c2990>
15:37:33,139 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:37:33,149 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c2a10>
15:37:33,150 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:33,153 httpcore.http11 DEBUG send_request_headers.complete
15:37:33,153 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:33,179 httpcore.http11 DEBUG send_request_body.complete
15:37:33,179 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:34,419 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'639'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3426791e60ac2bfb3d723afbac63872b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c41239b03035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:34,425 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:37:34,426 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:34,427 httpcore.http11 DEBUG receive_response_body.complete
15:37:34,428 httpcore.http11 DEBUG response_closed.started
15:37:34,429 httpcore.http11 DEBUG response_closed.complete
15:37:34,430 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:37:34,430 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:37:34,459 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:37:34,463 httpcore.connection DEBUG close.started
15:37:34,463 httpcore.connection DEBUG close.complete
15:37:34,464 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:37:34,466 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d2e90>
15:37:34,466 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79dfd0> server_hostname='api.openai.com' timeout=None
15:37:34,471 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d07d0>
15:37:34,472 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:34,473 httpcore.http11 DEBUG send_request_headers.complete
15:37:34,473 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:34,474 httpcore.http11 DEBUG send_request_body.complete
15:37:34,474 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:34,671 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'93'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'02f551ef3c7caf60d1e23b3798564967'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c41a7f4b4cf2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:34,676 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:37:34,677 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:34,679 httpcore.http11 DEBUG receive_response_body.complete
15:37:34,679 httpcore.http11 DEBUG response_closed.started
15:37:34,680 httpcore.http11 DEBUG response_closed.complete
15:37:34,681 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:37:34,699 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:37:34,703 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:37:38,105 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:37:38,126 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:37:38,131 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:37:40,135 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:37:40,152 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:37:40,156 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:37:43,558 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:37:43,561 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:37:43,565 httpcore.connection DEBUG close.started
15:37:43,565 httpcore.connection DEBUG close.complete
15:37:43,566 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:37:43,568 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c2c10>
15:37:43,569 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:37:43,576 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c1050>
15:37:43,577 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:43,578 httpcore.http11 DEBUG send_request_headers.complete
15:37:43,578 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:43,579 httpcore.http11 DEBUG send_request_body.complete
15:37:43,579 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:44,234 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:44 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'468'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'aa6c89497ccc227d136c4581395d12ec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c4535f9f4cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:44,239 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:37:44,240 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:44,571 httpcore.http11 DEBUG receive_response_body.complete
15:37:44,572 httpcore.http11 DEBUG response_closed.started
15:37:44,572 httpcore.http11 DEBUG response_closed.complete
15:37:44,573 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:37:44,636 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:37:55,554 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:37:55,559 httpcore.connection DEBUG close.started
15:37:55,559 httpcore.connection DEBUG close.complete
15:37:55,560 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:37:55,562 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58e790>
15:37:55,562 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:37:55,568 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58e850>
15:37:55,568 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:55,569 httpcore.http11 DEBUG send_request_headers.complete
15:37:55,569 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:55,600 httpcore.http11 DEBUG send_request_body.complete
15:37:55,601 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:56,357 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:56 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'26'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'367'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e066f62840120eb6c896372a046c915d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c49e4a033b93-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:56,363 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:37:56,364 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:56,365 httpcore.http11 DEBUG receive_response_body.complete
15:37:56,365 httpcore.http11 DEBUG response_closed.started
15:37:56,366 httpcore.http11 DEBUG response_closed.complete
15:37:56,366 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:37:56,367 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:37:56,396 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nnext to the orange block.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:37:56,400 httpcore.connection DEBUG close.started
15:37:56,400 httpcore.connection DEBUG close.complete
15:37:56,400 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:37:56,403 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c3a10>
15:37:56,403 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e060> server_hostname='api.openai.com' timeout=None
15:37:56,408 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c3d50>
15:37:56,408 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:56,409 httpcore.http11 DEBUG send_request_headers.complete
15:37:56,410 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:56,410 httpcore.http11 DEBUG send_request_body.complete
15:37:56,410 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:56,617 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dbfa47ac8327fa2802e735f42688f533'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c4a38e396ac8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:56,623 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:37:56,624 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:56,625 httpcore.http11 DEBUG receive_response_body.complete
15:37:56,626 httpcore.http11 DEBUG response_closed.started
15:37:56,626 httpcore.http11 DEBUG response_closed.complete
15:37:56,627 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:37:56,661 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nnext to the orange block.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:37:56,672 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:37:56,675 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a70f9d0>
15:37:56,675 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e3c0> server_hostname='api.openai.com' timeout=None
15:37:56,683 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a56cbd0>
15:37:56,683 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:56,685 httpcore.http11 DEBUG send_request_headers.complete
15:37:56,685 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:56,686 httpcore.http11 DEBUG send_request_body.complete
15:37:56,686 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:57,696 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'883'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'74095011761ec40b4c101322abe2cfbf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2cDkRLCexR2kHzfTor6GPTOrCb6MEn8HkmQkFWIUmr8-1702413477-1-AfeLqiFeX9qpe4UDEbRlzL5G7fJpqOSix3NbKF3OcA0/pqbDZgtqHzWTKCoN0fRdbR/pPcUIPpnnAqp3KheummY=; path=/; expires=Tue, 12-Dec-23 21:07:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=jAOaTBOJ8fjC21DV4LKwAmMweZa5WaRnASbCaymQlkI-1702413477690-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c4a54c37306b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:57,702 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:37:57,703 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:57,704 httpcore.http11 DEBUG receive_response_body.complete
15:37:57,704 httpcore.http11 DEBUG response_closed.started
15:37:57,705 httpcore.http11 DEBUG response_closed.complete
15:37:57,705 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:37:57,712 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Ok, I will place the third candle next to the orange block. Can you tell me where to place the fourth candle? Please provide me with a specific location.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:37:57,716 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:37:57,717 httpcore.http11 DEBUG send_request_headers.complete
15:37:57,717 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:37:57,718 httpcore.http11 DEBUG send_request_body.complete
15:37:57,718 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:37:58,421 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:37:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'565'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ab7c9e67c5263f39e6592250c3c2a5b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c4abbe423b93-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:37:58,426 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:37:58,427 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:37:59,853 httpcore.http11 DEBUG receive_response_body.complete
15:37:59,853 httpcore.http11 DEBUG response_closed.started
15:37:59,854 httpcore.http11 DEBUG response_closed.complete
15:37:59,854 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:37:59,920 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:38:17,753 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell9.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:38:17,760 httpcore.connection DEBUG close.started
15:38:17,760 httpcore.connection DEBUG close.complete
15:38:17,761 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:38:17,763 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d0c50>
15:38:17,763 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:38:17,769 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d1d90>
15:38:17,770 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:38:17,771 httpcore.http11 DEBUG send_request_headers.complete
15:38:17,771 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:38:17,799 httpcore.http11 DEBUG send_request_body.complete
15:38:17,800 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:38:18,910 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:38:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'413'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'521bc47facd378a99fa1a57f97f55d71'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c5291b00306b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:38:18,914 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:38:18,915 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:38:18,916 httpcore.http11 DEBUG receive_response_body.complete
15:38:18,917 httpcore.http11 DEBUG response_closed.started
15:38:18,918 httpcore.http11 DEBUG response_closed.complete
15:38:18,919 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:38:18,920 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:38:18,959 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nOk, I will place the third candle next to the orange block. Can you tell me where to place the fourth candle? Please provide me with a specific location.\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:38:18,963 httpcore.connection DEBUG close.started
15:38:18,963 httpcore.connection DEBUG close.complete
15:38:18,964 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:38:18,966 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d3010>
15:38:18,966 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e060> server_hostname='api.openai.com' timeout=None
15:38:18,972 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d1fd0>
15:38:18,973 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:38:18,974 httpcore.http11 DEBUG send_request_headers.complete
15:38:18,975 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:38:18,975 httpcore.http11 DEBUG send_request_body.complete
15:38:18,976 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:38:19,192 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:38:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2300b753bdef62c9e09b1d22e7dea17d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c5309acb3018-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:38:19,198 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:38:19,199 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:38:19,201 httpcore.http11 DEBUG receive_response_body.complete
15:38:19,202 httpcore.http11 DEBUG response_closed.started
15:38:19,203 httpcore.http11 DEBUG response_closed.complete
15:38:19,203 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:38:19,236 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nOk, I will place the third candle next to the orange block. Can you tell me where to place the fourth candle? Please provide me with a specific location.\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:38:19,239 httpcore.connection DEBUG close.started
15:38:19,239 httpcore.connection DEBUG close.complete
15:38:19,240 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:38:19,242 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a56f950>
15:38:19,242 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e3c0> server_hostname='api.openai.com' timeout=None
15:38:19,249 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a56f8d0>
15:38:19,250 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:38:19,251 httpcore.http11 DEBUG send_request_headers.complete
15:38:19,251 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:38:19,252 httpcore.http11 DEBUG send_request_body.complete
15:38:19,252 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:38:20,237 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:38:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'888'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e3f755fbc049cf9f5f3d53d210b72e4b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c5325e383b94-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:38:20,247 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:38:20,247 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:38:20,249 httpcore.http11 DEBUG receive_response_body.complete
15:38:20,249 httpcore.http11 DEBUG response_closed.started
15:38:20,249 httpcore.http11 DEBUG response_closed.complete
15:38:20,250 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:38:20,257 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Ok, I understand. Can you please tell me the exact location of the fourth candle? For example, is it to the left or right of the orange block? Or is it in the middle of the cake? Please provide me with a specific location.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:38:20,260 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:38:20,262 httpcore.http11 DEBUG send_request_headers.complete
15:38:20,262 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:38:20,262 httpcore.http11 DEBUG send_request_body.complete
15:38:20,263 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:38:20,894 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:38:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'568'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8d5d7d995fe0f474c157c9fd45a9fdc2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c538acf4306b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:38:20,899 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:38:20,900 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:38:23,138 httpcore.http11 DEBUG receive_response_body.complete
15:38:23,139 httpcore.http11 DEBUG response_closed.started
15:38:23,141 httpcore.http11 DEBUG response_closed.complete
15:38:23,143 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:38:23,215 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell10.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:38:45,191 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell10.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:38:45,195 httpcore.connection DEBUG close.started
15:38:45,196 httpcore.connection DEBUG close.complete
15:38:45,196 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:38:45,226 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c3e10>
15:38:45,227 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:38:45,238 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c3e90>
15:38:45,239 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:38:45,241 httpcore.http11 DEBUG send_request_headers.complete
15:38:45,242 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:38:45,276 httpcore.http11 DEBUG send_request_body.complete
15:38:45,276 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:38:46,145 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:38:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'20'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'426'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5dfa3b95289e1edf3336dcb2386e79d6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c5d4c8b54ce9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:38:46,150 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:38:46,151 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:38:46,153 httpcore.http11 DEBUG receive_response_body.complete
15:38:46,154 httpcore.http11 DEBUG response_closed.started
15:38:46,154 httpcore.http11 DEBUG response_closed.complete
15:38:46,154 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:38:46,155 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:38:46,187 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nOk, I understand. Can you please tell me the exact location of the fourth candle? For example, is it to the left or right of the orange block? Or is it in the middle of the cake? Please provide me with a specific location.\n'''\nAnd the human answered\n'''\nMiddle of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:38:46,190 httpcore.connection DEBUG close.started
15:38:46,190 httpcore.connection DEBUG close.complete
15:38:46,191 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:38:46,193 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d59d0>
15:38:46,193 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e060> server_hostname='api.openai.com' timeout=None
15:38:46,198 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d4090>
15:38:46,199 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:38:46,200 httpcore.http11 DEBUG send_request_headers.complete
15:38:46,200 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:38:46,201 httpcore.http11 DEBUG send_request_body.complete
15:38:46,201 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:38:46,532 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:38:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'221'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3a568b0e5004c7271982ae2de25a129e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c5dab8356ac6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:38:46,538 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:38:46,540 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:38:46,542 httpcore.http11 DEBUG receive_response_body.complete
15:38:46,542 httpcore.http11 DEBUG response_closed.started
15:38:46,542 httpcore.http11 DEBUG response_closed.complete
15:38:46,543 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:38:46,576 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''\n                                               \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0\n                                                                                             \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2                                               \n                                               \nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, y0: y1 == y0 - 1\nlambda x1, x0: x1==x0\n                                               \nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2                                    \n\nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 < surface_height // 2                                    \n                                                                                                                                       \nAnd the human answered\n'''\nMiddle of the cake.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:38:46,579 httpcore.connection DEBUG close.started
15:38:46,579 httpcore.connection DEBUG close.complete
15:38:46,580 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:38:46,582 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58c390>
15:38:46,582 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e840> server_hostname='api.openai.com' timeout=None
15:38:46,589 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a58c210>
15:38:46,590 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:38:46,591 httpcore.http11 DEBUG send_request_headers.complete
15:38:46,591 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:38:46,592 httpcore.http11 DEBUG send_request_body.complete
15:38:46,592 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:38:47,467 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:38:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'777'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'557ee5f7934121781f4ee1a4dc53ec90'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c5dd3cd53bac-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:38:47,473 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:38:47,475 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:38:47,477 httpcore.http11 DEBUG receive_response_body.complete
15:38:47,478 httpcore.http11 DEBUG response_closed.started
15:38:47,478 httpcore.http11 DEBUG response_closed.complete
15:38:47,478 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:38:47,802 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:38:47,805 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:38:54,307 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:38:54,325 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:38:54,329 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:38:59,331 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:38:59,351 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:38:59,354 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:39:01,357 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:39:01,373 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:39:01,377 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:39:04,779 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:39:04,800 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:39:04,804 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:39:11,306 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:39:11,324 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:39:11,327 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:39:15,929 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:39:15,946 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:39:15,950 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:39:19,353 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:39:19,358 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
15:39:19,364 httpcore.connection DEBUG close.started
15:39:19,365 httpcore.connection DEBUG close.complete
15:39:19,365 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:39:19,383 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5abe50>
15:39:19,383 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:39:19,393 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a580250>
15:39:19,394 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:39:19,396 httpcore.http11 DEBUG send_request_headers.complete
15:39:19,396 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:39:19,397 httpcore.http11 DEBUG send_request_body.complete
15:39:19,397 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:39:20,78 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:39:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'556'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b459f62083c744171bbf325dacdac38c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c6aa3c064cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:39:20,83 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
15:39:20,84 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:39:21,98 httpcore.http11 DEBUG receive_response_body.complete
15:39:21,99 httpcore.http11 DEBUG response_closed.started
15:39:21,100 httpcore.http11 DEBUG response_closed.complete
15:39:21,101 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
15:39:21,171 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Mitchell11.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
15:39:33,655 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Mitchell11.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
15:39:33,659 httpcore.connection DEBUG close.started
15:39:33,659 httpcore.connection DEBUG close.complete
15:39:33,660 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
15:39:33,662 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5cb250>
15:39:33,663 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79deb0> server_hostname='api.openai.com' timeout=5.0
15:39:33,668 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5cad10>
15:39:33,668 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:39:33,669 httpcore.http11 DEBUG send_request_headers.complete
15:39:33,669 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:39:33,692 httpcore.http11 DEBUG send_request_body.complete
15:39:33,692 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:39:34,458 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:39:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'347'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e3e114faf41defb726c24f232405e4e7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c7036b0f6aca-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:39:34,464 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
15:39:34,465 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:39:34,466 httpcore.http11 DEBUG receive_response_body.complete
15:39:34,466 httpcore.http11 DEBUG response_closed.started
15:39:34,467 httpcore.http11 DEBUG response_closed.complete
15:39:34,467 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
15:39:34,468 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
15:39:34,498 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:39:34,503 httpcore.connection DEBUG close.started
15:39:34,504 httpcore.connection DEBUG close.complete
15:39:34,504 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:39:34,507 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d1bd0>
15:39:34,507 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79e060> server_hostname='api.openai.com' timeout=None
15:39:34,514 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5c0490>
15:39:34,514 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:39:34,515 httpcore.http11 DEBUG send_request_headers.complete
15:39:34,516 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:39:34,516 httpcore.http11 DEBUG send_request_body.complete
15:39:34,517 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:39:34,710 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:39:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'75207c0d8c885f6be3ec3e51dde565c5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c708ba784ce0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:39:34,716 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:39:34,717 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:39:34,718 httpcore.http11 DEBUG receive_response_body.complete
15:39:34,718 httpcore.http11 DEBUG response_closed.started
15:39:34,719 httpcore.http11 DEBUG response_closed.complete
15:39:34,719 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:39:34,753 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
15:39:34,757 httpcore.connection DEBUG close.started
15:39:34,757 httpcore.connection DEBUG close.complete
15:39:34,757 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
15:39:34,760 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d5e50>
15:39:34,760 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc61a79dfd0> server_hostname='api.openai.com' timeout=None
15:39:34,765 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc61a5d5d10>
15:39:34,766 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
15:39:34,767 httpcore.http11 DEBUG send_request_headers.complete
15:39:34,767 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
15:39:34,768 httpcore.http11 DEBUG send_request_body.complete
15:39:34,768 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
15:39:34,998 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 20:39:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'134'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6c2e519581c89ac9b9f912de91f19d5d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8348c70a4d493b8d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
15:39:35,3 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
15:39:35,4 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
15:39:35,5 httpcore.http11 DEBUG receive_response_body.complete
15:39:35,6 httpcore.http11 DEBUG response_closed.started
15:39:35,6 httpcore.http11 DEBUG response_closed.complete
15:39:35,7 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
15:39:35,23 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:39:35,28 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:39:38,430 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:39:38,451 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:39:38,456 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:39:40,458 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
15:39:40,478 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
15:39:40,482 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
15:39:43,884 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:12:14,557 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:12:14,560 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:12:15,398 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:12:15,399 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:12:15,451 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:12:15,452 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:12:15,503 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:12:15,504 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:12:15,554 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:12:15,555 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:12:15,616 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:12:15,618 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:12:15,673 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:12:15,674 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:12:15,721 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:12:15,722 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:12:15,762 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:12:15,763 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:12:17,303 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Shijie. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:12:17,324 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:12:17,355 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871bf30150>
17:12:17,355 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f871bc09e20> server_hostname='api.openai.com' timeout=5.0
17:12:17,364 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871bb7fe90>
17:12:17,365 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:12:17,367 httpcore.http11 DEBUG send_request_headers.complete
17:12:17,368 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:12:17,368 httpcore.http11 DEBUG send_request_body.complete
17:12:17,369 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:12:17,831 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:12:17 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'36164f699475aff4cb5380edbb0db769'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dB1en3qn2MznmW_9x.29p3Bl93MMlaleg2bZqGuGvAA-1702419137-1-AT93UtZ+8mVZaxKftx5drtG9hJkUcWTU1iV8uD1lqZE9OLJj8/G71+tRM7SDi4ap+JtuRLXbpl5+QjVIlyAGeso=; path=/; expires=Tue, 12-Dec-23 22:42:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=MR8JcKApdGW_OlnyGKv.2E9303126LMnmG9sfKTCWXM-1702419137824-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83494ed88fb96ac7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:12:17,842 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:12:17,843 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:12:18,411 httpcore.http11 DEBUG receive_response_body.complete
17:12:18,412 httpcore.http11 DEBUG response_closed.started
17:12:18,413 httpcore.http11 DEBUG response_closed.complete
17:12:18,414 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:12:18,500 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:12:31,810 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:12:31,819 httpcore.connection DEBUG close.started
17:12:31,820 httpcore.connection DEBUG close.complete
17:12:31,820 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:12:31,823 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871bb7f090>
17:12:31,824 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f871bc09e20> server_hostname='api.openai.com' timeout=5.0
17:12:31,830 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871bb7cfd0>
17:12:31,831 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:12:31,832 httpcore.http11 DEBUG send_request_headers.complete
17:12:31,832 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:12:31,865 httpcore.http11 DEBUG send_request_body.complete
17:12:31,866 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:12:32,850 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:12:32 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'44'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'430'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a85030717062b54ae5a0189c18aa24e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83494f32fad23b7c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:12:32,855 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:12:32,856 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:12:32,857 httpcore.http11 DEBUG receive_response_body.complete
17:12:32,858 httpcore.http11 DEBUG response_closed.started
17:12:32,859 httpcore.http11 DEBUG response_closed.complete
17:12:32,860 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:12:32,861 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:12:32,912 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Shijie. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nYou should put it on the upper left corner.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:12:32,923 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:12:32,926 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871b9dc210>
17:12:32,926 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f871bc09fd0> server_hostname='api.openai.com' timeout=None
17:12:32,931 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871b9dcb90>
17:12:32,932 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:12:32,933 httpcore.http11 DEBUG send_request_headers.complete
17:12:32,933 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:12:32,933 httpcore.http11 DEBUG send_request_body.complete
17:12:32,934 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:12:33,149 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:12:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e59ceaca2cafc8a95e5be6d7e0f968fa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=8HNZePAD6NlNMt6OcE1fS549KPQXMpxyPHCua_Xv_uQ-1702419153-1-AaFfxDkbX3xBEXjVcbayYdL/7HeYqyKR6/RRWnkIHKqJLqTibCoPTfAJqvA70VLURYXonuCyRBL/FEOSskvmFzI=; path=/; expires=Tue, 12-Dec-23 22:42:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ht1.PRBnzIoiI7zZ6EoEUvDzmixAZfev8jOGv1LPD8E-1702419153144-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83494f39dfb14cfe-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:12:33,158 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:12:33,158 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:12:33,159 httpcore.http11 DEBUG receive_response_body.complete
17:12:33,159 httpcore.http11 DEBUG response_closed.started
17:12:33,160 httpcore.http11 DEBUG response_closed.complete
17:12:33,160 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:12:33,194 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked:\n'''\nWhere should I place the first candle?\n'''\n                                               \nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y0, surface_height: y0 < surface_height // 2\n                                               \nYou asked:\n'''\nWhere should I place the second candle?\n'''                                                                                       \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0                                               \n\nYou asked:\n'''\nWhere should I place the second candle?\n'''                                              \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2\n                                               \nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, y0: y2 == y0 - 1\nlambda x2, x0: x2==x0                                    \n\nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, surface_height: y2 > surface_height // 2\n                                                                                   \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nHi, Shijie. Let us decorate a cake. Where should I place the first candle?\n'''                                                                                         \nAnd the human answered\n'''\nYou should put it on the upper left corner.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:12:33,205 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:12:33,207 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871b9dd990>
17:12:33,208 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f871bc0a7b0> server_hostname='api.openai.com' timeout=None
17:12:33,214 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871b9dd590>
17:12:33,215 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:12:33,216 httpcore.http11 DEBUG send_request_headers.complete
17:12:33,216 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:12:33,217 httpcore.http11 DEBUG send_request_body.complete
17:12:33,217 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:12:33,742 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:12:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'432'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e0b7adb5617bddcdadfca82e6f1d03e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EXQd22twQz.P36iEsPup6XB.Oqr8SxG42VetIrQ8OPo-1702419153-1-ATJt199xlXJDjcncqyyFLmpOaffUYEi9DZmhLW0CK0yziLDKnYQFsV+IGnsISWzsqelw7Ba+OCqZKU344uI0Mc0=; path=/; expires=Tue, 12-Dec-23 22:42:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=2ErLF0oQF4V6hg0UBStuQUvm7CaFS5uNHoUo6YBUBj8-1702419153737-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83494f3b9d644d18-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:12:33,748 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:12:33,749 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:12:33,750 httpcore.http11 DEBUG receive_response_body.complete
17:12:33,750 httpcore.http11 DEBUG response_closed.started
17:12:33,751 httpcore.http11 DEBUG response_closed.complete
17:12:33,751 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:17:08,167 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:17:08,170 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:17:08,997 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:17:08,998 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:17:09,42 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:17:09,43 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:17:09,91 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:17:09,92 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:17:09,133 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:17:09,134 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:17:09,182 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:17:09,183 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:17:09,235 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:17:09,236 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:17:09,286 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:17:09,287 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:17:09,329 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:17:09,330 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:17:10,61 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Shijie. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:17:10,83 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:17:10,114 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea607a10>
17:17:10,114 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695e20> server_hostname='api.openai.com' timeout=5.0
17:17:10,124 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea607f50>
17:17:10,126 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:17:10,128 httpcore.http11 DEBUG send_request_headers.complete
17:17:10,129 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:17:10,129 httpcore.http11 DEBUG send_request_body.complete
17:17:10,130 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:17:10,811 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:17:10 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'553'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2587e5de9fbd49a12a6f3afe5b315eb4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=oIktnD1ixxJtJtQLqGqpjEUqmWsaKnQCOFNqr6HmNmU-1702419430-1-AcfQdDgJxMp03W4FCs9/d08dfPfluvpfOwnxQmF25leaLwfzbag2A2QpWZsdleUIGrFwEZIGD/r+WVYmzQ0xJBI=; path=/; expires=Tue, 12-Dec-23 22:47:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=_KIJYS9VnDXVeNWtGEbjxeIvFi0f0pgFU8rTpZlAtk4-1702419430805-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834955fe4e6c4cc2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:17:10,823 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:17:10,823 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:17:11,515 httpcore.http11 DEBUG receive_response_body.complete
17:17:11,516 httpcore.http11 DEBUG response_closed.started
17:17:11,517 httpcore.http11 DEBUG response_closed.complete
17:17:11,518 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:17:11,600 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:17:24,741 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:17:24,753 httpcore.connection DEBUG close.started
17:17:24,753 httpcore.connection DEBUG close.complete
17:17:24,753 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:17:24,772 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea607ed0>
17:17:24,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695e20> server_hostname='api.openai.com' timeout=5.0
17:17:24,779 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea607750>
17:17:24,780 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:17:24,781 httpcore.http11 DEBUG send_request_headers.complete
17:17:24,782 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:17:24,818 httpcore.http11 DEBUG send_request_body.complete
17:17:24,818 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:17:25,951 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:17:25 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'44'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'76108ff4a8a0b28cd9e9740bc625ff7e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495659ea854cc9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:17:25,957 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:17:25,958 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:17:25,959 httpcore.http11 DEBUG receive_response_body.complete
17:17:25,959 httpcore.http11 DEBUG response_closed.started
17:17:25,959 httpcore.http11 DEBUG response_closed.complete
17:17:25,960 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:17:25,961 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:17:25,997 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Shijie. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nYou can place it in the middle of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:17:26,8 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:17:26,10 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea664290>
17:17:26,11 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695fd0> server_hostname='api.openai.com' timeout=None
17:17:26,15 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea664210>
17:17:26,16 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:17:26,17 httpcore.http11 DEBUG send_request_headers.complete
17:17:26,17 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:17:26,18 httpcore.http11 DEBUG send_request_body.complete
17:17:26,18 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:17:26,227 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:17:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'102'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'139ec21c4fcab4dabc7a64902de5b5b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yfir9m93HDmAK588JMkomnn7zFdoLthL7QSR_fYHsi8-1702419446-1-AZ4F2FwaKtEy/I07K3G7yloSDAYuQBqKxEvs5JrTbSzewNBx635V/v3LFCbyUBekwf7fPfOOVcnwqiIfq62wbc0=; path=/; expires=Tue, 12-Dec-23 22:47:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=6QYSP8A4Dcf9OpbI3HfqFJZmQxUAWi7Vy9.VAN3JpzQ-1702419446223-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349566198986ac8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:17:26,234 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:17:26,235 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:17:26,236 httpcore.http11 DEBUG receive_response_body.complete
17:17:26,236 httpcore.http11 DEBUG response_closed.started
17:17:26,236 httpcore.http11 DEBUG response_closed.complete
17:17:26,237 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:17:26,272 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked:\n'''\nWhere should I place the first candle?\n'''\n                                               \nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y0, surface_height: y0 < surface_height // 2\n\n                                               \nYou asked:\n'''\nWhere should I place the second candle?\n'''                                                                                       \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0                                               \n\nYou asked:\n'''\nWhere should I place the second candle?\n'''                                              \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2\n                                               \nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, y0: y2 == y0 - 1\nlambda x2, x0: x2==x0                                    \n\nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, surface_height: y2 > surface_height // 2\n\n                                                                                   \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nHi, Shijie. Let us decorate a cake. Where should I place the first candle?\n'''                                                                                         \nAnd the human answered\n'''\nYou can place it in the middle of the cake.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:17:26,281 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:17:26,284 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea66ec90>
17:17:26,285 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea6967b0> server_hostname='api.openai.com' timeout=None
17:17:26,293 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea66fbd0>
17:17:26,294 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:17:26,295 httpcore.http11 DEBUG send_request_headers.complete
17:17:26,295 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:17:26,296 httpcore.http11 DEBUG send_request_body.complete
17:17:26,296 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:17:27,261 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:17:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'778'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'61114c5e5fd91b6d80c3d411cf0a5520'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pdvx5fYqiCy1nNpIKWAgX0t.7LYjzQr3RjuK4ODCtTc-1702419447-1-AYS1Q7a+7oeKi2rGQL/0pfMtBiTHoX8rdpnrV3EzelUnFQE7j77+9W/tmz77XEeGjBhARtPL4vydZhaH+qSmeTo=; path=/; expires=Tue, 12-Dec-23 22:47:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=jTIqA47h9ri.IkJeemFnBHoK8gDie3_THdbqg9RhN4A-1702419447256-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834956635a0c3031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:17:27,267 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:17:27,268 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:17:27,269 httpcore.http11 DEBUG receive_response_body.complete
17:17:27,270 httpcore.http11 DEBUG response_closed.started
17:17:27,271 httpcore.http11 DEBUG response_closed.complete
17:17:27,271 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:17:27,291 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:17:27,296 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:17:33,804 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:17:33,822 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:17:33,825 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:17:38,827 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:17:38,845 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:17:38,849 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:17:40,851 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:17:40,872 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:17:40,876 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:17:44,278 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:17:44,296 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:17:44,299 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:17:50,802 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:17:50,822 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:17:50,825 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:17:55,28 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:17:55,48 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:17:55,52 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:17:59,255 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:17:59,262 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:17:59,268 httpcore.connection DEBUG close.started
17:17:59,268 httpcore.connection DEBUG close.complete
17:17:59,269 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:17:59,271 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea607750>
17:17:59,272 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695e20> server_hostname='api.openai.com' timeout=5.0
17:17:59,280 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea650150>
17:17:59,280 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:17:59,282 httpcore.http11 DEBUG send_request_headers.complete
17:17:59,282 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:17:59,283 httpcore.http11 DEBUG send_request_body.complete
17:17:59,283 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:17:59,794 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:17:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'434'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'068cebe312e10465f7a4e81b401155f2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349573188b14cce-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:17:59,799 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:17:59,799 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:18:01,20 httpcore.http11 DEBUG receive_response_body.complete
17:18:01,21 httpcore.http11 DEBUG response_closed.started
17:18:01,22 httpcore.http11 DEBUG response_closed.complete
17:18:01,23 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:18:01,94 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:18:13,665 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:18:13,670 httpcore.connection DEBUG close.started
17:18:13,671 httpcore.connection DEBUG close.complete
17:18:13,671 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:18:13,701 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea4967d0>
17:18:13,702 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695e20> server_hostname='api.openai.com' timeout=5.0
17:18:13,709 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea496850>
17:18:13,710 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:18:13,712 httpcore.http11 DEBUG send_request_headers.complete
17:18:13,712 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:18:13,733 httpcore.http11 DEBUG send_request_body.complete
17:18:13,733 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:18:15,26 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:18:15 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'835'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9e9dbba75e847416ae9b87399ac82d38'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349578bbb433b9a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:18:15,28 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:18:15,28 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:18:15,29 httpcore.http11 DEBUG receive_response_body.complete
17:18:15,29 httpcore.http11 DEBUG response_closed.started
17:18:15,30 httpcore.http11 DEBUG response_closed.complete
17:18:15,30 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:18:15,31 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:18:15,61 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:18:15,65 httpcore.connection DEBUG close.started
17:18:15,65 httpcore.connection DEBUG close.complete
17:18:15,65 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:18:15,68 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea664210>
17:18:15,68 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695fd0> server_hostname='api.openai.com' timeout=None
17:18:15,73 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea664d90>
17:18:15,74 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:18:15,75 httpcore.http11 DEBUG send_request_headers.complete
17:18:15,75 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:18:15,76 httpcore.http11 DEBUG send_request_body.complete
17:18:15,76 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:18:15,277 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:18:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd47dae17215c8f9df25712db201d92e0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834957943ffe4ce2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:18:15,280 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:18:15,281 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:18:15,282 httpcore.http11 DEBUG receive_response_body.complete
17:18:15,282 httpcore.http11 DEBUG response_closed.started
17:18:15,282 httpcore.http11 DEBUG response_closed.complete
17:18:15,283 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:18:15,316 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:18:15,328 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:18:15,331 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea497050>
17:18:15,331 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695f40> server_hostname='api.openai.com' timeout=None
17:18:15,338 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea496ad0>
17:18:15,338 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:18:15,340 httpcore.http11 DEBUG send_request_headers.complete
17:18:15,340 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:18:15,341 httpcore.http11 DEBUG send_request_body.complete
17:18:15,341 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:18:15,598 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:18:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'131'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e9fcae3c5463810ec78009e757295f12'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qqgQyVL7VA5Xrvhsqaidbf9zT20tq1zjTubMFxdY9Vk-1702419495-1-ARjvLcfMp5D3twnpKzKHgISzD9VZa2lDKIyZIwEiNn94peQY6pITLUyxASqh+CP64IsW5F+c0pzhJcu+UHwT4lI=; path=/; expires=Tue, 12-Dec-23 22:48:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=0ofsoCdcueVnScCeHLW2U_cettmSfqwY6iiMJD0LCI4-1702419495592-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495795ee2d4d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:18:15,606 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:18:15,606 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:18:15,607 httpcore.http11 DEBUG receive_response_body.complete
17:18:15,608 httpcore.http11 DEBUG response_closed.started
17:18:15,608 httpcore.http11 DEBUG response_closed.complete
17:18:15,608 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:18:15,623 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:18:15,627 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:18:19,29 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:18:19,47 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:18:19,51 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:18:21,53 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:18:21,73 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:18:21,76 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:18:24,479 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:18:24,486 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:18:24,490 httpcore.connection DEBUG close.started
17:18:24,491 httpcore.connection DEBUG close.complete
17:18:24,491 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:18:24,494 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea4947d0>
17:18:24,494 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695e20> server_hostname='api.openai.com' timeout=5.0
17:18:24,501 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea495590>
17:18:24,501 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:18:24,503 httpcore.http11 DEBUG send_request_headers.complete
17:18:24,503 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:18:24,503 httpcore.http11 DEBUG send_request_body.complete
17:18:24,504 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:18:25,138 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:18:25 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'470'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'89522b8295c2bd97ec1dfcb633f91ad6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834957cf2b794d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:18:25,144 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:18:25,145 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:18:25,484 httpcore.http11 DEBUG receive_response_body.complete
17:18:25,485 httpcore.http11 DEBUG response_closed.started
17:18:25,486 httpcore.http11 DEBUG response_closed.complete
17:18:25,487 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:18:25,556 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:18:36,689 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:18:36,695 httpcore.connection DEBUG close.started
17:18:36,695 httpcore.connection DEBUG close.complete
17:18:36,696 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:18:36,698 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea4a2a10>
17:18:36,698 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695e20> server_hostname='api.openai.com' timeout=5.0
17:18:36,704 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea4a0cd0>
17:18:36,705 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:18:36,707 httpcore.http11 DEBUG send_request_headers.complete
17:18:36,708 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:18:36,739 httpcore.http11 DEBUG send_request_body.complete
17:18:36,740 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:18:37,880 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:18:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'633'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e13f1c0b302c78ae4e8e57fe027d4a47'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349581b6e684d1d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:18:37,884 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:18:37,885 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:18:37,886 httpcore.http11 DEBUG receive_response_body.complete
17:18:37,887 httpcore.http11 DEBUG response_closed.started
17:18:37,887 httpcore.http11 DEBUG response_closed.complete
17:18:37,888 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:18:37,889 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:18:37,922 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nYou shall put the second candle on the left of the first candle. There shall be some spaces between them but not that far.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:18:37,927 httpcore.connection DEBUG close.started
17:18:37,928 httpcore.connection DEBUG close.complete
17:18:37,928 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:18:37,931 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea4a9d10>
17:18:37,931 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea695fd0> server_hostname='api.openai.com' timeout=None
17:18:37,940 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea4a9d90>
17:18:37,941 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:18:37,943 httpcore.http11 DEBUG send_request_headers.complete
17:18:37,944 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:18:37,945 httpcore.http11 DEBUG send_request_body.complete
17:18:37,945 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:18:38,130 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:18:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4a6a03d077024ca6dea3fa09b15689dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834958232ae43b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:18:38,135 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:18:38,136 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:18:38,138 httpcore.http11 DEBUG receive_response_body.complete
17:18:38,138 httpcore.http11 DEBUG response_closed.started
17:18:38,138 httpcore.http11 DEBUG response_closed.complete
17:18:38,139 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:18:38,171 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked:\n'''\nWhere should I place the first candle?\n'''\n                                               \nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y0, surface_height: y0 < surface_height // 2\n\n                                               \nYou asked:\n'''\nWhere should I place the second candle?\n'''                                                                                       \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0                                               \n\nYou asked:\n'''\nWhere should I place the second candle?\n'''                                              \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2\n                                               \nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, y0: y2 == y0 - 1\nlambda x2, x0: x2==x0                                    \n\nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, surface_height: y2 > surface_height // 2\n\n                                                                                   \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''                                                                                         \nAnd the human answered\n'''\nYou shall put the second candle on the left of the first candle. There shall be some spaces between them but not that far.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:18:38,175 httpcore.connection DEBUG close.started
17:18:38,175 httpcore.connection DEBUG close.complete
17:18:38,176 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:18:38,178 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea496e90>
17:18:38,179 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efcea6967b0> server_hostname='api.openai.com' timeout=None
17:18:38,190 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efcea495590>
17:18:38,190 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:18:38,192 httpcore.http11 DEBUG send_request_headers.complete
17:18:38,192 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:18:38,193 httpcore.http11 DEBUG send_request_body.complete
17:18:38,193 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:18:38,867 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:18:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'564'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c685029dc9dab3b9eb8d30d391e59aed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495824ba364cfc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:18:38,872 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:18:38,873 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:18:38,875 httpcore.http11 DEBUG receive_response_body.complete
17:18:38,875 httpcore.http11 DEBUG response_closed.started
17:18:38,876 httpcore.http11 DEBUG response_closed.complete
17:18:38,877 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:20:47,444 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:20:47,448 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:20:48,288 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:20:48,289 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:20:48,332 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:20:48,333 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:20:48,383 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:20:48,384 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:20:48,425 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:20:48,426 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:20:48,479 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:20:48,481 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:20:48,521 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:20:48,522 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:20:48,570 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:20:48,571 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:20:48,611 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:20:48,612 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:20:50,202 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:20:50,225 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:20:50,256 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b0b593d50>
17:20:50,256 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b0b821d90> server_hostname='api.openai.com' timeout=5.0
17:20:50,268 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b0b593b50>
17:20:50,269 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:20:50,272 httpcore.http11 DEBUG send_request_headers.complete
17:20:50,273 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:20:50,274 httpcore.http11 DEBUG send_request_body.complete
17:20:50,274 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:20:50,700 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:20:50 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'354'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7547faa7867756e1363d2df49b2acdaa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BO2u4Y6XmdpSQ8i49QCLbXYPSMUY9rLATcWv0n4XLy4-1702419650-1-AZprirI6rS3bv1TEg2vsVwAT5rnIN5HOTC5dGvuwiGX7GCFjw+4+qRLKVF2B0PxropwNvlc3DNRfYYmP+a9/8Rg=; path=/; expires=Tue, 12-Dec-23 22:50:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=TVhr585ftbEoWolC8BhCKsVp_VHE089IDphrrnemlu8-1702419650693-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495b5e3c3a3035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:20:50,708 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:20:50,709 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:20:51,82 httpcore.http11 DEBUG receive_response_body.complete
17:20:51,83 httpcore.http11 DEBUG response_closed.started
17:20:51,84 httpcore.http11 DEBUG response_closed.complete
17:20:51,85 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:20:51,168 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:21:16,848 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:21:16,850 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:21:17,668 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:21:17,670 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:21:17,716 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:21:17,718 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:21:17,771 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:21:17,772 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:21:17,815 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:21:17,816 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:21:17,875 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:21:17,877 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:21:17,933 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:21:17,934 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:21:17,985 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:21:17,986 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:21:18,30 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:21:18,31 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:21:19,985 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:21:20,3 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:21:20,6 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0cfc959a90>
17:21:20,6 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0cfc919d90> server_hostname='api.openai.com' timeout=5.0
17:21:20,12 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0cfc88fb10>
17:21:20,13 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:21:20,14 httpcore.http11 DEBUG send_request_headers.complete
17:21:20,15 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:21:20,15 httpcore.http11 DEBUG send_request_body.complete
17:21:20,16 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:21:20,615 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:21:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'359f0d8c44c33629ce86959a27548b6e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=KewwGfE_RYSa10mYiu1p_9d7XHYSHBrZKMZNjJ1bxZU-1702419680-1-ATFX3UD6r8HVmm4i4RTjbCYOb6FqIF5sWzQcIauyYnr59VQNMOveNZHo8yz+B3iNBQ32wBUiWAyUVF6Owvq909E=; path=/; expires=Tue, 12-Dec-23 22:51:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BeJIEOw7I.UUXuaPv8tKUpP1u5Y0Z3Eva0oRHEQJLkA-1702419680608-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495c181a134d0c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:21:20,626 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:21:20,626 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:21:20,974 httpcore.http11 DEBUG receive_response_body.complete
17:21:20,976 httpcore.http11 DEBUG response_closed.started
17:21:20,976 httpcore.http11 DEBUG response_closed.complete
17:21:20,977 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:21:21,61 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:21:32,156 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:21:32,165 httpcore.connection DEBUG close.started
17:21:32,166 httpcore.connection DEBUG close.complete
17:21:32,166 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:21:32,169 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0cfc88fb10>
17:21:32,169 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0cfc919d90> server_hostname='api.openai.com' timeout=5.0
17:21:32,175 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0cfc88f7d0>
17:21:32,175 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:21:32,176 httpcore.http11 DEBUG send_request_headers.complete
17:21:32,176 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:21:32,206 httpcore.http11 DEBUG send_request_body.complete
17:21:32,207 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:21:33,411 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:21:33 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'501'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e614b37caea57ddd333cc4d3dd61fc94'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495c641ab84ccf-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:21:33,418 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:21:33,418 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:21:33,420 httpcore.http11 DEBUG receive_response_body.complete
17:21:33,420 httpcore.http11 DEBUG response_closed.started
17:21:33,421 httpcore.http11 DEBUG response_closed.complete
17:21:33,421 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:21:33,422 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:21:33,458 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nYou should play the second candle on the left of the first candle, but not too far away.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:21:33,468 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:21:33,471 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0cfc6ec290>
17:21:33,471 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0cfc919f40> server_hostname='api.openai.com' timeout=None
17:21:33,481 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0cfc6ec150>
17:21:33,482 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:21:33,484 httpcore.http11 DEBUG send_request_headers.complete
17:21:33,485 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:21:33,486 httpcore.http11 DEBUG send_request_body.complete
17:21:33,486 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:21:33,682 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:21:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c7f8268a608b12905e1d1dd8075c9a2e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=f3GW8GgK6jFAMDv9q5BGtx5R701mheQkoz78tph5kEc-1702419693-1-AQUV4vLnl6cSY5aU0hdT8WsKMA8xh3DzNHSNLeY6rpgYTXzQOksniajolIS0IY8B5ONn6VBkpnJuyIlW0GNFCFI=; path=/; expires=Tue, 12-Dec-23 22:51:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=TlliXl2SqcDLcDc03pCdLpGPy8It6KOsDuvEza1.bfg-1702419693676-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495c6c4c6b3059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:21:33,688 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:21:33,689 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:21:33,690 httpcore.http11 DEBUG receive_response_body.complete
17:21:33,691 httpcore.http11 DEBUG response_closed.started
17:21:33,691 httpcore.http11 DEBUG response_closed.complete
17:21:33,692 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:21:33,728 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked:\n'''\nWhere should I place the first candle?\n'''\n                                               \nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y0, surface_height: y0 < surface_height // 2\n\n                                               \nYou asked:\n'''\nWhere should I place the second candle?\n'''                                                                                       \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0                                               \n\nYou asked:\n'''\nWhere should I place the second candle?\n'''                                              \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2\n                                               \nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, y0: y2 == y0 - 1\nlambda x2, x0: x2==x0                                    \n\nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, surface_height: y2 > surface_height // 2\n\n                                                                                   \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the second candle?\n'''                                                                                         \nAnd the human answered\n'''\nYou should play the second candle on the left of the first candle, but not too far away.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:21:33,740 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:21:33,743 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0cfc6ed550>
17:21:33,743 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0cfc91a720> server_hostname='api.openai.com' timeout=None
17:21:33,749 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0cfc6ed5d0>
17:21:33,749 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:21:33,750 httpcore.http11 DEBUG send_request_headers.complete
17:21:33,751 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:21:33,752 httpcore.http11 DEBUG send_request_body.complete
17:21:33,752 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:21:34,653 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:21:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'774'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0e509181c5303bb955a3cedb18de630d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4.E0gJxyIV7RmbhWxbjsoIiC7NA5jOfzZe9EjE86_h0-1702419694-1-AYf8lIl/K0rFzrisbNNv67tOlshbvxxpeQ5HRVRb+l4Kno/oHJC8ieMD2VXlcVcr4RCySvUxurJb4mRbKDsMyss=; path=/; expires=Tue, 12-Dec-23 22:51:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LN1rJaBeGFWRISPrZ5Wd5LeosC335Qfq935wxjN2m68-1702419694648-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495c6dfcd83b99-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:21:34,661 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:21:34,662 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:21:34,663 httpcore.http11 DEBUG receive_response_body.complete
17:21:34,663 httpcore.http11 DEBUG response_closed.started
17:21:34,663 httpcore.http11 DEBUG response_closed.complete
17:21:34,664 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:22:11,522 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:22:11,525 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:22:12,369 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:22:12,370 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:22:12,411 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:22:12,412 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:22:12,460 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:22:12,461 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:22:12,502 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:22:12,503 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:22:12,550 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:22:12,552 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:22:12,614 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:22:12,616 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:22:12,665 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:22:12,666 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:22:12,706 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:22:12,707 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:22:13,650 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:22:13,668 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:22:13,698 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188ba61a50>
17:22:13,698 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201d90> server_hostname='api.openai.com' timeout=5.0
17:22:13,706 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a177d10>
17:22:13,708 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:22:13,710 httpcore.http11 DEBUG send_request_headers.complete
17:22:13,710 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:22:13,711 httpcore.http11 DEBUG send_request_body.complete
17:22:13,711 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:22:14,141 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:22:14 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'361'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7585b320ea5793ec5a2c3ffdbe75e2ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=M4dmlg7tNeYglIggBLXlbAVs2oaoIzr.whvW1fr_ZaY-1702419734-1-Actnf+ZXAGI/02KhpeSt0o529XjaelPqQoM5tCkgx5+GNHoRlqOAIpqI6JpUdQaIbyz+HrKY9aPHS5HdmiklDd0=; path=/; expires=Tue, 12-Dec-23 22:52:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ipkHaxnG5CC1qhDJz6Yd8Oyw4aX.uR9l8ftRChSpT1k-1702419734135-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495d67ac38300c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:22:14,148 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:22:14,149 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:22:14,556 httpcore.http11 DEBUG receive_response_body.complete
17:22:14,557 httpcore.http11 DEBUG response_closed.started
17:22:14,558 httpcore.http11 DEBUG response_closed.complete
17:22:14,559 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:22:14,641 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:22:25,521 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:22:25,531 httpcore.connection DEBUG close.started
17:22:25,532 httpcore.connection DEBUG close.complete
17:22:25,532 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:22:25,561 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a177d10>
17:22:25,562 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201d90> server_hostname='api.openai.com' timeout=5.0
17:22:25,571 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a177610>
17:22:25,572 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:22:25,574 httpcore.http11 DEBUG send_request_headers.complete
17:22:25,574 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:22:25,607 httpcore.http11 DEBUG send_request_body.complete
17:22:25,607 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:22:26,774 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:22:26 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'47'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'466'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7d807455e8de061c28bd1d928c0c666d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495db1d8744d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:22:26,779 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:22:26,780 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:22:26,782 httpcore.http11 DEBUG receive_response_body.complete
17:22:26,783 httpcore.http11 DEBUG response_closed.started
17:22:26,783 httpcore.http11 DEBUG response_closed.complete
17:22:26,784 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:22:26,785 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:22:26,823 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPlace the third candle below the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:22:26,834 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:22:26,837 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fd8310>
17:22:26,837 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201f40> server_hostname='api.openai.com' timeout=None
17:22:26,845 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fd8210>
17:22:26,846 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:22:26,849 httpcore.http11 DEBUG send_request_headers.complete
17:22:26,849 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:22:26,851 httpcore.http11 DEBUG send_request_body.complete
17:22:26,851 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:22:27,69 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:22:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'94f31335346d3a836ce1fe4fff4e6465'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aeG_BEt0ETUqyVFVtnGNfqQmXiaImI_a8v3mmzfnfEQ-1702419747-1-Afu8M/UsUAuBZDMth1+ECqNqiO98zKYuLGk9CTZsPxucoJCETfU987N2cBZKhXM2ln8RZ+aVLCrW7jTtyqg5Ar8=; path=/; expires=Tue, 12-Dec-23 22:52:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=YTI9cJf5XmZzyhf8XpxapMMrRVj9N1NkrTTGskGCJk0-1702419747064-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495db9cd8d4cee-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:22:27,74 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:22:27,75 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:22:27,77 httpcore.http11 DEBUG receive_response_body.complete
17:22:27,77 httpcore.http11 DEBUG response_closed.started
17:22:27,78 httpcore.http11 DEBUG response_closed.complete
17:22:27,78 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:22:27,118 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked:\n'''\nWhere should I place the first candle?\n'''\n                                               \nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y0, surface_height: y0 < surface_height // 2\n\n                                               \nYou asked:\n'''\nWhere should I place the second candle?\n'''                                                                                       \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 \nlambda x1, surface_width: x1 > surface_width // 2 \nlambda y0, y1: y1==y0                                               \n\nYou asked:\n'''\nWhere should I place the second candle?\n'''                                              \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1, surface_width: x1 == surface_width // 2\n                                               \nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, y0: y2 == y0 - 1\nlambda x2, x0: x2==x0                                    \n\nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda y2, surface_height: y2 > surface_height // 2\n\n                                                                                   \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the third candle?\n'''                                                                                         \nAnd the human answered\n'''\nPlace the third candle below the first candle.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:22:27,132 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:22:27,135 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fd9cd0>
17:22:27,135 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a202720> server_hostname='api.openai.com' timeout=None
17:22:27,142 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fd9b50>
17:22:27,143 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:22:27,144 httpcore.http11 DEBUG send_request_headers.complete
17:22:27,144 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:22:27,145 httpcore.http11 DEBUG send_request_body.complete
17:22:27,145 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:22:27,868 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:22:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'637'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'691d7a97f4cb44aac4b2b88c3433a216'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xDxui6mZG0hCjRma5rljEZGzEV.ruJdW0nO9zOpAkDc-1702419747-1-AdKmXdAs/4OvcK5Qf6u8Myv+WwZeCWDAJ8AQ+hTKGtClACbH0TUP8u/H4MUhGWS9sNqsoV4YstcDiUciJS5eDQI=; path=/; expires=Tue, 12-Dec-23 22:52:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3sHYjHkU4B_NStopxiZeWifzVlqQmANjBaFwnU9c6nw-1702419747863-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495dbba9353045-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:22:27,877 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:22:27,878 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:22:27,879 httpcore.http11 DEBUG receive_response_body.complete
17:22:27,879 httpcore.http11 DEBUG response_closed.started
17:22:27,880 httpcore.http11 DEBUG response_closed.complete
17:22:27,880 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:22:27,899 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:22:27,903 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:22:34,413 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:22:34,429 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:22:34,433 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:22:39,436 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:22:39,463 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:22:39,467 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:22:41,470 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:22:41,485 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:22:41,488 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:22:44,890 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:22:44,910 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:22:44,914 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:22:51,416 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:22:51,432 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:22:51,436 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:22:55,239 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:22:55,271 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:22:55,274 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:22:59,876 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:22:59,883 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:22:59,888 httpcore.connection DEBUG close.started
17:22:59,888 httpcore.connection DEBUG close.complete
17:22:59,889 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:22:59,892 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fe22d0>
17:22:59,893 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201d90> server_hostname='api.openai.com' timeout=5.0
17:22:59,902 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fbffd0>
17:22:59,903 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:22:59,906 httpcore.http11 DEBUG send_request_headers.complete
17:22:59,906 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:22:59,907 httpcore.http11 DEBUG send_request_body.complete
17:22:59,907 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:00,428 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'439'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9b5fdfa98ce3e33661574e2344ea4604'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495e886fe94d0c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:00,434 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:23:00,434 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:01,479 httpcore.http11 DEBUG receive_response_body.complete
17:23:01,480 httpcore.http11 DEBUG response_closed.started
17:23:01,481 httpcore.http11 DEBUG response_closed.complete
17:23:01,482 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:23:01,551 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:23:13,874 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:23:13,879 httpcore.connection DEBUG close.started
17:23:13,879 httpcore.connection DEBUG close.complete
17:23:13,880 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:23:13,912 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a00a5d0>
17:23:13,912 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201d90> server_hostname='api.openai.com' timeout=5.0
17:23:13,922 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a00a650>
17:23:13,923 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:13,925 httpcore.http11 DEBUG send_request_headers.complete
17:23:13,926 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:13,968 httpcore.http11 DEBUG send_request_body.complete
17:23:13,969 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:14,967 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'16'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'403'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e02638e3691046183247530e6992cc5a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495ee00baf4cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:14,971 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:23:14,972 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:14,973 httpcore.http11 DEBUG receive_response_body.complete
17:23:14,974 httpcore.http11 DEBUG response_closed.started
17:23:14,974 httpcore.http11 DEBUG response_closed.complete
17:23:14,975 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:23:14,976 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:23:15,10 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI'll move down.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:23:15,14 httpcore.connection DEBUG close.started
17:23:15,14 httpcore.connection DEBUG close.complete
17:23:15,15 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:23:15,17 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fe0810>
17:23:15,18 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201f40> server_hostname='api.openai.com' timeout=None
17:23:15,23 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fe12d0>
17:23:15,23 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:15,24 httpcore.http11 DEBUG send_request_headers.complete
17:23:15,24 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:15,25 httpcore.http11 DEBUG send_request_body.complete
17:23:15,25 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:15,230 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'348c17f270f0055a978495590f734961'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495ee6ed844ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:15,235 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:23:15,235 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:15,237 httpcore.http11 DEBUG receive_response_body.complete
17:23:15,237 httpcore.http11 DEBUG response_closed.started
17:23:15,237 httpcore.http11 DEBUG response_closed.complete
17:23:15,238 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:23:15,271 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI'll move down.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:23:15,283 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:23:15,285 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a009c50>
17:23:15,286 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201eb0> server_hostname='api.openai.com' timeout=None
17:23:15,292 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a009c10>
17:23:15,292 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:15,294 httpcore.http11 DEBUG send_request_headers.complete
17:23:15,294 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:15,295 httpcore.http11 DEBUG send_request_body.complete
17:23:15,295 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:15,493 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8bea75c7146137d04b45caadde7deeef'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=vN32B4ltsQNEZQEq20zAyj.FkuT.0uCiapd0Ks6UaTs-1702419795-1-Aasru+qsZ4U80AyNMSsZjlFU5DRti6ahRYm4ZAJhLyliQtYWjya0T/F3PQYdwXTNZ/c9BMi+5/MTaBjp0HM35Kw=; path=/; expires=Tue, 12-Dec-23 22:53:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Ka2sZZjz92zQ1O5WvWqN6A_QD5pNAr8Fv54eY.cGOqY-1702419795488-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495ee89e074d01-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:15,499 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:23:15,500 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:15,501 httpcore.http11 DEBUG receive_response_body.complete
17:23:15,502 httpcore.http11 DEBUG response_closed.started
17:23:15,502 httpcore.http11 DEBUG response_closed.complete
17:23:15,502 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:23:15,518 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:23:15,521 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:23:18,923 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:23:18,930 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:23:18,937 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:18,938 httpcore.http11 DEBUG send_request_headers.complete
17:23:18,939 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:18,939 httpcore.http11 DEBUG send_request_body.complete
17:23:18,939 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:19,429 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd01a00e819ec1c724d64b28374c7835b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495eff5f974cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:19,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:23:19,436 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:19,623 httpcore.http11 DEBUG receive_response_body.complete
17:23:19,624 httpcore.http11 DEBUG response_closed.started
17:23:19,624 httpcore.http11 DEBUG response_closed.complete
17:23:19,625 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:23:19,692 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:23:26,849 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:23:26,855 httpcore.connection DEBUG close.started
17:23:26,856 httpcore.connection DEBUG close.complete
17:23:26,857 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:23:26,860 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fea250>
17:23:26,861 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201d90> server_hostname='api.openai.com' timeout=5.0
17:23:26,868 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fea2d0>
17:23:26,869 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:26,870 httpcore.http11 DEBUG send_request_headers.complete
17:23:26,870 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:26,894 httpcore.http11 DEBUG send_request_body.complete
17:23:26,895 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:27,881 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:27 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'41'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'462'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0ca409e9958280e3794e9285e4021a83'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495f30fbea4cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:27,886 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:23:27,887 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:27,888 httpcore.http11 DEBUG receive_response_body.complete
17:23:27,889 httpcore.http11 DEBUG response_closed.started
17:23:27,890 httpcore.http11 DEBUG response_closed.complete
17:23:27,891 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:23:27,892 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:23:27,922 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nI'll move down a little bit more please.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:23:27,925 httpcore.connection DEBUG close.started
17:23:27,925 httpcore.connection DEBUG close.complete
17:23:27,926 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:23:27,929 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a021450>
17:23:27,929 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201eb0> server_hostname='api.openai.com' timeout=None
17:23:27,935 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a0214d0>
17:23:27,935 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:27,936 httpcore.http11 DEBUG send_request_headers.complete
17:23:27,937 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:27,937 httpcore.http11 DEBUG send_request_body.complete
17:23:27,937 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:28,125 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'98'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'261d0bc9e287e9fe9ba0121b71e328b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495f3799674d14-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:28,133 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:23:28,134 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:28,135 httpcore.http11 DEBUG receive_response_body.complete
17:23:28,135 httpcore.http11 DEBUG response_closed.started
17:23:28,135 httpcore.http11 DEBUG response_closed.complete
17:23:28,136 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:23:28,143 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:23:28,147 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:28,148 httpcore.http11 DEBUG send_request_headers.complete
17:23:28,148 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:28,149 httpcore.http11 DEBUG send_request_body.complete
17:23:28,149 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:28,680 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:28 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'450'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'448d32677c69403471631a4ec1b109fc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495f38ec9b4cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:28,684 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:23:28,684 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:29,725 httpcore.http11 DEBUG receive_response_body.complete
17:23:29,726 httpcore.http11 DEBUG response_closed.started
17:23:29,727 httpcore.http11 DEBUG response_closed.complete
17:23:29,728 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:23:29,800 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:23:42,55 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:23:42,61 httpcore.connection DEBUG close.started
17:23:42,62 httpcore.connection DEBUG close.complete
17:23:42,62 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:23:42,64 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fd9490>
17:23:42,65 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201d90> server_hostname='api.openai.com' timeout=5.0
17:23:42,72 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f1889fd8690>
17:23:42,72 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:42,73 httpcore.http11 DEBUG send_request_headers.complete
17:23:42,74 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:42,97 httpcore.http11 DEBUG send_request_body.complete
17:23:42,97 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:42,856 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:42 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'16'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'410'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6781cdc8e1c2880671875a11bc123415'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495f8ff9b14d10-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:42,861 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:23:42,861 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:42,863 httpcore.http11 DEBUG receive_response_body.complete
17:23:42,863 httpcore.http11 DEBUG response_closed.started
17:23:42,864 httpcore.http11 DEBUG response_closed.complete
17:23:42,865 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:23:42,866 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:23:42,896 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nI'll move down.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:23:42,899 httpcore.connection DEBUG close.started
17:23:42,900 httpcore.connection DEBUG close.complete
17:23:42,900 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:23:42,903 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a009190>
17:23:42,903 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201eb0> server_hostname='api.openai.com' timeout=None
17:23:42,908 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a00b990>
17:23:42,908 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:42,909 httpcore.http11 DEBUG send_request_headers.complete
17:23:42,910 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:42,910 httpcore.http11 DEBUG send_request_body.complete
17:23:42,910 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:43,150 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'140'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b9c3bf6f817eac040988b657747f4aec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495f952e264d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:43,156 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:23:43,157 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:43,159 httpcore.http11 DEBUG receive_response_body.complete
17:23:43,160 httpcore.http11 DEBUG response_closed.started
17:23:43,160 httpcore.http11 DEBUG response_closed.complete
17:23:43,161 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:23:43,176 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:23:43,179 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:23:46,581 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:23:46,590 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:23:46,596 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:46,597 httpcore.http11 DEBUG send_request_headers.complete
17:23:46,597 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:46,598 httpcore.http11 DEBUG send_request_body.complete
17:23:46,598 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:47,38 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:47 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'332'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e57b1f91e81219fac29ff6a1f9552c7e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495fac393f4d10-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:47,42 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:23:47,43 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:47,202 httpcore.http11 DEBUG receive_response_body.complete
17:23:47,203 httpcore.http11 DEBUG response_closed.started
17:23:47,203 httpcore.http11 DEBUG response_closed.complete
17:23:47,204 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:23:47,276 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Shijie4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:23:54,402 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Shijie4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:23:54,406 httpcore.connection DEBUG close.started
17:23:54,407 httpcore.connection DEBUG close.complete
17:23:54,407 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:23:54,410 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a022f90>
17:23:54,410 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201d90> server_hostname='api.openai.com' timeout=5.0
17:23:54,417 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a023090>
17:23:54,418 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:54,419 httpcore.http11 DEBUG send_request_headers.complete
17:23:54,419 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:54,437 httpcore.http11 DEBUG send_request_body.complete
17:23:54,438 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:55,165 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:55 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'338'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd8ff083db4643cd027ecb3a42b9bc19a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495fdd18703b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:55,170 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:23:55,171 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:55,173 httpcore.http11 DEBUG receive_response_body.complete
17:23:55,173 httpcore.http11 DEBUG response_closed.started
17:23:55,174 httpcore.http11 DEBUG response_closed.complete
17:23:55,174 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:23:55,175 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:23:55,203 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:23:55,206 httpcore.connection DEBUG close.started
17:23:55,206 httpcore.connection DEBUG close.complete
17:23:55,207 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:23:55,209 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a026390>
17:23:55,210 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f188a201eb0> server_hostname='api.openai.com' timeout=None
17:23:55,216 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f188a026410>
17:23:55,216 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:23:55,217 httpcore.http11 DEBUG send_request_headers.complete
17:23:55,217 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:23:55,218 httpcore.http11 DEBUG send_request_body.complete
17:23:55,218 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:23:55,431 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:23:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'85'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6b39f852a3e7917962b42ebfe644e3b1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83495fe21e7a3b82-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:23:55,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:23:55,436 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:23:55,437 httpcore.http11 DEBUG receive_response_body.complete
17:23:55,437 httpcore.http11 DEBUG response_closed.started
17:23:55,438 httpcore.http11 DEBUG response_closed.complete
17:23:55,438 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:23:55,456 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:23:55,461 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:23:58,864 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:23:58,882 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:23:58,887 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:24:00,890 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:24:00,910 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:24:00,915 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:24:04,317 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:37:42,492 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:37:42,495 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:37:43,329 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:37:43,330 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:37:43,374 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:37:43,375 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:37:43,424 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:37:43,425 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:37:43,466 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:37:43,467 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:37:43,515 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:37:43,516 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:37:43,557 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:37:43,558 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:37:43,607 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:37:43,608 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:37:43,649 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:37:43,650 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:15,282 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:38:15,302 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:38:15,334 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb4375d1a90>
17:38:15,334 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fb43758dd00> server_hostname='api.openai.com' timeout=5.0
17:38:15,345 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fb437507a10>
17:38:15,346 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:15,348 httpcore.http11 DEBUG send_request_headers.complete
17:38:15,348 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:15,349 httpcore.http11 DEBUG send_request_body.complete
17:38:15,350 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:15,792 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:38:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd6fc973d84afc98d0c4c1a1f262943c5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=n9n_87_YstxDYC0TWitSMZM_0HoR4QohXZP7HrnU_6g-1702420695-1-AUoPSsW889ZynXqQm4ekinhBJJCgErXJx6uWCvBdWZbnxj5UpiqAj5Adh74WA09qo3KXCJLDTGeIC2tFys6bKrc=; path=/; expires=Tue, 12-Dec-23 23:08:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pAZdQilaLDRe4VDd7yRwrDcKp.K9bpEi2iC5ECbKSjo-1702420695786-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834974e1ec1c3b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:15,800 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:38:15,801 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:16,191 httpcore.http11 DEBUG receive_response_body.complete
17:38:16,192 httpcore.http11 DEBUG response_closed.started
17:38:16,193 httpcore.http11 DEBUG response_closed.complete
17:38:16,194 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:38:16,280 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:38:42,58 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:38:42,61 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:42,883 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:38:42,884 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:42,932 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:38:42,933 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:42,990 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:38:42,991 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:43,36 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:38:43,37 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:43,93 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:38:43,94 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:43,140 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:38:43,141 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:43,197 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:38:43,199 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:43,247 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:38:43,248 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:38:44,538 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Yuhang. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:38:44,555 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:38:44,560 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035c12b910>
17:38:44,560 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b1eb0> server_hostname='api.openai.com' timeout=5.0
17:38:44,568 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035c12be50>
17:38:44,569 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:44,571 httpcore.http11 DEBUG send_request_headers.complete
17:38:44,572 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:44,573 httpcore.http11 DEBUG send_request_body.complete
17:38:44,573 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:38:45,228 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:38:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'529'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2a7204f75042dff14325fdfdd7a5c1f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LNZqbcGFCXrLJEw1tYtDs7q90RM1M_QWQtJ7mCWRNsM-1702420725-1-AV1POo5wFIy5Y7VtrkDtomcJNOLAifC83tC4XPkDq6/YB2XUQrK5PCn88CmqIVgXplt6MtDT+sY8P4sVtb0O5xo=; path=/; expires=Tue, 12-Dec-23 23:08:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=JMHH9s5RFn3a9VXnKiGIP_1jZWAbICaTW_u6EOqoRSY-1702420725221-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834975989b5d4ce0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:38:45,239 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:38:45,239 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:38:45,896 httpcore.http11 DEBUG receive_response_body.complete
17:38:45,897 httpcore.http11 DEBUG response_closed.started
17:38:45,898 httpcore.http11 DEBUG response_closed.complete
17:38:45,899 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:38:45,982 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:38:59,19 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:38:59,28 httpcore.connection DEBUG close.started
17:38:59,29 httpcore.connection DEBUG close.complete
17:38:59,29 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:38:59,32 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035c12bf90>
17:38:59,32 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b1eb0> server_hostname='api.openai.com' timeout=5.0
17:38:59,38 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035c12b650>
17:38:59,38 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:38:59,40 httpcore.http11 DEBUG send_request_headers.complete
17:38:59,41 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:38:59,62 httpcore.http11 DEBUG send_request_body.complete
17:38:59,62 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:00,34 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:39:00 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'38'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'467'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5f586eef33cdcbf91dc8ea0b104794ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834975f30b504cc2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:00,39 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:39:00,39 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:00,40 httpcore.http11 DEBUG receive_response_body.complete
17:39:00,41 httpcore.http11 DEBUG response_closed.started
17:39:00,41 httpcore.http11 DEBUG response_closed.complete
17:39:00,42 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:39:00,43 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:39:00,78 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Yuhang. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nWhat should I say? OK, Justin. So I'm\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:39:00,89 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:39:00,92 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bf8c1d0>
17:39:00,92 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b1fd0> server_hostname='api.openai.com' timeout=None
17:39:00,106 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bf8c250>
17:39:00,107 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:00,108 httpcore.http11 DEBUG send_request_headers.complete
17:39:00,109 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:00,109 httpcore.http11 DEBUG send_request_body.complete
17:39:00,110 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:00,350 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:39:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'147'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ec294c6513a7b52ff42b4ff2d5ea9126'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WcgfzJk5Shv3OuI8WgnM2g82GJuJjOwXLamecj29oRo-1702420740-1-AesC5q26Y1KS8GqdalhxUiLiSMmBIm2hy84Q6tV8vQCUErME1/a6cqWofw96A++QfvthisVxzY5mUfLh+cvuy60=; path=/; expires=Tue, 12-Dec-23 23:09:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1eiUYJBiRKQHepoCjhlhLPtg4vV2q4o8HLn8vTftxXo-1702420740345-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834975f9acb84cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:00,358 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:39:00,358 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:00,359 httpcore.http11 DEBUG receive_response_body.complete
17:39:00,360 httpcore.http11 DEBUG response_closed.started
17:39:00,360 httpcore.http11 DEBUG response_closed.complete
17:39:00,360 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:39:00,394 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nHi, Yuhang. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nWhat should I say? OK, Justin. So I'm\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:39:00,406 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:39:00,409 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035c3bc450>
17:39:00,409 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b2330> server_hostname='api.openai.com' timeout=None
17:39:00,415 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bf8ca90>
17:39:00,416 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:00,417 httpcore.http11 DEBUG send_request_headers.complete
17:39:00,417 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:00,418 httpcore.http11 DEBUG send_request_body.complete
17:39:00,418 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:01,476 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:39:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'956'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a5def9213c20bca2bec271e0088fd3a3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=bw2WcW_2YgJ4vr.SQNnCSE9iaFe4VVAsIetW2E5F4nc-1702420741-1-ASDhXLL76hTBZ6Q0cobdhdWJOYXravoouzzYCchNhktT1aBZ9yinkDVE0E459OlCFfC8ATAhHHLP1P7q9G22ucA=; path=/; expires=Tue, 12-Dec-23 23:09:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=CJNTbioAibFLpUKVDKCOz3yEoaQsjEv7rsOL8LLzFgU-1702420741471-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834975fb9e046aca-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:01,483 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:39:01,484 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:01,486 httpcore.http11 DEBUG receive_response_body.complete
17:39:01,486 httpcore.http11 DEBUG response_closed.started
17:39:01,487 httpcore.http11 DEBUG response_closed.complete
17:39:01,487 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:39:01,496 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I'm sorry, Yuhang. I didn't understand your response. Could you please tell me where you would like me to place the first candle? Let's focus on the task at hand and we can talk about other things later.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:39:01,500 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:01,503 httpcore.http11 DEBUG send_request_headers.complete
17:39:01,503 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:01,504 httpcore.http11 DEBUG send_request_body.complete
17:39:01,505 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:02,54 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:39:02 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'469'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'733c35b323ebcc5eaac8b6830c8bad8d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497602688d4cc2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:02,59 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:39:02,59 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:04,75 httpcore.http11 DEBUG receive_response_body.complete
17:39:04,76 httpcore.http11 DEBUG response_closed.started
17:39:04,77 httpcore.http11 DEBUG response_closed.complete
17:39:04,78 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:39:04,147 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:39:25,165 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:39:25,172 httpcore.connection DEBUG close.started
17:39:25,173 httpcore.connection DEBUG close.complete
17:39:25,173 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:39:25,203 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfa5450>
17:39:25,204 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b1eb0> server_hostname='api.openai.com' timeout=5.0
17:39:25,213 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfa54d0>
17:39:25,214 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:25,216 httpcore.http11 DEBUG send_request_headers.complete
17:39:25,216 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:25,258 httpcore.http11 DEBUG send_request_body.complete
17:39:25,259 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:26,155 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:39:26 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'38'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ecfff88a16dce4b5e3ccda9097a3446f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834976969e1d4cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:26,161 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:39:26,162 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:26,163 httpcore.http11 DEBUG receive_response_body.complete
17:39:26,163 httpcore.http11 DEBUG response_closed.started
17:39:26,163 httpcore.http11 DEBUG response_closed.complete
17:39:26,164 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:39:26,164 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:39:26,196 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI'm sorry, Yuhang. I didn't understand your response. Could you please tell me where you would like me to place the first candle? Let's focus on the task at hand and we can talk about other things later.\n'''\nAnd the human answered\n'''\nLike put the first one at the center.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:39:26,200 httpcore.connection DEBUG close.started
17:39:26,200 httpcore.connection DEBUG close.complete
17:39:26,200 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:39:26,202 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bf8c250>
17:39:26,203 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b1fd0> server_hostname='api.openai.com' timeout=None
17:39:26,216 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bf8c490>
17:39:26,216 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:26,217 httpcore.http11 DEBUG send_request_headers.complete
17:39:26,218 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:26,218 httpcore.http11 DEBUG send_request_body.complete
17:39:26,219 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:26,429 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:39:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'583cf72dcdd57e765253e6e358844a8d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349769cde093059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:26,436 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:39:26,437 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:26,438 httpcore.http11 DEBUG receive_response_body.complete
17:39:26,438 httpcore.http11 DEBUG response_closed.started
17:39:26,439 httpcore.http11 DEBUG response_closed.complete
17:39:26,439 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:39:26,473 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked:\n'''\nWhere should I place the first candle?\n'''\n                                               \nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y0 < surface_height // 2\n\n                                               \nYou asked:\n'''\nWhere should I place the second candle?\n'''                                                                                       \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y1 > surface_height // 2 \nlambda x0, y0, y0, y1, surface_width, surface_height: x1 > surface_width // 2 \nlambda x0, y0, y0, y1, surface_width, surface_height: y1==y0                                               \n\nYou asked:\n'''\nWhere should I place the second candle?\n'''                                              \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y1 == surface_height // 2\nlambda x0, y0, y0, y1, surface_width, surface_height: x1 == surface_width // 2\n                                               \nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y2 == y0 - 1\nlambda x0, y0, y0, y1, surface_width, surface_height: x2==x0                                    \n\nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y2 > surface_height // 2\n\n                                                                                   \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nI'm sorry, Yuhang. I didn't understand your response. Could you please tell me where you would like me to place the first candle? Let's focus on the task at hand and we can talk about other things later.\n'''                                                                                         \nAnd the human answered\n'''\nLike put the first one at the center.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:39:26,484 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:39:26,487 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfaab90>
17:39:26,487 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b27b0> server_hostname='api.openai.com' timeout=None
17:39:26,492 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfaae10>
17:39:26,492 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:26,493 httpcore.http11 DEBUG send_request_headers.complete
17:39:26,494 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:26,494 httpcore.http11 DEBUG send_request_body.complete
17:39:26,495 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:27,706 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:39:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ce65fdb62812e3ecd4aa3c30135b20b7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=TzuWlPBz5AbQ7aDNFKI9qhBVqQ.KlOljW.2ueGc1xoA-1702420767-1-AWr/c2q7MHmCuptkTCZHLMNpbvUWYN7pd7mNcLpUotg5tKm/gDmfyf/qVsH5FR5pPwSoAUnG6NL5/3OS/m1XmlQ=; path=/; expires=Tue, 12-Dec-23 23:09:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=9uXq.B1WDKlZUoyODXqvX85Bu3PHFAEVlCIyh3_wb.k-1702420767702-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349769e9fb54cd4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:27,713 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:39:27,714 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:39:27,716 httpcore.http11 DEBUG receive_response_body.complete
17:39:27,717 httpcore.http11 DEBUG response_closed.started
17:39:27,717 httpcore.http11 DEBUG response_closed.complete
17:39:27,718 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:39:27,738 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:27,742 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:34,253 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:34,267 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:34,270 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:39,272 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:39,295 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:39,298 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:41,300 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:41,318 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:41,321 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:44,723 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:44,743 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:44,747 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:51,249 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:51,268 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:51,275 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:55,79 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:55,97 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:39:55,100 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:39:58,901 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:39:58,906 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:39:58,913 httpcore.connection DEBUG close.started
17:39:58,914 httpcore.connection DEBUG close.complete
17:39:58,915 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:39:58,917 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfa40d0>
17:39:58,918 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b1eb0> server_hostname='api.openai.com' timeout=5.0
17:39:58,923 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfa9210>
17:39:58,924 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:39:58,925 httpcore.http11 DEBUG send_request_headers.complete
17:39:58,925 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:39:58,926 httpcore.http11 DEBUG send_request_body.complete
17:39:58,926 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:39:59,431 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:39:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f62a7c417f1267b48700df68d998a399'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497769488f305d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:39:59,437 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:39:59,438 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:00,667 httpcore.http11 DEBUG receive_response_body.complete
17:40:00,668 httpcore.http11 DEBUG response_closed.started
17:40:00,669 httpcore.http11 DEBUG response_closed.complete
17:40:00,670 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:40:00,744 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:40:13,218 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:40:13,223 httpcore.connection DEBUG close.started
17:40:13,223 httpcore.connection DEBUG close.complete
17:40:13,224 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:40:13,226 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfc77d0>
17:40:13,227 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b1eb0> server_hostname='api.openai.com' timeout=5.0
17:40:13,232 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfc7850>
17:40:13,233 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:13,234 httpcore.http11 DEBUG send_request_headers.complete
17:40:13,234 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:13,257 httpcore.http11 DEBUG send_request_body.complete
17:40:13,258 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:14,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:40:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a932e67c62bd9fb968260d02b73a9418'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834977c2bdf34d1e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:14,27 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:40:14,28 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:14,29 httpcore.http11 DEBUG receive_response_body.complete
17:40:14,30 httpcore.http11 DEBUG response_closed.started
17:40:14,30 httpcore.http11 DEBUG response_closed.complete
17:40:14,31 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:40:14,32 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:40:14,62 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nmove to right and up\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:40:14,66 httpcore.connection DEBUG close.started
17:40:14,66 httpcore.connection DEBUG close.complete
17:40:14,66 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:40:14,69 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfa7ed0>
17:40:14,69 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b1fd0> server_hostname='api.openai.com' timeout=None
17:40:14,80 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bf8c290>
17:40:14,80 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:14,81 httpcore.http11 DEBUG send_request_headers.complete
17:40:14,82 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:14,82 httpcore.http11 DEBUG send_request_body.complete
17:40:14,82 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:14,281 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:40:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'475693f12d54748acf03addcb6a4f3a6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834977c80e023ba5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:14,287 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:40:14,287 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:14,289 httpcore.http11 DEBUG receive_response_body.complete
17:40:14,289 httpcore.http11 DEBUG response_closed.started
17:40:14,289 httpcore.http11 DEBUG response_closed.complete
17:40:14,290 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:40:14,322 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nmove to right and up\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:40:14,334 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:40:14,338 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfc7ad0>
17:40:14,338 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f035c1b1f40> server_hostname='api.openai.com' timeout=None
17:40:14,344 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f035bfc5a90>
17:40:14,345 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:40:14,346 httpcore.http11 DEBUG send_request_headers.complete
17:40:14,346 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:40:14,347 httpcore.http11 DEBUG send_request_body.complete
17:40:14,347 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:40:14,612 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:40:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'162'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6d753571fb148ac83e278bcaaa845a48'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ruXMQ9zPaoMG8q2Q2425INMuaxo7seSuOtpjJeOcbwg-1702420814-1-AQ4LwKo1/OB5Qnera7wHrxWZbtUUL615aUdLl2ZlI2VIG9aL6nNfklEMOwxgwQKtVSUifryUG0tm7jKmGFDUTsQ=; path=/; expires=Tue, 12-Dec-23 23:10:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=m8oyiWIqWqbJ.fudbLZMICTEzRXS545.n6gMc6MivHQ-1702420814608-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834977c9a8b34d13-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:40:14,617 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:40:14,618 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:40:14,619 httpcore.http11 DEBUG receive_response_body.complete
17:40:14,620 httpcore.http11 DEBUG response_closed.started
17:40:14,620 httpcore.http11 DEBUG response_closed.complete
17:40:14,621 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:41:34,149 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:41:34,153 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:41:34,966 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:41:34,967 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:41:35,11 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:41:35,12 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:41:35,61 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:41:35,62 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:41:35,104 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:41:35,105 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:41:35,153 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:41:35,154 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:41:35,198 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:41:35,199 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:41:35,248 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:41:35,249 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:41:35,290 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:41:35,291 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:41:37,596 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Yuhang. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:41:37,620 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:41:37,652 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f654d7990>
17:41:37,652 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9f65759eb0> server_hostname='api.openai.com' timeout=5.0
17:41:37,661 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f654d7ed0>
17:41:37,662 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:37,665 httpcore.http11 DEBUG send_request_headers.complete
17:41:37,666 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:37,667 httpcore.http11 DEBUG send_request_body.complete
17:41:37,668 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:38,311 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:41:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'518'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4cbc5899094161c3e1485b4dccdd7036'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dKMgBwdF2ZnDN3eX3ZnqpdqBo2X69xIZVLq_IgUTJBU-1702420898-1-AZDafB9Xc11FjShsY0avN4hTjkCkFOmYNenBrX0CKAy4ne2pCUeH9PK819omPhIXKRjiwOyZjdszHHhGKHq3Fw0=; path=/; expires=Tue, 12-Dec-23 23:11:38 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=8sb0vIFZ5w5nE7IBrJ5QeOzwpqlxfXiWdrPnnO2nJV8-1702420898306-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834979d26aa84cee-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:38,321 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:41:38,322 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:38,944 httpcore.http11 DEBUG receive_response_body.complete
17:41:38,945 httpcore.http11 DEBUG response_closed.started
17:41:38,946 httpcore.http11 DEBUG response_closed.complete
17:41:38,947 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:41:39,34 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:41:52,422 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:41:52,432 httpcore.connection DEBUG close.started
17:41:52,432 httpcore.connection DEBUG close.complete
17:41:52,433 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:41:52,436 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f654d7fd0>
17:41:52,436 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9f65759eb0> server_hostname='api.openai.com' timeout=5.0
17:41:52,441 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f654d7b50>
17:41:52,441 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:52,443 httpcore.http11 DEBUG send_request_headers.complete
17:41:52,443 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:52,477 httpcore.http11 DEBUG send_request_body.complete
17:41:52,478 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:53,365 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:41:53 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'407'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1880f50decc1fd9a410e0aa6174d222c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497a2ecb8e4d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:53,369 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:41:53,370 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:53,371 httpcore.http11 DEBUG receive_response_body.complete
17:41:53,372 httpcore.http11 DEBUG response_closed.started
17:41:53,372 httpcore.http11 DEBUG response_closed.complete
17:41:53,373 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:41:53,374 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:41:53,414 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Yuhang. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nAnd put the first one at the center.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:41:53,426 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:41:53,430 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f655303d0>
17:41:53,430 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9f65759fd0> server_hostname='api.openai.com' timeout=None
17:41:53,441 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f65530f10>
17:41:53,442 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:53,444 httpcore.http11 DEBUG send_request_headers.complete
17:41:53,444 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:53,445 httpcore.http11 DEBUG send_request_body.complete
17:41:53,446 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:53,671 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:41:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'133'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a2e61ab3638a29864aee5c7a11153ab0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xOHpn1Ok5bE_tuJ36OhjiO18Y9w8JF_.YgHUSKmAohI-1702420913-1-AYaYN5YkdESxo4jQT29K4IVrYMo+Dq5sH8Yk3YcrZowRZj1AbyB9GRIwl1rEF3tNEx/j/6IHbi6c52H3LqoSnaE=; path=/; expires=Tue, 12-Dec-23 23:11:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=273tpoYwsB8G6cNPuqZbBEbzCoDydNfjHxpW1NOh9Kw-1702420913666-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497a350c584cec-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:53,678 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:41:53,678 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:53,679 httpcore.http11 DEBUG receive_response_body.complete
17:41:53,680 httpcore.http11 DEBUG response_closed.started
17:41:53,680 httpcore.http11 DEBUG response_closed.complete
17:41:53,681 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:41:53,735 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked:\n'''\nWhere should I place the first candle?\n'''\n                                               \nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y0 < surface_height // 2\n\n                                               \nYou asked:\n'''\nWhere should I place the second candle?\n'''                                                                                       \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y1 > surface_height // 2 \nlambda x0, y0, y0, y1, surface_width, surface_height: x1 > surface_width // 2 \nlambda x0, y0, y0, y1, surface_width, surface_height: y1==y0                                               \n\nYou asked:\n'''\nWhere should I place the second candle?\n'''                                              \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y1 == surface_height // 2\nlambda x0, y0, y0, y1, surface_width, surface_height: x1 == surface_width // 2\n                                               \nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y2 == y0 - 1\nlambda x0, y0, y0, y1, surface_width, surface_height: x2==x0                                    \n\nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, y0, y1, surface_width, surface_height: y2 > surface_height // 2\n\n                                                                                   \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nHi, Yuhang. Let us decorate a cake. Where should I place the first candle?\n'''                                                                                         \nAnd the human answered\n'''\nAnd put the first one at the center.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:41:53,747 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:41:53,750 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f65532110>
17:41:53,750 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9f6575a7b0> server_hostname='api.openai.com' timeout=None
17:41:53,758 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f65523750>
17:41:53,759 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:41:53,761 httpcore.http11 DEBUG send_request_headers.complete
17:41:53,762 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:41:53,763 httpcore.http11 DEBUG send_request_body.complete
17:41:53,763 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:41:54,706 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:41:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'819'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'da9394f25e90eaa5b41ce72fcaa2413b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cYtKKaDrrv0HVDkJcE4Lm7Jkthm6l1rS6L4hxEkCoHI-1702420914-1-AVOCuLd9SQOInOaqjJwuHJAoQT6dtAE7Il5JLJmvZJaqPU8P+kjcYbNd8g00zpHJdkU6Kmr4iL73lGxMwbrEPs4=; path=/; expires=Tue, 12-Dec-23 23:11:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=r8s9cBcQAsrxv1KFTVUchtbsAX1qpUyWHOYrYF0fGv8-1702420914701-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497a370f994d0d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:41:54,714 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:41:54,714 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:41:54,715 httpcore.http11 DEBUG receive_response_body.complete
17:41:54,715 httpcore.http11 DEBUG response_closed.started
17:41:54,716 httpcore.http11 DEBUG response_closed.complete
17:41:54,716 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:41:54,733 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:41:54,738 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:01,246 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:01,261 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:01,264 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:06,266 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:06,284 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:06,289 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:08,292 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:08,310 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:08,313 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:11,716 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:11,736 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:11,739 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:18,242 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:18,266 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:18,269 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:21,671 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:21,686 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:42:21,690 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:42:24,692 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:42:24,697 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:42:24,701 httpcore.connection DEBUG close.started
17:42:24,701 httpcore.connection DEBUG close.complete
17:42:24,702 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:42:24,705 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f654d7b50>
17:42:24,705 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9f65759eb0> server_hostname='api.openai.com' timeout=5.0
17:42:24,711 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9f65520450>
17:42:24,712 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:24,713 httpcore.http11 DEBUG send_request_headers.complete
17:42:24,713 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:24,714 httpcore.http11 DEBUG send_request_body.complete
17:42:24,714 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:25,290 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:42:25 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'581d3f7d9c3559dc41e58b3916552ecf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497af87bf33010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:25,295 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:42:25,296 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:30,57 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:44:30,61 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:44:30,872 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:44:30,873 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:44:30,921 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:44:30,922 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:44:30,979 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:44:30,980 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:44:31,27 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:44:31,29 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:44:31,81 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:44:31,82 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:44:31,122 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:44:31,123 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:44:31,170 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:44:31,171 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:44:31,211 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:44:31,212 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:44:32,245 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:32,267 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:32,299 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc349db850>
17:44:32,300 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a59f40> server_hostname='api.openai.com' timeout=5.0
17:44:32,309 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc349dbd90>
17:44:32,311 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:32,312 httpcore.http11 DEBUG send_request_headers.complete
17:44:32,313 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:32,313 httpcore.http11 DEBUG send_request_body.complete
17:44:32,314 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:32,782 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:44:32 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'358'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4bd07cf09342077ccb679c55e322cfdb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fBsTb2O.teJTw.8.pAgiXMNLfvuRheWu9eocKpxsytM-1702421072-1-AZQgOioTWMdeMqJMy5SeuOiNgM7gmqWZmkOYbIs7HH99Xyb/M6SH12IcvjbmwHTIMNvUoXZYom8sAyrtTzEFyXU=; path=/; expires=Tue, 12-Dec-23 23:14:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=L3mEkbEIys_QDMg5VmqS5NCv28sWEVg.fZqnanmcJe4-1702421072776-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497e15f9344d07-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:32,794 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:32,795 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:33,142 httpcore.http11 DEBUG receive_response_body.complete
17:44:33,142 httpcore.http11 DEBUG response_closed.started
17:44:33,142 httpcore.http11 DEBUG response_closed.complete
17:44:33,143 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:33,222 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:44:44,432 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:44:44,442 httpcore.connection DEBUG close.started
17:44:44,442 httpcore.connection DEBUG close.complete
17:44:44,443 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:44,445 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34a01a90>
17:44:44,445 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a59f40> server_hostname='api.openai.com' timeout=5.0
17:44:44,451 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc349dbe90>
17:44:44,451 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:44,452 httpcore.http11 DEBUG send_request_headers.complete
17:44:44,452 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:44,509 httpcore.http11 DEBUG send_request_body.complete
17:44:44,509 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:45,354 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:44:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'401'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e6dd4da3750fd6f8539d9276a2c2ed4b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497e61dac54d04-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:45,360 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:44:45,361 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:45,362 httpcore.http11 DEBUG receive_response_body.complete
17:44:45,362 httpcore.http11 DEBUG response_closed.started
17:44:45,363 httpcore.http11 DEBUG response_closed.complete
17:44:45,363 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:44:45,364 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:44:45,400 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nand her. I wonder what he will say.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:45,412 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:45,415 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34a380d0>
17:44:45,415 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a060> server_hostname='api.openai.com' timeout=None
17:44:45,420 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34a38090>
17:44:45,420 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:45,422 httpcore.http11 DEBUG send_request_headers.complete
17:44:45,422 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:45,422 httpcore.http11 DEBUG send_request_body.complete
17:44:45,423 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:45,659 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:44:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'763d52d99829b901e88984bf73247ddc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EOLdfV43kCeEwaE3agGfQkwMJPaC0IH_hB_Nsoo5.tQ-1702421085-1-Ac1FoOklWlIt4UvkRR18b3i/NfeWnlZlghVR7JVrme0XQZoVngvBXV2N7fM2djYv6n0avhd8Uac39Ud+alBZjzk=; path=/; expires=Tue, 12-Dec-23 23:14:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Z7ER3D3SvDU1GvAPrNDqe9C2SjPS76L3LsGN9zXPRyw-1702421085654-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497e67edd26ac7-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:45,665 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:45,666 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:45,667 httpcore.http11 DEBUG receive_response_body.complete
17:44:45,668 httpcore.http11 DEBUG response_closed.started
17:44:45,668 httpcore.http11 DEBUG response_closed.complete
17:44:45,669 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:45,706 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nand her. I wonder what he will say.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:45,718 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:45,721 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34a3b4d0>
17:44:45,721 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a3c0> server_hostname='api.openai.com' timeout=None
17:44:45,729 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34a39b50>
17:44:45,729 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:45,730 httpcore.http11 DEBUG send_request_headers.complete
17:44:45,731 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:45,731 httpcore.http11 DEBUG send_request_body.complete
17:44:45,732 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:46,506 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:44:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'661'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'37ee97bec554beb3d9e180f78726bc15'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LWFjf5duu1FwW5wEr03RFuGGkeAHuoqqGabbCZqRgWM-1702421086-1-AdlR9r2bnu0QCPdn9APWqTIhaZAlkRpdYk1tMIl9rUqi6mHZyq7E+abXGdRpwkRqJaWqOqK5zU4f6WPVTif9MxE=; path=/; expires=Tue, 12-Dec-23 23:14:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=6upxP3fICy4rir6vVLGDGojQzYuRw3Q2eRs9k9b2dSI-1702421086500-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497e69dda94d14-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:46,515 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:46,516 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:46,517 httpcore.http11 DEBUG receive_response_body.complete
17:44:46,518 httpcore.http11 DEBUG response_closed.started
17:44:46,518 httpcore.http11 DEBUG response_closed.complete
17:44:46,519 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:46,525 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I'm sorry, I didn't understand what you said. Could you please tell me where to place the second candle? It would help me complete the task of placing the candles on the cake. Thank you!", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:46,529 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:46,530 httpcore.http11 DEBUG send_request_headers.complete
17:44:46,530 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:46,531 httpcore.http11 DEBUG send_request_body.complete
17:44:46,531 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:47,106 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:44:47 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'477'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'73fc3672bcf5ca6949b017dbaa07737b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497e6ed9a84d04-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:47,111 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:47,112 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:48,978 httpcore.http11 DEBUG receive_response_body.complete
17:44:48,979 httpcore.http11 DEBUG response_closed.started
17:44:48,980 httpcore.http11 DEBUG response_closed.complete
17:44:48,981 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:49,45 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:09,321 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:09,325 httpcore.connection DEBUG close.started
17:45:09,325 httpcore.connection DEBUG close.complete
17:45:09,326 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:09,328 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34851750>
17:45:09,329 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a59f40> server_hostname='api.openai.com' timeout=5.0
17:45:09,336 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34851810>
17:45:09,337 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:09,338 httpcore.http11 DEBUG send_request_headers.complete
17:45:09,339 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:09,371 httpcore.http11 DEBUG send_request_body.complete
17:45:09,372 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:18,176 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:45:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'15'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'8416'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8efb53b2aab0df750ba2778e92135a28'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497efd5f854cc2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:18,181 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:18,182 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:18,182 httpcore.http11 DEBUG receive_response_body.complete
17:45:18,183 httpcore.http11 DEBUG response_closed.started
17:45:18,183 httpcore.http11 DEBUG response_closed.complete
17:45:18,183 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:18,184 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:18,213 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI'm sorry, I didn't understand what you said. Could you please tell me where to place the second candle? It would help me complete the task of placing the candles on the cake. Thank you!\n'''\nAnd the human answered\n'''\nat the center.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:18,217 httpcore.connection DEBUG close.started
17:45:18,217 httpcore.connection DEBUG close.complete
17:45:18,218 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:18,220 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34a38090>
17:45:18,221 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a060> server_hostname='api.openai.com' timeout=None
17:45:18,226 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34a382d0>
17:45:18,226 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:18,227 httpcore.http11 DEBUG send_request_headers.complete
17:45:18,227 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:18,228 httpcore.http11 DEBUG send_request_body.complete
17:45:18,228 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:18,503 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:45:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'582d964a5165243528c416a31c5df82c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497f34ede54d1e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:18,507 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:18,508 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:18,509 httpcore.http11 DEBUG receive_response_body.complete
17:45:18,510 httpcore.http11 DEBUG response_closed.started
17:45:18,510 httpcore.http11 DEBUG response_closed.complete
17:45:18,511 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:18,544 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked:\n'''\nWhere should I place the first candle?\n'''\n                                               \nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y0 < surface_height // 2\n\n                                               \nYou asked:\n'''\nWhere should I place the second candle?\n'''                                                                                       \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y1 > surface_height // 2 \nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: x1 > surface_width // 2 \nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y1==y0                                               \n\nYou asked:\n'''\nWhere should I place the second candle?\n'''                                              \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y1 == surface_height // 2\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: x1 == surface_width // 2\n                                               \nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y2 == y0 - 1\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: x2==x0                                    \n\nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y2 > surface_height // 2\n\n                                                                                   \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nI'm sorry, I didn't understand what you said. Could you please tell me where to place the second candle? It would help me complete the task of placing the candles on the cake. Thank you!\n'''                                                                                         \nAnd the human answered\n'''\nat the center.\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:18,556 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:18,558 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3485e1d0>
17:45:18,558 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a840> server_hostname='api.openai.com' timeout=None
17:45:18,567 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3485e150>
17:45:18,567 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:18,568 httpcore.http11 DEBUG send_request_headers.complete
17:45:18,569 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:18,569 httpcore.http11 DEBUG send_request_body.complete
17:45:18,570 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:20,323 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:45:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1655'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'07144612b50239db5afacf51d34a474a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PnaciePllyWIfwrZNYTkDuIvLcS7rAM5E80Ymo6xWAE-1702421120-1-AT9lteohJQZ75Ul7915zdaN8Al3XATjpQaJTfLvUtcil98sMRRtog3McGpjZ0CAtFsRHcim+/QItqE6FeFUhlwI=; path=/; expires=Tue, 12-Dec-23 23:15:20 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ryFIyDTw3OWA.EqS7b8CuqGxnpoVuOacGN5vdYtf3A8-1702421120318-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83497f3709ce4cee-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:20,330 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:20,330 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:20,332 httpcore.http11 DEBUG receive_response_body.complete
17:45:20,333 httpcore.http11 DEBUG response_closed.started
17:45:20,333 httpcore.http11 DEBUG response_closed.complete
17:45:20,334 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:20,353 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:20,357 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:26,865 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:26,881 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:26,884 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:31,887 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:31,908 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:31,911 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:33,914 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:33,934 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:33,939 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:37,342 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:37,362 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:37,365 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:43,867 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:43,889 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:43,892 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:48,94 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:48,111 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:48,115 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:52,317 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:52,323 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:52,328 httpcore.connection DEBUG close.started
17:45:52,329 httpcore.connection DEBUG close.complete
17:45:52,329 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:52,359 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34851810>
17:45:52,360 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a59f40> server_hostname='api.openai.com' timeout=5.0
17:45:52,366 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34851910>
17:45:52,367 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:52,370 httpcore.http11 DEBUG send_request_headers.complete
17:45:52,370 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:52,371 httpcore.http11 DEBUG send_request_body.complete
17:45:52,372 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:53,45 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:45:53 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'558'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8522aa97fd1fa35a39c9ff88d3f676d0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349800a4bba3b6f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:53,50 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:53,51 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:54,87 httpcore.http11 DEBUG receive_response_body.complete
17:45:54,88 httpcore.http11 DEBUG response_closed.started
17:45:54,88 httpcore.http11 DEBUG response_closed.complete
17:45:54,89 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:54,159 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:46:06,446 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:46:06,450 httpcore.connection DEBUG close.started
17:46:06,451 httpcore.connection DEBUG close.complete
17:46:06,451 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:46:06,454 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc348805d0>
17:46:06,454 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a59f40> server_hostname='api.openai.com' timeout=5.0
17:46:06,459 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34880650>
17:46:06,460 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:06,461 httpcore.http11 DEBUG send_request_headers.complete
17:46:06,461 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:06,486 httpcore.http11 DEBUG send_request_body.complete
17:46:06,486 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:07,339 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f92379603a9020fef14a967ed06cecc1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834980626bae4cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:07,345 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:46:07,346 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:07,347 httpcore.http11 DEBUG receive_response_body.complete
17:46:07,347 httpcore.http11 DEBUG response_closed.started
17:46:07,347 httpcore.http11 DEBUG response_closed.complete
17:46:07,348 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:46:07,348 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:46:07,383 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nThank you for watching!\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:07,386 httpcore.connection DEBUG close.started
17:46:07,387 httpcore.connection DEBUG close.complete
17:46:07,387 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:07,390 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34852790>
17:46:07,391 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a060> server_hostname='api.openai.com' timeout=None
17:46:07,396 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34a38110>
17:46:07,397 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:07,398 httpcore.http11 DEBUG send_request_headers.complete
17:46:07,398 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:07,399 httpcore.http11 DEBUG send_request_body.complete
17:46:07,399 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:07,623 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'11b6512fdb6626024736cb7947079ab3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834980683d7c4d08-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:07,630 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:07,631 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:07,633 httpcore.http11 DEBUG receive_response_body.complete
17:46:07,634 httpcore.http11 DEBUG response_closed.started
17:46:07,634 httpcore.http11 DEBUG response_closed.complete
17:46:07,634 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:07,667 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nThank you for watching!\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:07,671 httpcore.connection DEBUG close.started
17:46:07,671 httpcore.connection DEBUG close.complete
17:46:07,672 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:07,674 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3486b210>
17:46:07,674 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a3c0> server_hostname='api.openai.com' timeout=None
17:46:07,679 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34a398d0>
17:46:07,680 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:07,681 httpcore.http11 DEBUG send_request_headers.complete
17:46:07,681 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:07,681 httpcore.http11 DEBUG send_request_body.complete
17:46:07,682 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:08,740 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'954'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'beb8b685baa70dc9314d67d6bbb7251b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349806a0ffb3b69-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:08,745 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:08,746 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:08,747 httpcore.http11 DEBUG receive_response_body.complete
17:46:08,747 httpcore.http11 DEBUG response_closed.started
17:46:08,748 httpcore.http11 DEBUG response_closed.complete
17:46:08,748 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:08,756 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I'm sorry, I didn't understand your response. Could you please tell me if this is a good location for the candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:46:08,759 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:08,760 httpcore.http11 DEBUG send_request_headers.complete
17:46:08,761 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:08,761 httpcore.http11 DEBUG send_request_body.complete
17:46:08,761 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:09,347 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:09 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'496'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fd1ae5b1a373e02557bdf73590c4f2f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83498070cf2c4cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:09,352 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:46:09,353 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:11,430 httpcore.http11 DEBUG receive_response_body.complete
17:46:11,431 httpcore.http11 DEBUG response_closed.started
17:46:11,432 httpcore.http11 DEBUG response_closed.complete
17:46:11,432 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:46:11,509 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:46:30,758 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:46:30,763 httpcore.connection DEBUG close.started
17:46:30,764 httpcore.connection DEBUG close.complete
17:46:30,764 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:46:30,766 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc348897d0>
17:46:30,767 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a59f40> server_hostname='api.openai.com' timeout=5.0
17:46:30,772 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34889850>
17:46:30,772 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:30,774 httpcore.http11 DEBUG send_request_headers.complete
17:46:30,774 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:30,803 httpcore.http11 DEBUG send_request_body.complete
17:46:30,804 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:31,859 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'6'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'408'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'891510b45ac32b0f0f7de06766497177'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834980fa58f43b93-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:31,863 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:46:31,864 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:31,865 httpcore.http11 DEBUG receive_response_body.complete
17:46:31,866 httpcore.http11 DEBUG response_closed.started
17:46:31,866 httpcore.http11 DEBUG response_closed.complete
17:46:31,867 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:46:31,867 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:46:31,900 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI'm sorry, I didn't understand your response. Could you please tell me if this is a good location for the candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.\n'''\nAnd the human answered\n'''\nLove.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:31,903 httpcore.connection DEBUG close.started
17:46:31,904 httpcore.connection DEBUG close.complete
17:46:31,904 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:31,907 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3488ca10>
17:46:31,907 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a060> server_hostname='api.openai.com' timeout=None
17:46:31,913 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3488ca90>
17:46:31,914 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:31,915 httpcore.http11 DEBUG send_request_headers.complete
17:46:31,915 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:31,915 httpcore.http11 DEBUG send_request_body.complete
17:46:31,916 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:32,118 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'16c4124710d641761bd9d924448241eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834981017a444ce9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:32,121 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:32,122 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:32,123 httpcore.http11 DEBUG receive_response_body.complete
17:46:32,123 httpcore.http11 DEBUG response_closed.started
17:46:32,123 httpcore.http11 DEBUG response_closed.complete
17:46:32,124 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:32,157 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nI'm sorry, I didn't understand your response. Could you please tell me if this is a good location for the candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.\n'''\nAnd the human answered\n'''\nLove.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:32,160 httpcore.connection DEBUG close.started
17:46:32,160 httpcore.connection DEBUG close.complete
17:46:32,161 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:32,163 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3486abd0>
17:46:32,164 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a3c0> server_hostname='api.openai.com' timeout=None
17:46:32,171 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3486ac90>
17:46:32,171 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:32,172 httpcore.http11 DEBUG send_request_headers.complete
17:46:32,172 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:32,173 httpcore.http11 DEBUG send_request_body.complete
17:46:32,173 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:33,251 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'983'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2017e3e528e8c80ada5c23eeed191faa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834981031fa44cf9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:33,256 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:33,257 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:33,258 httpcore.http11 DEBUG receive_response_body.complete
17:46:33,259 httpcore.http11 DEBUG response_closed.started
17:46:33,259 httpcore.http11 DEBUG response_closed.complete
17:46:33,260 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:33,270 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'I\'m sorry, I don\'t understand what you mean by "love". Could you please tell me if this is a good location for the candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:46:33,276 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:33,278 httpcore.http11 DEBUG send_request_headers.complete
17:46:33,278 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:33,279 httpcore.http11 DEBUG send_request_body.complete
17:46:33,279 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:34,61 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:34 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'498'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'81224db75e34c189b8ce5db4ffa43f5b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83498109fa763b93-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:34,64 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:46:34,65 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:36,187 httpcore.http11 DEBUG receive_response_body.complete
17:46:36,188 httpcore.http11 DEBUG response_closed.started
17:46:36,188 httpcore.http11 DEBUG response_closed.complete
17:46:36,189 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:46:36,258 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:46:55,926 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:46:55,931 httpcore.connection DEBUG close.started
17:46:55,931 httpcore.connection DEBUG close.complete
17:46:55,932 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:46:55,960 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34880e50>
17:46:55,960 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a59f40> server_hostname='api.openai.com' timeout=5.0
17:46:55,968 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34883f10>
17:46:55,969 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:55,971 httpcore.http11 DEBUG send_request_headers.complete
17:46:55,972 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:55,997 httpcore.http11 DEBUG send_request_body.complete
17:46:55,997 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:56,894 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:56 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'381'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fcd2ae7f09ea05b4b910b934a06c594d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83498197deda4cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:56,901 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:46:56,902 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:56,902 httpcore.http11 DEBUG receive_response_body.complete
17:46:56,903 httpcore.http11 DEBUG response_closed.started
17:46:56,903 httpcore.http11 DEBUG response_closed.complete
17:46:56,904 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:46:56,904 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:46:56,935 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ['You are an assistant robot helping a human place candles on a cake. You asked \n\'\'\'\nI\'m sorry, I don\'t understand what you mean by "love". Could you please tell me if this is a good location for the candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.\n\'\'\'\nAnd the human answered\n\'\'\'\nYes.\n\n\'\'\'\nDetermine whether the human\'s answer is related to your question. Answer with \'yes\' or \'no\' only.\nAnswer:\n'], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:56,939 httpcore.connection DEBUG close.started
17:46:56,940 httpcore.connection DEBUG close.complete
17:46:56,940 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:56,942 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3488ed10>
17:46:56,943 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a060> server_hostname='api.openai.com' timeout=None
17:46:56,948 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3488ea90>
17:46:56,949 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:56,949 httpcore.http11 DEBUG send_request_headers.complete
17:46:56,950 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:56,950 httpcore.http11 DEBUG send_request_body.complete
17:46:56,951 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:57,181 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'895d06015065cc3aa5c1f8a145b76933'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349819debb24cf8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:57,185 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:57,186 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:57,188 httpcore.http11 DEBUG receive_response_body.complete
17:46:57,188 httpcore.http11 DEBUG response_closed.started
17:46:57,189 httpcore.http11 DEBUG response_closed.complete
17:46:57,190 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:57,225 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ['You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n\'\'\'\nI\'m sorry, I don\'t understand what you mean by "love". Could you please tell me if this is a good location for the candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.\n\'\'\'\nAnd the human answered\n\'\'\'\nYes.\n\n\'\'\'\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n'], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:57,228 httpcore.connection DEBUG close.started
17:46:57,229 httpcore.connection DEBUG close.complete
17:46:57,229 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:57,232 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3488b050>
17:46:57,232 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a3c0> server_hostname='api.openai.com' timeout=None
17:46:57,238 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34889b90>
17:46:57,239 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:57,240 httpcore.http11 DEBUG send_request_headers.complete
17:46:57,240 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:57,241 httpcore.http11 DEBUG send_request_body.complete
17:46:57,241 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:58,413 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1062'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'16602a6caae9885eb931167ef8e0094d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349819fbdf93b94-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:58,416 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:58,416 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:58,417 httpcore.http11 DEBUG receive_response_body.complete
17:46:58,418 httpcore.http11 DEBUG response_closed.started
17:46:58,418 httpcore.http11 DEBUG response_closed.complete
17:46:58,418 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:58,427 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Great! Let's keep going. Where would you like to place the next candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:46:58,431 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:58,432 httpcore.http11 DEBUG send_request_headers.complete
17:46:58,432 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:58,432 httpcore.http11 DEBUG send_request_body.complete
17:46:58,433 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:59,160 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:46:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'608'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4241fbba215ff70d0ea3738446ea8554'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834981a73d7d4cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:59,165 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:46:59,166 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:47:00,458 httpcore.http11 DEBUG receive_response_body.complete
17:47:00,459 httpcore.http11 DEBUG response_closed.started
17:47:00,460 httpcore.http11 DEBUG response_closed.complete
17:47:00,461 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:47:00,532 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:47:17,215 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:47:17,220 httpcore.connection DEBUG close.started
17:47:17,221 httpcore.connection DEBUG close.complete
17:47:17,221 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:47:17,224 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34885810>
17:47:17,224 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a59f40> server_hostname='api.openai.com' timeout=5.0
17:47:17,230 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc34885890>
17:47:17,230 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:47:17,232 httpcore.http11 DEBUG send_request_headers.complete
17:47:17,232 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:47:17,255 httpcore.http11 DEBUG send_request_body.complete
17:47:17,255 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:47:18,143 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:47:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'459'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4cb746b615ea9522c8c7a195990faad6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349821cb9e94d1e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:47:18,147 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:47:18,148 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:47:18,150 httpcore.http11 DEBUG receive_response_body.complete
17:47:18,150 httpcore.http11 DEBUG response_closed.started
17:47:18,150 httpcore.http11 DEBUG response_closed.complete
17:47:18,151 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:47:18,152 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:47:18,183 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nGreat! Let's keep going. Where would you like to place the next candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.\n'''\nAnd the human answered\n'''\nI think because it misheard you the previous time, so it's a...\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:47:18,187 httpcore.connection DEBUG close.started
17:47:18,187 httpcore.connection DEBUG close.complete
17:47:18,188 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:47:18,191 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3488fe10>
17:47:18,191 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a060> server_hostname='api.openai.com' timeout=None
17:47:18,197 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc3488e790>
17:47:18,197 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:47:18,198 httpcore.http11 DEBUG send_request_headers.complete
17:47:18,199 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:47:18,199 httpcore.http11 DEBUG send_request_body.complete
17:47:18,199 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:47:18,452 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:47:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'131'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0777e1add6b71255fba0c2303b12c976'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83498222bbad4cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:47:18,455 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:47:18,455 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:47:18,456 httpcore.http11 DEBUG receive_response_body.complete
17:47:18,456 httpcore.http11 DEBUG response_closed.started
17:47:18,457 httpcore.http11 DEBUG response_closed.complete
17:47:18,457 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:47:18,490 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You have no vision and are only able to interact with the human through language. You asked \n'''\nGreat! Let's keep going. Where would you like to place the next candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.\n'''\nAnd the human answered\n'''\nI think because it misheard you the previous time, so it's a...\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:47:18,493 httpcore.connection DEBUG close.started
17:47:18,494 httpcore.connection DEBUG close.complete
17:47:18,494 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:47:19,523 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc348835d0>
17:47:19,524 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7efc34a5a3c0> server_hostname='api.openai.com' timeout=None
17:47:19,532 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7efc348836d0>
17:47:19,533 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:47:19,534 httpcore.http11 DEBUG send_request_headers.complete
17:47:19,535 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:47:19,535 httpcore.http11 DEBUG send_request_body.complete
17:47:19,536 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:47:20,640 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:47:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1010'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c1d221dbe06b4a53904dc9618d7b12c5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349822b19684d16-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:47:20,642 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:47:20,643 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:47:20,644 httpcore.http11 DEBUG receive_response_body.complete
17:47:20,645 httpcore.http11 DEBUG response_closed.started
17:47:20,645 httpcore.http11 DEBUG response_closed.complete
17:47:20,645 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:47:20,654 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I apologize for the misunderstanding. Let's try again. Where would you like to place the next candle? You can say either yes, no, or move to the left, to the right, move up or move down. Let me know what you think.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:47:20,661 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:47:20,663 httpcore.http11 DEBUG send_request_headers.complete
17:47:20,663 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:47:20,664 httpcore.http11 DEBUG send_request_body.complete
17:47:20,664 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:47:21,263 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:47:21 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'530'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'af4a5b257507ebafe39e08740ce9acc7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834982322f544d1e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:47:21,268 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:47:21,269 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:47:23,437 httpcore.http11 DEBUG receive_response_body.complete
17:47:23,438 httpcore.http11 DEBUG response_closed.started
17:47:23,439 httpcore.http11 DEBUG response_closed.complete
17:47:23,440 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:47:23,518 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:47:44,207 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:47:44,213 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:47:45,19 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:47:45,21 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:47:45,69 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:47:45,70 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:47:45,114 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:47:45,115 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:47:45,155 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:47:45,156 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:47:45,199 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:47:45,200 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:47:45,245 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:47:45,246 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:47:45,288 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:47:45,289 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:47:45,326 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:47:45,327 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:47:45,368 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:47:45,380 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:47:45,384 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493b36710>
17:47:45,384 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493badf40> server_hostname='api.openai.com' timeout=5.0
17:47:45,391 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493b36c90>
17:47:45,392 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:47:45,392 httpcore.http11 DEBUG send_request_headers.complete
17:47:45,393 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:47:45,393 httpcore.http11 DEBUG send_request_body.complete
17:47:45,393 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:47:45,871 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:47:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8581b881e48c07d156880a994dc848e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=y_AlLzqecPEeeXJt3jK737xeC1a6uZs6D_dIdD97OW0-1702421265-1-AR3CNT3jAXjF2seqLNdQ7ZpANz32pX77GcPWma/IJTpdOZbaq5JsyLKBLx1Mu/UTSJLoxQOE5gzMho8Mdgx1itw=; path=/; expires=Tue, 12-Dec-23 23:17:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fVxqUKRvgXE63cDu0HNT0OpfxCNF0m8K5E.9pUi4iaA-1702421265866-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834982ccbf2e3b99-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:47:45,877 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:47:45,878 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:47:46,328 httpcore.http11 DEBUG receive_response_body.complete
17:47:46,328 httpcore.http11 DEBUG response_closed.started
17:47:46,329 httpcore.http11 DEBUG response_closed.complete
17:47:46,330 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:47:46,407 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:47:57,664 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:47:57,672 httpcore.connection DEBUG close.started
17:47:57,672 httpcore.connection DEBUG close.complete
17:47:57,672 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:47:57,702 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493b36c90>
17:47:57,702 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493badf40> server_hostname='api.openai.com' timeout=5.0
17:47:57,709 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493b35e90>
17:47:57,710 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:47:57,711 httpcore.http11 DEBUG send_request_headers.complete
17:47:57,711 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:47:57,743 httpcore.http11 DEBUG send_request_body.complete
17:47:57,743 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:47:58,589 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:47:58 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'439'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c42bdfafdcc98aa420eeb0f40e437667'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83498319b9566ac6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:47:58,591 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:47:58,592 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:47:58,592 httpcore.http11 DEBUG receive_response_body.complete
17:47:58,593 httpcore.http11 DEBUG response_closed.started
17:47:58,593 httpcore.http11 DEBUG response_closed.complete
17:47:58,594 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:47:58,594 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:47:58,613 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nleft top\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:47:58,621 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:47:58,623 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493988190>
17:47:58,624 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493bae060> server_hostname='api.openai.com' timeout=None
17:47:58,628 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493988110>
17:47:58,629 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:47:58,629 httpcore.http11 DEBUG send_request_headers.complete
17:47:58,629 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:47:58,630 httpcore.http11 DEBUG send_request_body.complete
17:47:58,630 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:47:58,812 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:47:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'91'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ad0343d9911d9de369c226aba65e3493'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RGlbVw4k8XPfQ11cPtWlpHJ65qv1xY4AznDrQpp1Obw-1702421278-1-AWW57jSMP1d2Iwx+PToGN0e2cZg9vr4Fx+Z0udy2J/ncEPKpIvE7lvJR1kgfdqHIrCJ6F4u2UWHIhQ02sfa4sUE=; path=/; expires=Tue, 12-Dec-23 23:17:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OIVwSwm6BYj2sBexaL3y7Po.1hyB9MJrowH81r6IWnM-1702421278807-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349831f6e623031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:47:58,815 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:47:58,816 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:47:58,817 httpcore.http11 DEBUG receive_response_body.complete
17:47:58,817 httpcore.http11 DEBUG response_closed.started
17:47:58,818 httpcore.http11 DEBUG response_closed.complete
17:47:58,818 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:47:58,844 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked:\n'''\nWhere should I place the first candle?\n'''\n                                               \nAnd the human answered\n'''\nPut it on the lower side.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y0 < surface_height // 2\n\n                                               \nYou asked:\n'''\nWhere should I place the second candle?\n'''                                                                                       \nAnd the human answered\n'''\nIt should be on the top right side and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y1 > surface_height // 2 \nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: x1 > surface_width // 2 \nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y1==y0                                               \n\nYou asked:\n'''\nWhere should I place the second candle?\n'''                                              \nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y1 == surface_height // 2\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: x1 == surface_width // 2\n                                               \nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it directly below the first.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y2 == y0 - 1\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: x2==x0                                    \n\nYou asked:\n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it on the top.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\nlambda x0, y0, x1, y1, x2, y2, surface_width, surface_height: y2 > surface_height // 2\n\n                                                                                   \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 6 in the x direction and 6 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (6, 6). You asked \n'''\nWhere should I place the third candle?\n'''                                                                                         \nAnd the human answered\n'''\nleft top\n\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface. Your answer should always be a list of lambda functions.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:47:58,853 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:47:58,856 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493b34410>
17:47:58,856 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493bae840> server_hostname='api.openai.com' timeout=None
17:47:58,862 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939892d0>
17:47:58,862 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:47:58,863 httpcore.http11 DEBUG send_request_headers.complete
17:47:58,863 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:47:58,864 httpcore.http11 DEBUG send_request_body.complete
17:47:58,864 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:48:00,64 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:48:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1090'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dd67810322597e438ed06a087bf4173b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uobK8P_Sj4vpdSBCMNPdBrZM6BBGBk6LzJRtV_RxL.0-1702421280-1-ASz5qjq7AVCTG4SYcWw30LuqzvFQPWFVRQnh+4+i8unJ0bpy5+j4KxwXbEnJd+LSzbJjGDYFjzd+VKjC7Z//rE8=; path=/; expires=Tue, 12-Dec-23 23:18:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kxJfXImsSvr1WNvuC0GNrnBJtgEXF7zC64AUXIsjvLs-1702421280060-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83498320e9cf4cd8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:48:00,66 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:48:00,66 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:48:00,67 httpcore.http11 DEBUG receive_response_body.complete
17:48:00,67 httpcore.http11 DEBUG response_closed.started
17:48:00,67 httpcore.http11 DEBUG response_closed.complete
17:48:00,68 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:48:00,82 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:48:00,85 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:48:06,590 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:48:06,605 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:48:06,616 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:48:11,618 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:48:11,634 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:48:11,636 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:48:13,638 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:48:13,651 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:48:13,654 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:48:17,55 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:48:17,64 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:48:17,67 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:48:23,569 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:48:23,584 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:48:23,588 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:48:26,589 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:48:26,602 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:48:26,604 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:48:31,605 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:48:31,609 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:48:31,614 httpcore.connection DEBUG close.started
17:48:31,614 httpcore.connection DEBUG close.complete
17:48:31,615 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:48:31,618 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493b35e90>
17:48:31,618 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493badf40> server_hostname='api.openai.com' timeout=5.0
17:48:31,625 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493b360d0>
17:48:31,625 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:48:31,626 httpcore.http11 DEBUG send_request_headers.complete
17:48:31,626 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:48:31,627 httpcore.http11 DEBUG send_request_body.complete
17:48:31,627 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:48:32,142 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:48:32 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'184d4b5ca44086fbf47780987aa6e2d6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834983edabdf4ce8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:48:32,146 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:48:32,147 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:48:33,247 httpcore.http11 DEBUG receive_response_body.complete
17:48:33,248 httpcore.http11 DEBUG response_closed.started
17:48:33,248 httpcore.http11 DEBUG response_closed.complete
17:48:33,249 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:48:33,314 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:48:45,574 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:48:45,577 httpcore.connection DEBUG close.started
17:48:45,578 httpcore.connection DEBUG close.complete
17:48:45,578 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:48:45,581 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939c6250>
17:48:45,581 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493badf40> server_hostname='api.openai.com' timeout=5.0
17:48:45,586 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939c62d0>
17:48:45,587 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:48:45,587 httpcore.http11 DEBUG send_request_headers.complete
17:48:45,587 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:48:45,608 httpcore.http11 DEBUG send_request_body.complete
17:48:45,609 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:48:46,398 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:48:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'372'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2027acb33a1ab4d664eb648d594b2ebd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83498444ee534d04-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:48:46,400 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:48:46,401 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:48:46,401 httpcore.http11 DEBUG receive_response_body.complete
17:48:46,402 httpcore.http11 DEBUG response_closed.started
17:48:46,402 httpcore.http11 DEBUG response_closed.complete
17:48:46,402 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:48:46,402 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:48:46,418 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove left.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:48:46,421 httpcore.connection DEBUG close.started
17:48:46,421 httpcore.connection DEBUG close.complete
17:48:46,421 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:48:46,424 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc493988210>
17:48:46,424 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493bae060> server_hostname='api.openai.com' timeout=None
17:48:46,431 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939881d0>
17:48:46,432 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:48:46,433 httpcore.http11 DEBUG send_request_headers.complete
17:48:46,433 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:48:46,434 httpcore.http11 DEBUG send_request_body.complete
17:48:46,434 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:48:46,630 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:48:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7f84bb00297fdbcd297f83a9f4713b92'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349844a3f324d04-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:48:46,632 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:48:46,632 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:48:46,633 httpcore.http11 DEBUG receive_response_body.complete
17:48:46,634 httpcore.http11 DEBUG response_closed.started
17:48:46,634 httpcore.http11 DEBUG response_closed.complete
17:48:46,634 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:48:46,651 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove left.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:48:46,661 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:48:46,664 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939c7a50>
17:48:46,664 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493badfd0> server_hostname='api.openai.com' timeout=None
17:48:46,670 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939c7a10>
17:48:46,670 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:48:46,671 httpcore.http11 DEBUG send_request_headers.complete
17:48:46,671 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:48:46,672 httpcore.http11 DEBUG send_request_body.complete
17:48:46,672 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:48:46,863 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:48:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ba8df4f63b47c7b45458e19c20b9cf9f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1KUJWK_mA_7P.RDIQSrwPi4p0QIosU86QU3eZqtw08k-1702421326-1-AakwbFrcuETD1iDJKXrvDtUtCIDnq1zxWNw2kzxTmglPLeUCPsQ/8jWNZlp1mAK1jHymY0V8VZfQYzrfz1+eXaQ=; path=/; expires=Tue, 12-Dec-23 23:18:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=O.5sjj10AsO3Q0GuErB7YJoF3tJZdKa.LKMWyDjQYlQ-1702421326858-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349844bbd1e4ce2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:48:46,866 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:48:46,866 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:48:46,867 httpcore.http11 DEBUG receive_response_body.complete
17:48:46,867 httpcore.http11 DEBUG response_closed.started
17:48:46,868 httpcore.http11 DEBUG response_closed.complete
17:48:46,868 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:48:46,879 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:48:46,882 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:48:50,284 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:48:50,288 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:48:50,291 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:48:50,292 httpcore.http11 DEBUG send_request_headers.complete
17:48:50,292 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:48:50,292 httpcore.http11 DEBUG send_request_body.complete
17:48:50,293 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:48:50,714 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:48:50 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'355'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f3886dda85e007f2a7b34a6abb2519b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'834984625d4a4d04-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:48:50,718 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:48:50,719 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:48:50,851 httpcore.http11 DEBUG receive_response_body.complete
17:48:50,851 httpcore.http11 DEBUG response_closed.started
17:48:50,852 httpcore.http11 DEBUG response_closed.complete
17:48:50,852 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:48:50,915 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Yuhang2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:48:58,204 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Yuhang2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:48:58,208 httpcore.connection DEBUG close.started
17:48:58,208 httpcore.connection DEBUG close.complete
17:48:58,208 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:48:58,237 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939a2090>
17:48:58,238 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493badf40> server_hostname='api.openai.com' timeout=5.0
17:48:58,245 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939a2110>
17:48:58,245 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:48:58,246 httpcore.http11 DEBUG send_request_headers.complete
17:48:58,247 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:48:58,275 httpcore.http11 DEBUG send_request_body.complete
17:48:58,275 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:48:59,53 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:48:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'378'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'31f6eac021bd118c18faa123eef02390'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349849408da3b8d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:48:59,54 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:48:59,54 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:48:59,55 httpcore.http11 DEBUG receive_response_body.complete
17:48:59,55 httpcore.http11 DEBUG response_closed.started
17:48:59,55 httpcore.http11 DEBUG response_closed.complete
17:48:59,55 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:48:59,56 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:48:59,68 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nyes\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:48:59,70 httpcore.connection DEBUG close.started
17:48:59,70 httpcore.connection DEBUG close.complete
17:48:59,70 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:48:59,73 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939d9210>
17:48:59,73 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc493badfd0> server_hostname='api.openai.com' timeout=None
17:48:59,79 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc4939d9310>
17:48:59,79 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:48:59,80 httpcore.http11 DEBUG send_request_headers.complete
17:48:59,80 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:48:59,81 httpcore.http11 DEBUG send_request_body.complete
17:48:59,81 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:48:59,277 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 12 Dec 2023 22:48:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'102'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'92451798cc0511d072e584dced46ad18'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8349849948093059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:48:59,281 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:48:59,282 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:48:59,283 httpcore.http11 DEBUG receive_response_body.complete
17:48:59,284 httpcore.http11 DEBUG response_closed.started
17:48:59,284 httpcore.http11 DEBUG response_closed.complete
17:48:59,285 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:48:59,295 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:48:59,297 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:49:02,699 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:49:02,709 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:49:02,712 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:49:04,714 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:49:04,727 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:49:04,730 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:49:08,131 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
