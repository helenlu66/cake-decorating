18:04:21,622 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:21,623 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,389 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,390 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,427 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,427 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,463 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,463 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,496 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,496 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,529 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,530 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,562 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,562 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,595 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,596 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,629 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,629 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,660 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:04:22,669 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:04:22,702 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f35ba84c810>
18:04:22,702 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f35ba61c170> server_hostname='api.openai.com' timeout=5.0
18:04:22,708 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f35ba82a050>
18:04:22,709 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:04:22,709 httpcore.http11 DEBUG send_request_headers.complete
18:04:22,709 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:04:22,710 httpcore.http11 DEBUG send_request_body.complete
18:04:22,710 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:04:23,243 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:04:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8a1b342bd8f027ad464bf3499661f716'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_vwJq7f_YtnDfo7kT3LQIpt8PoYRZ42x8IjNJ.tINvU-1701903863-0-Aas5pB/11cVRQt3Cxrc1MGAavRRZILVLQQM2yTrM6F7cUcfsBbudyQBtPUzh3QXYG7S1N3sDO65Yj92PGArdkfU=; path=/; expires=Wed, 06-Dec-23 23:34:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=36Qo1ZYu6gQdOCDfqnA4zeNaIqH3vP3YtsEoftUbH2g-1701903863241-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182ae5eceb6ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:04:23,245 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:04:23,245 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:04:23,767 httpcore.http11 DEBUG receive_response_body.complete
18:04:23,767 httpcore.http11 DEBUG response_closed.started
18:04:23,767 httpcore.http11 DEBUG response_closed.complete
18:04:23,768 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:10,562 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:10,563 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,328 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,329 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,368 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,369 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,403 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,403 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,436 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,436 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,469 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,469 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,501 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,501 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,534 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,535 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,565 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,566 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,596 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:06:11,605 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:06:11,633 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c92add0>
18:06:11,633 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986cb33c80> server_hostname='api.openai.com' timeout=5.0
18:06:11,640 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c935750>
18:06:11,641 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:11,641 httpcore.http11 DEBUG send_request_headers.complete
18:06:11,641 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:11,642 httpcore.http11 DEBUG send_request_body.complete
18:06:11,642 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:12,87 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:12 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'359'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'86b27ebb4df5bb027061a47a4a23a408'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7OBsIGWLKw429wzNfubpBG1w1xPo9p_pn0f6xrLiTKI-1701903972-0-AVz57idx+VRHj3//Be5Xro1KpS6xo5GySIXgt2QxBI0pxs3Yd76f6BKTVjgjrPPIl1JxN1dYCyI003RVuZbX+ZA=; path=/; expires=Wed, 06-Dec-23 23:36:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=51BY5i2lwp6sgvCs2Vq.kLOMPs.7fiKtpCi1Sm45j2Y-1701903972084-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182d8ecc8b4cef-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:12,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:06:12,89 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:12,439 httpcore.http11 DEBUG receive_response_body.complete
18:06:12,439 httpcore.http11 DEBUG response_closed.started
18:06:12,439 httpcore.http11 DEBUG response_closed.complete
18:06:12,440 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:12,514 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:06:26,287 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:06:26,289 httpcore.connection DEBUG close.started
18:06:26,289 httpcore.connection DEBUG close.complete
18:06:26,289 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:06:26,292 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c934e10>
18:06:26,292 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986cb33c80> server_hostname='api.openai.com' timeout=5.0
18:06:26,298 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986cc14c10>
18:06:26,298 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:26,299 httpcore.http11 DEBUG send_request_headers.complete
18:06:26,299 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:26,334 httpcore.http11 DEBUG send_request_body.complete
18:06:26,334 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:28,964 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:28 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'1'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1893'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5bec98e9862a580d6efccd0d023504a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182dea5eef3ba6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:28,965 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:06:28,965 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:28,965 httpcore.http11 DEBUG receive_response_body.complete
18:06:28,965 httpcore.http11 DEBUG response_closed.started
18:06:28,965 httpcore.http11 DEBUG response_closed.complete
18:06:28,966 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:06:28,966 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 2 column 1 (char 1)
18:06:28,975 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\n\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:06:28,983 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:06:28,985 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c755090>
18:06:28,985 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986cb33bf0> server_hostname='api.openai.com' timeout=None
18:06:28,993 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c7550d0>
18:06:28,993 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:28,994 httpcore.http11 DEBUG send_request_headers.complete
18:06:28,994 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:28,994 httpcore.http11 DEBUG send_request_body.complete
18:06:28,994 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:29,388 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'242'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f2f42517cf15248f3ff1bb96beab6a74'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uc5orlaxhb0ZcteprbJs2Xa4CDOyG13cBf8Me1.Rq_0-1701903989-0-AWNKkThf4sgC84DSHjlRsOPq/618IxHhsyu0HQWfFxqcBP2Gjj1N9Lotkd4HyBNAwscdrSR2yBEz+eLB98OJudg=; path=/; expires=Wed, 06-Dec-23 23:36:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=duNqR8Wjcid7Omebc9tIirrXdOjFRpKA2suM7guSmc8-1701903989386-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182dfb3c264d14-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:29,390 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:06:29,390 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:29,390 httpcore.http11 DEBUG receive_response_body.complete
18:06:29,390 httpcore.http11 DEBUG response_closed.started
18:06:29,391 httpcore.http11 DEBUG response_closed.complete
18:06:29,391 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:06:29,400 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\n\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:06:29,408 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:06:29,410 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c778610>
18:06:29,410 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986ca00290> server_hostname='api.openai.com' timeout=None
18:06:29,416 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c76e290>
18:06:29,416 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:29,417 httpcore.http11 DEBUG send_request_headers.complete
18:06:29,417 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:29,417 httpcore.http11 DEBUG send_request_body.complete
18:06:29,417 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:30,585 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1065'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9207908209e01a3602f1fea617be88b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aG4uNt6aPcJ8f5jiDGhP3NjLfnUgCYLh7t7Qnrg2jlI-1701903990-0-AbT4R5pGqX91gzP+zpmAUPxOunDK2SZ2J7NOgnRgNQmEq5d2xDvzBnf8xxA1S4Z6WDztsLrTv6B7CC8FR6VhlzE=; path=/; expires=Wed, 06-Dec-23 23:36:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=HGBGp4DM4fSOnAr6j9OrbTutJmgN.vDcFD7qj2NM0yM-1701903990583-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182dfddb863b69-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:30,587 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:06:30,587 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:30,587 httpcore.http11 DEBUG receive_response_body.complete
18:06:30,588 httpcore.http11 DEBUG response_closed.started
18:06:30,588 httpcore.http11 DEBUG response_closed.complete
18:06:30,588 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:06:30,591 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Ok, let's start with the first candle. Can you tell me where you would like me to place it? Please be as specific as possible so I can help you accurately place the candles.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:06:30,593 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:30,593 httpcore.http11 DEBUG send_request_headers.complete
18:06:30,593 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:30,593 httpcore.http11 DEBUG send_request_body.complete
18:06:30,594 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:31,300 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'591'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e475a4697f85a0c0194679c8836f47a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182e053d1c3ba6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:31,301 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:06:31,301 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:32,910 httpcore.http11 DEBUG receive_response_body.complete
18:06:32,911 httpcore.http11 DEBUG response_closed.started
18:06:32,911 httpcore.http11 DEBUG response_closed.complete
18:06:32,911 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:32,978 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:14:23,343 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:23,345 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,108 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,109 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,143 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,144 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,177 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,178 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,209 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,209 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,241 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,241 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,270 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,271 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,301 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,301 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,331 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,332 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,361 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:14:24,370 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:14:24,400 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603364c50>
18:14:24,400 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa603563c80> server_hostname='api.openai.com' timeout=5.0
18:14:24,405 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603395f50>
18:14:24,405 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:24,405 httpcore.http11 DEBUG send_request_headers.complete
18:14:24,406 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:24,406 httpcore.http11 DEBUG send_request_body.complete
18:14:24,406 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:24,885 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:24 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'26605efdef44faeb5fa397dab600436d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.5_fPErG5K9yT9CzSLuLk4xxrEUHDSPB8HlHAJbSn3s-1701904464-0-AUwZLBAqvU8hvqGFBloYcA/QvYrRDYCiuK9HELpp1xr8kyM+NnOgu27PcE9hjH2sF2XpwPfJiHKanB5K9FsgnVQ=; path=/; expires=Wed, 06-Dec-23 23:44:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RrcE_r3qRBeJA9XO3QDWwJXkPumpU5oUi8W0SM8uHak-1701904464882-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8318399688244d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:24,887 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:14:24,887 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:25,387 httpcore.http11 DEBUG receive_response_body.complete
18:14:25,387 httpcore.http11 DEBUG response_closed.started
18:14:25,387 httpcore.http11 DEBUG response_closed.complete
18:14:25,387 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:14:25,453 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:14:39,676 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:14:39,679 httpcore.connection DEBUG close.started
18:14:39,679 httpcore.connection DEBUG close.complete
18:14:39,679 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:14:39,682 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603364d90>
18:14:39,682 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa603563c80> server_hostname='api.openai.com' timeout=5.0
18:14:39,691 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603364bd0>
18:14:39,691 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:39,691 httpcore.http11 DEBUG send_request_headers.complete
18:14:39,691 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:39,712 httpcore.http11 DEBUG send_request_body.complete
18:14:39,712 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:40,830 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:40 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'463'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f119909bbf016b463e69a8b85f8f7499'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'831839f61ffa4cfc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:40,831 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:14:40,831 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:40,831 httpcore.http11 DEBUG receive_response_body.complete
18:14:40,832 httpcore.http11 DEBUG response_closed.started
18:14:40,832 httpcore.http11 DEBUG response_closed.complete
18:14:40,832 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:14:40,832 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:14:40,842 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nHi, put it to the left.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:14:40,849 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:14:40,852 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa6031876d0>
18:14:40,852 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa603563bf0> server_hostname='api.openai.com' timeout=None
18:14:40,856 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603185350>
18:14:40,856 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:40,857 httpcore.http11 DEBUG send_request_headers.complete
18:14:40,857 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:40,857 httpcore.http11 DEBUG send_request_body.complete
18:14:40,857 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:41,203 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'248'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9f8f58dd013b12c3fb666bc2ce803985'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.puo5hr42Xfy6VXBM2_hu.ajlEasEBr.VZAeHhhdlfk-1701904481-0-AZ5atlemN9efs9P73MdzgjDVfL4fiDIr+iuYSc6oSycd2iIevVRCTmWaougAT7VH3SCIiFSBwdJfg1kQo8HPgok=; path=/; expires=Wed, 06-Dec-23 23:44:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fzLBxL33cqWWyrCo5LxWD3e5yXHVNlNdPtYWLHZWdKg-1701904481201-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'831839fd5a643b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:41,204 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:14:41,205 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:41,205 httpcore.http11 DEBUG receive_response_body.complete
18:14:41,205 httpcore.http11 DEBUG response_closed.started
18:14:41,205 httpcore.http11 DEBUG response_closed.complete
18:14:41,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:14:41,217 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 20 in the x direction and 20 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (20, 20). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 20 in the x direction and 20 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (20, 20). You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nHi, put it to the left.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:14:41,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:14:41,226 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa6031a8ad0>
18:14:41,226 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa60342c680> server_hostname='api.openai.com' timeout=None
18:14:41,233 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa60319e650>
18:14:41,233 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:41,233 httpcore.http11 DEBUG send_request_headers.complete
18:14:41,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:41,233 httpcore.http11 DEBUG send_request_body.complete
18:14:41,233 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:41,841 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'511'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'bfef72e3ebef5a20041562e23339b414'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.gLcC.aGbDun4o4tCJNM1Nw9_M9d2J3Lr6ohlWLIWNY-1701904481-0-AfSLW8aiQLGs033TGofP75MYjpOKsDiAAb25q2mvxbJU7t1Mh3QfTKR1AIY0SNeoQNk6jSaIZ7Xw8jb8onC02pE=; path=/; expires=Wed, 06-Dec-23 23:44:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=N0n1QIYAmak4GdVuITmDa9uCgDJuv.oVsCGfsEqwf0Q-1701904481838-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'831839ffbcdb3bab-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:41,842 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:14:41,842 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:41,842 httpcore.http11 DEBUG receive_response_body.complete
18:14:41,843 httpcore.http11 DEBUG response_closed.started
18:14:41,843 httpcore.http11 DEBUG response_closed.complete
18:14:41,843 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:14:41,846 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:14:41,848 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:41,848 httpcore.http11 DEBUG send_request_headers.complete
18:14:41,848 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:41,849 httpcore.http11 DEBUG send_request_body.complete
18:14:41,849 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:42,282 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a01e73ae8692ff7669545c8f6d6d2ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83183a038aee4cfc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:42,283 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:14:42,284 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:42,546 httpcore.http11 DEBUG receive_response_body.complete
18:14:42,546 httpcore.http11 DEBUG response_closed.started
18:14:42,546 httpcore.http11 DEBUG response_closed.complete
18:14:42,547 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:14:42,614 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:37:39,803 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:39,805 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,587 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,587 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,627 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,628 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,663 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,664 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,696 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,697 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,730 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,731 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,763 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,764 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,796 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,796 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,827 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,828 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,858 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:37:40,867 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:40,898 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980ea1910>
18:37:40,898 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980dbfc80> server_hostname='api.openai.com' timeout=5.0
18:37:40,904 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980bc1650>
18:37:40,905 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:40,905 httpcore.http11 DEBUG send_request_headers.complete
18:37:40,905 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:40,906 httpcore.http11 DEBUG send_request_body.complete
18:37:40,906 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:41,340 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:41 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'604426a3dd0bf52bfb7bf8720d30b357'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=de6QToKOzo_TOprGGzP4kqrM4aDhqYNAQShJBa2ekGY-1701905861-0-AW7P/Y78OT1+BpbixU52xxnQl2904QjHRIvGvM8Do11SnvDHIk01CLz6ckixBiLJcC74Q7ShbyWcwhE9SA8dAlo=; path=/; expires=Thu, 07-Dec-23 00:07:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=atZXLIi7KvMZ4QIH45s2rsC_OD3On6OmUfS1z8lUQsU-1701905861338-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185baea9da4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:41,342 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:37:41,342 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:41,804 httpcore.http11 DEBUG receive_response_body.complete
18:37:41,804 httpcore.http11 DEBUG response_closed.started
18:37:41,804 httpcore.http11 DEBUG response_closed.complete
18:37:41,804 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:37:41,872 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:37:56,194 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:37:56,196 httpcore.connection DEBUG close.started
18:37:56,196 httpcore.connection DEBUG close.complete
18:37:56,196 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:56,199 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980bc0dd0>
18:37:56,199 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980dbfc80> server_hostname='api.openai.com' timeout=5.0
18:37:56,204 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980bc1650>
18:37:56,204 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:56,204 httpcore.http11 DEBUG send_request_headers.complete
18:37:56,205 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:56,238 httpcore.http11 DEBUG send_request_body.complete
18:37:56,238 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:57,347 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'304b683735aad1698e99e070bc91657e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c0e4c4c3b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:57,348 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:37:57,348 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:57,348 httpcore.http11 DEBUG receive_response_body.complete
18:37:57,348 httpcore.http11 DEBUG response_closed.started
18:37:57,349 httpcore.http11 DEBUG response_closed.complete
18:37:57,349 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:37:57,349 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:37:57,359 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nWhat? What the hell?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:57,366 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:57,373 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f29809e1310>
18:37:57,373 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980dbfbf0> server_hostname='api.openai.com' timeout=None
18:37:57,383 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f29809e36d0>
18:37:57,383 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:57,383 httpcore.http11 DEBUG send_request_headers.complete
18:37:57,383 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:57,383 httpcore.http11 DEBUG send_request_body.complete
18:37:57,384 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:57,750 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'283'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0fe0f87f58127da520805ba11a341f02'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tkIpVU8zlHVgog7ySbANVP48LRNh1ZluWPznK0zxESM-1701905877-0-ASNPR2sFTnIrf9qf2ByHDdZgl5ibgtRO/DVScrwmhYpeK6rZSZTfkbK2fpTcZvVrePEKQconE6kPD/zU1MC8thY=; path=/; expires=Thu, 07-Dec-23 00:07:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LgIa1EKKFXm04ANCyoYfIri1oGws56qPbS76CvFRCN0-1701905877747-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c15afe54cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:57,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:57,751 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:57,752 httpcore.http11 DEBUG receive_response_body.complete
18:37:57,752 httpcore.http11 DEBUG response_closed.started
18:37:57,752 httpcore.http11 DEBUG response_closed.complete
18:37:57,752 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:57,762 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nWhat? What the hell?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:57,769 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:57,771 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980a04590>
18:37:57,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980c88290> server_hostname='api.openai.com' timeout=None
18:37:57,781 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f29809fa050>
18:37:57,781 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:57,782 httpcore.http11 DEBUG send_request_headers.complete
18:37:57,782 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:57,783 httpcore.http11 DEBUG send_request_body.complete
18:37:57,783 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:58,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'923'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dbdb68d56db24ee3169a697f331e243f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ofgQFnumf_P1RqpMbtybZU5_e7FY1Ccj8nWibhFtJkc-1701905878-0-Afy/8PaqwnU4rzj0KppX0Rdp7dW0nza7hqQrPmPsWCGIGKvNdPqZR8Z6qzvJafd3p5y3ZIF6dMaT6M9FYxn+MOw=; path=/; expires=Thu, 07-Dec-23 00:07:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=tZb85p34uxKEet0sTPLGoGvUvbtL.enYL.LCK.gSax4-1701905878853-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c1829004ce4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:58,857 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:58,857 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:58,858 httpcore.http11 DEBUG receive_response_body.complete
18:37:58,858 httpcore.http11 DEBUG response_closed.started
18:37:58,858 httpcore.http11 DEBUG response_closed.complete
18:37:58,858 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:58,861 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I apologize for the confusion. I'm an assistant robot here to help you place the candles on the cake. Could you please tell me where you would like me to place the first candle?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:37:58,863 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:58,863 httpcore.http11 DEBUG send_request_headers.complete
18:37:58,863 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:58,864 httpcore.http11 DEBUG send_request_body.complete
18:37:58,864 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:59,558 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'563'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd32feb71cc070df82be98a9b0fcb6c5c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c1eeb4b3b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:59,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:37:59,559 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:00,919 httpcore.http11 DEBUG receive_response_body.complete
18:38:00,919 httpcore.http11 DEBUG response_closed.started
18:38:00,919 httpcore.http11 DEBUG response_closed.complete
18:38:00,920 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:38:00,990 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
16:55:11,373 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:11,374 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,151 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,152 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,192 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,193 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,228 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,229 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,262 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,263 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,298 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,298 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,332 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,332 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,367 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,367 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,401 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,401 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,436 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
16:55:12,445 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:55:12,476 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ade90>
16:55:12,476 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb2afd10> server_hostname='api.openai.com' timeout=5.0
16:55:12,481 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ae990>
16:55:12,482 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:12,482 httpcore.http11 DEBUG send_request_headers.complete
16:55:12,482 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:12,482 httpcore.http11 DEBUG send_request_body.complete
16:55:12,482 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:13,319 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:13 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'686'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1c8ff1093f8090a98d62e8cd557fc279'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4zYLpK4yTUQ0n0kaSrsah29EYn2ZRZrBnMB0lQok4BQ-1702072513-1-AbE5Lw1tjGBcR1wV449SOIelknkIgqMtqV73ZGs6HLfh8hYsiYbC/7kwhuWde/p+OFDOJJygNGFym6qLP/1s0ms=; path=/; expires=Fri, 08-Dec-23 22:25:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=MlOgY.svFauQZRJUJFtVu1FA6nZ3.aLWSFNdT1VM8x0-1702072513316-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840530e9f3031-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:13,321 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
16:55:13,321 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:13,714 httpcore.http11 DEBUG receive_response_body.complete
16:55:13,714 httpcore.http11 DEBUG response_closed.started
16:55:13,714 httpcore.http11 DEBUG response_closed.complete
16:55:13,715 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
16:55:13,785 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
16:55:29,394 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
16:55:29,398 httpcore.connection DEBUG close.started
16:55:29,398 httpcore.connection DEBUG close.complete
16:55:29,399 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:55:29,401 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ae990>
16:55:29,401 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb2afd10> server_hostname='api.openai.com' timeout=5.0
16:55:29,407 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ade90>
16:55:29,407 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:29,408 httpcore.http11 DEBUG send_request_headers.complete
16:55:29,408 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:29,437 httpcore.http11 DEBUG send_request_body.complete
16:55:29,437 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:30,392 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'437'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e5629beaede2321395038eb80c11384b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840bccbf03010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:30,393 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
16:55:30,393 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:30,393 httpcore.http11 DEBUG receive_response_body.complete
16:55:30,393 httpcore.http11 DEBUG response_closed.started
16:55:30,393 httpcore.http11 DEBUG response_closed.complete
16:55:30,394 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
16:55:30,394 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
16:55:30,402 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:55:30,409 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:55:30,412 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0d1e50>
16:55:30,412 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb2afc80> server_hostname='api.openai.com' timeout=None
16:55:30,420 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0d1e90>
16:55:30,420 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:30,421 httpcore.http11 DEBUG send_request_headers.complete
16:55:30,421 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:30,421 httpcore.http11 DEBUG send_request_body.complete
16:55:30,421 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:30,770 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'186'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5269eee3b54f3a98592582eef1560f4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=v3.Kb7jblhUJRA1BN_uhHrQvvXW6dluGTmtW8K_b..o-1702072530-1-ASArlEnPeikY1DISWext0GMx4JILrJz5p7bk/tVYcXDaZGjVTOJihU/eoUAJ3/3vG+N6o/XiZWMB0a/oR83SbMs=; path=/; expires=Fri, 08-Dec-23 22:25:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=VOhwumN2dYGtyYK4S5LP05AfgKDyemM5C6pZiEt7BqM-1702072530768-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840c32fce3b94-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:30,772 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:55:30,772 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:30,772 httpcore.http11 DEBUG receive_response_body.complete
16:55:30,773 httpcore.http11 DEBUG response_closed.started
16:55:30,773 httpcore.http11 DEBUG response_closed.complete
16:55:30,773 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:55:30,783 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:55:30,790 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:55:30,792 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0e52d0>
16:55:30,792 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb378710> server_hostname='api.openai.com' timeout=None
16:55:30,800 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdc468510>
16:55:30,800 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:30,800 httpcore.http11 DEBUG send_request_headers.complete
16:55:30,801 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:30,801 httpcore.http11 DEBUG send_request_body.complete
16:55:30,801 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:31,450 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'531'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7efefc471661137d4f864c61148267ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ew5pdzQq0nfh8fpyLkNAOpjDgXXrFCyFZr1oTrzxCrQ-1702072531-1-AUXExlmI8OdCM2BViZUCm7t6Y6Y7xUYMcY66dk2zo6aMyBEuOpTXbn7hNfI6GVWD6tZ+Un/PjkQAA4cj5DNm+WQ=; path=/; expires=Fri, 08-Dec-23 22:25:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=XhS5ZcvpMGOkKOM.GPRroqOZwEZhwvIYBJqHUJ13m7w-1702072531447-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840c58b114cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:31,451 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:55:31,451 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:31,452 httpcore.http11 DEBUG receive_response_body.complete
16:55:31,452 httpcore.http11 DEBUG response_closed.started
16:55:31,452 httpcore.http11 DEBUG response_closed.complete
16:55:31,452 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:55:31,458 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:31,461 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:35,164 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:35,167 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:35,169 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:38,870 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:38,873 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:38,875 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:42,576 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:42,579 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:42,581 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:46,282 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:46,285 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:46,288 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:58:16,994 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:16,995 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,777 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,779 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,819 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,820 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,855 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,856 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,889 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,890 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,925 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,925 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,958 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,959 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,994 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,994 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:18,29 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:18,29 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:18,65 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
16:58:18,75 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:58:18,105 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345828c10>
16:58:18,105 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0345a2bd10> server_hostname='api.openai.com' timeout=5.0
16:58:18,113 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345b18910>
16:58:18,113 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:18,114 httpcore.http11 DEBUG send_request_headers.complete
16:58:18,114 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:18,115 httpcore.http11 DEBUG send_request_body.complete
16:58:18,115 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:18,591 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:18 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'393'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b399c5855eee82464de261ac5ab6d325'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=oLEvUg0.bIurRQ7aq8DlLv77vlvw0flsXM4OVlp7yuU-1702072698-1-ASpUvYKeIJ3XIpgej0NYiDs0VlcE6ymfC2I05gaJ4RcaxnMQtrrxXjmwOjUqNrvJv2/en2ApcY0kA7IoW9Q9lTA=; path=/; expires=Fri, 08-Dec-23 22:28:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=nqwjw0Zf2JL21eKZD9M5gjdel.0bPqjDQ64r0idKm1Y-1702072698588-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832844db3a4f4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:18,593 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
16:58:18,594 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:19,280 httpcore.http11 DEBUG receive_response_body.complete
16:58:19,280 httpcore.http11 DEBUG response_closed.started
16:58:19,280 httpcore.http11 DEBUG response_closed.complete
16:58:19,281 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
16:58:19,351 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
16:58:35,45 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
16:58:35,48 httpcore.connection DEBUG close.started
16:58:35,48 httpcore.connection DEBUG close.complete
16:58:35,48 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:58:35,50 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345af5a50>
16:58:35,50 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0345a2bd10> server_hostname='api.openai.com' timeout=5.0
16:58:35,55 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f034582a210>
16:58:35,55 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:35,56 httpcore.http11 DEBUG send_request_headers.complete
16:58:35,56 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:35,90 httpcore.http11 DEBUG send_request_body.complete
16:58:35,90 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:36,101 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:36 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'438'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'26e6de7c22dd2b79bd55d37543beba4e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832845451d004cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:36,102 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
16:58:36,102 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:36,103 httpcore.http11 DEBUG receive_response_body.complete
16:58:36,103 httpcore.http11 DEBUG response_closed.started
16:58:36,103 httpcore.http11 DEBUG response_closed.complete
16:58:36,103 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
16:58:36,103 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
16:58:36,112 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:58:36,117 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:58:36,119 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345650d90>
16:58:36,120 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0345a2bc80> server_hostname='api.openai.com' timeout=None
16:58:36,125 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f03456511d0>
16:58:36,125 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:36,125 httpcore.http11 DEBUG send_request_headers.complete
16:58:36,125 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:36,126 httpcore.http11 DEBUG send_request_body.complete
16:58:36,126 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:36,338 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a7d3c852bea74ac1142eff1fee56aab3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5ky0R..GYuMBz6_cK0.cFzL.cxh1GQ55GSPfLD9XnFQ-1702072716-1-ATE6JAyZyD0415ecWJbHiPocs0tCnmW4De6MCqZB8WMoybShM2RSqVjdxPZueb4kNoWrbLQxYNcWB8SpXB8IA5Y=; path=/; expires=Fri, 08-Dec-23 22:28:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=AS6y5vKL0QVgfEWrVmApqgusuR4EaZs2_Un_DUMKscM-1702072716335-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328454bc8274cfa-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:36,339 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:58:36,339 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:36,340 httpcore.http11 DEBUG receive_response_body.complete
16:58:36,340 httpcore.http11 DEBUG response_closed.started
16:58:36,340 httpcore.http11 DEBUG response_closed.complete
16:58:36,340 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:58:36,351 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:58:36,358 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:58:36,361 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f034565fd50>
16:58:36,361 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f03458f8710> server_hostname='api.openai.com' timeout=None
16:58:36,366 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345666250>
16:58:36,366 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:36,367 httpcore.http11 DEBUG send_request_headers.complete
16:58:36,367 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:36,367 httpcore.http11 DEBUG send_request_body.complete
16:58:36,367 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:36,854 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b77a3bf21164697821d25da9fc1d331e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xoo35dNVIb4Yi4KzEVHWIddfcPLnpSkwfVIrdXtp2Wc-1702072716-1-Ab/te3M34njoDiKAhJb78KhjQ8NdVVFZV2v1D0heYRj78mW8w2ZwoZkdEXzASekxYWAAEZOMElubohd3/3cMuF0=; path=/; expires=Fri, 08-Dec-23 22:28:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=u_OW2rULnHVUHx5C6jTo.3Ghj5DJsl0LgmlKhQwjkjg-1702072716850-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328454d4ae23068-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:36,855 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:58:36,855 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:36,855 httpcore.http11 DEBUG receive_response_body.complete
16:58:36,856 httpcore.http11 DEBUG response_closed.started
16:58:36,856 httpcore.http11 DEBUG response_closed.complete
16:58:36,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:58:36,860 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:58:36,863 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:58:40,566 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:58:40,568 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:58:40,571 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:58:44,272 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:58:44,274 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:58:44,276 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:59:44,209 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:44,211 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:44,994 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:44,996 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,32 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,32 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,67 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,67 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,100 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,100 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,133 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,134 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,165 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,166 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,198 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,198 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,230 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,231 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,263 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
16:59:45,272 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:59:45,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e28606d0>
16:59:45,301 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
16:59:45,308 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571e90>
16:59:45,308 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:59:45,308 httpcore.http11 DEBUG send_request_headers.complete
16:59:45,309 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:59:45,309 httpcore.http11 DEBUG send_request_body.complete
16:59:45,309 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:59:45,761 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:59:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'378'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'62871b462068aeb8478f769924f1ef08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=l9pnjJ10wrk6VJdpc0EQmWAdUckzhr7AF74lC7T705g-1702072785-1-AbPqxEcXVeqY39XHmJh4tgzmb4yU2TYDKpBgNG2bU9QczKn84f2qy8dGMG6CSiNo2jwGTRetv6lgn5WBxOjUG50=; path=/; expires=Fri, 08-Dec-23 22:29:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=YyGTkFLiueEaI15vagqpOObSiZlgSLA5smuzvNluYyw-1702072785758-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832846fc2b654cd6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:59:45,763 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
16:59:45,763 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:59:46,546 httpcore.http11 DEBUG receive_response_body.complete
16:59:46,547 httpcore.http11 DEBUG response_closed.started
16:59:46,547 httpcore.http11 DEBUG response_closed.complete
16:59:46,547 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
16:59:46,619 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:00:02,343 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:00:02,346 httpcore.connection DEBUG close.started
17:00:02,346 httpcore.connection DEBUG close.complete
17:00:02,346 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:00:02,348 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571e90>
17:00:02,348 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:00:02,353 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571710>
17:00:02,353 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:02,354 httpcore.http11 DEBUG send_request_headers.complete
17:00:02,354 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:02,364 httpcore.http11 DEBUG send_request_body.complete
17:00:02,364 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:03,258 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:03 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'483'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8ea4d98b2ed1727b9dbd6d7c177be133'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284766bd2a304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:03,259 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:00:03,259 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:03,260 httpcore.http11 DEBUG receive_response_body.complete
17:00:03,260 httpcore.http11 DEBUG response_closed.started
17:00:03,260 httpcore.http11 DEBUG response_closed.complete
17:00:03,260 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:00:03,261 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:00:03,270 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:03,277 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:03,279 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595650>
17:00:03,279 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:00:03,288 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595d10>
17:00:03,289 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:03,289 httpcore.http11 DEBUG send_request_headers.complete
17:00:03,289 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:03,289 httpcore.http11 DEBUG send_request_body.complete
17:00:03,290 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:03,514 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a8de8edd4a2574d8937a8f009b32b191'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2dz_LzaTTVdrO2zXC.prMPCK6viwTrMNUMj2ADy9UTo-1702072803-1-AaQw5kOM9KFasftiwjul3Tz4HGu62YK13LUlFNTsSiI40J6TPdXtnIiNuF6BiblW/ByglPyIfCOGdCcb/IBSSqM=; path=/; expires=Fri, 08-Dec-23 22:30:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Mkh7vJhMOqAMnnvy68CFViiMYWDHn3oFx0EdiEpBIJs-1702072803511-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328476c8a184ce9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:03,515 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:03,515 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:03,516 httpcore.http11 DEBUG receive_response_body.complete
17:00:03,516 httpcore.http11 DEBUG response_closed.started
17:00:03,516 httpcore.http11 DEBUG response_closed.complete
17:00:03,517 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:03,527 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:03,534 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:03,536 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25a8cd0>
17:00:03,536 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2838710> server_hostname='api.openai.com' timeout=None
17:00:03,547 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25a8d10>
17:00:03,547 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:03,548 httpcore.http11 DEBUG send_request_headers.complete
17:00:03,548 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:03,548 httpcore.http11 DEBUG send_request_body.complete
17:00:03,548 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:04,42 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'391'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9b8825da9b8ffc65e55f2e2b2f24f507'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PjJpiPCfUI7cP3H3Q8HpHAYxX2Cnk_orHSSUnXG5oZA-1702072804-1-AUkjFLCFY0WsM0vrgsBXl0M3sx/zBEL1UABda9FWN8VBBEKAr9+PLBMW0x/zbfQBcn7cdZs2iAtcg4FDOajeIMg=; path=/; expires=Fri, 08-Dec-23 22:30:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pAJ0Xfv.a6DaPyD6qYyEKb4EMXstPa9CxtrXnuwja3U-1702072804039-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328476e2b4e4ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:04,44 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:04,44 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:04,45 httpcore.http11 DEBUG receive_response_body.complete
17:00:04,45 httpcore.http11 DEBUG response_closed.started
17:00:04,45 httpcore.http11 DEBUG response_closed.complete
17:00:04,45 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:04,51 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:04,54 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:07,757 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:07,761 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:07,763 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:11,465 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:11,467 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:11,470 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:15,171 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:15,174 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:15,177 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:18,878 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:18,881 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:18,884 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:22,585 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:22,587 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:22,590 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:26,291 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:26,294 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:26,297 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:29,998 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:30,2 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:30,5 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:33,706 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:33,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:00:33,709 httpcore.connection DEBUG close.started
17:00:33,709 httpcore.connection DEBUG close.complete
17:00:33,709 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:00:33,738 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571710>
17:00:33,738 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:00:33,747 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2594c90>
17:00:33,747 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:33,747 httpcore.http11 DEBUG send_request_headers.complete
17:00:33,747 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:33,747 httpcore.http11 DEBUG send_request_body.complete
17:00:33,747 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:34,434 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:34 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'576'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9d0b9798f5ad1e8260f041a86e9c7e18'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328482ae9c84d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:34,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:00:34,435 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:34,705 httpcore.http11 DEBUG receive_response_body.complete
17:00:34,705 httpcore.http11 DEBUG response_closed.started
17:00:34,705 httpcore.http11 DEBUG response_closed.complete
17:00:34,706 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:00:34,775 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:00:47,498 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:00:47,499 httpcore.connection DEBUG close.started
17:00:47,499 httpcore.connection DEBUG close.complete
17:00:47,499 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:00:47,515 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b1090>
17:00:47,515 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:00:47,521 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b0510>
17:00:47,521 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:47,522 httpcore.http11 DEBUG send_request_headers.complete
17:00:47,522 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:47,553 httpcore.http11 DEBUG send_request_body.complete
17:00:47,554 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:48,439 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'382'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1fc2b7602aad4ca93c849b17173ffb50'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832848810e0e3074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:48,440 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:00:48,440 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:48,441 httpcore.http11 DEBUG receive_response_body.complete
17:00:48,441 httpcore.http11 DEBUG response_closed.started
17:00:48,441 httpcore.http11 DEBUG response_closed.complete
17:00:48,441 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:00:48,441 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:00:48,449 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:48,451 httpcore.connection DEBUG close.started
17:00:48,452 httpcore.connection DEBUG close.complete
17:00:48,452 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:48,454 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595d10>
17:00:48,454 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:00:48,459 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595710>
17:00:48,459 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:48,459 httpcore.http11 DEBUG send_request_headers.complete
17:00:48,459 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:48,460 httpcore.http11 DEBUG send_request_body.complete
17:00:48,460 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:48,672 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'98'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'51384e70329e3d88c964aaeabb875f68'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284886dbb74cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:48,673 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:48,673 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:48,674 httpcore.http11 DEBUG receive_response_body.complete
17:00:48,674 httpcore.http11 DEBUG response_closed.started
17:00:48,674 httpcore.http11 DEBUG response_closed.complete
17:00:48,674 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:48,684 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:48,691 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:48,693 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c6610>
17:00:48,693 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773e30> server_hostname='api.openai.com' timeout=None
17:00:48,699 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c6410>
17:00:48,699 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:48,699 httpcore.http11 DEBUG send_request_headers.complete
17:00:48,699 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:48,700 httpcore.http11 DEBUG send_request_body.complete
17:00:48,700 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:48,945 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'133'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3e3859be5d4ec909f33068e030fd479c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=agydFVpaIi0uRPHsRxUQRk3raHVyGUDWdK93ce33IuA-1702072848-1-ATKSAAUV1EmL/QbEPiz6oBVOSwToRCc6eCtDYDrSQZc0nQCPNd6Z84h2jApl8PFyr9X3pvhrZcA1SHVL9VozSvc=; path=/; expires=Fri, 08-Dec-23 22:30:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=D64X7tNyLEpH1ev9iA1XxE2rblqGvtTZ9Vfsy1DwtHk-1702072848942-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832848885d374d06-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:48,946 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:48,947 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:48,947 httpcore.http11 DEBUG receive_response_body.complete
17:00:48,947 httpcore.http11 DEBUG response_closed.started
17:00:48,947 httpcore.http11 DEBUG response_closed.complete
17:00:48,948 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:48,951 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:48,954 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:52,655 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:52,657 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:52,660 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:56,361 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:56,364 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:56,366 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:00,67 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:00,68 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:01:00,70 httpcore.connection DEBUG close.started
17:01:00,70 httpcore.connection DEBUG close.complete
17:01:00,70 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:01:00,73 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cc650>
17:01:00,73 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:01:00,81 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cccd0>
17:01:00,81 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:00,82 httpcore.http11 DEBUG send_request_headers.complete
17:01:00,82 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:00,82 httpcore.http11 DEBUG send_request_body.complete
17:01:00,82 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:00,820 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'500'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1c7254255dbe193e67d5efa3a15e55cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832848cf8fb94cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:00,820 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:01:00,821 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:01,161 httpcore.http11 DEBUG receive_response_body.complete
17:01:01,162 httpcore.http11 DEBUG response_closed.started
17:01:01,162 httpcore.http11 DEBUG response_closed.complete
17:01:01,162 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:01:01,230 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:01:14,521 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:01:14,524 httpcore.connection DEBUG close.started
17:01:14,524 httpcore.connection DEBUG close.complete
17:01:14,524 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:01:14,527 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c6f90>
17:01:14,527 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:01:14,534 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c7090>
17:01:14,534 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:14,534 httpcore.http11 DEBUG send_request_headers.complete
17:01:14,535 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:14,564 httpcore.http11 DEBUG send_request_body.complete
17:01:14,564 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:15,448 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:15 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'434'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'46476bc6e3794aa8f299099c8f91b153'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284929d8cf3b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:15,449 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:01:15,450 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:15,450 httpcore.http11 DEBUG receive_response_body.complete
17:01:15,450 httpcore.http11 DEBUG response_closed.started
17:01:15,450 httpcore.http11 DEBUG response_closed.complete
17:01:15,450 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:01:15,451 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:01:15,457 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:01:15,458 httpcore.connection DEBUG close.started
17:01:15,458 httpcore.connection DEBUG close.complete
17:01:15,459 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:01:15,461 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b3950>
17:01:15,461 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:01:15,468 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b1e90>
17:01:15,468 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:15,468 httpcore.http11 DEBUG send_request_headers.complete
17:01:15,469 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:15,469 httpcore.http11 DEBUG send_request_body.complete
17:01:15,469 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:15,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'300'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd53d3064a6086635bb2238a7ab6f8e84'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328492fad654d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:15,856 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:01:15,856 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:15,857 httpcore.http11 DEBUG receive_response_body.complete
17:01:15,857 httpcore.http11 DEBUG response_closed.started
17:01:15,857 httpcore.http11 DEBUG response_closed.complete
17:01:15,857 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:01:15,867 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:01:15,868 httpcore.connection DEBUG close.started
17:01:15,869 httpcore.connection DEBUG close.complete
17:01:15,869 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:01:15,872 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2573950>
17:01:15,872 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2838710> server_hostname='api.openai.com' timeout=None
17:01:15,878 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2573f90>
17:01:15,878 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:15,878 httpcore.http11 DEBUG send_request_headers.complete
17:01:15,878 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:15,878 httpcore.http11 DEBUG send_request_body.complete
17:01:15,878 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:16,406 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'413'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'048dfa6c6cf4bd8bf777de3725d7b011'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284932398a4d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:16,406 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:01:16,407 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:16,407 httpcore.http11 DEBUG receive_response_body.complete
17:01:16,407 httpcore.http11 DEBUG response_closed.started
17:01:16,407 httpcore.http11 DEBUG response_closed.complete
17:01:16,407 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:01:16,412 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:16,414 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:20,115 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:20,118 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:20,120 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:23,821 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:23,823 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:23,826 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:27,527 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:27,530 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:27,537 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:31,238 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:31,241 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:31,243 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:34,944 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:34,946 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:34,949 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:38,650 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:38,652 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:38,673 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:42,373 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:42,376 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:42,379 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:46,80 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:46,83 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:46,85 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:49,786 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:49,789 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:49,791 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:53,492 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:53,495 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:53,497 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:57,198 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:57,200 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:57,202 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:00,903 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:00,904 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:02:00,906 httpcore.connection DEBUG close.started
17:02:00,906 httpcore.connection DEBUG close.complete
17:02:00,906 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:02:00,935 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c60d0>
17:02:00,936 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:02:00,946 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c5d10>
17:02:00,946 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:00,946 httpcore.http11 DEBUG send_request_headers.complete
17:02:00,947 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:00,947 httpcore.http11 DEBUG send_request_body.complete
17:02:00,947 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:01,364 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f4569221506058a12bcd2392a8d12130'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284a4be8c43071-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:01,365 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:02:01,365 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:01,645 httpcore.http11 DEBUG receive_response_body.complete
17:02:01,646 httpcore.http11 DEBUG response_closed.started
17:02:01,646 httpcore.http11 DEBUG response_closed.complete
17:02:01,646 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:02:01,714 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:02:14,403 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:02:14,404 httpcore.connection DEBUG close.started
17:02:14,405 httpcore.connection DEBUG close.complete
17:02:14,405 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:02:14,407 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cc810>
17:02:14,407 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:02:14,412 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cc610>
17:02:14,413 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:14,413 httpcore.http11 DEBUG send_request_headers.complete
17:02:14,413 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:14,443 httpcore.http11 DEBUG send_request_body.complete
17:02:14,443 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:15,702 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:15 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f6658bb19dc7371d1798ca045351f907'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284aa01b9c3008-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:15,702 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:02:15,702 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:15,703 httpcore.http11 DEBUG receive_response_body.complete
17:02:15,703 httpcore.http11 DEBUG response_closed.started
17:02:15,703 httpcore.http11 DEBUG response_closed.complete
17:02:15,703 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:02:15,703 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:02:15,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:02:15,708 httpcore.connection DEBUG close.started
17:02:15,708 httpcore.connection DEBUG close.complete
17:02:15,708 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:02:15,711 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25d5690>
17:02:15,711 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:02:15,719 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25d4f90>
17:02:15,720 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:15,720 httpcore.http11 DEBUG send_request_headers.complete
17:02:15,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:15,721 httpcore.http11 DEBUG send_request_body.complete
17:02:15,721 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:15,912 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'101'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ecd4c53851c8e5f03a906e43943af6a1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284aa84df63b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:15,912 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:02:15,913 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:15,913 httpcore.http11 DEBUG receive_response_body.complete
17:02:15,913 httpcore.http11 DEBUG response_closed.started
17:02:15,913 httpcore.http11 DEBUG response_closed.complete
17:02:15,913 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:02:15,920 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:02:15,921 httpcore.connection DEBUG close.started
17:02:15,921 httpcore.connection DEBUG close.complete
17:02:15,921 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:02:15,923 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b39d0>
17:02:15,923 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773e30> server_hostname='api.openai.com' timeout=None
17:02:15,929 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b2510>
17:02:15,929 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:15,929 httpcore.http11 DEBUG send_request_headers.complete
17:02:15,929 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:15,930 httpcore.http11 DEBUG send_request_body.complete
17:02:15,930 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:16,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cbb47112dc4dd6256e4e950421e1d60f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284aa98af23b8e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:16,127 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:02:16,127 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:16,127 httpcore.http11 DEBUG receive_response_body.complete
17:02:16,127 httpcore.http11 DEBUG response_closed.started
17:02:16,127 httpcore.http11 DEBUG response_closed.complete
17:02:16,128 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:02:16,131 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:02:16,133 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:19,834 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:19,838 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:02:19,840 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:23,541 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:23,544 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:02:23,547 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:27,247 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:27,248 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:02:27,249 httpcore.connection DEBUG close.started
17:02:27,249 httpcore.connection DEBUG close.complete
17:02:27,249 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:02:27,251 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b2050>
17:02:27,252 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:02:27,257 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b2110>
17:02:27,257 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:27,257 httpcore.http11 DEBUG send_request_headers.complete
17:02:27,258 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:27,258 httpcore.http11 DEBUG send_request_body.complete
17:02:27,258 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:27,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'449'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8020f093ad53e6afde755c8df2d0ce49'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284af059c54ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:27,821 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:02:27,821 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:28,244 httpcore.http11 DEBUG receive_response_body.complete
17:02:28,244 httpcore.http11 DEBUG response_closed.started
17:02:28,245 httpcore.http11 DEBUG response_closed.complete
17:02:28,245 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:02:28,312 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:42:51,316 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:51,319 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,138 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,140 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,182 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,183 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,231 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,232 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,273 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,274 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,322 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,323 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,363 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,364 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,412 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,413 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,454 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,455 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:55,612 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:42:55,636 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:42:55,654 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa2599a90>
17:42:55,655 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:42:55,662 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f771d0>
17:42:55,663 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:55,665 httpcore.http11 DEBUG send_request_headers.complete
17:42:55,666 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:55,667 httpcore.http11 DEBUG send_request_body.complete
17:42:55,667 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:56,304 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:42:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'503'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c4d9faf20af794464e44451784fb0114'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hcwEV4YeN53KbWYeynAhXHuSFyXCbSQVuPontRzJ_NM-1702075376-1-AfOFqF6fo0n7K3qqZ38C6NfpT53ZKfAeDydv33JWcmMuT1ClxobG/9COVLHrOMoKCFuKrPYRK+Ks8wr7y5a7w8M=; path=/; expires=Fri, 08-Dec-23 23:12:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=T9HzWSHYRM2Zw_iE1fw6u9y3OCaj4C24TmT2_4HvyTY-1702075376299-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288639edc74cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:56,314 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:42:56,315 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:57,137 httpcore.http11 DEBUG receive_response_body.complete
17:42:57,138 httpcore.http11 DEBUG response_closed.started
17:42:57,139 httpcore.http11 DEBUG response_closed.complete
17:42:57,140 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:42:57,211 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:43:13,3 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:43:13,13 httpcore.connection DEBUG close.started
17:43:13,14 httpcore.connection DEBUG close.complete
17:43:13,14 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:43:13,16 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f771d0>
17:43:13,16 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:43:13,22 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f77410>
17:43:13,22 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:13,23 httpcore.http11 DEBUG send_request_headers.complete
17:43:13,24 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:13,55 httpcore.http11 DEBUG send_request_body.complete
17:43:13,55 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:14,45 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:43:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'457'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ad0c7cf71d3797488592eb246f7aaa1a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832886a66d653035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:14,49 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:43:14,50 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:14,51 httpcore.http11 DEBUG receive_response_body.complete
17:43:14,51 httpcore.http11 DEBUG response_closed.started
17:43:14,52 httpcore.http11 DEBUG response_closed.complete
17:43:14,52 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:43:14,53 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:43:14,88 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:43:14,100 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:43:14,103 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcb150>
17:43:14,103 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9eb0> server_hostname='api.openai.com' timeout=None
17:43:14,117 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcb010>
17:43:14,118 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:14,119 httpcore.http11 DEBUG send_request_headers.complete
17:43:14,120 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:14,121 httpcore.http11 DEBUG send_request_body.complete
17:43:14,121 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:14,364 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:43:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9f2bdf70efce46b39ba7be1dc470a5f2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3Kt38mmV2MuKJo21sBRk1W31dKpT3u2kJ2RsGCr9UuI-1702075394-1-AUGGDfbt80RYKPv3zeGi6k4JnRTSKI+2rOo83x0ml+Rt2uJHtWSmVRPTsmuZBgiyz/sow+g2jBGHZyzGGdhfKjM=; path=/; expires=Fri, 08-Dec-23 23:13:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BC8AiFYMeFeCmUhVHL85Yr01uzaVA_5S5L5chC56I70-1702075394360-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832886ad49394d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:14,373 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:43:14,374 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:14,374 httpcore.http11 DEBUG receive_response_body.complete
17:43:14,375 httpcore.http11 DEBUG response_closed.started
17:43:14,375 httpcore.http11 DEBUG response_closed.complete
17:43:14,375 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:43:14,408 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:43:14,419 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:43:14,422 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0ddf990>
17:43:14,422 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ffa7b0> server_hostname='api.openai.com' timeout=None
17:43:14,428 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0ddf790>
17:43:14,429 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:14,430 httpcore.http11 DEBUG send_request_headers.complete
17:43:14,430 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:14,431 httpcore.http11 DEBUG send_request_body.complete
17:43:14,431 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:14,993 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:43:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'478'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fc6c609dd563d1d9609c7a78c6adcb59'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4NITqCPlM1B4VMqRzNquqEdORArm1rtIbj09Pe6YaHQ-1702075394-1-AcSTYurJ0y9qrTkyb//2jYffZszQ4sN4ovdh6m638bbPcXxYQ1g6CpI1vpgHeBXFvkRFrH5wcDhLBiL9DFPC1oA=; path=/; expires=Fri, 08-Dec-23 23:13:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IYdOLrWclqHvzdZQmjiBCY9RCmnq9Ox6r5sdOMG.M64-1702075394989-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832886af39923045-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:15,0 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:43:15,1 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:15,3 httpcore.http11 DEBUG receive_response_body.complete
17:43:15,4 httpcore.http11 DEBUG response_closed.started
17:43:15,5 httpcore.http11 DEBUG response_closed.complete
17:43:15,5 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:43:15,22 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:15,27 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:22,234 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:22,245 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:22,248 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:27,450 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:27,468 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:27,472 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:32,675 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:32,693 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:32,698 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:37,901 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:37,921 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:37,926 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:45,129 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:45,151 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:45,155 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:50,358 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:50,377 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:50,380 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:55,582 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:55,602 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:55,606 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:00,809 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:00,829 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:44:00,833 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:06,36 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:06,44 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:06,48 httpcore.connection DEBUG close.started
17:44:06,49 httpcore.connection DEBUG close.complete
17:44:06,49 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:06,79 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f77410>
17:44:06,80 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:06,87 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0ddbed0>
17:44:06,88 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:06,89 httpcore.http11 DEBUG send_request_headers.complete
17:44:06,90 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:06,91 httpcore.http11 DEBUG send_request_body.complete
17:44:06,91 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:07,173 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'956'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'57c361ac2d2baaf42a3e80df39159ba6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832887f21cc04d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:07,178 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:07,179 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:07,482 httpcore.http11 DEBUG receive_response_body.complete
17:44:07,483 httpcore.http11 DEBUG response_closed.started
17:44:07,484 httpcore.http11 DEBUG response_closed.complete
17:44:07,485 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:07,552 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:44:20,292 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:44:20,298 httpcore.connection DEBUG close.started
17:44:20,298 httpcore.connection DEBUG close.complete
17:44:20,299 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:20,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09a50>
17:44:20,302 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:20,309 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09ad0>
17:44:20,309 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:20,310 httpcore.http11 DEBUG send_request_headers.complete
17:44:20,310 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:20,347 httpcore.http11 DEBUG send_request_body.complete
17:44:20,348 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:21,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'389'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c96069710dbb00f5fb7f88bb03cb2b77'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328884afe934cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:21,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:44:21,460 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:21,461 httpcore.http11 DEBUG receive_response_body.complete
17:44:21,461 httpcore.http11 DEBUG response_closed.started
17:44:21,462 httpcore.http11 DEBUG response_closed.complete
17:44:21,462 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:44:21,463 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:44:21,496 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:21,500 httpcore.connection DEBUG close.started
17:44:21,501 httpcore.connection DEBUG close.complete
17:44:21,501 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:21,504 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dca1d0>
17:44:21,504 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9eb0> server_hostname='api.openai.com' timeout=None
17:44:21,509 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcb110>
17:44:21,510 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:21,511 httpcore.http11 DEBUG send_request_headers.complete
17:44:21,511 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:21,512 httpcore.http11 DEBUG send_request_body.complete
17:44:21,512 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:21,705 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fb643bb5c44ed7c6e942a67ba414a70f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888527f5f4cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:21,712 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:21,713 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:21,715 httpcore.http11 DEBUG receive_response_body.complete
17:44:21,716 httpcore.http11 DEBUG response_closed.started
17:44:21,716 httpcore.http11 DEBUG response_closed.complete
17:44:21,717 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:21,752 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:21,767 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:21,770 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09e50>
17:44:21,771 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:44:21,777 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09050>
17:44:21,777 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:21,778 httpcore.http11 DEBUG send_request_headers.complete
17:44:21,778 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:21,779 httpcore.http11 DEBUG send_request_body.complete
17:44:21,779 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:21,994 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8af60fac07d0d6e94e9ca8bdb3e58fdc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Wp_iVMatOZMSFDkPdpMQt_hy17v_wIK.dyzDzdNXN4c-1702075461-1-AcwPH6cdh/ZGIQcavKJgJm3Pm6bqYSh4dv13grlgXpT8LSHGU1ZyKlE3qOF0dfpuCxP4ZT/aWThSAxkPvQvYPg4=; path=/; expires=Fri, 08-Dec-23 23:14:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=QltwJ6RX5me7d1gAx1ZEmXTSD2j.p5H7bXtMBKbGViM-1702075461989-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888541ff94ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:22,4 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:22,5 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:22,6 httpcore.http11 DEBUG receive_response_body.complete
17:44:22,6 httpcore.http11 DEBUG response_closed.started
17:44:22,7 httpcore.http11 DEBUG response_closed.complete
17:44:22,7 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:22,22 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:44:22,27 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:27,231 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:27,236 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:27,241 httpcore.connection DEBUG close.started
17:44:27,241 httpcore.connection DEBUG close.complete
17:44:27,242 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:27,244 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e08cd0>
17:44:27,245 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:27,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0b490>
17:44:27,251 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:27,253 httpcore.http11 DEBUG send_request_headers.complete
17:44:27,253 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:27,254 httpcore.http11 DEBUG send_request_body.complete
17:44:27,254 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:27,664 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'339'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'557c902f8ceba2f99e4df00384ff57c4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888765d374d17-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:27,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:27,671 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:27,853 httpcore.http11 DEBUG receive_response_body.complete
17:44:27,854 httpcore.http11 DEBUG response_closed.started
17:44:27,855 httpcore.http11 DEBUG response_closed.complete
17:44:27,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:27,928 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:44:40,661 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:44:40,669 httpcore.connection DEBUG close.started
17:44:40,670 httpcore.connection DEBUG close.complete
17:44:40,671 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:40,674 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e11850>
17:44:40,674 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:40,682 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e118d0>
17:44:40,683 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:40,685 httpcore.http11 DEBUG send_request_headers.complete
17:44:40,686 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:40,718 httpcore.http11 DEBUG send_request_body.complete
17:44:40,718 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:41,628 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:41 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'72d1af114600a180239e224359e9e870'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888ca4b5a4ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:41,633 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:44:41,634 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:41,635 httpcore.http11 DEBUG receive_response_body.complete
17:44:41,635 httpcore.http11 DEBUG response_closed.started
17:44:41,635 httpcore.http11 DEBUG response_closed.complete
17:44:41,636 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:44:41,636 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:44:41,666 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:41,669 httpcore.connection DEBUG close.started
17:44:41,670 httpcore.connection DEBUG close.complete
17:44:41,670 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:41,672 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ca10>
17:44:41,673 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:44:41,680 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ca90>
17:44:41,681 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:41,682 httpcore.http11 DEBUG send_request_headers.complete
17:44:41,682 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:41,683 httpcore.http11 DEBUG send_request_body.complete
17:44:41,683 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:41,884 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'174f7159ade3952c06b9f4739ffac3f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888d08b2c4cdb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:41,890 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:41,891 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:41,892 httpcore.http11 DEBUG receive_response_body.complete
17:44:41,892 httpcore.http11 DEBUG response_closed.started
17:44:41,893 httpcore.http11 DEBUG response_closed.complete
17:44:41,893 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:41,910 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:44:41,915 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:47,117 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:47,123 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:47,128 httpcore.connection DEBUG close.started
17:44:47,129 httpcore.connection DEBUG close.complete
17:44:47,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:47,131 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e117d0>
17:44:47,131 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:47,141 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e126d0>
17:44:47,142 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:47,144 httpcore.http11 DEBUG send_request_headers.complete
17:44:47,144 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:47,145 httpcore.http11 DEBUG send_request_body.complete
17:44:47,146 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:47,586 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:47 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'371'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0b52604eb0551e7ecffc578365b1f9dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888f2a8596ac9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:47,590 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:47,591 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:47,780 httpcore.http11 DEBUG receive_response_body.complete
17:44:47,781 httpcore.http11 DEBUG response_closed.started
17:44:47,782 httpcore.http11 DEBUG response_closed.complete
17:44:47,783 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:47,849 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:00,393 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:00,397 httpcore.connection DEBUG close.started
17:45:00,397 httpcore.connection DEBUG close.complete
17:45:00,397 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:00,400 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0a650>
17:45:00,400 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:00,407 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0a4d0>
17:45:00,408 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:00,409 httpcore.http11 DEBUG send_request_headers.complete
17:45:00,409 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:00,447 httpcore.http11 DEBUG send_request_body.complete
17:45:00,447 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:01,430 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:01 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd5ddffa97fde7c58351c4f71a7377efb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889458a984d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:01,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:01,435 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:01,436 httpcore.http11 DEBUG receive_response_body.complete
17:45:01,437 httpcore.http11 DEBUG response_closed.started
17:45:01,437 httpcore.http11 DEBUG response_closed.complete
17:45:01,438 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:01,439 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:01,469 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\ndown\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:01,472 httpcore.connection DEBUG close.started
17:45:01,472 httpcore.connection DEBUG close.complete
17:45:01,473 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:01,475 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0b050>
17:45:01,475 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:45:01,481 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09b50>
17:45:01,481 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:01,482 httpcore.http11 DEBUG send_request_headers.complete
17:45:01,483 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:01,483 httpcore.http11 DEBUG send_request_body.complete
17:45:01,484 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:01,762 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'134'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b9c73caec8e0e791549baa62c9b5280b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328894c4ff43010-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:01,768 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:01,769 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:01,770 httpcore.http11 DEBUG receive_response_body.complete
17:45:01,771 httpcore.http11 DEBUG response_closed.started
17:45:01,771 httpcore.http11 DEBUG response_closed.complete
17:45:01,772 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:01,790 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:01,794 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:06,995 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:07,2 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:07,10 httpcore.connection DEBUG close.started
17:45:07,10 httpcore.connection DEBUG close.complete
17:45:07,11 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:07,42 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0ba50>
17:45:07,43 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:07,50 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0a950>
17:45:07,51 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:07,52 httpcore.http11 DEBUG send_request_headers.complete
17:45:07,53 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:07,54 httpcore.http11 DEBUG send_request_body.complete
17:45:07,54 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:07,484 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'351'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'db9c5552fc7aee2bca1847df98796cd1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328896f1ad74cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:07,489 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:07,490 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:07,752 httpcore.http11 DEBUG receive_response_body.complete
17:45:07,753 httpcore.http11 DEBUG response_closed.started
17:45:07,754 httpcore.http11 DEBUG response_closed.complete
17:45:07,755 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:07,820 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:20,463 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:20,468 httpcore.connection DEBUG close.started
17:45:20,469 httpcore.connection DEBUG close.complete
17:45:20,469 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:20,472 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1e9d0>
17:45:20,472 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:20,478 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ea90>
17:45:20,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:20,479 httpcore.http11 DEBUG send_request_headers.complete
17:45:20,480 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:20,516 httpcore.http11 DEBUG send_request_body.complete
17:45:20,517 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:21,728 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'644'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'acfafac8b0c92ef392f24a50f5faeb55'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889c30bc24cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:21,732 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:21,733 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:21,734 httpcore.http11 DEBUG receive_response_body.complete
17:45:21,735 httpcore.http11 DEBUG response_closed.started
17:45:21,735 httpcore.http11 DEBUG response_closed.complete
17:45:21,736 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:21,737 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:21,765 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nforward.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:21,769 httpcore.connection DEBUG close.started
17:45:21,769 httpcore.connection DEBUG close.complete
17:45:21,769 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:21,772 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e19b90>
17:45:21,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:45:21,779 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e19c10>
17:45:21,780 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:21,781 httpcore.http11 DEBUG send_request_headers.complete
17:45:21,781 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:21,782 httpcore.http11 DEBUG send_request_body.complete
17:45:21,782 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:21,979 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'051529ebf99663b80ec99b5432bd273f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889cb2c714cd6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:21,983 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:21,984 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:21,986 httpcore.http11 DEBUG receive_response_body.complete
17:45:21,986 httpcore.http11 DEBUG response_closed.started
17:45:21,987 httpcore.http11 DEBUG response_closed.complete
17:45:21,987 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:22,5 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:22,9 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:27,212 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:27,218 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:27,224 httpcore.connection DEBUG close.started
17:45:27,224 httpcore.connection DEBUG close.complete
17:45:27,224 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:27,227 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ebd0>
17:45:27,227 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:27,233 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1f850>
17:45:27,234 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:27,235 httpcore.http11 DEBUG send_request_headers.complete
17:45:27,235 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:27,236 httpcore.http11 DEBUG send_request_body.complete
17:45:27,236 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:27,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'478'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'de3cead6a00db61ee829722dce0d9382'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889ed3ff04d08-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:27,859 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:27,861 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:28,140 httpcore.http11 DEBUG receive_response_body.complete
17:45:28,141 httpcore.http11 DEBUG response_closed.started
17:45:28,142 httpcore.http11 DEBUG response_closed.complete
17:45:28,143 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:28,209 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:40,894 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:40,898 httpcore.connection DEBUG close.started
17:45:40,899 httpcore.connection DEBUG close.complete
17:45:40,899 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:40,901 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f68910>
17:45:40,902 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:40,908 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f68710>
17:45:40,909 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:40,911 httpcore.http11 DEBUG send_request_headers.complete
17:45:40,912 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:40,950 httpcore.http11 DEBUG send_request_body.complete
17:45:40,951 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:41,846 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:41 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'387'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8f93cdb2836f72aa5d1e79a0adcdc8f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288a42bef74cde-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:41,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:41,852 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:41,854 httpcore.http11 DEBUG receive_response_body.complete
17:45:41,855 httpcore.http11 DEBUG response_closed.started
17:45:41,855 httpcore.http11 DEBUG response_closed.complete
17:45:41,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:41,857 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:41,884 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:41,887 httpcore.connection DEBUG close.started
17:45:41,888 httpcore.connection DEBUG close.complete
17:45:41,888 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:41,890 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09750>
17:45:41,891 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:45:41,895 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0ba50>
17:45:41,896 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:41,897 httpcore.http11 DEBUG send_request_headers.complete
17:45:41,897 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:41,897 httpcore.http11 DEBUG send_request_body.complete
17:45:41,898 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:42,103 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'741106a7e8fefa1071eba29ce1648572'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288a48df5c3b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:42,110 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:42,110 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:42,111 httpcore.http11 DEBUG receive_response_body.complete
17:45:42,112 httpcore.http11 DEBUG response_closed.started
17:45:42,112 httpcore.http11 DEBUG response_closed.complete
17:45:42,112 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:42,128 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:42,131 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:47,333 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:47,348 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:47,351 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:52,554 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:52,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:52,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:57,781 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:57,789 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:57,794 httpcore.connection DEBUG close.started
17:45:57,794 httpcore.connection DEBUG close.complete
17:45:57,795 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:57,797 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0bb90>
17:45:57,798 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:57,806 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09810>
17:45:57,807 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:57,809 httpcore.http11 DEBUG send_request_headers.complete
17:45:57,810 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:57,811 httpcore.http11 DEBUG send_request_body.complete
17:45:57,811 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:58,255 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1c6496de4c649c1c16fbc9adaae4a679'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288aac5f794cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:58,260 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:58,261 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:58,632 httpcore.http11 DEBUG receive_response_body.complete
17:45:58,633 httpcore.http11 DEBUG response_closed.started
17:45:58,634 httpcore.http11 DEBUG response_closed.complete
17:45:58,635 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:58,703 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:46:12,270 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:46:12,275 httpcore.connection DEBUG close.started
17:46:12,275 httpcore.connection DEBUG close.complete
17:46:12,275 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:46:12,305 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e19d50>
17:46:12,306 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:46:12,312 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1a310>
17:46:12,313 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:12,315 httpcore.http11 DEBUG send_request_headers.complete
17:46:12,315 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:12,347 httpcore.http11 DEBUG send_request_body.complete
17:46:12,348 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:13,483 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:13 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'39'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'416'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c2b570e392ed39fe920ab4a4212f31c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b06fcea3010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:13,487 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:46:13,488 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:13,489 httpcore.http11 DEBUG receive_response_body.complete
17:46:13,490 httpcore.http11 DEBUG response_closed.started
17:46:13,490 httpcore.http11 DEBUG response_closed.complete
17:46:13,491 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:46:13,491 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:46:13,522 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nI don't know, do you have suggestions?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:13,527 httpcore.connection DEBUG close.started
17:46:13,528 httpcore.connection DEBUG close.complete
17:46:13,529 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:13,533 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcaf50>
17:46:13,534 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9eb0> server_hostname='api.openai.com' timeout=None
17:46:13,539 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dca1d0>
17:46:13,539 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:13,540 httpcore.http11 DEBUG send_request_headers.complete
17:46:13,541 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:13,541 httpcore.http11 DEBUG send_request_body.complete
17:46:13,541 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:14,360 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'723'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd153d7a4faee8abf407ec6dbb4bf9807'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b0eaa1f4d04-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:14,369 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:14,370 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:14,370 httpcore.http11 DEBUG receive_response_body.complete
17:46:14,371 httpcore.http11 DEBUG response_closed.started
17:46:14,371 httpcore.http11 DEBUG response_closed.complete
17:46:14,371 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:14,405 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nI don't know, do you have suggestions?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:14,419 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:14,422 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1b2d0>
17:46:14,423 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ffa330> server_hostname='api.openai.com' timeout=None
17:46:14,430 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ab50>
17:46:14,430 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:14,431 httpcore.http11 DEBUG send_request_headers.complete
17:46:14,432 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:14,432 httpcore.http11 DEBUG send_request_body.complete
17:46:14,433 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:15,564 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1037'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1811757b03dbea470d826b8dbc8c7ff2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YMuLF_lv.L3t46b8rx2n6_f4ad4eUvKoklDoBLCWiTo-1702075575-1-ASK49isOOMTWcfj7tzqPFtQ7qTjRWu1qXRUiR3oqX77Q/o9D/ZAjkDRKEu0cUQ1bgpLoYTfK8pdat63J5Gv+7Uc=; path=/; expires=Fri, 08-Dec-23 23:16:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=FrWjeQm.9SpF2yEIu0hyHl.sP3scNoo2LGq0Gm5498k-1702075575559-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b143c3a3ba0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:15,571 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:15,572 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:15,573 httpcore.http11 DEBUG receive_response_body.complete
17:46:15,574 httpcore.http11 DEBUG response_closed.started
17:46:15,574 httpcore.http11 DEBUG response_closed.complete
17:46:15,575 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:15,582 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'I suggest placing the second candle directly across from the first candle. That way, the candles will be evenly spaced around the cake. Shall I go ahead and place the second candle there?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:46:15,586 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:15,587 httpcore.http11 DEBUG send_request_headers.complete
17:46:15,588 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:15,588 httpcore.http11 DEBUG send_request_body.complete
17:46:15,589 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:16,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'465'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9a07111c011108c35350f35374f20433'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b1b6a653010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:16,131 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:46:16,132 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:17,896 httpcore.http11 DEBUG receive_response_body.complete
17:46:17,897 httpcore.http11 DEBUG response_closed.started
17:46:17,898 httpcore.http11 DEBUG response_closed.complete
17:46:17,898 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:46:17,971 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:58:04,276 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:04,280 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,118 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,119 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,163 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,164 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,212 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,213 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,254 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,255 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,302 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,303 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,343 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,344 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,392 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,393 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,433 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,434 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:45,731 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:45,734 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,569 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,570 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,612 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,613 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,660 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,661 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,703 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,704 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,751 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,752 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,793 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,794 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,841 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,842 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,882 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,883 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:48,190 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:58:48,210 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:58:48,241 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d3190>
17:58:48,241 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
17:58:48,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d3690>
17:58:48,253 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:58:48,256 httpcore.http11 DEBUG send_request_headers.complete
17:58:48,256 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:58:48,257 httpcore.http11 DEBUG send_request_body.complete
17:58:48,258 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:58:48,722 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:58:48 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ac569a87614adb6fb1f6f2ecb763610b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6CntS1cxn46BYQ6TxeHy2uH5.71dbNbSBXuwlyT3TnQ-1702076328-1-Ace9EsaQUzXzYwiA/qt428W+V29XaW4XcdsnxyeTAnW2zGGe701zYZcaUxRSy1IWEhDHwQJXPaxmsGhxXzWKVbY=; path=/; expires=Fri, 08-Dec-23 23:28:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=FUK2NY5e7HqqJ.RiJF5e8K2PXnDF8BMZzpTXKPHcGjE-1702076328717-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289d7b9a3a4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:58:48,732 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:58:48,733 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:58:49,549 httpcore.http11 DEBUG receive_response_body.complete
17:58:49,550 httpcore.http11 DEBUG response_closed.started
17:58:49,551 httpcore.http11 DEBUG response_closed.complete
17:58:49,552 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:58:49,639 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:59:03,208 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:59:03,222 httpcore.connection DEBUG close.started
17:59:03,223 httpcore.connection DEBUG close.complete
17:59:03,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:59:03,225 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d3690>
17:59:03,226 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
17:59:03,231 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d38d0>
17:59:03,232 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:59:03,233 httpcore.http11 DEBUG send_request_headers.complete
17:59:03,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:59:03,271 httpcore.http11 DEBUG send_request_body.complete
17:59:03,272 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:59:04,160 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:59:04 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'10be7de730dbeef26d67bd4316620be7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289dd939664d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:59:04,163 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:59:04,164 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:59:04,166 httpcore.http11 DEBUG receive_response_body.complete
17:59:04,167 httpcore.http11 DEBUG response_closed.started
17:59:04,168 httpcore.http11 DEBUG response_closed.complete
17:59:04,168 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:59:04,170 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:59:04,206 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:59:04,219 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:59:04,222 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf28287d0>
17:59:04,222 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859fd0> server_hostname='api.openai.com' timeout=None
17:59:04,230 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2828750>
17:59:04,231 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:59:04,232 httpcore.http11 DEBUG send_request_headers.complete
17:59:04,232 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:59:04,233 httpcore.http11 DEBUG send_request_body.complete
17:59:04,233 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:59:04,470 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:59:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b2528ca6c8ce5584683f9f6166ee64d8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mZ8gxZBR2DcChR4F.pLZ1CtzRM5smSRnIZBxtQBoMSQ-1702076344-1-ASFLYminXObAdcconYf2zyKHdtigVIsKNcKkNkLAzvE8/UYftJvxkb2VblsiU29MIsE4vkbYbTQ3YcrN9RLk2gY=; path=/; expires=Fri, 08-Dec-23 23:29:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=62HD2qCHMXW7UH8_9wEEgmueG8SJ2l_MYcPvkgEygWI-1702076344466-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289ddf78084ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:59:04,476 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:59:04,477 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:59:04,478 httpcore.http11 DEBUG receive_response_body.complete
17:59:04,478 httpcore.http11 DEBUG response_closed.started
17:59:04,479 httpcore.http11 DEBUG response_closed.complete
17:59:04,479 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:59:04,513 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:59:04,524 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:59:04,527 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2837710>
17:59:04,527 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf285a7b0> server_hostname='api.openai.com' timeout=None
17:59:04,536 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2834350>
17:59:04,536 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:59:04,537 httpcore.http11 DEBUG send_request_headers.complete
17:59:04,537 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:59:04,538 httpcore.http11 DEBUG send_request_body.complete
17:59:04,539 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:59:05,75 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:59:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'414'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0c7c552e9bc3c9ba3ac42d62b9062e32'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JsNp_.Nm6azw8J.iO0xmqu7B9L4GWs3v5Q8aNuRg5uo-1702076345-1-AUW1pz97OwBIrOot5YEgKQNpMO5IF7lEPhvQ27Mm7fwF4ZyzeOkmuWqnVkkCmFTQdfR2clV3UBKM/DKAUXe/B9U=; path=/; expires=Fri, 08-Dec-23 23:29:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=CYbqbW3mFK3XsRGj4QdsECRGC2RLVk0nPrwHDuRes3Y-1702076345070-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289de15c0a3b8e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:59:05,82 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:59:05,83 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:59:05,83 httpcore.http11 DEBUG receive_response_body.complete
17:59:05,84 httpcore.http11 DEBUG response_closed.started
17:59:05,84 httpcore.http11 DEBUG response_closed.complete
17:59:05,84 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:59:05,101 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:05,106 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:12,314 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:12,330 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:12,333 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:17,538 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:17,558 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:17,562 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:22,764 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:22,783 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:22,786 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:27,988 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:28,4 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:28,8 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:35,210 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:35,228 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:35,232 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:40,435 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:40,452 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:40,456 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:45,659 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:45,683 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:45,687 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:50,889 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:50,907 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:50,911 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:56,114 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:56,132 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:56,135 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:01,338 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:01,344 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:00:01,351 httpcore.connection DEBUG close.started
18:00:01,351 httpcore.connection DEBUG close.complete
18:00:01,351 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:01,383 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2894e50>
18:00:01,383 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:01,390 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2648090>
18:00:01,391 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:01,393 httpcore.http11 DEBUG send_request_headers.complete
18:00:01,394 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:01,395 httpcore.http11 DEBUG send_request_body.complete
18:00:01,395 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:02,3 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:02 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'492'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3344db0081bb6388243b45fef530d60'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f44bc654d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:02,8 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:00:02,9 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:02,203 httpcore.http11 DEBUG receive_response_body.complete
18:00:02,204 httpcore.http11 DEBUG response_closed.started
18:00:02,205 httpcore.http11 DEBUG response_closed.complete
18:00:02,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:00:02,271 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:00:09,815 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:00:09,819 httpcore.connection DEBUG close.started
18:00:09,820 httpcore.connection DEBUG close.complete
18:00:09,820 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:09,823 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265dd50>
18:00:09,823 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:09,831 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265ddd0>
18:00:09,831 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:09,833 httpcore.http11 DEBUG send_request_headers.complete
18:00:09,833 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:09,902 httpcore.http11 DEBUG send_request_body.complete
18:00:09,903 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:10,960 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:10 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'67f5c93b689dc1a082cc488ededc6538'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f797eb43bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:10,965 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:00:10,966 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:10,968 httpcore.http11 DEBUG receive_response_body.complete
18:00:10,968 httpcore.http11 DEBUG response_closed.started
18:00:10,969 httpcore.http11 DEBUG response_closed.complete
18:00:10,969 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:00:10,970 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:00:11,3 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMove forward.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:11,6 httpcore.connection DEBUG close.started
18:00:11,6 httpcore.connection DEBUG close.complete
18:00:11,7 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:00:11,9 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2822fd0>
18:00:11,10 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859fd0> server_hostname='api.openai.com' timeout=None
18:00:11,16 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2823f10>
18:00:11,16 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:11,17 httpcore.http11 DEBUG send_request_headers.complete
18:00:11,18 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:11,18 httpcore.http11 DEBUG send_request_body.complete
18:00:11,19 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:11,269 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'676b94a77ac4d2a5f09ce57e1eef6445'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f80daa44d0d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:11,275 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:11,277 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:11,279 httpcore.http11 DEBUG receive_response_body.complete
18:00:11,279 httpcore.http11 DEBUG response_closed.started
18:00:11,280 httpcore.http11 DEBUG response_closed.complete
18:00:11,280 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:11,288 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or to the left, right, up or down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:00:11,292 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:11,293 httpcore.http11 DEBUG send_request_headers.complete
18:00:11,294 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:11,294 httpcore.http11 DEBUG send_request_body.complete
18:00:11,294 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:12,58 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:12 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'691'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1531eaf516916d0a32f192ab023c7db4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f829dcb3bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:12,62 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:00:12,63 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:12,989 httpcore.http11 DEBUG receive_response_body.complete
18:00:12,990 httpcore.http11 DEBUG response_closed.started
18:00:12,990 httpcore.http11 DEBUG response_closed.complete
18:00:12,991 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:00:13,58 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:00:27,289 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:00:27,294 httpcore.connection DEBUG close.started
18:00:27,295 httpcore.connection DEBUG close.complete
18:00:27,296 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:27,298 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265f250>
18:00:27,298 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:27,303 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265e850>
18:00:27,304 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:27,305 httpcore.http11 DEBUG send_request_headers.complete
18:00:27,305 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:27,337 httpcore.http11 DEBUG send_request_body.complete
18:00:27,337 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:28,153 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:28 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'70ca47bce3b16a6bb9ceaacbc27f2b5b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289fe6a8604d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:28,158 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:00:28,159 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:28,159 httpcore.http11 DEBUG receive_response_body.complete
18:00:28,160 httpcore.http11 DEBUG response_closed.started
18:00:28,160 httpcore.http11 DEBUG response_closed.complete
18:00:28,160 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:00:28,161 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:00:28,191 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or to the left, right, up or down.\n'''\nAnd the human answered\n'''\nUp.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:28,203 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:00:28,206 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266cd90>
18:00:28,206 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859f40> server_hostname='api.openai.com' timeout=None
18:00:28,213 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266cd10>
18:00:28,214 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:28,215 httpcore.http11 DEBUG send_request_headers.complete
18:00:28,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:28,216 httpcore.http11 DEBUG send_request_body.complete
18:00:28,216 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:28,431 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2b9c6447414e16771bc74604d53d763c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YF2IZaCcr2QQl28Zz1ASq2Ihf_fADTIzydIdR16uf54-1702076428-1-AfYQ8aYu/AUFClEp6kxbourjvTKtmTp0Cct44dYritFKtUkMcbAUkVx9trjhjYi/HLe/WVzdNQ9a+SxydACjUt4=; path=/; expires=Fri, 08-Dec-23 23:30:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=bWMThyFXdmzDK4JwGf7c9IjZi.b9v6WDGhEVBsVJLNI-1702076428427-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289fec5b734cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:28,437 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:28,438 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:28,440 httpcore.http11 DEBUG receive_response_body.complete
18:00:28,440 httpcore.http11 DEBUG response_closed.started
18:00:28,441 httpcore.http11 DEBUG response_closed.complete
18:00:28,441 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:28,474 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or to the left, right, up or down.\n'''\nAnd the human answered\n'''\nUp.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:28,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:28,479 httpcore.http11 DEBUG send_request_headers.complete
18:00:28,479 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:28,479 httpcore.http11 DEBUG send_request_body.complete
18:00:28,480 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:28,724 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'143'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b41d9669c62d5187f2af96d444f9e364'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289fee0ef44cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:28,731 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:28,732 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:28,734 httpcore.http11 DEBUG receive_response_body.complete
18:00:28,735 httpcore.http11 DEBUG response_closed.started
18:00:28,735 httpcore.http11 DEBUG response_closed.complete
18:00:28,736 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:28,752 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:28,757 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:33,960 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:33,967 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:00:33,973 httpcore.connection DEBUG close.started
18:00:33,973 httpcore.connection DEBUG close.complete
18:00:33,974 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:33,976 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266d7d0>
18:00:33,976 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:33,984 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266d710>
18:00:33,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:33,985 httpcore.http11 DEBUG send_request_headers.complete
18:00:33,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:33,986 httpcore.http11 DEBUG send_request_body.complete
18:00:33,987 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:34,604 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:34 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'490'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'db6497489e3b0910acdaec4a2ad54c50'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a0106c403b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:34,610 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:00:34,611 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:34,818 httpcore.http11 DEBUG receive_response_body.complete
18:00:34,819 httpcore.http11 DEBUG response_closed.started
18:00:34,820 httpcore.http11 DEBUG response_closed.complete
18:00:34,820 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:00:34,891 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:00:45,527 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:00:45,532 httpcore.connection DEBUG close.started
18:00:45,532 httpcore.connection DEBUG close.complete
18:00:45,533 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:45,535 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265e750>
18:00:45,535 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:45,541 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265e890>
18:00:45,541 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:45,542 httpcore.http11 DEBUG send_request_headers.complete
18:00:45,542 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:45,573 httpcore.http11 DEBUG send_request_body.complete
18:00:45,574 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:46,419 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'7'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'df8d6a12c5b7dce1fa5e62032bc3f6cc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a058ae7a4ce4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:46,425 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:00:46,426 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:46,426 httpcore.http11 DEBUG receive_response_body.complete
18:00:46,427 httpcore.http11 DEBUG response_closed.started
18:00:46,427 httpcore.http11 DEBUG response_closed.complete
18:00:46,427 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:00:46,428 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:00:46,457 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nRight.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:46,461 httpcore.connection DEBUG close.started
18:00:46,461 httpcore.connection DEBUG close.complete
18:00:46,461 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:00:46,464 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265d890>
18:00:46,464 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859f40> server_hostname='api.openai.com' timeout=None
18:00:46,470 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265ff50>
18:00:46,470 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:46,471 httpcore.http11 DEBUG send_request_headers.complete
18:00:46,471 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:46,472 httpcore.http11 DEBUG send_request_body.complete
18:00:46,472 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:46,731 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'144'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'052a40cd9df75181705f4e77786a7580'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a05e7864300c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:46,737 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:46,738 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:46,740 httpcore.http11 DEBUG receive_response_body.complete
18:00:46,741 httpcore.http11 DEBUG response_closed.started
18:00:46,741 httpcore.http11 DEBUG response_closed.complete
18:00:46,742 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:46,759 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:46,763 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:51,966 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:51,984 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:51,988 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:57,190 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:57,207 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:57,211 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:02,413 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:02,420 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:01:02,427 httpcore.connection DEBUG close.started
18:01:02,427 httpcore.connection DEBUG close.complete
18:01:02,428 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:01:02,594 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265d610>
18:01:02,595 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:01:02,603 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265d350>
18:01:02,603 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:02,605 httpcore.http11 DEBUG send_request_headers.complete
18:01:02,605 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:02,606 httpcore.http11 DEBUG send_request_body.complete
18:01:02,606 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:03,211 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:01:03 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'467'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'dfb6c72e49cdd8069ce88f480b96391f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a0c34fdc4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:03,216 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:01:03,217 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:15,28 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,32 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:15,880 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,882 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:15,929 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,930 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:15,986 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,987 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,30 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,31 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,82 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,83 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,126 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,127 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,178 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,179 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,220 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,221 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:17,467 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vicent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:23:17,489 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:17,520 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee34d0>
18:23:17,521 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:23:17,531 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee3990>
18:23:17,532 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:17,535 httpcore.http11 DEBUG send_request_headers.complete
18:23:17,535 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:17,536 httpcore.http11 DEBUG send_request_body.complete
18:23:17,536 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:18,2 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:17 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e9ca4e281ca6f77f64b908e3f4ba0baf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xUWW4x9NzaNcAa5uVx_gIunLCU5YwGTWv8GSc3X1C_A-1702077797-1-AZdrdYV8eV2OLH0lMBPqoFzfs91CB06uhzFjy97uKWoPurccld0M5lejQa1P+yoML9uPgY9FAHq3l7nOqoTc62M=; path=/; expires=Fri, 08-Dec-23 23:53:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Q_1_OgfTeEUutufDcIQaDF2njOyVvdkVaJCOgTXxRB8-1702077797997-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c15a9e4d4cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:18,11 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:23:18,12 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:18,713 httpcore.http11 DEBUG receive_response_body.complete
18:23:18,714 httpcore.http11 DEBUG response_closed.started
18:23:18,715 httpcore.http11 DEBUG response_closed.complete
18:23:18,715 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:23:18,799 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:23:32,430 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:23:32,443 httpcore.connection DEBUG close.started
18:23:32,443 httpcore.connection DEBUG close.complete
18:23:32,444 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:32,446 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee3990>
18:23:32,446 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:23:32,451 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee3a90>
18:23:32,452 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:32,453 httpcore.http11 DEBUG send_request_headers.complete
18:23:32,453 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:32,481 httpcore.http11 DEBUG send_request_body.complete
18:23:32,482 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:33,466 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:33 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'431'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'552ce54d1a09d6a2d281322c6b96f1c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1b7da5c3049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:33,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:23:33,472 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:33,473 httpcore.http11 DEBUG receive_response_body.complete
18:23:33,473 httpcore.http11 DEBUG response_closed.started
18:23:33,473 httpcore.http11 DEBUG response_closed.complete
18:23:33,474 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:23:33,474 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:23:33,515 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vicent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nTell it.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:33,530 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:33,533 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38150>
18:23:33,533 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65f40> server_hostname='api.openai.com' timeout=None
18:23:33,542 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38110>
18:23:33,542 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:33,544 httpcore.http11 DEBUG send_request_headers.complete
18:23:33,544 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:33,545 httpcore.http11 DEBUG send_request_body.complete
18:23:33,545 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:33,789 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7574a139f9405dd5724740f59e183259'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=OK4QdgFhZe1YNKHqYgNSpHQChB5xRl.PIpZEAh26u88-1702077813-1-AfgS4NdTF3Rn2Ib/AStVPCfOgjpepWx4sYKE4YsLcue4tPgR+hAkJokllr2XzAhTDD0bCNH1gE+JtMdTdw8CVxw=; path=/; expires=Fri, 08-Dec-23 23:53:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=tgHR3w5fbYt2g2Prv1iOPDprn5VMdlJTarIXteunFFE-1702077813783-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1beafc14cc2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:33,798 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:33,799 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:33,801 httpcore.http11 DEBUG receive_response_body.complete
18:23:33,802 httpcore.http11 DEBUG response_closed.started
18:23:33,802 httpcore.http11 DEBUG response_closed.complete
18:23:33,802 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:33,838 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vicent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nTell it.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:33,849 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:33,851 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d39890>
18:23:33,852 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f662a0> server_hostname='api.openai.com' timeout=None
18:23:33,858 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d39d10>
18:23:33,858 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:33,859 httpcore.http11 DEBUG send_request_headers.complete
18:23:33,860 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:33,860 httpcore.http11 DEBUG send_request_body.complete
18:23:33,860 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:34,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'856'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b77e020a7d006c2a9a145018a4a45663'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3HRjSjzp3RWjGVCXNn4ZIPLtk39gs76yTZVri09Lzps-1702077814-1-AV3/GfUWQdHxRHFvlfs0a+TfuOFejekuWcEDusdyRQoI8nX8HVyACadYn0aW530JxlH1v7XIwV1334Wul0g+jmg=; path=/; expires=Fri, 08-Dec-23 23:53:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=4JX4gMGR7KJIDVG95hLkEfOwUECbp3OBKhK.ypi3LMg-1702077814816-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1c0981c4d1c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:34,828 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:34,829 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:34,830 httpcore.http11 DEBUG receive_response_body.complete
18:23:34,830 httpcore.http11 DEBUG response_closed.started
18:23:34,831 httpcore.http11 DEBUG response_closed.complete
18:23:34,831 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:34,841 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "\nGreat, let's start with the first candle. Where would you like me to place it? Please give me a specific location on the cake so I can help you place the candle.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:23:34,845 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:34,846 httpcore.http11 DEBUG send_request_headers.complete
18:23:34,847 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:34,847 httpcore.http11 DEBUG send_request_body.complete
18:23:34,847 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:35,373 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'460'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ea20feffce2c47fc4dc62084b42d1963'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1c6ceb83049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:35,378 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:23:35,378 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:37,27 httpcore.http11 DEBUG receive_response_body.complete
18:23:37,28 httpcore.http11 DEBUG response_closed.started
18:23:37,29 httpcore.http11 DEBUG response_closed.complete
18:23:37,30 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:23:37,103 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:23:56,124 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:23:56,128 httpcore.connection DEBUG close.started
18:23:56,128 httpcore.connection DEBUG close.complete
18:23:56,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:56,131 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55cd0>
18:23:56,131 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:23:56,137 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55d50>
18:23:56,137 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:56,138 httpcore.http11 DEBUG send_request_headers.complete
18:23:56,138 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:56,172 httpcore.http11 DEBUG send_request_body.complete
18:23:56,172 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:57,188 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'532'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'982913517078f6bf97aa09c9ba5d4d67'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c24bd9ae4cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:57,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:23:57,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:57,196 httpcore.http11 DEBUG receive_response_body.complete
18:23:57,196 httpcore.http11 DEBUG response_closed.started
18:23:57,197 httpcore.http11 DEBUG response_closed.complete
18:23:57,198 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:23:57,198 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:23:57,227 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\n\nGreat, let's start with the first candle. Where would you like me to place it? Please give me a specific location on the cake so I can help you place the candle.\n'''\nAnd the human answered\n'''\nput it in the center\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:57,231 httpcore.connection DEBUG close.started
18:23:57,231 httpcore.connection DEBUG close.complete
18:23:57,232 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:57,234 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38110>
18:23:57,235 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65f40> server_hostname='api.openai.com' timeout=None
18:23:57,241 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38bd0>
18:23:57,242 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:57,243 httpcore.http11 DEBUG send_request_headers.complete
18:23:57,243 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:57,244 httpcore.http11 DEBUG send_request_body.complete
18:23:57,244 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:57,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9a7077a8c2e00d80ecd5637c3df36dab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c252cbcc3061-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:57,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:57,459 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:57,461 httpcore.http11 DEBUG receive_response_body.complete
18:23:57,461 httpcore.http11 DEBUG response_closed.started
18:23:57,461 httpcore.http11 DEBUG response_closed.complete
18:23:57,462 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:57,495 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\n\nGreat, let's start with the first candle. Where would you like me to place it? Please give me a specific location on the cake so I can help you place the candle.\n'''\nAnd the human answered\n'''\nput it in the center\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:57,506 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:57,509 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d61350>
18:23:57,509 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f66720> server_hostname='api.openai.com' timeout=None
18:23:57,516 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d63610>
18:23:57,516 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:57,517 httpcore.http11 DEBUG send_request_headers.complete
18:23:57,517 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:57,518 httpcore.http11 DEBUG send_request_body.complete
18:23:57,518 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:58,376 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'770'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5b1a86b0e9bf6900638848b618d2fa14'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=X1jKHHb4hvhU3kk0UkI3emNxF7qmSfUGNULWagG7FXk-1702077838-1-AQAUxjk5QIYmXKUcO2wuk9KCR9JQ1V4gmqDewbj3BXw1bXv/oQR+u8PNMR8ekGW9jiEwf3JCHASUQnGtUWat8m8=; path=/; expires=Fri, 08-Dec-23 23:53:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=0o_wmImkxugk3a9YvyFgUlQ3qNApN1kbwSEktx7guE0-1702077838371-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c2547ddd3059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:58,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:58,383 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:58,385 httpcore.http11 DEBUG receive_response_body.complete
18:23:58,385 httpcore.http11 DEBUG response_closed.started
18:23:58,386 httpcore.http11 DEBUG response_closed.complete
18:23:58,386 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:58,801 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:23:58,805 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:06,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:06,28 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:06,31 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:11,233 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:11,257 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:11,260 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:16,462 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:16,478 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:16,482 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:21,684 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:21,703 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:21,707 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:28,909 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:28,928 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:28,937 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:34,140 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:34,159 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:34,163 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:39,364 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:39,382 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:39,385 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:44,587 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:44,602 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:44,605 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:49,807 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:49,824 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:49,828 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:55,30 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:55,47 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:55,50 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:25:00,252 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:25:00,260 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:25:00,270 httpcore.connection DEBUG close.started
18:25:00,271 httpcore.connection DEBUG close.complete
18:25:00,272 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:00,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55c10>
18:25:00,302 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:00,309 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55e50>
18:25:00,309 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:00,311 httpcore.http11 DEBUG send_request_headers.complete
18:25:00,312 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:00,313 httpcore.http11 DEBUG send_request_body.complete
18:25:00,313 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:00,781 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'355'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bed552900bdaf75d0f9d78e25c298f21'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c3dcfff24ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:00,787 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:25:00,788 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:00,979 httpcore.http11 DEBUG receive_response_body.complete
18:25:00,981 httpcore.http11 DEBUG response_closed.started
18:25:00,981 httpcore.http11 DEBUG response_closed.complete
18:25:00,983 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:25:01,54 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:25:08,662 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:25:08,667 httpcore.connection DEBUG close.started
18:25:08,667 httpcore.connection DEBUG close.complete
18:25:08,668 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:08,670 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80a50>
18:25:08,670 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:08,677 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80ad0>
18:25:08,678 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:08,679 httpcore.http11 DEBUG send_request_headers.complete
18:25:08,679 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:08,714 httpcore.http11 DEBUG send_request_body.complete
18:25:08,714 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:09,479 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:09 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'322'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'84de94c52755d4f33c2b3458de718116'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4113c8b4ce8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:09,485 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:25:09,486 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:09,488 httpcore.http11 DEBUG receive_response_body.complete
18:25:09,489 httpcore.http11 DEBUG response_closed.started
18:25:09,489 httpcore.http11 DEBUG response_closed.complete
18:25:09,490 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:25:09,490 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:25:09,524 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:09,527 httpcore.connection DEBUG close.started
18:25:09,528 httpcore.connection DEBUG close.complete
18:25:09,528 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:09,530 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38bd0>
18:25:09,531 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65f40> server_hostname='api.openai.com' timeout=None
18:25:09,539 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38cd0>
18:25:09,539 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:09,541 httpcore.http11 DEBUG send_request_headers.complete
18:25:09,542 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:09,543 httpcore.http11 DEBUG send_request_body.complete
18:25:09,543 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:09,763 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9f21fed6e24c1380fc32e3547dd920e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c416aa3d4d07-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:09,769 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:09,771 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:09,772 httpcore.http11 DEBUG receive_response_body.complete
18:25:09,772 httpcore.http11 DEBUG response_closed.started
18:25:09,772 httpcore.http11 DEBUG response_closed.complete
18:25:09,773 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:09,805 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:09,817 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:09,819 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d810d0>
18:25:09,819 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65eb0> server_hostname='api.openai.com' timeout=None
18:25:09,824 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d81250>
18:25:09,825 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:09,826 httpcore.http11 DEBUG send_request_headers.complete
18:25:09,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:09,827 httpcore.http11 DEBUG send_request_body.complete
18:25:09,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:10,33 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1d8ee58fbeef267175cd7c2559ad57ef'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fBY4YD7lLKLqufnDVhuWLyIEHNN0OjByFqt4o6sVDIg-1702077910-1-AYLmfmdXUh0cKd42QuWOk4vmSOOjhgGdFA48Qd1n/qeWzI5FlaOo/HYBdNZ+c/y253hnCl05bg3ODkx+h8b5g3A=; path=/; expires=Fri, 08-Dec-23 23:55:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=s8gVlfggjFVWmPbiqNL.Zn9gx1Qw5la5M_EdQStQAHE-1702077910029-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4186875305d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:10,42 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:10,43 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:10,43 httpcore.http11 DEBUG receive_response_body.complete
18:25:10,44 httpcore.http11 DEBUG response_closed.started
18:25:10,44 httpcore.http11 DEBUG response_closed.complete
18:25:10,44 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:10,59 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:25:10,63 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:25:15,265 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:25:15,272 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:25:15,279 httpcore.connection DEBUG close.started
18:25:15,279 httpcore.connection DEBUG close.complete
18:25:15,279 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:15,282 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80990>
18:25:15,282 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:15,288 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80810>
18:25:15,289 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:15,290 httpcore.http11 DEBUG send_request_headers.complete
18:25:15,290 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:15,291 httpcore.http11 DEBUG send_request_body.complete
18:25:15,291 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:15,733 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb95a15999b3418cdd3b4b93e4850bab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c43a9cd74cde-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:15,738 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:25:15,739 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:16,36 httpcore.http11 DEBUG receive_response_body.complete
18:25:16,37 httpcore.http11 DEBUG response_closed.started
18:25:16,38 httpcore.http11 DEBUG response_closed.complete
18:25:16,39 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:25:16,110 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:25:23,813 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:25:23,817 httpcore.connection DEBUG close.started
18:25:23,818 httpcore.connection DEBUG close.complete
18:25:23,818 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:23,821 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d86790>
18:25:23,822 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:23,827 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d86810>
18:25:23,828 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:23,829 httpcore.http11 DEBUG send_request_headers.complete
18:25:23,829 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:23,852 httpcore.http11 DEBUG send_request_body.complete
18:25:23,853 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:24,551 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:24 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'309'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b11b02134efdddac2b04a4256ec8e73d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c46fe8ff4d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:24,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:25:24,557 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:24,559 httpcore.http11 DEBUG receive_response_body.complete
18:25:24,559 httpcore.http11 DEBUG response_closed.started
18:25:24,560 httpcore.http11 DEBUG response_closed.complete
18:25:24,561 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:25:24,562 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:25:24,590 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:24,593 httpcore.connection DEBUG close.started
18:25:24,594 httpcore.connection DEBUG close.complete
18:25:24,594 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:24,597 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d8d8d0>
18:25:24,597 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65eb0> server_hostname='api.openai.com' timeout=None
18:25:24,604 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d8d950>
18:25:24,604 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:24,605 httpcore.http11 DEBUG send_request_headers.complete
18:25:24,606 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:24,606 httpcore.http11 DEBUG send_request_body.complete
18:25:24,606 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:24,820 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3b50e9c7e76b05af90d0138a9f909801'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c474c8bf4d08-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:24,825 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:24,826 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:24,828 httpcore.http11 DEBUG receive_response_body.complete
18:25:24,828 httpcore.http11 DEBUG response_closed.started
18:25:24,829 httpcore.http11 DEBUG response_closed.complete
18:25:24,829 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:24,849 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:25:24,853 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:25:30,55 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:25:30,63 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:25:30,68 httpcore.connection DEBUG close.started
18:25:30,68 httpcore.connection DEBUG close.complete
18:25:30,69 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:30,71 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d86550>
18:25:30,71 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:30,78 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d879d0>
18:25:30,78 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:30,79 httpcore.http11 DEBUG send_request_headers.complete
18:25:30,79 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:30,80 httpcore.http11 DEBUG send_request_body.complete
18:25:30,80 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:30,530 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:30 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'365'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3ca591c8b673a82faccfe25779b920b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c496f9003ba0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:30,534 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:25:30,534 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:30,801 httpcore.http11 DEBUG receive_response_body.complete
18:25:30,802 httpcore.http11 DEBUG response_closed.started
18:25:30,802 httpcore.http11 DEBUG response_closed.complete
18:25:30,803 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:25:30,868 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:25:38,532 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:25:38,536 httpcore.connection DEBUG close.started
18:25:38,537 httpcore.connection DEBUG close.complete
18:25:38,537 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:38,540 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d87bd0>
18:25:38,540 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:38,547 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d84e50>
18:25:38,548 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:38,549 httpcore.http11 DEBUG send_request_headers.complete
18:25:38,549 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:38,562 httpcore.http11 DEBUG send_request_body.complete
18:25:38,563 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:39,691 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:39 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'637'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'98e0711b71b0ae6e5fbd74c71d4cad7e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4cbec0e300c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:39,695 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:25:39,696 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:39,697 httpcore.http11 DEBUG receive_response_body.complete
18:25:39,698 httpcore.http11 DEBUG response_closed.started
18:25:39,698 httpcore.http11 DEBUG response_closed.complete
18:25:39,699 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:25:39,699 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:25:39,730 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:39,733 httpcore.connection DEBUG close.started
18:25:39,734 httpcore.connection DEBUG close.complete
18:25:39,734 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:39,736 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80050>
18:25:39,737 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65eb0> server_hostname='api.openai.com' timeout=None
18:25:39,741 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d81010>
18:25:39,742 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:39,743 httpcore.http11 DEBUG send_request_headers.complete
18:25:39,743 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:39,744 httpcore.http11 DEBUG send_request_body.complete
18:25:39,744 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:39,965 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c46a0462a3848e50c802561ddd0a0f36'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4d3682d6ac6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:39,972 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:39,973 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:39,974 httpcore.http11 DEBUG receive_response_body.complete
18:25:39,974 httpcore.http11 DEBUG response_closed.started
18:25:39,975 httpcore.http11 DEBUG response_closed.complete
18:25:39,975 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:39,990 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:25:39,993 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:29:54,154 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:54,158 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:54,987 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:54,988 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,32 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,33 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,82 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,83 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,125 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,126 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,174 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,175 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,216 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,217 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,266 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,267 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,309 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,310 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:58,168 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:29:58,186 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:58,218 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8934537910>
18:29:58,218 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fdd90> server_hostname='api.openai.com' timeout=5.0
18:29:58,226 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f893447f890>
18:29:58,226 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:58,228 httpcore.http11 DEBUG send_request_headers.complete
18:29:58,228 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:58,228 httpcore.http11 DEBUG send_request_body.complete
18:29:58,229 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:58,686 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:29:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'017bd1ee9bc6e1438c7c05807e0198a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0Is7Y8KR.l9FcBdTCYag6iwuL.YEOQ7bUfhNQqV4iTk-1702078198-1-AcPGqEbMcyFUlXX+syLVmDwI7ieaHi7J+7TO76683ogrZnHCYqPGsiYR7nY3yPGB9uOU6OE0ycTz5vxtvVh/euA=; path=/; expires=Fri, 08-Dec-23 23:59:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=MDogYZKkc0nDuRGyl2pUP7P2jg79vEHDrtw_an_d7vQ-1702078198681-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb22ef42300c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:58,694 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:29:58,694 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:59,607 httpcore.http11 DEBUG receive_response_body.complete
18:29:59,608 httpcore.http11 DEBUG response_closed.started
18:29:59,609 httpcore.http11 DEBUG response_closed.complete
18:29:59,610 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:29:59,695 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:30:13,610 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:30:13,620 httpcore.connection DEBUG close.started
18:30:13,621 httpcore.connection DEBUG close.complete
18:30:13,622 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:30:13,624 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f893449f390>
18:30:13,625 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fdd90> server_hostname='api.openai.com' timeout=5.0
18:30:13,631 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f893447ea90>
18:30:13,632 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:13,633 httpcore.http11 DEBUG send_request_headers.complete
18:30:13,633 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:13,661 httpcore.http11 DEBUG send_request_body.complete
18:30:13,662 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:14,940 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:30:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'620'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fc001f635c0c71ef5e6ad9d95a029e36'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb8338bd4d16-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:14,944 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:30:14,944 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:14,945 httpcore.http11 DEBUG receive_response_body.complete
18:30:14,945 httpcore.http11 DEBUG response_closed.started
18:30:14,946 httpcore.http11 DEBUG response_closed.complete
18:30:14,946 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:30:14,947 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:30:14,985 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:14,997 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:15,34 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344d0050>
18:30:15,35 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fdf40> server_hostname='api.openai.com' timeout=None
18:30:15,44 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344d09d0>
18:30:15,45 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:15,47 httpcore.http11 DEBUG send_request_headers.complete
18:30:15,48 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:15,49 httpcore.http11 DEBUG send_request_body.complete
18:30:15,50 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:15,270 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:30:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'126'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f3c3625e971ea3fb70da5adfcf286b4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dbargJkkEaFHQlRLZ27GrWHvuEM9ku.1CXn.O33WS3k-1702078215-1-AWDr0h2WHGkOftqneN1AjW7w73OWa1JmVT+FlGutLRYMN89juH+VAODdDOZWfm1rNkITDFmoDNR6vapkyerxBpc=; path=/; expires=Sat, 09-Dec-23 00:00:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=b5_Kgpbm9qWypxiqBy4M0qNdlv3lRcqoHaF8N6Km9hI-1702078215265-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb8c0eaf3074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:15,281 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:15,282 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:15,283 httpcore.http11 DEBUG receive_response_body.complete
18:30:15,283 httpcore.http11 DEBUG response_closed.started
18:30:15,283 httpcore.http11 DEBUG response_closed.complete
18:30:15,284 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:15,318 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:15,330 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:15,333 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344d34d0>
18:30:15,334 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fe720> server_hostname='api.openai.com' timeout=None
18:30:15,341 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344c3390>
18:30:15,342 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:15,343 httpcore.http11 DEBUG send_request_headers.complete
18:30:15,343 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:15,344 httpcore.http11 DEBUG send_request_body.complete
18:30:15,344 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:16,33 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:30:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'582'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3ccf74c03bfa36b94aa9ccaa35fa818e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ygw5NT9AtjcNhF8ntOgI2jR7guV_pQD9Oq.y84PJujQ-1702078216-1-AbV1bJE/bLvHlSNhlet46qQwCI7PgaxFt2Akprl01QP3hS9hSFKANB2FuJwdPackoE2vWb4XNKNkjE468H4uiZU=; path=/; expires=Sat, 09-Dec-23 00:00:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ZwmI4wipG.EaPhIYQxoZRWsPiUnvL4cgTTDUs2zRV5I-1702078216029-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb8dede14cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:16,40 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:16,42 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:16,44 httpcore.http11 DEBUG receive_response_body.complete
18:30:16,45 httpcore.http11 DEBUG response_closed.started
18:30:16,45 httpcore.http11 DEBUG response_closed.complete
18:30:16,46 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:16,478 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:16,483 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:30:23,692 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:30:23,709 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:23,713 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:30:28,915 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:30:28,930 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:28,933 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:03,833 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:03,836 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,642 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,643 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,685 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,686 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,735 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,736 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,777 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,778 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,825 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,826 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,867 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,868 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,916 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,917 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,957 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,958 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:05,769 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:32:05,789 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:05,819 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5957190>
18:32:05,820 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:32:05,828 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5957690>
18:32:05,829 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:05,831 httpcore.http11 DEBUG send_request_headers.complete
18:32:05,831 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:05,831 httpcore.http11 DEBUG send_request_body.complete
18:32:05,832 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:06,290 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:06 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'377'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'32613f16b25f4de3d8e5dcd331fbeafd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9HmoBvScVOe.Z.OztyDEvfeNTWsn_yP.MqJ4wSRWs5s-1702078326-1-AQtG60gO3oyV9HIGAEVz8m0h0yRbGJnImquaur/klkYWi4i0ciWutJWjalSgYnGSbhfwQX5eLB1HhSMWnsttuhs=; path=/; expires=Sat, 09-Dec-23 00:02:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BlUebMc3WvduuuIx_5GL781YUhfCu.N1O6lLu65Jm_g-1702078326284-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ce407fb04cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:06,298 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:32:06,299 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:07,60 httpcore.http11 DEBUG receive_response_body.complete
18:32:07,61 httpcore.http11 DEBUG response_closed.started
18:32:07,62 httpcore.http11 DEBUG response_closed.complete
18:32:07,62 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:32:07,141 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:32:20,759 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:32:20,768 httpcore.connection DEBUG close.started
18:32:20,769 httpcore.connection DEBUG close.complete
18:32:20,769 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:20,772 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5957a50>
18:32:20,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:32:20,779 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59578d0>
18:32:20,780 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:20,781 httpcore.http11 DEBUG send_request_headers.complete
18:32:20,781 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:20,813 httpcore.http11 DEBUG send_request_body.complete
18:32:20,813 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:21,995 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'15'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'365'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bf0e59de5342c6686a9ed873c6cb964f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ce9de94d4d0e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:21,998 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:32:21,998 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:21,999 httpcore.http11 DEBUG receive_response_body.complete
18:32:21,999 httpcore.http11 DEBUG response_closed.started
18:32:22,0 httpcore.http11 DEBUG response_closed.complete
18:32:22,0 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:32:22,1 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:32:22,34 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nat the center.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:32:22,45 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:32:22,48 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ac050>
18:32:22,48 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1f40> server_hostname='api.openai.com' timeout=None
18:32:22,55 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ac9d0>
18:32:22,55 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:22,56 httpcore.http11 DEBUG send_request_headers.complete
18:32:22,57 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:22,57 httpcore.http11 DEBUG send_request_body.complete
18:32:22,58 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:22,276 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2293db4494c04809be682fdf7514c255'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=m1zrGgYQjxfwCcem2nnhb5LCrREj0b0xvPFTu60.zD8-1702078342-1-AcBQ5zOi+fmc/SI7ebIixQZATlaXbY+fUIlfhVC5v7OxnFmw2SHl/Nj0kKNuTKXxAVgBc9BZmBMJ82gV8Bid7jE=; path=/; expires=Sat, 09-Dec-23 00:02:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=cvD7tntWNsq.6jpjHkXGxgb_fz.pb.N1RBc_y6XSJ9U-1702078342271-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cea5d9b26ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:22,285 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:32:22,286 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:22,287 httpcore.http11 DEBUG receive_response_body.complete
18:32:22,287 httpcore.http11 DEBUG response_closed.started
18:32:22,287 httpcore.http11 DEBUG response_closed.complete
18:32:22,288 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:32:22,322 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nat the center.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:32:22,332 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:32:22,335 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5df0510>
18:32:22,335 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be2720> server_hostname='api.openai.com' timeout=None
18:32:22,341 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ad810>
18:32:22,341 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:22,342 httpcore.http11 DEBUG send_request_headers.complete
18:32:22,342 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:22,343 httpcore.http11 DEBUG send_request_body.complete
18:32:22,343 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:23,72 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'633'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5e67480df490c2521f325e712ab21bcd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=z0ghITu4MfFJldyk04tPCJw5hPK_t7CCKynH1_NGIiM-1702078343-1-AbvYghKjT0JhRWSQMT3FyCY2GYtGzoeXOdC+jt8wBCVOCGZ7uLqI2CKOUKW+sYEhWgSRaVqL5VBjfYliu6pNSfI=; path=/; expires=Sat, 09-Dec-23 00:02:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kRO4TA0a.aG68ZSpVgsgT.oghKyYLs11qI_aYEythu8-1702078343067-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cea7a9253025-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:23,78 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:32:23,79 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:23,80 httpcore.http11 DEBUG receive_response_body.complete
18:32:23,81 httpcore.http11 DEBUG response_closed.started
18:32:23,82 httpcore.http11 DEBUG response_closed.complete
18:32:23,82 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:32:23,492 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:23,496 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:30,704 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:30,720 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:30,724 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:35,926 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:35,944 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:35,949 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:41,152 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:41,169 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:41,173 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:46,376 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:46,393 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:46,397 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:53,600 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:53,620 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:53,623 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:58,824 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:58,841 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:58,845 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:04,47 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:04,66 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:04,69 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:09,271 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:09,289 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:09,292 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:14,494 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:14,512 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:14,515 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:19,718 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:19,726 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:33:19,732 httpcore.connection DEBUG close.started
18:33:19,732 httpcore.connection DEBUG close.complete
18:33:19,733 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:19,760 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5a17650>
18:33:19,760 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:19,767 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59cbc50>
18:33:19,768 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:19,770 httpcore.http11 DEBUG send_request_headers.complete
18:33:19,771 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:19,772 httpcore.http11 DEBUG send_request_body.complete
18:33:19,772 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:20,491 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'566'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f46fb0a20ea44e0cc7741973439b41ea'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d00e9ebf4d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:20,495 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:33:20,496 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:21,418 httpcore.http11 DEBUG receive_response_body.complete
18:33:21,418 httpcore.http11 DEBUG response_closed.started
18:33:21,419 httpcore.http11 DEBUG response_closed.complete
18:33:21,419 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:33:21,483 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:33:33,469 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:33:33,476 httpcore.connection DEBUG close.started
18:33:33,476 httpcore.connection DEBUG close.complete
18:33:33,476 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:33,479 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de950>
18:33:33,479 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:33,486 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de9d0>
18:33:33,486 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:33,487 httpcore.http11 DEBUG send_request_headers.complete
18:33:33,488 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:33,514 httpcore.http11 DEBUG send_request_body.complete
18:33:33,514 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:34,322 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'354'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6ea4f4f06d0b6bd01a3fca57ec1e0b7b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0644c634ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:34,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:33:34,324 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:34,325 httpcore.http11 DEBUG receive_response_body.complete
18:33:34,325 httpcore.http11 DEBUG response_closed.started
18:33:34,325 httpcore.http11 DEBUG response_closed.complete
18:33:34,326 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:33:34,326 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:33:34,355 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nUh, most of the...\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:33:34,358 httpcore.connection DEBUG close.started
18:33:34,359 httpcore.connection DEBUG close.complete
18:33:34,359 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:33:34,361 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ac9d0>
18:33:34,361 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1f40> server_hostname='api.openai.com' timeout=None
18:33:34,368 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59aca50>
18:33:34,368 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:34,369 httpcore.http11 DEBUG send_request_headers.complete
18:33:34,370 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:34,370 httpcore.http11 DEBUG send_request_body.complete
18:33:34,370 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:34,588 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e160c6b4cd9e533a737dc8610c926234'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d069ca7a4cf2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:34,595 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:33:34,597 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:34,599 httpcore.http11 DEBUG receive_response_body.complete
18:33:34,600 httpcore.http11 DEBUG response_closed.started
18:33:34,601 httpcore.http11 DEBUG response_closed.complete
18:33:34,601 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:33:34,608 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:33:34,612 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:34,613 httpcore.http11 DEBUG send_request_headers.complete
18:33:34,613 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:34,613 httpcore.http11 DEBUG send_request_body.complete
18:33:34,614 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:35,285 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'555'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9e1403a25c2f0f9162f184678aaffec9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d06b5f114ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:35,290 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:33:35,291 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:36,358 httpcore.http11 DEBUG receive_response_body.complete
18:33:36,358 httpcore.http11 DEBUG response_closed.started
18:33:36,359 httpcore.http11 DEBUG response_closed.complete
18:33:36,360 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:33:36,434 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:33:49,118 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:33:49,125 httpcore.connection DEBUG close.started
18:33:49,126 httpcore.connection DEBUG close.complete
18:33:49,126 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:49,129 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59dcb10>
18:33:49,129 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:49,136 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59dd410>
18:33:49,136 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:49,138 httpcore.http11 DEBUG send_request_headers.complete
18:33:49,138 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:49,163 httpcore.http11 DEBUG send_request_body.complete
18:33:49,164 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:50,31 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:50 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'371'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'be53eab8116e395b4c0f9f7211a466da'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0c61c5c4cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:50,35 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:33:50,36 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:50,37 httpcore.http11 DEBUG receive_response_body.complete
18:33:50,37 httpcore.http11 DEBUG response_closed.started
18:33:50,38 httpcore.http11 DEBUG response_closed.complete
18:33:50,38 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:33:50,39 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:33:50,69 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:33:50,78 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:33:50,81 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59edf10>
18:33:50,81 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:33:50,89 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59eded0>
18:33:50,89 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:50,91 httpcore.http11 DEBUG send_request_headers.complete
18:33:50,91 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:50,92 httpcore.http11 DEBUG send_request_body.complete
18:33:50,92 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:50,326 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1ec717c35c2eecaf712d20dc9bd377b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qjIMCtEoaSLJp_MQ2EXqxL30whdS1mIOSN8H3LdfQbM-1702078430-1-AdCwUQ+ZThDSIRTbD3WV0cOeGpDZIzsv0OI9V7PKWjoPN1jxxVhke5+102Sj2kM6zVXOa9bB1e9hF2qOPtSgSqA=; path=/; expires=Sat, 09-Dec-23 00:03:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BihLozpwzEEi8EODi.w2D2yyOgL8lrSw_QiYkSdosDc-1702078430320-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0cc1bb44d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:50,334 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:33:50,335 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:50,336 httpcore.http11 DEBUG receive_response_body.complete
18:33:50,336 httpcore.http11 DEBUG response_closed.started
18:33:50,336 httpcore.http11 DEBUG response_closed.complete
18:33:50,337 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:33:50,370 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:33:50,374 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:50,375 httpcore.http11 DEBUG send_request_headers.complete
18:33:50,375 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:50,376 httpcore.http11 DEBUG send_request_body.complete
18:33:50,376 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:50,592 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1fffccca370d09b92f5eb46b9f6cba81'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0cddf104d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:50,597 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:33:50,598 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:50,600 httpcore.http11 DEBUG receive_response_body.complete
18:33:50,601 httpcore.http11 DEBUG response_closed.started
18:33:50,602 httpcore.http11 DEBUG response_closed.complete
18:33:50,602 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:33:50,618 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:50,621 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:55,823 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:55,829 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:33:55,835 httpcore.connection DEBUG close.started
18:33:55,835 httpcore.connection DEBUG close.complete
18:33:55,836 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:55,838 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ee5d0>
18:33:55,839 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:55,844 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ef790>
18:33:55,845 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:55,847 httpcore.http11 DEBUG send_request_headers.complete
18:33:55,847 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:55,848 httpcore.http11 DEBUG send_request_body.complete
18:33:55,848 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:56,428 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'469'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'74fb29e2d51344f09da55043bc76f8bf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0f00c4e4cd4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:56,433 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:33:56,434 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:56,722 httpcore.http11 DEBUG receive_response_body.complete
18:33:56,722 httpcore.http11 DEBUG response_closed.started
18:33:56,723 httpcore.http11 DEBUG response_closed.complete
18:33:56,723 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:33:56,788 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:34:04,548 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:34:04,555 httpcore.connection DEBUG close.started
18:34:04,555 httpcore.connection DEBUG close.complete
18:34:04,556 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:04,558 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59df110>
18:34:04,559 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:04,567 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de350>
18:34:04,568 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:04,569 httpcore.http11 DEBUG send_request_headers.complete
18:34:04,569 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:04,646 httpcore.http11 DEBUG send_request_body.complete
18:34:04,647 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:05,520 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:05 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c028e0b52c8bf36837d083fa2ef74384'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d12688e14ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:05,524 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:34:05,525 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:05,526 httpcore.http11 DEBUG receive_response_body.complete
18:34:05,527 httpcore.http11 DEBUG response_closed.started
18:34:05,527 httpcore.http11 DEBUG response_closed.complete
18:34:05,528 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:34:05,529 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:34:05,560 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMoved out.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:34:05,563 httpcore.connection DEBUG close.started
18:34:05,563 httpcore.connection DEBUG close.complete
18:34:05,564 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:34:05,566 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59df550>
18:34:05,567 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:34:05,575 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de650>
18:34:05,575 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:05,576 httpcore.http11 DEBUG send_request_headers.complete
18:34:05,577 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:05,578 httpcore.http11 DEBUG send_request_body.complete
18:34:05,578 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:05,815 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2229ce4935f11453a5eeb597cad3ab9a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d12cde264ce9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:05,820 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:34:05,821 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:05,822 httpcore.http11 DEBUG receive_response_body.complete
18:34:05,822 httpcore.http11 DEBUG response_closed.started
18:34:05,822 httpcore.http11 DEBUG response_closed.complete
18:34:05,823 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:34:05,839 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:34:05,843 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:34:11,45 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:34:11,51 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:34:11,58 httpcore.connection DEBUG close.started
18:34:11,59 httpcore.connection DEBUG close.complete
18:34:11,59 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:11,62 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59df090>
18:34:11,62 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:11,70 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59deed0>
18:34:11,70 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:11,71 httpcore.http11 DEBUG send_request_headers.complete
18:34:11,72 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:11,72 httpcore.http11 DEBUG send_request_body.complete
18:34:11,73 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:11,499 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:11 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'352'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6a5cc310aaebe4c5c4ff55b87fe8f352'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d14f39464cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:11,505 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:34:11,506 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:11,777 httpcore.http11 DEBUG receive_response_body.complete
18:34:11,778 httpcore.http11 DEBUG response_closed.started
18:34:11,779 httpcore.http11 DEBUG response_closed.complete
18:34:11,779 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:34:11,845 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:34:19,670 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:34:19,674 httpcore.connection DEBUG close.started
18:34:19,674 httpcore.connection DEBUG close.complete
18:34:19,674 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:19,677 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f7b50>
18:34:19,677 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:19,683 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f7bd0>
18:34:19,683 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:19,685 httpcore.http11 DEBUG send_request_headers.complete
18:34:19,685 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:19,706 httpcore.http11 DEBUG send_request_body.complete
18:34:19,706 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:20,539 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:20 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'498'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb87ba7bf2d4506f73dbd82e4e5e332b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1850f373b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:20,544 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:34:20,546 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:20,547 httpcore.http11 DEBUG receive_response_body.complete
18:34:20,548 httpcore.http11 DEBUG response_closed.started
18:34:20,548 httpcore.http11 DEBUG response_closed.complete
18:34:20,549 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:34:20,550 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:34:20,579 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:34:20,582 httpcore.connection DEBUG close.started
18:34:20,583 httpcore.connection DEBUG close.complete
18:34:20,583 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:34:20,614 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59fedd0>
18:34:20,614 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:34:20,623 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59fee50>
18:34:20,624 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:20,627 httpcore.http11 DEBUG send_request_headers.complete
18:34:20,627 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:20,628 httpcore.http11 DEBUG send_request_body.complete
18:34:20,629 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:20,841 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ad4fe815c833158de85947bd8dc9f37a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d18ae91e4cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:20,848 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:34:20,849 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:20,852 httpcore.http11 DEBUG receive_response_body.complete
18:34:20,853 httpcore.http11 DEBUG response_closed.started
18:34:20,853 httpcore.http11 DEBUG response_closed.complete
18:34:20,854 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:34:20,872 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:34:20,875 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:34:26,77 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:34:26,86 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:34:26,90 httpcore.connection DEBUG close.started
18:34:26,91 httpcore.connection DEBUG close.complete
18:34:26,91 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:26,94 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f5750>
18:34:26,94 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:26,100 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f5ad0>
18:34:26,101 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:26,102 httpcore.http11 DEBUG send_request_headers.complete
18:34:26,102 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:26,102 httpcore.http11 DEBUG send_request_body.complete
18:34:26,103 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:26,535 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:26 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bb950392a890502ad403a97cf3c9a648'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1ad2c93304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:26,540 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:34:26,541 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:26,811 httpcore.http11 DEBUG receive_response_body.complete
18:34:26,812 httpcore.http11 DEBUG response_closed.started
18:34:26,813 httpcore.http11 DEBUG response_closed.complete
18:34:26,814 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:34:26,883 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:34:34,593 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:34:34,597 httpcore.connection DEBUG close.started
18:34:34,597 httpcore.connection DEBUG close.complete
18:34:34,598 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:34,600 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e599dcd0>
18:34:34,600 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:34,605 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e599c390>
18:34:34,606 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:34,607 httpcore.http11 DEBUG send_request_headers.complete
18:34:34,607 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:34,630 httpcore.http11 DEBUG send_request_body.complete
18:34:34,630 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:35,426 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:35 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'336'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'58c6fad6d2b59197e5ebf3181c628e6e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1e24fdf4cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:35,430 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:34:35,431 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:35,432 httpcore.http11 DEBUG receive_response_body.complete
18:34:35,432 httpcore.http11 DEBUG response_closed.started
18:34:35,432 httpcore.http11 DEBUG response_closed.complete
18:34:35,433 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:34:35,433 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:34:35,463 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:34:35,466 httpcore.connection DEBUG close.started
18:34:35,467 httpcore.connection DEBUG close.complete
18:34:35,467 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:34:35,469 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ef010>
18:34:35,470 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:34:35,475 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ee450>
18:34:35,476 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:35,477 httpcore.http11 DEBUG send_request_headers.complete
18:34:35,477 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:35,478 httpcore.http11 DEBUG send_request_body.complete
18:34:35,478 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:35,684 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'38b68a276c8269fbb7b84f4750a6a859'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1e7b8884d1e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:35,690 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:34:35,692 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:35,693 httpcore.http11 DEBUG receive_response_body.complete
18:34:35,693 httpcore.http11 DEBUG response_closed.started
18:34:35,694 httpcore.http11 DEBUG response_closed.complete
18:34:35,694 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:34:35,710 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:34:35,713 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:41:41,494 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:41,498 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,337 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,338 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,381 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,382 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,429 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,430 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,470 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,471 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,518 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,519 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,559 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,560 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,608 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,609 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,649 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,650 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:42:45,929 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:42:45,948 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:42:45,980 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064f850>
18:42:45,981 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:42:45,989 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064fd50>
18:42:45,991 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:42:45,994 httpcore.http11 DEBUG send_request_headers.complete
18:42:45,995 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:42:45,996 httpcore.http11 DEBUG send_request_body.complete
18:42:45,997 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:42:46,464 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:42:46 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'99b41040259ebd3bc782f6f4f2ac88bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=wi_FXDO2QKu2OL8vQus_m1LE9jBhW0NTBOGuxR4CuD4-1702078966-1-AYnT8afk/4CRrar/B4GsZuuHFJv7l0Jj8n2lQ7pSb33yvhl9r3vc7PIxIdvgegevkzEL3LU/53SLXaRDq/DHxX8=; path=/; expires=Sat, 09-Dec-23 00:12:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=08XvDRGHVrTqXpcytxXI9BeyktXmRV1qNTQelLTZ4Y8-1702078966460-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328dde17c603074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:42:46,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:42:46,473 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:42:47,206 httpcore.http11 DEBUG receive_response_body.complete
18:42:47,207 httpcore.http11 DEBUG response_closed.started
18:42:47,208 httpcore.http11 DEBUG response_closed.complete
18:42:47,209 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:42:47,293 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:43:01,20 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:43:01,34 httpcore.connection DEBUG close.started
18:43:01,34 httpcore.connection DEBUG close.complete
18:43:01,35 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:43:01,38 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064fc10>
18:43:01,39 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:43:01,47 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064e3d0>
18:43:01,48 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:01,50 httpcore.http11 DEBUG send_request_headers.complete
18:43:01,50 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:01,82 httpcore.http11 DEBUG send_request_body.complete
18:43:01,83 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:02,4 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:43:02 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2117486d1cb246e760553bc28c2dae1c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328de3f8eb04d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:02,8 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:43:02,9 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:02,9 httpcore.http11 DEBUG receive_response_body.complete
18:43:02,10 httpcore.http11 DEBUG response_closed.started
18:43:02,10 httpcore.http11 DEBUG response_closed.complete
18:43:02,11 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:43:02,12 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:43:02,49 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:43:02,60 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:43:02,62 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc590>
18:43:02,63 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9f40> server_hostname='api.openai.com' timeout=None
18:43:02,70 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc510>
18:43:02,71 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:02,72 httpcore.http11 DEBUG send_request_headers.complete
18:43:02,73 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:02,73 httpcore.http11 DEBUG send_request_body.complete
18:43:02,74 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:02,294 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:43:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd380830568c83b1629eeb170ca5cdc52'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IotWwaSYls2XBWPILfuL.kRIqZN1FfcmaIgKE8d03bM-1702078982-1-AWisfyM23/Nej7pH2wfyLfput/fQKw5Dt1bedUVw+eywK/Vt4vNnc8254ospV1LTxcUItdIqhqpjHaW2XDTI1Iw=; path=/; expires=Sat, 09-Dec-23 00:13:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OSSESw2HPKvvyx4qOyoYOoixayRS28jmxa.0nlKrXlk-1702078982289-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328de45fc5a3b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:02,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:43:02,304 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:02,306 httpcore.http11 DEBUG receive_response_body.complete
18:43:02,306 httpcore.http11 DEBUG response_closed.started
18:43:02,306 httpcore.http11 DEBUG response_closed.complete
18:43:02,307 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:43:02,342 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:43:02,357 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:43:02,360 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504c2d90>
18:43:02,360 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506da720> server_hostname='api.openai.com' timeout=None
18:43:02,367 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504c2d10>
18:43:02,367 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:02,368 httpcore.http11 DEBUG send_request_headers.complete
18:43:02,369 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:02,370 httpcore.http11 DEBUG send_request_body.complete
18:43:02,370 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:03,262 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:43:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'764'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e49cccdeb5a77ff05f9bfe87928556e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ghm66SyyP6DHtF9PC6dGI1JUUnObmysNUC5niSlcnAg-1702078983-1-AfdTfmkzpvpY0gvJUpS4H3zE4VKlF5xbuxlZv6hvrulwhZ16PdzrLZLREzvE4YCWz8g1YFMdItglEXJ5OXrFSQM=; path=/; expires=Sat, 09-Dec-23 00:13:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NMlCLq77tPJASCAw_TcAwUEkFhBL3QAgF39QkRJbHeQ-1702078983256-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328de47cd5e4cfb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:03,269 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:43:03,270 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:03,271 httpcore.http11 DEBUG receive_response_body.complete
18:43:03,272 httpcore.http11 DEBUG response_closed.started
18:43:03,272 httpcore.http11 DEBUG response_closed.complete
18:43:03,273 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:43:03,557 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:03,561 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:10,769 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:10,783 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:10,787 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:15,990 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:16,12 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:16,16 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:21,218 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:21,236 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:21,239 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:26,441 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:26,459 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:26,463 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:33,665 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:33,681 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:33,685 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:38,887 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:38,908 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:38,912 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:44,114 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:44,131 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:44,134 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:49,336 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:49,351 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:49,355 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:54,557 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:54,572 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:54,580 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:59,782 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:59,802 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:59,805 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:05,7 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:05,13 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:44:05,19 httpcore.connection DEBUG close.started
18:44:05,19 httpcore.connection DEBUG close.complete
18:44:05,19 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:05,48 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25081d890>
18:44:05,49 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:05,56 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504cd350>
18:44:05,57 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:05,59 httpcore.http11 DEBUG send_request_headers.complete
18:44:05,59 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:05,61 httpcore.http11 DEBUG send_request_body.complete
18:44:05,61 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:05,623 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'457'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a72d868546398846336e6cb9186059f0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328dfcf9ee63021-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:05,628 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:44:05,630 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:06,754 httpcore.http11 DEBUG receive_response_body.complete
18:44:06,755 httpcore.http11 DEBUG response_closed.started
18:44:06,755 httpcore.http11 DEBUG response_closed.complete
18:44:06,756 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:44:06,817 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:44:19,638 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:44:19,642 httpcore.connection DEBUG close.started
18:44:19,642 httpcore.connection DEBUG close.complete
18:44:19,643 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:19,647 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e2450>
18:44:19,647 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:19,652 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e24d0>
18:44:19,653 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:19,654 httpcore.http11 DEBUG send_request_headers.complete
18:44:19,654 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:19,677 httpcore.http11 DEBUG send_request_body.complete
18:44:19,678 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:21,279 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'891'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'111fa734b29acb5b37bf3cd91c7ade74'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e02adb0f4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:21,282 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:44:21,282 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:21,283 httpcore.http11 DEBUG receive_response_body.complete
18:44:21,284 httpcore.http11 DEBUG response_closed.started
18:44:21,284 httpcore.http11 DEBUG response_closed.complete
18:44:21,285 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:44:21,285 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:44:21,315 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:21,318 httpcore.connection DEBUG close.started
18:44:21,318 httpcore.connection DEBUG close.complete
18:44:21,319 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:21,321 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc510>
18:44:21,321 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9f40> server_hostname='api.openai.com' timeout=None
18:44:21,327 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc5d0>
18:44:21,327 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:21,328 httpcore.http11 DEBUG send_request_headers.complete
18:44:21,329 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:21,329 httpcore.http11 DEBUG send_request_body.complete
18:44:21,329 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:21,565 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3aa1c78749a7b4393dcbb99e0fef59df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e035484a6ac7-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:21,572 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:21,573 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:21,575 httpcore.http11 DEBUG receive_response_body.complete
18:44:21,575 httpcore.http11 DEBUG response_closed.started
18:44:21,575 httpcore.http11 DEBUG response_closed.complete
18:44:21,576 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:21,611 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:21,623 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:21,625 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e0a50>
18:44:21,625 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9eb0> server_hostname='api.openai.com' timeout=None
18:44:21,635 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e1710>
18:44:21,635 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:21,636 httpcore.http11 DEBUG send_request_headers.complete
18:44:21,637 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:21,638 httpcore.http11 DEBUG send_request_body.complete
18:44:21,638 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:21,850 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'bc576522874978d0af920b82881d9940'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lRxa3Yn3qd31UYZEaVnA6qjrTbCfOVzR4Pa5qsVDB2o-1702079061-1-AV9728OAGIXxecbahCvnWFbyT3oUQhO59+ZlJdh1YyfT4n4zC6+HwSHkahCjJi1lpTngOFx92mPv0WtXTKBAJeA=; path=/; expires=Sat, 09-Dec-23 00:14:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=gMYtQlB4yxjNIAvFzMuIVIgXXAmBq6pjavXnKoIEPR8-1702079061846-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0373a7a3b7b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:21,856 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:21,857 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:21,858 httpcore.http11 DEBUG receive_response_body.complete
18:44:21,859 httpcore.http11 DEBUG response_closed.started
18:44:21,859 httpcore.http11 DEBUG response_closed.complete
18:44:21,859 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:21,875 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:21,878 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:27,80 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:27,98 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:27,102 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:32,304 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:32,322 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:32,325 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:37,527 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:37,530 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:44:37,535 httpcore.connection DEBUG close.started
18:44:37,535 httpcore.connection DEBUG close.complete
18:44:37,536 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:37,538 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e0ed0>
18:44:37,539 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:37,544 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e0fd0>
18:44:37,544 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:37,545 httpcore.http11 DEBUG send_request_headers.complete
18:44:37,546 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:37,546 httpcore.http11 DEBUG send_request_body.complete
18:44:37,546 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:38,146 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a167828c9e8827a7be1fc8b095348094'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e09aa9ca4cd0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:38,149 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:44:38,150 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:38,517 httpcore.http11 DEBUG receive_response_body.complete
18:44:38,518 httpcore.http11 DEBUG response_closed.started
18:44:38,519 httpcore.http11 DEBUG response_closed.complete
18:44:38,519 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:44:38,587 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:44:49,934 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:44:49,939 httpcore.connection DEBUG close.started
18:44:49,939 httpcore.connection DEBUG close.complete
18:44:49,940 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:49,942 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e6590>
18:44:49,943 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:49,950 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e6610>
18:44:49,950 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:49,952 httpcore.http11 DEBUG send_request_headers.complete
18:44:49,952 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:49,983 httpcore.http11 DEBUG send_request_body.complete
18:44:49,983 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:51,80 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:51 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'17'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'359'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8eb63832b3b7fb39ad18c876cab499d4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0e83da14cef-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:51,85 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:44:51,86 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:51,87 httpcore.http11 DEBUG receive_response_body.complete
18:44:51,88 httpcore.http11 DEBUG response_closed.started
18:44:51,88 httpcore.http11 DEBUG response_closed.complete
18:44:51,89 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:44:51,90 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:44:51,124 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTop left corner.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:51,128 httpcore.connection DEBUG close.started
18:44:51,129 httpcore.connection DEBUG close.complete
18:44:51,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:51,132 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504fd810>
18:44:51,132 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9f40> server_hostname='api.openai.com' timeout=None
18:44:51,137 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504fd890>
18:44:51,138 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:51,138 httpcore.http11 DEBUG send_request_headers.complete
18:44:51,139 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:51,139 httpcore.http11 DEBUG send_request_body.complete
18:44:51,140 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:51,335 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'29d8292cba0aed70deebd23b81b3c015'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0ef9a414d18-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:51,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:51,345 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:51,346 httpcore.http11 DEBUG receive_response_body.complete
18:44:51,347 httpcore.http11 DEBUG response_closed.started
18:44:51,347 httpcore.http11 DEBUG response_closed.complete
18:44:51,348 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:51,381 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTop left corner.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:51,384 httpcore.connection DEBUG close.started
18:44:51,385 httpcore.connection DEBUG close.complete
18:44:51,385 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:51,387 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e6c50>
18:44:51,388 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506da720> server_hostname='api.openai.com' timeout=None
18:44:51,401 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e4310>
18:44:51,401 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:51,402 httpcore.http11 DEBUG send_request_headers.complete
18:44:51,403 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:51,403 httpcore.http11 DEBUG send_request_body.complete
18:44:51,404 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:52,104 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'606'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8c3b945b27b48f9080f1644271379082'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0f14fa64cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:52,107 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:52,107 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:52,108 httpcore.http11 DEBUG receive_response_body.complete
18:44:52,108 httpcore.http11 DEBUG response_closed.started
18:44:52,109 httpcore.http11 DEBUG response_closed.complete
18:44:52,109 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:52,448 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:52,450 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:59,652 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:59,675 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:59,678 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:04,879 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:04,900 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:04,904 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:10,107 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:10,127 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:10,131 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:15,333 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:15,351 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:15,354 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:22,556 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:22,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:22,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:27,780 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:27,796 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:27,799 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:33,1 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:33,20 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:33,23 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:38,225 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:38,243 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:38,246 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:43,448 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:43,466 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:43,470 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:48,674 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:48,692 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:48,695 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:53,898 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:53,915 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:53,919 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:59,121 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:59,126 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:45:59,131 httpcore.connection DEBUG close.started
18:45:59,131 httpcore.connection DEBUG close.complete
18:45:59,132 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:45:59,163 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e64d0>
18:45:59,164 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:45:59,171 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e4a90>
18:45:59,171 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:45:59,172 httpcore.http11 DEBUG send_request_headers.complete
18:45:59,173 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:45:59,173 httpcore.http11 DEBUG send_request_body.complete
18:45:59,173 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:45:59,670 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:45:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'86b424eb81b7831c353cf4d5979932f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e298d81b3b9f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:45:59,673 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:45:59,673 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:46:00,700 httpcore.http11 DEBUG receive_response_body.complete
18:46:00,701 httpcore.http11 DEBUG response_closed.started
18:46:00,702 httpcore.http11 DEBUG response_closed.complete
18:46:00,703 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:46:00,770 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:47:56,52 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:56,56 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:56,904 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:56,905 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:56,950 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:56,951 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,1 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,2 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,48 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,49 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,101 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,102 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,147 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,149 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,201 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,202 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,249 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,250 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:48:09,925 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:48:09,944 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:48:09,976 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc5689a90>
18:48:09,976 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5645d90> server_hostname='api.openai.com' timeout=5.0
18:48:09,983 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc55bfd10>
18:48:09,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:09,986 httpcore.http11 DEBUG send_request_headers.complete
18:48:09,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:09,987 httpcore.http11 DEBUG send_request_body.complete
18:48:09,988 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:10,456 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:10 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'449a95a7f51aab3ec967c1af2e7d7467'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=e9v_Yq1LjGMEUFZmhDQhdX2BRWr1F4pqoarj3JpJNTE-1702079290-1-ARwwPrWU+5K2XmjUt8yncnIwPTlPZTK+TIrHTNEufnuB+3Mj2QBXVZu0gKsbl/COp3usz96LrMZI1Mo3yMMYcZE=; path=/; expires=Sat, 09-Dec-23 00:18:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ADNQZqI8wiHniLCbIPKsSjE4Czw1gMYxw9uvawUzKEw-1702079290449-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e5ca6d904cf8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:10,463 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:48:10,464 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:11,114 httpcore.http11 DEBUG receive_response_body.complete
18:48:11,115 httpcore.http11 DEBUG response_closed.started
18:48:11,116 httpcore.http11 DEBUG response_closed.complete
18:48:11,117 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:48:11,197 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:48:24,724 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:48:24,735 httpcore.connection DEBUG close.started
18:48:24,735 httpcore.connection DEBUG close.complete
18:48:24,735 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:48:24,738 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc540d290>
18:48:24,738 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5645d90> server_hostname='api.openai.com' timeout=5.0
18:48:24,746 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc540d310>
18:48:24,747 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:24,748 httpcore.http11 DEBUG send_request_headers.complete
18:48:24,748 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:24,783 httpcore.http11 DEBUG send_request_body.complete
18:48:24,784 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:25,762 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:25 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'afec12eeba1bf50ad7035d4d1a3f18dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e626a92b4ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:25,767 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:48:25,768 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:25,769 httpcore.http11 DEBUG receive_response_body.complete
18:48:25,770 httpcore.http11 DEBUG response_closed.started
18:48:25,771 httpcore.http11 DEBUG response_closed.complete
18:48:25,772 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:48:25,773 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:48:25,806 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:48:25,816 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:48:25,818 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc541f990>
18:48:25,819 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5645f40> server_hostname='api.openai.com' timeout=None
18:48:25,824 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc541f950>
18:48:25,825 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:25,826 httpcore.http11 DEBUG send_request_headers.complete
18:48:25,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:25,827 httpcore.http11 DEBUG send_request_body.complete
18:48:25,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:26,39 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7f620ed3632d59c441a29472144e2cf8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WHjNpa9IOIxC1uAayIgMQVuIe3sR4gQsdvz4vpCW3WI-1702079306-1-AVX8P8w3Ms7A353KWBIEYSweKNzXgz3QRBNkwrDnGjEInY5xyVLxE8joKyuhDadUjuHfNFeKPy79x8JOoupdKhQ=; path=/; expires=Sat, 09-Dec-23 00:18:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zs2F1hwN2b6znnmh3UVH5c25Uut56iobzVMew6Ldrx8-1702079306035-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e62d6f404ce4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:26,46 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:48:26,46 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:26,47 httpcore.http11 DEBUG receive_response_body.complete
18:48:26,47 httpcore.http11 DEBUG response_closed.started
18:48:26,48 httpcore.http11 DEBUG response_closed.complete
18:48:26,48 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:48:26,82 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:48:26,93 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:48:26,96 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc55ec410>
18:48:26,96 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5646720> server_hostname='api.openai.com' timeout=None
18:48:26,103 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc5431610>
18:48:26,104 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:26,105 httpcore.http11 DEBUG send_request_headers.complete
18:48:26,105 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:26,106 httpcore.http11 DEBUG send_request_body.complete
18:48:26,106 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:26,935 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'736'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c114ec412e02adfc286bbe8020fbe22d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ewj2m4UQcMA6xJ7gxuZNhZvJpIVitnQvrncsKI4jhr8-1702079306-1-AdkzviaW+F1u6+IDaIAFY+WQvKoYYVabsiqV/001/ApCwCn3Ksa9jisEYJKMQnCUZ3tEvkgTryeG6rDu52MbJQU=; path=/; expires=Sat, 09-Dec-23 00:18:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1IXrh_2oGeGP1CmVdRLwHh_n9mIhlvN17KTPNVwxyW8-1702079306930-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e62f2dd84cf4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:26,942 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:48:26,942 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:26,943 httpcore.http11 DEBUG receive_response_body.complete
18:48:26,944 httpcore.http11 DEBUG response_closed.started
18:48:26,944 httpcore.http11 DEBUG response_closed.complete
18:48:26,944 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:46,538 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:46,543 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,364 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,366 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,413 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,414 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,467 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,468 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,512 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,513 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,568 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,569 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,613 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,614 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,665 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,667 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,710 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,711 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:51:27,217 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:51:27,235 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:27,265 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6f0c590>
18:51:27,266 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f99d90> server_hostname='api.openai.com' timeout=5.0
18:51:27,273 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6f0a5d0>
18:51:27,274 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:27,276 httpcore.http11 DEBUG send_request_headers.complete
18:51:27,277 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:27,278 httpcore.http11 DEBUG send_request_body.complete
18:51:27,278 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:27,739 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'382'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'89ec8f8157188fbdedbedc2939cc4ced'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cv5BcEheV2lQH63JB07Zn4QnxjPzqyFbIcOYJiHIkls-1702079487-1-AXtwi+zeEiCI05U8dZCNhwfnnybf/ryTwM3d+scARDTsC8cWu9PAdPIIiAplRDp7ypQVv2D1Dc46NQ8hrsh+vRA=; path=/; expires=Sat, 09-Dec-23 00:21:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=S.CKZe5di2.CNojoRRbkSiVLweo2LJ3cMTHHG3AYh1E-1702079487732-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ea9b7db14cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:27,746 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:51:27,747 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:28,435 httpcore.http11 DEBUG receive_response_body.complete
18:51:28,436 httpcore.http11 DEBUG response_closed.started
18:51:28,437 httpcore.http11 DEBUG response_closed.complete
18:51:28,438 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:51:28,516 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:51:42,186 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:51:42,195 httpcore.connection DEBUG close.started
18:51:42,196 httpcore.connection DEBUG close.complete
18:51:42,196 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:42,199 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d621d0>
18:51:42,199 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f99d90> server_hostname='api.openai.com' timeout=5.0
18:51:42,204 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d62250>
18:51:42,204 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:42,205 httpcore.http11 DEBUG send_request_headers.complete
18:51:42,206 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:42,233 httpcore.http11 DEBUG send_request_body.complete
18:51:42,234 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:43,7 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:43 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'12'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6e4c48ae0fc4da7f997a08c106ea4897'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eaf8c8426ac7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:43,13 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:51:43,14 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:43,14 httpcore.http11 DEBUG receive_response_body.complete
18:51:43,15 httpcore.http11 DEBUG response_closed.started
18:51:43,15 httpcore.http11 DEBUG response_closed.complete
18:51:43,16 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:51:43,16 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:51:43,51 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nthe middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:43,64 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:43,66 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d80610>
18:51:43,67 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f99f40> server_hostname='api.openai.com' timeout=None
18:51:43,74 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d80590>
18:51:43,74 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:43,76 httpcore.http11 DEBUG send_request_headers.complete
18:51:43,76 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:43,77 httpcore.http11 DEBUG send_request_body.complete
18:51:43,77 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:43,271 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ebb291b2736136fe297c2bc490e8b5d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6IzzDXaNhw6A_oHbLwOXHXIglQGTipgr3.U5WJ7u5kU-1702079503-1-AaLQyDjPIK0dXWyBw0s/OgOeOWeEzqpNixXjT1NkLSCBmX2bMi2mZCMDS9/Qjpe1lo6xQjjaYe8QjdWvTpEG7BI=; path=/; expires=Sat, 09-Dec-23 00:21:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3SJBydyFukFYWn70QWR3ehIh43L2vCm4RjL.0wXZ.lY-1702079503266-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eafe3e243b69-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:43,278 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:43,279 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:43,280 httpcore.http11 DEBUG receive_response_body.complete
18:51:43,280 httpcore.http11 DEBUG response_closed.started
18:51:43,280 httpcore.http11 DEBUG response_closed.complete
18:51:43,281 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:51:43,315 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nthe middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:43,325 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:43,328 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d85dd0>
18:51:43,328 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f9a720> server_hostname='api.openai.com' timeout=None
18:51:43,334 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d85e90>
18:51:43,334 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:43,335 httpcore.http11 DEBUG send_request_headers.complete
18:51:43,336 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:43,336 httpcore.http11 DEBUG send_request_body.complete
18:51:43,337 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:44,154 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'727'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd275a54142d87d510b333b933f105403'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BzcslWb8HcNPpblypowyx4qD82JTHxtYnd64sgVYzOs-1702079504-1-Aa3HhS1CV2iMPSyCXF5hdZImb/5ha8DUyJL/KVcdUPubwXu4zwEftYfixP3TabQ7ivpTB2smnnfyiNkfhQQz/SU=; path=/; expires=Sat, 09-Dec-23 00:21:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Qthr1NCaH.k4eZDNxC7pfvx36kSbYfWLO3JCYmvUBls-1702079504149-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eaffde723074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:44,162 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:44,162 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:44,163 httpcore.http11 DEBUG receive_response_body.complete
18:51:44,164 httpcore.http11 DEBUG response_closed.started
18:51:44,164 httpcore.http11 DEBUG response_closed.complete
18:51:44,164 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:34,922 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:34,925 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,711 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,712 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,750 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,751 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,791 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,792 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,829 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,830 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,869 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,870 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,907 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,908 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,957 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,958 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,997 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,998 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:36,41 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:52:36,53 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:52:36,85 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd6dd0>
18:52:36,86 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a061d90> server_hostname='api.openai.com' timeout=5.0
18:52:36,95 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd7310>
18:52:36,96 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:36,98 httpcore.http11 DEBUG send_request_headers.complete
18:52:36,98 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:36,98 httpcore.http11 DEBUG send_request_body.complete
18:52:36,98 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:36,603 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'775c16faba4146365bd8c0ae07f32222'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Mfmw4EPT_jTakmvNpKDO6jMRDzRtP8VTdGi1AiaFQYA-1702079556-1-AeVKSYgiD1t9lGNvPVmasvUWXlcX6Rz4rrx5I6dTFeSsy5ioeMaL5YwcpnBNu9f99R7nzn0wBUvt4LNYSTm9gCk=; path=/; expires=Sat, 09-Dec-23 00:22:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RFzAmMtwMLoviWsElxfjF0gQuC_Tz0MDfPvOO44BvmU-1702079556598-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ec4998264cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:36,608 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:52:36,608 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:37,410 httpcore.http11 DEBUG receive_response_body.complete
18:52:37,411 httpcore.http11 DEBUG response_closed.started
18:52:37,411 httpcore.http11 DEBUG response_closed.complete
18:52:37,412 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:52:37,483 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:52:51,326 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:52:51,332 httpcore.connection DEBUG close.started
18:52:51,332 httpcore.connection DEBUG close.complete
18:52:51,333 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:52:51,335 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd7250>
18:52:51,335 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a061d90> server_hostname='api.openai.com' timeout=5.0
18:52:51,342 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd7610>
18:52:51,342 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:51,343 httpcore.http11 DEBUG send_request_headers.complete
18:52:51,343 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:51,373 httpcore.http11 DEBUG send_request_body.complete
18:52:51,373 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:52,191 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:52 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'350'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1190784aedabb98b9b1816cd1c691718'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eca8ef044ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:52,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:52:52,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:52,195 httpcore.http11 DEBUG receive_response_body.complete
18:52:52,195 httpcore.http11 DEBUG response_closed.started
18:52:52,195 httpcore.http11 DEBUG response_closed.complete
18:52:52,196 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:52:52,196 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:52:52,215 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:52,226 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:52,228 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a0340d0>
18:52:52,228 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a061f40> server_hostname='api.openai.com' timeout=None
18:52:52,237 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a034090>
18:52:52,237 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:52,238 httpcore.http11 DEBUG send_request_headers.complete
18:52:52,238 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:52,239 httpcore.http11 DEBUG send_request_body.complete
18:52:52,239 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:52,462 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'126'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b5cfd52460b8f786f856cdff10f18595'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WNBnanKjT2zx1FCeLCTfspPIndN7Wzf0zHrr3s3pW4s-1702079572-1-AacBzi4gHxRe5M7gC5kdlUYh+mTmJqTo3cWJqwTrpoF8do9o9w/pJ+JkmX817611AnFus6vHXbWMJkMTI8be+ds=; path=/; expires=Sat, 09-Dec-23 00:22:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qEkBcI7szGPGOXBWdPORCtFUeo0KJFd0gsnViCrBldA-1702079572458-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ecae7bc83008-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:52,466 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:52,467 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:52,468 httpcore.http11 DEBUG receive_response_body.complete
18:52:52,468 httpcore.http11 DEBUG response_closed.started
18:52:52,469 httpcore.http11 DEBUG response_closed.complete
18:52:52,469 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:52,486 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1, surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:52,495 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:52,497 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a023290>
18:52:52,497 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a062720> server_hostname='api.openai.com' timeout=None
18:52:52,503 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a020ed0>
18:52:52,504 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:52,504 httpcore.http11 DEBUG send_request_headers.complete
18:52:52,504 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:52,505 httpcore.http11 DEBUG send_request_body.complete
18:52:52,505 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:53,353 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'759'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6fea5a5d84504d3c70e1b0723cbfdc4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3uo9fb4A5hlcwwhbM4DHbLKQqAnx.pVFQvURi67oK.E-1702079573-1-AXvDqDkGfe8ylgrvbpOJmH1sVrwvvAizG6DEoUaQk36tZBu1jg/XDiK2Rqy/kywhGmWaISH2t3NSHprmRZUerYo=; path=/; expires=Sat, 09-Dec-23 00:22:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=C3caYzHytfZdkIme09_IYeUnnEIBFzQl33oZuxI5710-1702079573350-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ecb02e5b3b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:53,356 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:53,357 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:53,358 httpcore.http11 DEBUG receive_response_body.complete
18:52:53,358 httpcore.http11 DEBUG response_closed.started
18:52:53,358 httpcore.http11 DEBUG response_closed.complete
18:52:53,359 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:53,554 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:52:53,557 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:53:00,762 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:53:00,770 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:53:00,772 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:53:05,973 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:53:05,986 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:53:05,987 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:53:41,707 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:41,710 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,528 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,530 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,579 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,581 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,631 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,632 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,676 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,677 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,728 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,729 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,774 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,775 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,832 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,834 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,880 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,882 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:51,122 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:53:51,142 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:53:51,174 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f6058610>
18:53:51,175 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e5d90> server_hostname='api.openai.com' timeout=5.0
18:53:51,181 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f6061090>
18:53:51,182 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:53:51,183 httpcore.http11 DEBUG send_request_headers.complete
18:53:51,184 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:53:51,184 httpcore.http11 DEBUG send_request_body.complete
18:53:51,184 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:53:51,655 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:53:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ee28c9c26f6477a1f7fbd742e2976d2f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=thxRTcHv4WcPdJuqTdGu.rE6CSxx7Be5tJOUUwFMXnE-1702079631-1-ARJSeC8V96/xLNaEzjJqrqn/Q0xoAgJMrcELjPPbkU0CI10puUWupQotIlvAKil6zi4jA1KAQ6ewh6JBZpZv3is=; path=/; expires=Sat, 09-Dec-23 00:23:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=a9cRWtm88Di0eqdaHTp4y4BS66EudSZZZzOlssMsAMY-1702079631648-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee1eeeaa4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:53:51,667 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:53:51,668 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:53:52,427 httpcore.http11 DEBUG receive_response_body.complete
18:53:52,428 httpcore.http11 DEBUG response_closed.started
18:53:52,429 httpcore.http11 DEBUG response_closed.complete
18:53:52,430 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:53:52,512 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:54:06,458 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:54:06,468 httpcore.connection DEBUG close.started
18:54:06,469 httpcore.connection DEBUG close.complete
18:54:06,469 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:54:06,472 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5eade10>
18:54:06,472 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e5d90> server_hostname='api.openai.com' timeout=5.0
18:54:06,478 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5eade90>
18:54:06,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:54:06,479 httpcore.http11 DEBUG send_request_headers.complete
18:54:06,480 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:54:06,508 httpcore.http11 DEBUG send_request_body.complete
18:54:06,509 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:54:07,298 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:54:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'15'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'79eea58607ea2273c9cbc7676dc585dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee7e79ad3ba5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:54:07,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:54:07,304 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:54:07,306 httpcore.http11 DEBUG receive_response_body.complete
18:54:07,307 httpcore.http11 DEBUG response_closed.started
18:54:07,308 httpcore.http11 DEBUG response_closed.complete
18:54:07,309 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:54:07,310 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:54:07,345 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:54:07,360 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:54:07,364 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ecc610>
18:54:07,364 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e5f40> server_hostname='api.openai.com' timeout=None
18:54:07,370 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ecc590>
18:54:07,371 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:54:07,372 httpcore.http11 DEBUG send_request_headers.complete
18:54:07,372 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:54:07,373 httpcore.http11 DEBUG send_request_body.complete
18:54:07,373 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:54:07,597 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:54:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'412c66d70872091d1f00b7ff86f2589d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yLoFHGZAWxMqZiD0Ku9AIawNZn.sjxp9.uC6buXy_NQ-1702079647-1-AW8zA0kLS/F3M+ByUObm3+6cXLn8lf9xsSuYlHXBS5NGtjbU/3g3bn6nBroqZBsIyC+LPV4cy3qiOSwn8pYXfkc=; path=/; expires=Sat, 09-Dec-23 00:24:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ASop8s9C.97.346TCxsFoC4M2dvULj3I_6brHiRML3g-1702079647592-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee841f484cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:54:07,605 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:54:07,607 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:54:07,609 httpcore.http11 DEBUG receive_response_body.complete
18:54:07,610 httpcore.http11 DEBUG response_closed.started
18:54:07,610 httpcore.http11 DEBUG response_closed.complete
18:54:07,611 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:54:07,646 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1, surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:54:07,659 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:54:07,662 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ed1a90>
18:54:07,663 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e6720> server_hostname='api.openai.com' timeout=None
18:54:07,668 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ed2810>
18:54:07,668 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:54:07,669 httpcore.http11 DEBUG send_request_headers.complete
18:54:07,670 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:54:07,670 httpcore.http11 DEBUG send_request_body.complete
18:54:07,670 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:54:08,569 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:54:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'802'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'73a59ff0790f3ac4a47084f33242f1de'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ovigVkpz1HTHiuqtL9srzDmoTvhTO2BII3yc2rReqxM-1702079648-1-Ae2/H9JZSgVzHGyMa0sI6VRD4uuGamLZ2LpfXlDBZRpLIj3PNRGu3LamzXx0phYheG+n3/klrQpC9SFZUeqYR8s=; path=/; expires=Sat, 09-Dec-23 00:24:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kbnLYr3Z6nPOYndHky9SpbvjWe2poxL8kbUfxBqKX0A-1702079648564-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee85ebe44cc9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:54:08,577 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:54:08,578 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:54:08,578 httpcore.http11 DEBUG receive_response_body.complete
18:54:08,579 httpcore.http11 DEBUG response_closed.started
18:54:08,579 httpcore.http11 DEBUG response_closed.complete
18:54:08,579 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:57:45,844 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:45,850 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,683 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,684 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,733 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,734 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,785 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,786 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,829 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,830 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,879 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,880 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,922 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,923 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,971 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,972 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:47,12 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:47,13 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:50,834 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:57:50,853 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:57:50,898 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6850>
18:57:50,898 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631d90> server_hostname='api.openai.com' timeout=5.0
18:57:50,906 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6d50>
18:57:50,906 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:50,908 httpcore.http11 DEBUG send_request_headers.complete
18:57:50,909 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:50,909 httpcore.http11 DEBUG send_request_body.complete
18:57:50,910 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:51,549 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:57:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'520'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3b96eca2e0f0adc5e3fdb377eb81365'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IvRsw4EWyqP75u9_k8UmWBJe8fgpbv2iaRXRvbRhEDA-1702079871-1-Aa9w8lAwGGkmDaFqWrWqmE0eFzSzF+F5uiEn7yXyRftMbU5JAta9XtSvOpGFdFFcbsEsk9CNvfMcCKK78X3KYro=; path=/; expires=Sat, 09-Dec-23 00:27:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=n804DXmYhBUICp43ibOi_zeYTzFrfGiPs1PQZf8OHwM-1702079871541-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f3f92f4a4cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:51,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:57:51,557 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:52,336 httpcore.http11 DEBUG receive_response_body.complete
18:57:52,337 httpcore.http11 DEBUG response_closed.started
18:57:52,338 httpcore.http11 DEBUG response_closed.complete
18:57:52,339 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:57:52,417 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:58:06,160 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:58:06,170 httpcore.connection DEBUG close.started
18:58:06,170 httpcore.connection DEBUG close.complete
18:58:06,171 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:58:06,173 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6d50>
18:58:06,173 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631d90> server_hostname='api.openai.com' timeout=5.0
18:58:06,180 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6e90>
18:58:06,181 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:06,182 httpcore.http11 DEBUG send_request_headers.complete
18:58:06,182 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:06,215 httpcore.http11 DEBUG send_request_body.complete
18:58:06,215 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:07,24 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:58:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ff25fa70e96caff7bde9b19b211527c7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f458acb23018-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:07,29 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:58:07,29 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:07,30 httpcore.http11 DEBUG receive_response_body.complete
18:58:07,30 httpcore.http11 DEBUG response_closed.started
18:58:07,31 httpcore.http11 DEBUG response_closed.complete
18:58:07,31 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:58:07,32 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:58:07,65 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:07,77 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:07,79 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715fdc50>
18:58:07,80 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631f40> server_hostname='api.openai.com' timeout=None
18:58:07,86 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715fd350>
18:58:07,87 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:07,88 httpcore.http11 DEBUG send_request_headers.complete
18:58:07,88 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:07,88 httpcore.http11 DEBUG send_request_body.complete
18:58:07,89 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:07,313 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:58:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5ed6a9f9d2d30e4543be80a86ff586c3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=G3E8TL4a8hKafqYK81ZWneet7UwuE5ZLoHvnEkF.lZ8-1702079887-1-ARR87A7TjBQy0OAwREz2bL/L0wL1zHCTO+tqJVrG9NjbGT3jzGPYxwq/k/8wqXy6ba6+nNse1egX2lXT95f4G8g=; path=/; expires=Sat, 09-Dec-23 00:28:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=EbKlL5x6HOTuU2zpmvGpktFeB23WTYBRy2pi.o66bKs-1702079887310-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f45e4c384cc3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:07,317 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:07,318 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:07,319 httpcore.http11 DEBUG receive_response_body.complete
18:58:07,319 httpcore.http11 DEBUG response_closed.started
18:58:07,320 httpcore.http11 DEBUG response_closed.complete
18:58:07,320 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:07,359 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:07,372 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:07,375 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8171420190>
18:58:07,375 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172632720> server_hostname='api.openai.com' timeout=None
18:58:07,381 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8171420110>
18:58:07,381 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:07,382 httpcore.http11 DEBUG send_request_headers.complete
18:58:07,382 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:07,383 httpcore.http11 DEBUG send_request_body.complete
18:58:07,383 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:08,332 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:58:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'839'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e001f844add94d9f1ba790550ea41a31'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PRgqPKtcRrmPT5tMYG_bDk3mIJV9E3gZbq2sAnWZ1bc-1702079888-1-AQZaM1buRl1/7SwgVQuU/VaiWgk0F82DBVpwQRP0Zrs3thRYXvc34+dtF3kX3Y/0A1fe35TB0iRgfSbQjVQl6Ug=; path=/; expires=Sat, 09-Dec-23 00:28:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=lQ3QATF2tG1CdKrR0FKlVaOIroZqEoE.x5h20qnM.ss-1702079888327-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f4602cde4ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:08,340 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:08,341 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:08,342 httpcore.http11 DEBUG receive_response_body.complete
18:58:08,342 httpcore.http11 DEBUG response_closed.started
18:58:08,343 httpcore.http11 DEBUG response_closed.complete
18:58:08,343 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:48,906 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:58:48,910 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:58:56,120 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:58:56,134 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:58:56,141 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:01,344 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:01,362 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:01,365 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:06,567 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:06,586 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:06,590 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:11,791 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:11,810 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:11,813 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:19,16 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:19,34 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:19,37 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:24,239 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:24,255 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:24,257 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:29,459 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:29,479 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:29,482 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:34,684 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:34,700 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:34,705 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:39,907 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:39,914 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:59:39,920 httpcore.connection DEBUG close.started
18:59:39,920 httpcore.connection DEBUG close.complete
18:59:39,921 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:59:39,953 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b7010>
18:59:39,953 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631d90> server_hostname='api.openai.com' timeout=5.0
18:59:39,961 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715a0e50>
18:59:39,961 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:59:39,963 httpcore.http11 DEBUG send_request_headers.complete
18:59:39,963 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:59:39,964 httpcore.http11 DEBUG send_request_body.complete
18:59:39,965 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:59:40,477 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:59:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f4e8abc5cdee16d649b4e143ecda98a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f6a2cc7b4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:59:40,482 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:59:40,484 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:59:41,426 httpcore.http11 DEBUG receive_response_body.complete
18:59:41,427 httpcore.http11 DEBUG response_closed.started
18:59:41,427 httpcore.http11 DEBUG response_closed.complete
18:59:41,428 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:59:41,495 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:01:42,181 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:42,184 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,24 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,25 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,67 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,68 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,115 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,116 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,156 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,157 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,204 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,205 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,246 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,247 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,295 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,296 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,336 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,337 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:44,672 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:01:44,687 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:01:44,717 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f13f90>
19:01:44,718 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:01:44,724 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f13ed0>
19:01:44,725 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:01:44,728 httpcore.http11 DEBUG send_request_headers.complete
19:01:44,729 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:01:44,730 httpcore.http11 DEBUG send_request_body.complete
19:01:44,730 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:01:45,369 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:01:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'522'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cd6e9133806440c15d35f02475c3a83d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WVaETcnGkhLhF8PNV19cPKqYMbAZPi5EZyhK5CALbKU-1702080105-1-AfejuIfypisadAKse/Dd3U1Gmq6BtqKTHTR7KzV5/XZ5UWmJWzMVRZKfc9XYBsqrowhZ5vyxQGzZQuogmD1g2Dg=; path=/; expires=Sat, 09-Dec-23 00:31:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OM7OSsBXbfwjVGM4vaibR0NEi1C1qeM3fY99iiT1ZZ0-1702080105364-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f9ae880f3068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:01:45,379 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:01:45,380 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:01:46,158 httpcore.http11 DEBUG receive_response_body.complete
19:01:46,159 httpcore.http11 DEBUG response_closed.started
19:01:46,160 httpcore.http11 DEBUG response_closed.complete
19:01:46,161 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:01:46,247 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:02:00,82 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:02:00,94 httpcore.connection DEBUG close.started
19:02:00,95 httpcore.connection DEBUG close.complete
19:02:00,95 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:02:00,98 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f13ed0>
19:02:00,98 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:02:00,104 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243fcf350>
19:02:00,105 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:02:00,106 httpcore.http11 DEBUG send_request_headers.complete
19:02:00,106 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:02:00,160 httpcore.http11 DEBUG send_request_body.complete
19:02:00,161 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:02:01,39 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:02:01 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'371'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'23cec489945949461f1848e19aa2034f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fa0ead4c4cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:02:01,45 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:02:01,46 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:02:01,47 httpcore.http11 DEBUG receive_response_body.complete
19:02:01,47 httpcore.http11 DEBUG response_closed.started
19:02:01,47 httpcore.http11 DEBUG response_closed.complete
19:02:01,48 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:02:01,49 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:02:01,91 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:02:01,103 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:02:01,105 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d80410>
19:02:01,106 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:02:01,116 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d803d0>
19:02:01,117 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:02:01,118 httpcore.http11 DEBUG send_request_headers.complete
19:02:01,119 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:02:01,119 httpcore.http11 DEBUG send_request_body.complete
19:02:01,120 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:02:01,377 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:02:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fcc9183ac8a21c416d5d0f88fed1b093'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=x8m7i0IsrJIAVIPzhK.sQ9fzVqXJehZ4B4t2LZR5n94-1702080121-1-AaUg6xnIruC9j8M+VcSyHVxfYmRFfWMmBilgKBfe0lv8iUH8G9y7tyumpbHEI8AmhqUgJPxjGkp9t9Vu2new3a8=; path=/; expires=Sat, 09-Dec-23 00:32:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=A65AmvKHgPjBv8Urd0GxGvpA9RWRs2pJn.7iZ1TGXA8-1702080121372-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fa14fe644d0b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:02:01,385 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:02:01,386 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:02:01,387 httpcore.http11 DEBUG receive_response_body.complete
19:02:01,387 httpcore.http11 DEBUG response_closed.started
19:02:01,388 httpcore.http11 DEBUG response_closed.complete
19:02:01,388 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:02:01,423 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:02:01,434 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:02:01,437 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d5fed0>
19:02:01,437 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9e720> server_hostname='api.openai.com' timeout=None
19:02:01,442 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d5fcd0>
19:02:01,443 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:02:01,444 httpcore.http11 DEBUG send_request_headers.complete
19:02:01,444 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:02:01,445 httpcore.http11 DEBUG send_request_body.complete
19:02:01,445 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:02:02,550 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:02:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1014'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ba22ca9eefe7237d9cb5cf93067b8211'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yz8JsX975OWbJv1CWRyPS9VSe494XdcZlsJnK5memO8-1702080122-1-ARYWIvVH7ENMThNzpSWuYg2CAo4g8FuYzSBeqZ6PYhXAvXKz53SqL5mgfeMW8q/vu6YtV8aaU0D8UMhCA5GM4U0=; path=/; expires=Sat, 09-Dec-23 00:32:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=DjpjU9E5MDJWZLYXdzoNAiQoVnXTeO74E3gt7UvXpsQ-1702080122545-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fa170b6d3025-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:02:02,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:02:02,557 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:02:02,558 httpcore.http11 DEBUG receive_response_body.complete
19:02:02,559 httpcore.http11 DEBUG response_closed.started
19:02:02,559 httpcore.http11 DEBUG response_closed.complete
19:02:02,559 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:02:02,582 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:02,586 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:09,794 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:09,808 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:09,812 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:15,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:15,33 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:15,36 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:20,239 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:20,257 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:20,260 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:25,463 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:25,480 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:25,484 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:32,686 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:32,705 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:32,708 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:37,909 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:37,927 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:37,931 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:43,133 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:43,151 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:43,155 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:48,359 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:48,376 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:48,379 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:53,581 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:53,598 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:53,601 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:58,803 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:58,822 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:58,825 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:04,27 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:04,34 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:03:04,40 httpcore.connection DEBUG close.started
19:03:04,40 httpcore.connection DEBUG close.complete
19:03:04,40 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:04,69 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2440e1950>
19:03:04,70 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:04,77 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d8fdd0>
19:03:04,78 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:04,80 httpcore.http11 DEBUG send_request_headers.complete
19:03:04,80 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:04,81 httpcore.http11 DEBUG send_request_body.complete
19:03:04,82 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:04,765 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:04 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'552'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'47945773f414b2f53227d942fb597e27'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fb9e8b694cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:04,769 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:03:04,770 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:05,646 httpcore.http11 DEBUG receive_response_body.complete
19:03:05,647 httpcore.http11 DEBUG response_closed.started
19:03:05,648 httpcore.http11 DEBUG response_closed.complete
19:03:05,649 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:03:05,716 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:03:18,400 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:03:18,406 httpcore.connection DEBUG close.started
19:03:18,407 httpcore.connection DEBUG close.complete
19:03:18,407 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:18,409 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daae10>
19:03:18,410 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:18,416 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daae90>
19:03:18,417 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:18,418 httpcore.http11 DEBUG send_request_headers.complete
19:03:18,418 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:18,442 httpcore.http11 DEBUG send_request_body.complete
19:03:18,443 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:19,161 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:19 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a66179a0c4fc8470c94e186a4cdaac5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fbf81cd74d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:19,166 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:03:19,167 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:19,169 httpcore.http11 DEBUG receive_response_body.complete
19:03:19,169 httpcore.http11 DEBUG response_closed.started
19:03:19,170 httpcore.http11 DEBUG response_closed.complete
19:03:19,171 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:03:19,172 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:03:19,200 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:19,204 httpcore.connection DEBUG close.started
19:03:19,204 httpcore.connection DEBUG close.complete
19:03:19,204 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:19,207 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243da9bd0>
19:03:19,207 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:03:19,214 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daa990>
19:03:19,214 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:19,215 httpcore.http11 DEBUG send_request_headers.complete
19:03:19,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:19,216 httpcore.http11 DEBUG send_request_body.complete
19:03:19,216 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:19,441 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'132'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4d850911e3ab92dc8e2131898e4fd3cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fbfd1ac44d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:19,447 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:19,447 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:19,448 httpcore.http11 DEBUG receive_response_body.complete
19:03:19,449 httpcore.http11 DEBUG response_closed.started
19:03:19,449 httpcore.http11 DEBUG response_closed.complete
19:03:19,450 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:19,482 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:19,493 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:19,496 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fd50>
19:03:19,496 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:03:19,501 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fe10>
19:03:19,501 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:19,503 httpcore.http11 DEBUG send_request_headers.complete
19:03:19,503 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:19,503 httpcore.http11 DEBUG send_request_body.complete
19:03:19,504 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:19,733 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'138'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7af4f9f0af9180030c819aa00c2c97c4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YFaREg4nOIA.DoUyA6p0fLht9BLGrpMUsf.bX1tFE5U-1702080199-1-AdZnRyw64l0yHTxiBzC5sLkrk8ZBoBY5wYaBG0TNQWeBj2pppOUxaZQjWUvbpLcb7zQCRFkfq380c58hWF1BHDo=; path=/; expires=Sat, 09-Dec-23 00:33:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=mlhRjw1nqy4Op7tWJvXGRo01vSJo6cVXOcVD.rYMTac-1702080199729-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fbfeec334cf8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:19,738 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:19,739 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:19,741 httpcore.http11 DEBUG receive_response_body.complete
19:03:19,741 httpcore.http11 DEBUG response_closed.started
19:03:19,742 httpcore.http11 DEBUG response_closed.complete
19:03:19,742 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:19,756 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:19,759 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:24,960 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:24,978 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:24,981 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:30,183 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:30,200 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:30,203 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:35,405 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:35,413 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:03:35,420 httpcore.connection DEBUG close.started
19:03:35,420 httpcore.connection DEBUG close.complete
19:03:35,420 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:35,423 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243da9410>
19:03:35,424 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:35,431 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daaf90>
19:03:35,432 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:35,433 httpcore.http11 DEBUG send_request_headers.complete
19:03:35,434 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:35,434 httpcore.http11 DEBUG send_request_body.complete
19:03:35,435 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:35,879 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1171da99a282cf7ce62b08886bc57a78'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fc6279ae3059-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:35,885 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:03:35,885 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:36,337 httpcore.http11 DEBUG receive_response_body.complete
19:03:36,338 httpcore.http11 DEBUG response_closed.started
19:03:36,338 httpcore.http11 DEBUG response_closed.complete
19:03:36,340 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:03:36,413 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:03:47,981 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:03:47,986 httpcore.connection DEBUG close.started
19:03:47,986 httpcore.connection DEBUG close.complete
19:03:47,986 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:47,989 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2f90>
19:03:47,989 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:47,995 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db3010>
19:03:47,995 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:47,996 httpcore.http11 DEBUG send_request_headers.complete
19:03:47,997 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:48,30 httpcore.http11 DEBUG send_request_body.complete
19:03:48,31 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:48,902 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'40'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'68ec42b20cc7ab24e5f95cabbc8e2f06'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fcb0fb504cf2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:48,909 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:03:48,910 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:48,911 httpcore.http11 DEBUG receive_response_body.complete
19:03:48,912 httpcore.http11 DEBUG response_closed.started
19:03:48,913 httpcore.http11 DEBUG response_closed.complete
19:03:48,914 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:03:48,914 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:03:48,943 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:48,946 httpcore.connection DEBUG close.started
19:03:48,947 httpcore.connection DEBUG close.complete
19:03:48,947 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:48,949 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2110>
19:03:48,950 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:03:48,957 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2190>
19:03:48,958 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:48,959 httpcore.http11 DEBUG send_request_headers.complete
19:03:48,959 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:48,959 httpcore.http11 DEBUG send_request_body.complete
19:03:48,960 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:49,171 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd147926c3c075eb20118aeae2ce65ca4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fcb6fb7c3051-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:49,176 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:49,177 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:49,179 httpcore.http11 DEBUG receive_response_body.complete
19:03:49,180 httpcore.http11 DEBUG response_closed.started
19:03:49,181 httpcore.http11 DEBUG response_closed.complete
19:03:49,182 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:49,218 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:49,221 httpcore.connection DEBUG close.started
19:03:49,221 httpcore.connection DEBUG close.complete
19:03:49,222 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:49,224 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d8c710>
19:03:49,225 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9e720> server_hostname='api.openai.com' timeout=None
19:03:49,231 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7da50>
19:03:49,232 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:49,233 httpcore.http11 DEBUG send_request_headers.complete
19:03:49,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:49,234 httpcore.http11 DEBUG send_request_body.complete
19:03:49,234 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:49,770 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2ef90031b681f7b24d8722b25668f953'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fcb8bd8f4cf8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:49,777 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:49,778 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:49,780 httpcore.http11 DEBUG receive_response_body.complete
19:03:49,781 httpcore.http11 DEBUG response_closed.started
19:03:49,781 httpcore.http11 DEBUG response_closed.complete
19:03:49,782 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:49,798 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:49,801 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:57,3 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:57,21 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:57,28 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:02,230 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:02,248 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:02,251 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:07,453 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:07,471 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:07,475 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:12,677 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:12,693 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:12,697 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:19,898 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:19,915 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:19,918 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:25,120 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:25,137 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:25,142 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:30,344 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:30,362 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:30,366 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:35,568 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:35,574 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:04:35,579 httpcore.connection DEBUG close.started
19:04:35,579 httpcore.connection DEBUG close.complete
19:04:35,580 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:04:35,609 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2f10>
19:04:35,609 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:04:35,617 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2490>
19:04:35,618 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:35,620 httpcore.http11 DEBUG send_request_headers.complete
19:04:35,621 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:35,622 httpcore.http11 DEBUG send_request_body.complete
19:04:35,623 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:36,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bc13ad7bf9a0d19998e061321b92e1dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fddaaca64cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:36,131 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:04:36,132 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:37,157 httpcore.http11 DEBUG receive_response_body.complete
19:04:37,158 httpcore.http11 DEBUG response_closed.started
19:04:37,159 httpcore.http11 DEBUG response_closed.complete
19:04:37,161 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:04:37,228 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:04:49,833 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:04:49,837 httpcore.connection DEBUG close.started
19:04:49,838 httpcore.connection DEBUG close.complete
19:04:49,838 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:04:49,867 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dabe10>
19:04:49,868 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:04:49,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243da9c50>
19:04:49,876 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:49,878 httpcore.http11 DEBUG send_request_headers.complete
19:04:49,878 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:49,903 httpcore.http11 DEBUG send_request_body.complete
19:04:49,904 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:50,643 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:50 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fa17006c87aeb734210acccb7315c945'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe33b8df4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:50,646 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:04:50,646 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:50,647 httpcore.http11 DEBUG receive_response_body.complete
19:04:50,647 httpcore.http11 DEBUG response_closed.started
19:04:50,648 httpcore.http11 DEBUG response_closed.complete
19:04:50,648 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:04:50,649 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:04:50,678 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:04:50,681 httpcore.connection DEBUG close.started
19:04:50,681 httpcore.connection DEBUG close.complete
19:04:50,682 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:04:50,684 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2990>
19:04:50,685 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:04:50,690 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc06d0>
19:04:50,691 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:50,691 httpcore.http11 DEBUG send_request_headers.complete
19:04:50,692 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:50,692 httpcore.http11 DEBUG send_request_body.complete
19:04:50,692 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:50,903 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'70b7b71bd7c0cc2625ed9785264198e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe38dd264cef-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:50,909 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:04:50,910 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:50,911 httpcore.http11 DEBUG receive_response_body.complete
19:04:50,912 httpcore.http11 DEBUG response_closed.started
19:04:50,912 httpcore.http11 DEBUG response_closed.complete
19:04:50,913 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:04:50,946 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:04:50,949 httpcore.connection DEBUG close.started
19:04:50,949 httpcore.connection DEBUG close.complete
19:04:50,950 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:04:50,952 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fe10>
19:04:50,953 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:04:50,957 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fd10>
19:04:50,958 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:50,959 httpcore.http11 DEBUG send_request_headers.complete
19:04:50,959 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:50,959 httpcore.http11 DEBUG send_request_body.complete
19:04:50,960 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:51,189 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'137'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'eadafd5d547cf97835c778ad942fc690'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe3a7cd24cd6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:51,194 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:04:51,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:51,196 httpcore.http11 DEBUG receive_response_body.complete
19:04:51,196 httpcore.http11 DEBUG response_closed.started
19:04:51,197 httpcore.http11 DEBUG response_closed.complete
19:04:51,197 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:04:51,214 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:51,217 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:56,419 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:56,435 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:56,439 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:01,641 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:01,661 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:01,664 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:06,867 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:06,874 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:05:06,879 httpcore.connection DEBUG close.started
19:05:06,880 httpcore.connection DEBUG close.complete
19:05:06,880 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:06,883 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daac10>
19:05:06,883 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:05:06,892 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dab5d0>
19:05:06,892 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:06,894 httpcore.http11 DEBUG send_request_headers.complete
19:05:06,894 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:06,894 httpcore.http11 DEBUG send_request_body.complete
19:05:06,895 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:07,526 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'484'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e4cb57ceb0b846f02c4076695ac13f9f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe9e1d834cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:07,532 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:05:07,532 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:07,894 httpcore.http11 DEBUG receive_response_body.complete
19:05:07,895 httpcore.http11 DEBUG response_closed.started
19:05:07,895 httpcore.http11 DEBUG response_closed.complete
19:05:07,896 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:05:07,962 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:05:19,401 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:05:19,405 httpcore.connection DEBUG close.started
19:05:19,406 httpcore.connection DEBUG close.complete
19:05:19,406 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:19,409 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7f4d0>
19:05:19,409 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:05:19,417 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f0e510>
19:05:19,418 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:19,419 httpcore.http11 DEBUG send_request_headers.complete
19:05:19,419 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:19,451 httpcore.http11 DEBUG send_request_body.complete
19:05:19,452 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:20,337 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:20 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'434'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4f98f20d22b2d1683bedf6b5b69f56f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328feec5de83059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:20,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:05:20,344 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:20,346 httpcore.http11 DEBUG receive_response_body.complete
19:05:20,346 httpcore.http11 DEBUG response_closed.started
19:05:20,347 httpcore.http11 DEBUG response_closed.complete
19:05:20,347 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:05:20,348 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:05:20,376 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it between the first candle and second candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:20,380 httpcore.connection DEBUG close.started
19:05:20,380 httpcore.connection DEBUG close.complete
19:05:20,381 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:20,384 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc06d0>
19:05:20,384 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:05:20,389 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2750>
19:05:20,390 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:20,391 httpcore.http11 DEBUG send_request_headers.complete
19:05:20,391 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:20,391 httpcore.http11 DEBUG send_request_body.complete
19:05:20,392 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:20,618 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2a9b177b774968eda5a755ad3b1f1625'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fef27e484cdb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:20,623 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:20,624 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:20,625 httpcore.http11 DEBUG receive_response_body.complete
19:05:20,626 httpcore.http11 DEBUG response_closed.started
19:05:20,626 httpcore.http11 DEBUG response_closed.complete
19:05:20,627 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:20,662 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it between the first candle and second candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:20,666 httpcore.connection DEBUG close.started
19:05:20,666 httpcore.connection DEBUG close.complete
19:05:20,666 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:20,669 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d5fcd0>
19:05:20,669 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9e720> server_hostname='api.openai.com' timeout=None
19:05:20,675 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db3c90>
19:05:20,675 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:20,676 httpcore.http11 DEBUG send_request_headers.complete
19:05:20,676 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:20,677 httpcore.http11 DEBUG send_request_body.complete
19:05:20,677 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:21,712 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'952'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9a5d8bc83c80f762753f90ca58062994'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fef439413068-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:21,719 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:21,720 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:21,722 httpcore.http11 DEBUG receive_response_body.complete
19:05:21,722 httpcore.http11 DEBUG response_closed.started
19:05:21,723 httpcore.http11 DEBUG response_closed.complete
19:05:21,723 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:22,326 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:22,329 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:29,531 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:29,551 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:29,554 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:34,755 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:34,773 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:34,776 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:39,978 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:39,996 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:40,0 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:45,204 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:45,221 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:45,224 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:52,426 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:52,443 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:52,447 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:57,650 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:57,668 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:57,672 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:02,875 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:02,893 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:02,896 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:08,98 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:08,119 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:08,122 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:13,324 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:13,340 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:13,344 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:18,546 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:18,554 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:18,559 httpcore.connection DEBUG close.started
19:06:18,559 httpcore.connection DEBUG close.complete
19:06:18,560 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:18,590 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd0c10>
19:06:18,590 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:18,598 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd0210>
19:06:18,599 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:18,601 httpcore.http11 DEBUG send_request_headers.complete
19:06:18,601 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:18,602 httpcore.http11 DEBUG send_request_body.complete
19:06:18,602 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:19,186 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'507'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9986ac1178e3429391ead91f39c3c691'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329005e48ec4ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:19,192 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:19,193 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:20,200 httpcore.http11 DEBUG receive_response_body.complete
19:06:20,201 httpcore.http11 DEBUG response_closed.started
19:06:20,202 httpcore.http11 DEBUG response_closed.complete
19:06:20,203 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:20,276 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:32,866 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:32,872 httpcore.connection DEBUG close.started
19:06:32,872 httpcore.connection DEBUG close.complete
19:06:32,872 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:32,875 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd2dd0>
19:06:32,875 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:32,883 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd2e50>
19:06:32,884 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:32,885 httpcore.http11 DEBUG send_request_headers.complete
19:06:32,885 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:32,911 httpcore.http11 DEBUG send_request_body.complete
19:06:32,911 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:33,708 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:33 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'352'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0c56ab70c1a50f4276d3aa4ef9ad6048'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900b78e6c4cc8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:33,710 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:33,710 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:33,711 httpcore.http11 DEBUG receive_response_body.complete
19:06:33,711 httpcore.http11 DEBUG response_closed.started
19:06:33,712 httpcore.http11 DEBUG response_closed.complete
19:06:33,712 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:33,713 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:33,741 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nTo the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:33,745 httpcore.connection DEBUG close.started
19:06:33,745 httpcore.connection DEBUG close.complete
19:06:33,746 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:33,748 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc6d10>
19:06:33,749 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:06:33,755 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc5410>
19:06:33,755 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:33,756 httpcore.http11 DEBUG send_request_headers.complete
19:06:33,756 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:33,757 httpcore.http11 DEBUG send_request_body.complete
19:06:33,757 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:33,976 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'114'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f24d6a64c7bb4aeeb758034f6d20aa68'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900bcfd1b4cf0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:33,982 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:33,983 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:33,984 httpcore.http11 DEBUG receive_response_body.complete
19:06:33,985 httpcore.http11 DEBUG response_closed.started
19:06:33,985 httpcore.http11 DEBUG response_closed.complete
19:06:33,986 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:34,20 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nTo the right.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:34,23 httpcore.connection DEBUG close.started
19:06:34,23 httpcore.connection DEBUG close.complete
19:06:34,24 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:34,26 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fc90>
19:06:34,26 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:06:34,31 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7ead0>
19:06:34,32 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:34,33 httpcore.http11 DEBUG send_request_headers.complete
19:06:34,33 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:34,34 httpcore.http11 DEBUG send_request_body.complete
19:06:34,34 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:34,300 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'149'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0ddfa16731c4ae7b4d27222bc48afb81'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900bebf0c6ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:34,307 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:34,308 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:34,310 httpcore.http11 DEBUG receive_response_body.complete
19:06:34,310 httpcore.http11 DEBUG response_closed.started
19:06:34,311 httpcore.http11 DEBUG response_closed.complete
19:06:34,312 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:34,328 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:34,333 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:39,536 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:39,541 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:39,547 httpcore.connection DEBUG close.started
19:06:39,547 httpcore.connection DEBUG close.complete
19:06:39,548 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:39,550 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc7750>
19:06:39,551 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:39,558 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc6f50>
19:06:39,559 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:39,560 httpcore.http11 DEBUG send_request_headers.complete
19:06:39,560 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:39,561 httpcore.http11 DEBUG send_request_body.complete
19:06:39,561 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:40,15 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0aeb6b288e56d919359f1689fff77ed2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900e14a354d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:40,20 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:40,21 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:40,224 httpcore.http11 DEBUG receive_response_body.complete
19:06:40,225 httpcore.http11 DEBUG response_closed.started
19:06:40,226 httpcore.http11 DEBUG response_closed.complete
19:06:40,227 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:40,296 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:48,11 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:48,17 httpcore.connection DEBUG close.started
19:06:48,17 httpcore.connection DEBUG close.complete
19:06:48,17 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:48,20 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc1490>
19:06:48,20 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:48,26 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc1850>
19:06:48,26 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:48,27 httpcore.http11 DEBUG send_request_headers.complete
19:06:48,27 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:48,47 httpcore.http11 DEBUG send_request_body.complete
19:06:48,48 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:48,924 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f18a096a7e1711fdce19e6c6c6222b0b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832901162afe4cc2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:48,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:48,929 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:48,931 httpcore.http11 DEBUG receive_response_body.complete
19:06:48,931 httpcore.http11 DEBUG response_closed.started
19:06:48,932 httpcore.http11 DEBUG response_closed.complete
19:06:48,933 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:48,934 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:48,964 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:48,967 httpcore.connection DEBUG close.started
19:06:48,967 httpcore.connection DEBUG close.complete
19:06:48,967 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:48,970 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd0950>
19:06:48,970 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:06:48,975 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd1e50>
19:06:48,976 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:48,977 httpcore.http11 DEBUG send_request_headers.complete
19:06:48,977 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:48,978 httpcore.http11 DEBUG send_request_body.complete
19:06:48,978 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:49,196 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'682b7add316cb684eca57e0761a74c7f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329011c1c143074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:49,202 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:49,203 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:49,204 httpcore.http11 DEBUG receive_response_body.complete
19:06:49,205 httpcore.http11 DEBUG response_closed.started
19:06:49,205 httpcore.http11 DEBUG response_closed.complete
19:06:49,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:49,222 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:49,225 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:54,427 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:54,434 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:54,438 httpcore.connection DEBUG close.started
19:06:54,438 httpcore.connection DEBUG close.complete
19:06:54,439 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:54,441 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc3a10>
19:06:54,442 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:54,447 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc38d0>
19:06:54,447 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:54,448 httpcore.http11 DEBUG send_request_headers.complete
19:06:54,449 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:54,449 httpcore.http11 DEBUG send_request_body.complete
19:06:54,450 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:54,894 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:54 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'361'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7f9da588ced1feb5a11bfc8e0b8aec1e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329013e4f763b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:54,898 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:54,899 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:55,183 httpcore.http11 DEBUG receive_response_body.complete
19:06:55,184 httpcore.http11 DEBUG response_closed.started
19:06:55,184 httpcore.http11 DEBUG response_closed.complete
19:06:55,185 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:55,255 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:07:02,917 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:07:02,923 httpcore.connection DEBUG close.started
19:07:02,923 httpcore.connection DEBUG close.complete
19:07:02,924 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:07:02,926 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2cd0>
19:07:02,926 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:07:02,933 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2450>
19:07:02,934 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:02,936 httpcore.http11 DEBUG send_request_headers.complete
19:07:02,937 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:02,961 httpcore.http11 DEBUG send_request_body.complete
19:07:02,962 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:03,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:07:03 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'336'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0abb778d97b7ab6f4b7a6690c7fc2d9b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832901735e784d17-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:03,826 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:07:03,826 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:03,827 httpcore.http11 DEBUG receive_response_body.complete
19:07:03,828 httpcore.http11 DEBUG response_closed.started
19:07:03,828 httpcore.http11 DEBUG response_closed.complete
19:07:03,829 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:07:03,829 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:07:03,860 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:07:03,863 httpcore.connection DEBUG close.started
19:07:03,864 httpcore.connection DEBUG close.complete
19:07:03,864 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:07:03,867 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daaa90>
19:07:03,867 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:07:03,871 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dab110>
19:07:03,872 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:03,873 httpcore.http11 DEBUG send_request_headers.complete
19:07:03,873 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:03,873 httpcore.http11 DEBUG send_request_body.complete
19:07:03,874 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:04,98 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:07:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'560151d52e6f22bc122fc976618478f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329017939f93021-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:04,102 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:07:04,103 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:04,104 httpcore.http11 DEBUG receive_response_body.complete
19:07:04,105 httpcore.http11 DEBUG response_closed.started
19:07:04,106 httpcore.http11 DEBUG response_closed.complete
19:07:04,107 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:07:04,124 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:07:04,128 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:09,330 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:07:09,349 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:07:09,353 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:14,556 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:07:14,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:07:14,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:19,783 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:57:59,805 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:57:59,808 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,645 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,646 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,687 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,688 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,736 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,737 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,777 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,778 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,825 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,826 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,867 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,868 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,916 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,917 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:00,957 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:00,958 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:01,936 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:58:01,960 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:58:01,991 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d92a1210>
17:58:01,992 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe4d9b25f40> server_hostname='api.openai.com' timeout=5.0
17:58:02,2 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe4d92a1790>
17:58:02,3 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:58:02,4 httpcore.http11 DEBUG send_request_headers.complete
17:58:02,4 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:58:02,5 httpcore.http11 DEBUG send_request_body.complete
17:58:02,5 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:58:02,121 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Sun, 10 Dec 2023 22:58:02 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'301'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'6b9dd969f554d62dd7c38779e16b3186'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zRASVXUDfI9b82JFgDgTP4yp0XxepOTHvgd1BUgb5Fs-1702249082-1-AT+wBGFq5TDPxJp8fbNyFiBVVhrYDHOVSBDqGrSGmaiOxgyoea8mW1+afzgla8Uj0e/0xEZ1Be58yoBSQ3NxJSI=; path=/; expires=Sun, 10-Dec-23 23:28:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fDHMsjGlcCJh_Q1Ax5TCq3DGWyFafgmZaJ_GZkCjMrc-1702249082116-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339171a88f93b9a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:58:02,131 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 401 Unauthorized"
17:58:02,131 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:58:02,132 httpcore.http11 DEBUG receive_response_body.complete
17:58:02,132 httpcore.http11 DEBUG response_closed.started
17:58:02,133 httpcore.http11 DEBUG response_closed.complete
17:58:02,133 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "401 Unauthorized"
18:01:12,977 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:12,981 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,789 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,790 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,837 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,838 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,886 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,887 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,929 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,930 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:13,988 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:13,989 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:14,30 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:14,31 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:14,79 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:14,80 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:14,121 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:01:14,122 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:01:15,723 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:01:15,747 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:01:15,781 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673810>
18:01:15,782 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fde20> server_hostname='api.openai.com' timeout=5.0
18:01:15,789 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673d10>
18:01:15,790 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:15,792 httpcore.http11 DEBUG send_request_headers.complete
18:01:15,792 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:15,793 httpcore.http11 DEBUG send_request_body.complete
18:01:15,793 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:16,337 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:01:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'13a21ea9b957e5f9ba5cc08774ef8e1c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_PkASAQaztgStxMVOD6LEfjyEN_pQiOfVHwtHaRHn4A-1702249276-1-AaeCGXCsfwnpBuOpj5BsunlqwKVJ4Wxe4AWLAnQ25/yCWj8zLZslFPNd23n2hzACm1cMYS3WTPYPMLA4SmW+MNs=; path=/; expires=Sun, 10-Dec-23 23:31:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=TDwxJAVHwfOnl.i.1mFxOac4V1ZDw7Je8KZGz_8XrW8-1702249276329-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391bd5ba234cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:16,344 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:01:16,345 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:01:17,129 httpcore.http11 DEBUG receive_response_body.complete
18:01:17,130 httpcore.http11 DEBUG response_closed.started
18:01:17,130 httpcore.http11 DEBUG response_closed.complete
18:01:17,131 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:01:17,212 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:01:30,933 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:01:30,943 httpcore.connection DEBUG close.started
18:01:30,943 httpcore.connection DEBUG close.complete
18:01:30,944 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:01:30,946 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68acaeecd0>
18:01:30,946 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fde20> server_hostname='api.openai.com' timeout=5.0
18:01:30,952 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673f10>
18:01:30,953 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:30,954 httpcore.http11 DEBUG send_request_headers.complete
18:01:30,954 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:30,976 httpcore.http11 DEBUG send_request_body.complete
18:01:30,977 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:31,899 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:01:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'404'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3348cb32091b7521a81be7bf7757f52d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391c347ce83b69-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:31,904 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:01:31,905 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:01:31,906 httpcore.http11 DEBUG receive_response_body.complete
18:01:31,906 httpcore.http11 DEBUG response_closed.started
18:01:31,907 httpcore.http11 DEBUG response_closed.complete
18:01:31,907 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:01:31,908 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:01:31,948 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:01:31,960 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:01:31,963 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6d42d0>
18:01:31,963 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fdfd0> server_hostname='api.openai.com' timeout=None
18:01:31,969 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6d4290>
18:01:31,969 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:31,970 httpcore.http11 DEBUG send_request_headers.complete
18:01:31,971 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:31,971 httpcore.http11 DEBUG send_request_body.complete
18:01:31,971 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:32,466 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:01:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'288'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'76be7950cd2c3dad305b51b741b6f3e4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SG1Fw8cOCJch9u3E4DwQmUXJAm8Xyt0fw5HMPQR.Zkk-1702249292-1-AcqKbTjuMeSOWFP1P7AJsoUwFv47E03sqT6gBxEen2RpINLv9vjlTiPi4hwMgY6LXdIha4YNCi4TXW0HazIEsDQ=; path=/; expires=Sun, 10-Dec-23 23:31:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rGL0sbEaUyYfGufGhvasF._kxzdAjqIoN5rugWUsiHc-1702249292463-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391c3ad8673b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:32,472 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:01:32,473 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:01:32,474 httpcore.http11 DEBUG receive_response_body.complete
18:01:32,475 httpcore.http11 DEBUG response_closed.started
18:01:32,475 httpcore.http11 DEBUG response_closed.complete
18:01:32,476 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:01:32,514 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:01:32,524 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:01:32,527 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6dc410>
18:01:32,527 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fe7b0> server_hostname='api.openai.com' timeout=None
18:01:32,536 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6de850>
18:01:32,536 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:32,538 httpcore.http11 DEBUG send_request_headers.complete
18:01:32,538 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:32,539 httpcore.http11 DEBUG send_request_body.complete
18:01:32,539 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:33,187 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:01:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'544'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3d766cdec300c046ae1f73f727f7d290'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_x2viZhoF9IFeKtUnuJYsGLarmFjksDchRGQgG1Nojk-1702249293-1-Ab5aPKH6D0C1RIYzQ6B5Syi7lVYmKcP2YqSqA9vJLwrcYTQSerz/bkkh8YbKIOcUZKX6fcCSLaP8eDRmRXArhl0=; path=/; expires=Sun, 10-Dec-23 23:31:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=N8825IhUlGj8BiUyyCLYXRt0nxLbZVuR83iaZ_bcA0M-1702249293183-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391c3e5e154d0d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:33,194 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:01:33,195 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:01:33,196 httpcore.http11 DEBUG receive_response_body.complete
18:01:33,197 httpcore.http11 DEBUG response_closed.started
18:01:33,197 httpcore.http11 DEBUG response_closed.complete
18:01:33,198 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:01:33,219 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:33,261 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:38,972 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:38,990 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:38,995 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:41,997 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:42,15 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:42,19 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:45,21 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:45,40 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:45,44 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:48,447 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:48,468 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:48,471 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:54,173 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:54,193 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:54,197 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:57,599 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:57,616 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:01:57,620 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:02:01,24 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:02:01,31 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:02:01,38 httpcore.connection DEBUG close.started
18:02:01,39 httpcore.connection DEBUG close.complete
18:02:01,40 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:02:01,42 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673f10>
18:02:01,43 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fde20> server_hostname='api.openai.com' timeout=5.0
18:02:01,51 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac673e10>
18:02:01,52 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:02:01,53 httpcore.http11 DEBUG send_request_headers.complete
18:02:01,54 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:02:01,54 httpcore.http11 DEBUG send_request_body.complete
18:02:01,55 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:02:01,831 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:02:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'650'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f30394fa62cc8a5670d0364fdbe212bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391cf099c33bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:02:01,835 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:02:01,836 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:02:02,952 httpcore.http11 DEBUG receive_response_body.complete
18:02:02,952 httpcore.http11 DEBUG response_closed.started
18:02:02,953 httpcore.http11 DEBUG response_closed.complete
18:02:02,953 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:02:03,18 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:02:15,657 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:02:15,661 httpcore.connection DEBUG close.started
18:02:15,662 httpcore.connection DEBUG close.complete
18:02:15,662 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:02:15,664 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac5061d0>
18:02:15,665 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fde20> server_hostname='api.openai.com' timeout=5.0
18:02:15,673 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac506250>
18:02:15,673 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:02:15,674 httpcore.http11 DEBUG send_request_headers.complete
18:02:15,675 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:02:15,684 httpcore.http11 DEBUG send_request_body.complete
18:02:15,685 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:02:16,502 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:02:16 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b539798969e852940532c14c0625ff22'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391d4bfff83b94-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:02:16,507 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:02:16,507 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:02:16,508 httpcore.http11 DEBUG receive_response_body.complete
18:02:16,509 httpcore.http11 DEBUG response_closed.started
18:02:16,509 httpcore.http11 DEBUG response_closed.complete
18:02:16,510 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:02:16,511 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:02:16,545 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:02:16,548 httpcore.connection DEBUG close.started
18:02:16,549 httpcore.connection DEBUG close.complete
18:02:16,549 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:02:16,579 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6d4250>
18:02:16,579 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fdfd0> server_hostname='api.openai.com' timeout=None
18:02:16,588 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac6d41d0>
18:02:16,589 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:02:16,591 httpcore.http11 DEBUG send_request_headers.complete
18:02:16,592 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:02:16,593 httpcore.http11 DEBUG send_request_body.complete
18:02:16,594 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:02:16,947 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:02:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'252'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0e0757184eca8408870abbbae71daf16'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391d51b86d4cd9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:02:16,954 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:02:16,954 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:02:16,955 httpcore.http11 DEBUG receive_response_body.complete
18:02:16,956 httpcore.http11 DEBUG response_closed.started
18:02:16,956 httpcore.http11 DEBUG response_closed.complete
18:02:16,956 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:02:16,988 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location, or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:02:16,999 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:02:17,1 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac505890>
18:02:17,2 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f68ac6fdf40> server_hostname='api.openai.com' timeout=None
18:02:17,9 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f68ac505790>
18:02:17,9 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:02:17,11 httpcore.http11 DEBUG send_request_headers.complete
18:02:17,11 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:02:17,12 httpcore.http11 DEBUG send_request_body.complete
18:02:17,12 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:02:17,415 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:02:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'314'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ca83690eb6e9408ebc62ef63d18deda7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=HyelhPJsiodedacVgfsY5gbX1gDuIuL0k.diFjBmrb8-1702249337-1-AYmKQe6BrN7deZcXrhvj/29n/Y3J/aC3v95xYA1pAqBdHzaH3Q8TTPsHIHzt3DMHWRW6hoTR0dancbHcO6S8EA4=; path=/; expires=Sun, 10-Dec-23 23:32:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=xZSzJ38IPp7gfdB.6wiZA6qJJ_d4zENPoDDGaLXbiKU-1702249337412-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83391d545ade3b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:02:17,421 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:02:17,421 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:02:17,423 httpcore.http11 DEBUG receive_response_body.complete
18:02:17,423 httpcore.http11 DEBUG response_closed.started
18:02:17,424 httpcore.http11 DEBUG response_closed.complete
18:02:17,425 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:07:52,176 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:52,181 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,3 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,5 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,50 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,51 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,102 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,103 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,145 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,147 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,197 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,198 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,242 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,243 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,294 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,295 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:53,339 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:07:53,340 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:07:54,186 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:07:54,203 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:07:54,235 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f8d9310>
18:07:54,236 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:07:54,243 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f8dff10>
18:07:54,245 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:07:54,247 httpcore.http11 DEBUG send_request_headers.complete
18:07:54,248 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:07:54,249 httpcore.http11 DEBUG send_request_body.complete
18:07:54,249 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:07:54,764 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:07:54 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'405'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'79c3ed4270e2636767015fcb3ab2d58f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cVf_jErXT2PAKJ5Gri8bvJ8FDWJUO1sKGfT09AVrZVM-1702249674-1-AR+g0WR6eVVvO5PZQXDF8POAu+51QPiQXFFHUIDursPAWKGZl6pvrT/DMe2co4Y6G79pfRWHK3d1fUfUnwEdmm4=; path=/; expires=Sun, 10-Dec-23 23:37:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=n1NHhX6ivKLr54k38h7BMF_3t1EPRwBm.nG5znHPcK8-1702249674758-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339259009024d1d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:07:54,773 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:07:54,774 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:07:55,616 httpcore.http11 DEBUG receive_response_body.complete
18:07:55,618 httpcore.http11 DEBUG response_closed.started
18:07:55,618 httpcore.http11 DEBUG response_closed.complete
18:07:55,620 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:07:55,707 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:08:09,478 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:08:09,487 httpcore.connection DEBUG close.started
18:08:09,487 httpcore.connection DEBUG close.complete
18:08:09,488 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:08:09,490 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f8df790>
18:08:09,491 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:08:09,495 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f8df7d0>
18:08:09,496 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:09,497 httpcore.http11 DEBUG send_request_headers.complete
18:08:09,497 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:09,523 httpcore.http11 DEBUG send_request_body.complete
18:08:09,523 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:10,428 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:10 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'493'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cfa0635d9db78a82706c9f664e13fe4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833925ef5f613b9f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:10,433 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:08:10,434 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:10,436 httpcore.http11 DEBUG receive_response_body.complete
18:08:10,436 httpcore.http11 DEBUG response_closed.started
18:08:10,437 httpcore.http11 DEBUG response_closed.complete
18:08:10,438 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:08:10,439 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:08:10,474 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:08:10,485 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:08:10,487 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744490>
18:08:10,488 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969fd0> server_hostname='api.openai.com' timeout=None
18:08:10,495 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744450>
18:08:10,495 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:10,497 httpcore.http11 DEBUG send_request_headers.complete
18:08:10,497 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:10,498 httpcore.http11 DEBUG send_request_body.complete
18:08:10,498 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:10,698 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'97'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'15a31ad29b7ac9294640957e2e2f2cd6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PU9Td4dTzT35uM7oyNU5RjpPlMZMn85RECbc2lMYYFw-1702249690-1-AT9Nc/F4zrXFpSrXCRBY3NvIFGC5v3FnvK/1tVL8Si5wQehQTMZHOcBK0kvsw+COSPKS6OAE9fy4x+u1gsJLJQM=; path=/; expires=Sun, 10-Dec-23 23:38:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=p5wCJ2pqRuQJym2M0wwlGmDfw18CpmxgXIr.G8EjEpk-1702249690693-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833925f598bc4d01-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:10,705 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:08:10,706 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:10,708 httpcore.http11 DEBUG receive_response_body.complete
18:08:10,709 httpcore.http11 DEBUG response_closed.started
18:08:10,710 httpcore.http11 DEBUG response_closed.complete
18:08:10,710 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:08:10,745 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:08:10,756 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:08:10,758 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744dd0>
18:08:10,759 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f96a7b0> server_hostname='api.openai.com' timeout=None
18:08:10,764 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f7462d0>
18:08:10,765 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:10,766 httpcore.http11 DEBUG send_request_headers.complete
18:08:10,766 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:10,767 httpcore.http11 DEBUG send_request_body.complete
18:08:10,767 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:11,134 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'266'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'826a6feadf67c0824e8a7c7b6b136327'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Z8lZt0gxcsGWenuSHuAUV1KKAnM2zhTxAwecTH53ECs-1702249691-1-AdzylJktaiW2TLSAJxTVPSOQ2ATr/P5aK7vMlEcHSMdTTnJVenqsSGYkBBYncYH3Kdsg7ZaWIZk4/IVejuA89fA=; path=/; expires=Sun, 10-Dec-23 23:38:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=B1QVvNjpvG_3ENhsG3maU2n4np_B36glSji.BWdouOM-1702249691130-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833925f74c643b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:11,143 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:08:11,144 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:11,146 httpcore.http11 DEBUG receive_response_body.complete
18:08:11,146 httpcore.http11 DEBUG response_closed.started
18:08:11,146 httpcore.http11 DEBUG response_closed.complete
18:08:11,147 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:08:11,165 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:11,169 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:16,877 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:16,891 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:16,895 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:20,897 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:20,913 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:20,916 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:23,918 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:23,938 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:23,942 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:27,346 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:27,362 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:27,366 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:33,68 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:33,90 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:33,96 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:36,500 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:36,519 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:08:36,522 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:08:40,724 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:08:40,731 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:08:40,739 httpcore.connection DEBUG close.started
18:08:40,739 httpcore.connection DEBUG close.complete
18:08:40,739 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:08:40,742 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5fb5f950>
18:08:40,742 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:08:40,748 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f92c590>
18:08:40,749 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:40,750 httpcore.http11 DEBUG send_request_headers.complete
18:08:40,750 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:40,751 httpcore.http11 DEBUG send_request_body.complete
18:08:40,751 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:41,432 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:41 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'566'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f8691637c734e716f3f1895bf4ee2924'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833926b2b9063045-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:41,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:08:41,435 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:42,422 httpcore.http11 DEBUG receive_response_body.complete
18:08:42,423 httpcore.http11 DEBUG response_closed.started
18:08:42,423 httpcore.http11 DEBUG response_closed.complete
18:08:42,424 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:08:42,491 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:08:55,41 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:08:55,46 httpcore.connection DEBUG close.started
18:08:55,47 httpcore.connection DEBUG close.complete
18:08:55,47 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:08:55,78 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772b10>
18:08:55,78 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:08:55,86 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772b90>
18:08:55,86 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:55,88 httpcore.http11 DEBUG send_request_headers.complete
18:08:55,89 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:55,103 httpcore.http11 DEBUG send_request_body.complete
18:08:55,104 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:55,997 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:55 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'381'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'67956e25e283587b6b6f815e4f465584'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339270c4cc06ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:56,0 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:08:56,1 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:56,2 httpcore.http11 DEBUG receive_response_body.complete
18:08:56,2 httpcore.http11 DEBUG response_closed.started
18:08:56,3 httpcore.http11 DEBUG response_closed.complete
18:08:56,3 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:08:56,4 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:08:56,38 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:08:56,43 httpcore.connection DEBUG close.started
18:08:56,44 httpcore.connection DEBUG close.complete
18:08:56,45 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:08:56,47 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744450>
18:08:56,48 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969fd0> server_hostname='api.openai.com' timeout=None
18:08:56,54 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f744590>
18:08:56,54 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:56,55 httpcore.http11 DEBUG send_request_headers.complete
18:08:56,55 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:56,56 httpcore.http11 DEBUG send_request_body.complete
18:08:56,56 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:56,421 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'271'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1157ee10f7993910953db80f46d2b7be'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339271259e93b70-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:56,428 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:08:56,429 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:56,431 httpcore.http11 DEBUG receive_response_body.complete
18:08:56,432 httpcore.http11 DEBUG response_closed.started
18:08:56,433 httpcore.http11 DEBUG response_closed.complete
18:08:56,434 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:08:56,441 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:08:56,444 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:08:56,446 httpcore.http11 DEBUG send_request_headers.complete
18:08:56,446 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:08:56,446 httpcore.http11 DEBUG send_request_body.complete
18:08:56,447 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:08:56,951 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:08:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'413'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e379fadd4ab427cd58baca90680ecdb6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392714cedc6ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:08:56,955 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:08:56,956 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:08:58,71 httpcore.http11 DEBUG receive_response_body.complete
18:08:58,72 httpcore.http11 DEBUG response_closed.started
18:08:58,72 httpcore.http11 DEBUG response_closed.complete
18:08:58,73 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:08:58,143 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:09:10,784 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:09:10,792 httpcore.connection DEBUG close.started
18:09:10,793 httpcore.connection DEBUG close.complete
18:09:10,793 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:09:10,796 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f771c10>
18:09:10,796 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:09:10,812 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772390>
18:09:10,813 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:10,815 httpcore.http11 DEBUG send_request_headers.complete
18:09:10,815 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:10,836 httpcore.http11 DEBUG send_request_body.complete
18:09:10,836 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:11,656 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:11 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'6'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'358'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3beb33c0af10b65c68e494f7ee4855ba'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339276e9a644cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:11,661 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:09:11,661 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:11,663 httpcore.http11 DEBUG receive_response_body.complete
18:09:11,663 httpcore.http11 DEBUG response_closed.started
18:09:11,664 httpcore.http11 DEBUG response_closed.complete
18:09:11,665 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:09:11,666 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:09:11,698 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNope.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:11,713 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:09:11,716 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f781fd0>
18:09:11,717 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969f40> server_hostname='api.openai.com' timeout=None
18:09:11,722 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f782890>
18:09:11,722 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:11,723 httpcore.http11 DEBUG send_request_headers.complete
18:09:11,723 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:11,724 httpcore.http11 DEBUG send_request_body.complete
18:09:11,724 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:12,102 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'263'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8cf3225dd05b5f288be87ac0d50dcecb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IEY134K2lQWXxSte6z9gsejg5.Mtdxo8vnqY0oMLy0o-1702249752-1-AXzePmROvRCdo1r+Yszv/3ujA0XdaqyX4NpnPUGQAeochSYamcY/0iAtFtRLcPFL2+knuozt4p2Rb1SQf+BSdcs=; path=/; expires=Sun, 10-Dec-23 23:39:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=XBUX6Y8JgE2a2KkbijoRxhwrf8GgCyRFg59YnfTwCZ8-1702249752097-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392774498e3b8d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:12,111 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:12,112 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:12,114 httpcore.http11 DEBUG receive_response_body.complete
18:09:12,114 httpcore.http11 DEBUG response_closed.started
18:09:12,114 httpcore.http11 DEBUG response_closed.complete
18:09:12,115 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:12,147 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNope.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:12,150 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:12,151 httpcore.http11 DEBUG send_request_headers.complete
18:09:12,152 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:12,152 httpcore.http11 DEBUG send_request_body.complete
18:09:12,152 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:12,593 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'347'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7439ac1831bfacdfc28a56df3ab21c39'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392776fd963b8d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:12,599 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:12,599 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:12,601 httpcore.http11 DEBUG receive_response_body.complete
18:09:12,601 httpcore.http11 DEBUG response_closed.started
18:09:12,602 httpcore.http11 DEBUG response_closed.complete
18:09:12,602 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:12,612 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:09:12,615 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:12,616 httpcore.http11 DEBUG send_request_headers.complete
18:09:12,617 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:12,617 httpcore.http11 DEBUG send_request_body.complete
18:09:12,617 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:13,69 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:13 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'387'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'670341e1ced7d1615694071e4ff7580b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392779d9d04cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:13,74 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:09:13,75 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:13,979 httpcore.http11 DEBUG receive_response_body.complete
18:09:13,980 httpcore.http11 DEBUG response_closed.started
18:09:13,981 httpcore.http11 DEBUG response_closed.complete
18:09:13,981 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:09:14,52 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:09:25,413 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:09:25,417 httpcore.connection DEBUG close.started
18:09:25,418 httpcore.connection DEBUG close.complete
18:09:25,419 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:09:25,421 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f7734d0>
18:09:25,421 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:09:25,426 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f773cd0>
18:09:25,427 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:25,428 httpcore.http11 DEBUG send_request_headers.complete
18:09:25,428 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:25,452 httpcore.http11 DEBUG send_request_body.complete
18:09:25,453 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:49,553 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:49 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'23705'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'96ce27e9c230ee9973002e799c9de4f3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833927c9e9ba4cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:49,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:09:49,558 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:49,559 httpcore.http11 DEBUG receive_response_body.complete
18:09:49,559 httpcore.http11 DEBUG response_closed.started
18:09:49,560 httpcore.http11 DEBUG response_closed.complete
18:09:49,560 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:09:49,561 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:09:49,590 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhich way should I move? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove left.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:09:49,594 httpcore.connection DEBUG close.started
18:09:49,594 httpcore.connection DEBUG close.complete
18:09:49,595 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:09:49,597 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772ad0>
18:09:49,597 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969f40> server_hostname='api.openai.com' timeout=None
18:09:49,602 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772b10>
18:09:49,603 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:49,604 httpcore.http11 DEBUG send_request_headers.complete
18:09:49,604 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:49,604 httpcore.http11 DEBUG send_request_body.complete
18:09:49,605 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:49,806 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ffee0b4e210f9cbb0fb52135da611834'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833928610af53b82-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:49,812 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:09:49,814 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:49,816 httpcore.http11 DEBUG receive_response_body.complete
18:09:49,816 httpcore.http11 DEBUG response_closed.started
18:09:49,817 httpcore.http11 DEBUG response_closed.complete
18:09:49,818 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:09:49,833 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:09:49,838 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:09:53,241 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:09:53,248 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:09:53,253 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:09:53,254 httpcore.http11 DEBUG send_request_headers.complete
18:09:53,254 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:09:53,254 httpcore.http11 DEBUG send_request_body.complete
18:09:53,255 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:09:53,828 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:09:53 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c4c71f03a74302f8ba46a4655fe92a15'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392877d9004cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:09:53,833 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:09:53,834 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:09:54,302 httpcore.http11 DEBUG receive_response_body.complete
18:09:54,303 httpcore.http11 DEBUG response_closed.started
18:09:54,303 httpcore.http11 DEBUG response_closed.complete
18:09:54,304 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:09:54,371 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:10:03,643 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:10:03,647 httpcore.connection DEBUG close.started
18:10:03,648 httpcore.connection DEBUG close.complete
18:10:03,648 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:10:03,677 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f78b8d0>
18:10:03,678 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:10:03,685 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f78b950>
18:10:03,686 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:03,688 httpcore.http11 DEBUG send_request_headers.complete
18:10:03,688 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:03,712 httpcore.http11 DEBUG send_request_body.complete
18:10:03,712 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:04,742 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:04 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'360'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3e9c0d48eef0da4f05f9990a9e08764'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833928b90f114cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:04,748 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:10:04,749 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:04,750 httpcore.http11 DEBUG receive_response_body.complete
18:10:04,750 httpcore.http11 DEBUG response_closed.started
18:10:04,750 httpcore.http11 DEBUG response_closed.complete
18:10:04,751 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:10:04,751 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:10:04,778 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:10:04,781 httpcore.connection DEBUG close.started
18:10:04,782 httpcore.connection DEBUG close.complete
18:10:04,782 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:10:04,784 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f792c50>
18:10:04,785 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969f40> server_hostname='api.openai.com' timeout=None
18:10:04,790 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f792cd0>
18:10:04,790 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:04,791 httpcore.http11 DEBUG send_request_headers.complete
18:10:04,791 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:04,792 httpcore.http11 DEBUG send_request_body.complete
18:10:04,792 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:05,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'143'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd3d097f75f55bf6a993287e4b73bd03d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833928bffac56ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:05,28 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:10:05,28 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:05,30 httpcore.http11 DEBUG receive_response_body.complete
18:10:05,30 httpcore.http11 DEBUG response_closed.started
18:10:05,31 httpcore.http11 DEBUG response_closed.complete
18:10:05,31 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:10:05,39 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:10:05,43 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:05,44 httpcore.http11 DEBUG send_request_headers.complete
18:10:05,44 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:05,44 httpcore.http11 DEBUG send_request_body.complete
18:10:05,45 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:05,680 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'03bd15dea41dfa04da6f92cf8aa00337'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833928c18fe34cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:05,683 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:10:05,684 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:06,617 httpcore.http11 DEBUG receive_response_body.complete
18:10:06,618 httpcore.http11 DEBUG response_closed.started
18:10:06,618 httpcore.http11 DEBUG response_closed.complete
18:10:06,619 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:10:06,687 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:10:18,129 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:10:18,133 httpcore.connection DEBUG close.started
18:10:18,134 httpcore.connection DEBUG close.complete
18:10:18,134 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:10:18,136 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f788690>
18:10:18,137 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969e20> server_hostname='api.openai.com' timeout=5.0
18:10:18,143 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f78bc50>
18:10:18,144 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:18,145 httpcore.http11 DEBUG send_request_headers.complete
18:10:18,145 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:18,165 httpcore.http11 DEBUG send_request_body.complete
18:10:18,166 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:18,965 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'27'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1462df083379627bfe48314bcbda90e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833929136888304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:18,970 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:10:18,971 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:18,972 httpcore.http11 DEBUG receive_response_body.complete
18:10:18,973 httpcore.http11 DEBUG response_closed.started
18:10:18,974 httpcore.http11 DEBUG response_closed.complete
18:10:18,974 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:10:18,974 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:10:19,1 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhich way should I move? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes, it's a good location.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:10:19,4 httpcore.connection DEBUG close.started
18:10:19,5 httpcore.connection DEBUG close.complete
18:10:19,5 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:10:19,8 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f773f10>
18:10:19,8 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4d5f969f40> server_hostname='api.openai.com' timeout=None
18:10:19,15 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4d5f772d50>
18:10:19,15 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:19,16 httpcore.http11 DEBUG send_request_headers.complete
18:10:19,17 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:19,17 httpcore.http11 DEBUG send_request_body.complete
18:10:19,17 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:19,252 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'942ba2346a269c3de98f9555b3db5935'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392918d8404cfb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:19,259 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:10:19,260 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:19,262 httpcore.http11 DEBUG receive_response_body.complete
18:10:19,263 httpcore.http11 DEBUG response_closed.started
18:10:19,264 httpcore.http11 DEBUG response_closed.complete
18:10:19,264 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:10:19,272 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:10:19,276 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:10:19,277 httpcore.http11 DEBUG send_request_headers.complete
18:10:19,277 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:10:19,277 httpcore.http11 DEBUG send_request_body.complete
18:10:19,278 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:10:19,747 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:10:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'346de604f5815a16c141006342e95aa8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339291a7bfa304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:10:19,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:10:19,752 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:10:20,683 httpcore.http11 DEBUG receive_response_body.complete
18:10:20,684 httpcore.http11 DEBUG response_closed.started
18:10:20,685 httpcore.http11 DEBUG response_closed.complete
18:10:20,686 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:10:20,754 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:14:52,683 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:52,688 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,528 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,530 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,573 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,574 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,622 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,623 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,668 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,669 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,723 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,725 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,782 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,783 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,830 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,831 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:53,871 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:53,872 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:58,41 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:14:58,59 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:14:58,90 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fefd3c90>
18:14:58,91 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f50fef99e20> server_hostname='api.openai.com' timeout=5.0
18:14:58,100 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fef0fc10>
18:14:58,101 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:58,104 httpcore.http11 DEBUG send_request_headers.complete
18:14:58,105 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:58,105 httpcore.http11 DEBUG send_request_body.complete
18:14:58,106 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:58,755 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:14:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'525'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2201e80530b27812b40ef3cf120a0151'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YBEIF76WUlGtVVFgsScBrpQr5rQe12WQrE8JQPJeV_I-1702250098-1-AYzEC0ru6ONZnGDlYCDG/tDVjZqPOzX77dVscdqg3os7H70+tW/clnqvrAxlafFlFH0J4cV2Ayuj8WrfD/3/Zu0=; path=/; expires=Sun, 10-Dec-23 23:44:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ttaR.WItJw.Wk2Jh2Vd3vSQNp3NEsu73W6pINfCIKUI-1702250098749-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83392fe92fdb4d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:58,763 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:14:58,763 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:59,442 httpcore.http11 DEBUG receive_response_body.complete
18:14:59,443 httpcore.http11 DEBUG response_closed.started
18:14:59,444 httpcore.http11 DEBUG response_closed.complete
18:14:59,445 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:14:59,530 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:15:13,86 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:15:13,100 httpcore.connection DEBUG close.started
18:15:13,100 httpcore.connection DEBUG close.complete
18:15:13,101 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:15:13,103 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fef0fd50>
18:15:13,103 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f50fef99e20> server_hostname='api.openai.com' timeout=5.0
18:15:13,108 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fef0eed0>
18:15:13,109 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:13,110 httpcore.http11 DEBUG send_request_headers.complete
18:15:13,110 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:13,141 httpcore.http11 DEBUG send_request_body.complete
18:15:13,142 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:13,977 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:15:13 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'374'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ca38a87b90128c13d3bcedc870665e1f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393046fa6e4d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:13,982 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:15:13,984 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:13,985 httpcore.http11 DEBUG receive_response_body.complete
18:15:13,986 httpcore.http11 DEBUG response_closed.started
18:15:13,986 httpcore.http11 DEBUG response_closed.complete
18:15:13,987 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:15:13,988 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:15:14,26 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only. Answer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:15:14,38 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:15:14,40 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fed74c90>
18:15:14,41 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f50fef99fd0> server_hostname='api.openai.com' timeout=None
18:15:14,45 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fed74c50>
18:15:14,46 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:14,47 httpcore.http11 DEBUG send_request_headers.complete
18:15:14,47 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:14,47 httpcore.http11 DEBUG send_request_body.complete
18:15:14,48 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:14,378 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:15:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'241'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a2ac7ca9390279a21655a29897a11d98'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6ZRULtM4zrLydltExvbUoLkc2DhHqwFsbP9236dknC0-1702250114-1-AZJHVoAN9rmvBKAYWm7ZyTW0Oux0USd2nQJwqPZ1QbkE9erA0RujCGz3++ujM32poRxF7nJ3+IcV/jxH7e9B9/U=; path=/; expires=Sun, 10-Dec-23 23:45:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=lDLO4UAlA3ril7oSwiMwGnoRhWHdDdegedwjh5ci.ps-1702250114373-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339304ccb0e4d19-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:14,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:15:14,384 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:14,386 httpcore.http11 DEBUG receive_response_body.complete
18:15:14,386 httpcore.http11 DEBUG response_closed.started
18:15:14,387 httpcore.http11 DEBUG response_closed.complete
18:15:14,387 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:15:14,422 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:15:14,434 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:15:14,436 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fed75950>
18:15:14,437 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f50fef9a330> server_hostname='api.openai.com' timeout=None
18:15:14,446 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f50fed75990>
18:15:14,447 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:14,449 httpcore.http11 DEBUG send_request_headers.complete
18:15:14,449 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:14,451 httpcore.http11 DEBUG send_request_body.complete
18:15:14,451 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:14,952 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:15:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'402'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'59b3d7e351673e69131f3b8c3b42d489'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RNwnucsesZLUtfcNKQs9ULF33cgqST1aiS128h5Qkso-1702250114-1-AYSHS8lfAVhqM2zy9X8MbXLfJREWjDjkSQOLmOzbOXvo0CYfvYMiotIyIFEYzVoY69v46J9U7wLio81agreBLoM=; path=/; expires=Sun, 10-Dec-23 23:45:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=oSE7pz7sk.i7qfYck.pVCSA9e8ljIbhN48lNbrackFc-1702250114948-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339304f4f334ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:14,956 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:15:14,957 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:14,958 httpcore.http11 DEBUG receive_response_body.complete
18:15:14,959 httpcore.http11 DEBUG response_closed.started
18:15:14,959 httpcore.http11 DEBUG response_closed.complete
18:15:14,960 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:15:14,969 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Great! I'll place the first candle in the middle. Now, where should I place the next candle? Shall we continue with the candle placement?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:15:14,973 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:15:14,974 httpcore.http11 DEBUG send_request_headers.complete
18:15:14,974 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:15:14,975 httpcore.http11 DEBUG send_request_body.complete
18:15:14,975 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:15:15,479 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:15:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bae895adf54f0214ef378d431fdb5f74'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833930529a484d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:15:15,483 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:15:15,484 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:15:17,2 httpcore.http11 DEBUG receive_response_body.complete
18:15:17,3 httpcore.http11 DEBUG response_closed.started
18:15:17,4 httpcore.http11 DEBUG response_closed.complete
18:15:17,4 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:15:17,82 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:18:05,698 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:05,702 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,517 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,518 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,560 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,561 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,610 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,611 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,652 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,653 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,702 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,703 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,745 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,746 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,795 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,796 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:06,837 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:06,838 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:07,198 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:18:07,217 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:07,249 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871a9b37d0>
18:18:07,249 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f871aa55d90> server_hostname='api.openai.com' timeout=5.0
18:18:07,256 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f871a9c7010>
18:18:07,257 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:07,259 httpcore.http11 DEBUG send_request_headers.complete
18:18:07,259 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:07,260 httpcore.http11 DEBUG send_request_body.complete
18:18:07,260 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:07,722 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:18:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'372'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cf78c8172bc3e96e5d2b3d8f2a52148d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3Fr2BikjoTIGdyBVfm5MXmftt9V.lc6j_pK_QOlPN6o-1702250287-1-AXnrxMpRvKWiNepqQUnPf3XQt4xb+GjTbH05vuI7teUgjlWLOTnLq6zKnzjmGzVb286iclHBrL46H6ZZWrjfRik=; path=/; expires=Sun, 10-Dec-23 23:48:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=KrsfD3K136WiCRADgb7eozfG0vmwE_Wu8__D4bBhOTM-1702250287715-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833934875a364cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:07,731 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:18:07,732 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:08,591 httpcore.http11 DEBUG receive_response_body.complete
18:18:08,592 httpcore.http11 DEBUG response_closed.started
18:18:08,593 httpcore.http11 DEBUG response_closed.complete
18:18:08,594 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:18:08,672 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:18:25,577 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:25,581 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,393 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,394 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,443 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,444 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,492 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,493 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,534 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,535 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,585 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,586 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,628 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,630 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,678 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,679 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:26,720 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:18:26,722 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:18:27,948 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:18:27,968 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:27,971 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4cc58150>
18:18:27,972 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7e4c935d90> server_hostname='api.openai.com' timeout=5.0
18:18:27,977 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c8ab950>
18:18:27,978 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:27,979 httpcore.http11 DEBUG send_request_headers.complete
18:18:27,979 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:27,980 httpcore.http11 DEBUG send_request_body.complete
18:18:27,980 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:28,489 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:18:28 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'85ed5a24e75e99da8a0ccba371353489'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Uq5CJojlrGHFYlx.oT42gF0oRWXEyeO86jhiyO0vh28-1702250308-1-AaSv+Xtzo7qh4NBhzbDLW0X9lCquHelqQT4Sm3hnYaq4hM3eFkjplPHa10WXbe7qTK6yzcB2zf/82wMsnWvK/XA=; path=/; expires=Sun, 10-Dec-23 23:48:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kxUcIADBP3GHbFl6n7AQxEI38zm3KnoPq87uYkv_KXU-1702250308483-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393508da5e4d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:28,496 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:18:28,496 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:29,169 httpcore.http11 DEBUG receive_response_body.complete
18:18:29,170 httpcore.http11 DEBUG response_closed.started
18:18:29,171 httpcore.http11 DEBUG response_closed.complete
18:18:29,172 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:18:29,254 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:18:42,934 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:18:42,943 httpcore.connection DEBUG close.started
18:18:42,944 httpcore.connection DEBUG close.complete
18:18:42,944 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:18:42,947 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c8ab210>
18:18:42,947 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7e4c935d90> server_hostname='api.openai.com' timeout=5.0
18:18:42,954 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c8abc10>
18:18:42,954 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:42,956 httpcore.http11 DEBUG send_request_headers.complete
18:18:42,956 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:43,77 httpcore.http11 DEBUG send_request_body.complete
18:18:43,78 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:43,912 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:18:43 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a36ab64a8412a9e9b61d0d46160545fe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833935667e1c4ce0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:43,917 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:18:43,918 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:43,919 httpcore.http11 DEBUG receive_response_body.complete
18:18:43,919 httpcore.http11 DEBUG response_closed.started
18:18:43,920 httpcore.http11 DEBUG response_closed.complete
18:18:43,920 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:18:43,921 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:18:49,324 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only. Answer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:18:49,335 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:18:49,337 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c708fd0>
18:18:49,338 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7e4c935f40> server_hostname='api.openai.com' timeout=None
18:18:49,344 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c708310>
18:18:49,345 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:18:49,346 httpcore.http11 DEBUG send_request_headers.complete
18:18:49,346 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:18:49,347 httpcore.http11 DEBUG send_request_body.complete
18:18:49,347 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:18:49,533 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:18:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'91'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'05ee611f0a3458568b22ac77221d675f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jrip2MolwvqAq94XUTVERGobcUwb.F55tntZcFeK9fc-1702250329-1-Ab0DpzcJ4FT8o6gx0OMLbY9TavvTiuN1erTHEG8Ig6KuDbyH3ayL2BFAPKpC01Eb0r23K3WzmSIU73lHZ4MXeIA=; path=/; expires=Sun, 10-Dec-23 23:48:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=GL289jtese.YHxvW.H4iFXdLGaOGRrEA27b7EgNtrww-1702250329529-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339358e6b3f3021-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:18:49,539 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:18:49,540 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:18:49,541 httpcore.http11 DEBUG receive_response_body.complete
18:18:49,541 httpcore.http11 DEBUG response_closed.started
18:18:49,541 httpcore.http11 DEBUG response_closed.complete
18:18:49,542 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:22:26,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only. Answer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:22:26,709 httpcore.connection DEBUG close.started
18:22:26,709 httpcore.connection DEBUG close.complete
18:22:26,709 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:22:26,740 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c731290>
18:22:26,740 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f7e4c935f40> server_hostname='api.openai.com' timeout=None
18:22:26,750 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f7e4c708210>
18:22:26,750 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:22:26,751 httpcore.http11 DEBUG send_request_headers.complete
18:22:26,751 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:22:26,751 httpcore.http11 DEBUG send_request_body.complete
18:22:26,751 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:22:26,960 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:22:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6651a5ed6ae79e2ee95ad8b51a14182c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393add3a4e4cde-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:22:26,961 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:22:26,961 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:22:26,962 httpcore.http11 DEBUG receive_response_body.complete
18:22:26,962 httpcore.http11 DEBUG response_closed.started
18:22:26,962 httpcore.http11 DEBUG response_closed.complete
18:22:26,962 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:22:48,66 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:48,72 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:48,874 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:48,875 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:48,918 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:48,919 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:48,962 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:48,963 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,10 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,11 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,51 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,52 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,90 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,91 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,132 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,133 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,170 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:22:49,171 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:22:49,211 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:22:49,224 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:22:49,228 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f300298bb10>
18:22:49,228 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3002799d90> server_hostname='api.openai.com' timeout=5.0
18:22:49,233 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002712850>
18:22:49,234 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:22:49,235 httpcore.http11 DEBUG send_request_headers.complete
18:22:49,235 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:22:49,235 httpcore.http11 DEBUG send_request_body.complete
18:22:49,235 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:22:49,702 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:22:49 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'74142f0d6133fa67396a2275f7195861'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=foAHfeqvSILOUn9T8RaGhaj.CeAJ7FXQavJgiilhIPI-1702250569-1-AS3VmZohHmV1SAsPSsp4UyAaDx1tHc4r11AEidMNMkGxWsNzXJGKWuZr8znEXalLlNnU5YMwtZprU9seOV+NcC8=; path=/; expires=Sun, 10-Dec-23 23:52:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RwfpaTuRDC48FS8lKd9MU5W85MPUlD2lRmuyxVETbAI-1702250569697-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393b69bd244cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:22:49,709 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:22:49,710 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:22:50,370 httpcore.http11 DEBUG receive_response_body.complete
18:22:50,371 httpcore.http11 DEBUG response_closed.started
18:22:50,371 httpcore.http11 DEBUG response_closed.complete
18:22:50,372 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:22:50,447 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:23:03,764 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:23:03,770 httpcore.connection DEBUG close.started
18:23:03,771 httpcore.connection DEBUG close.complete
18:23:03,771 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:03,773 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002712750>
18:23:03,773 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3002799d90> server_hostname='api.openai.com' timeout=5.0
18:23:03,780 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002712850>
18:23:03,780 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:03,781 httpcore.http11 DEBUG send_request_headers.complete
18:23:03,781 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:03,804 httpcore.http11 DEBUG send_request_body.complete
18:23:03,804 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:05,429 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:23:05 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'891'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'90dcd84cfb3dc9347e42a5d045893c73'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393bc4aa293b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:05,432 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:23:05,432 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:05,433 httpcore.http11 DEBUG receive_response_body.complete
18:23:05,434 httpcore.http11 DEBUG response_closed.started
18:23:05,434 httpcore.http11 DEBUG response_closed.complete
18:23:05,435 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:23:05,436 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:23:28,950 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only. Answer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:28,959 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:28,989 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002565350>
18:23:28,990 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3002799f40> server_hostname='api.openai.com' timeout=None
18:23:28,997 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3002564c10>
18:23:28,998 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:29,0 httpcore.http11 DEBUG send_request_headers.complete
18:23:29,0 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:29,1 httpcore.http11 DEBUG send_request_body.complete
18:23:29,2 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:29,483 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:23:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'229'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6715f73abab7283a7325ff5dfb385b43'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ci_cwy00BM.tVJBS2Fdpy8ON4nc2YKD8u1WO7oSr2UU-1702250609-1-ATdo0z4XJOuFd2KOUjhQMOzrCoAj4UPajT50RNhSZYAKdRN/kQedam4TZbSGxQPmBfMqguuVDjCO2Gv4CPFZqQg=; path=/; expires=Sun, 10-Dec-23 23:53:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=eWjqMZzg0pDNoajjAqVtiCyyS1tW1FCzN62g8EO7.so-1702250609478-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83393c624ed64cfe-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:29,491 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:29,492 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:29,494 httpcore.http11 DEBUG receive_response_body.complete
18:23:29,494 httpcore.http11 DEBUG response_closed.started
18:23:29,495 httpcore.http11 DEBUG response_closed.complete
18:23:29,495 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:27:13,35 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:13,39 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:13,876 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:13,877 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:13,918 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:13,919 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:13,966 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:13,967 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,7 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,8 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,58 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,59 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,101 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,102 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,150 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,151 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:14,191 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:27:14,192 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:27:15,96 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:27:15,116 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:27:15,144 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85e55950>
18:27:15,145 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:27:15,151 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bcff50>
18:27:15,152 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:27:15,155 httpcore.http11 DEBUG send_request_headers.complete
18:27:15,156 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:27:15,157 httpcore.http11 DEBUG send_request_body.complete
18:27:15,157 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:27:15,795 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:27:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'519'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4b3983cbd1cb6cc7346266abac83a15f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dMmOZQ0JULMIc0r.1EjhvN4L8lbeOn33sCS.70eux3s-1702250835-1-Ae39Zt1NCEDhUyXpnW7Q57ru9D6d6G++DhH3xOjXIH9gdjf8/H55q7x2Qq0nblE9hguq2Z7i2ahRaJi8P8ul6f0=; path=/; expires=Sun, 10-Dec-23 23:57:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=n6IWS65iUi5bQOAbypttO1OWjjFL8iaX2ZpewILkmh0-1702250835788-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833941e7bade4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:27:15,804 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:27:15,804 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:27:16,447 httpcore.http11 DEBUG receive_response_body.complete
18:27:16,448 httpcore.http11 DEBUG response_closed.started
18:27:16,449 httpcore.http11 DEBUG response_closed.complete
18:27:16,450 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:27:16,530 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:27:30,108 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:27:30,117 httpcore.connection DEBUG close.started
18:27:30,117 httpcore.connection DEBUG close.complete
18:27:30,118 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:27:30,136 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bcf9d0>
18:27:30,136 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:27:30,141 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bcf490>
18:27:30,142 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:27:30,144 httpcore.http11 DEBUG send_request_headers.complete
18:27:30,144 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:27:30,178 httpcore.http11 DEBUG send_request_body.complete
18:27:30,179 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:27:31,306 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:27:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'356'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2722a3d74e5a07691c96f15c90e420ee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833942456cc94d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:27:31,311 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:27:31,312 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:27:31,314 httpcore.http11 DEBUG receive_response_body.complete
18:27:31,314 httpcore.http11 DEBUG response_closed.started
18:27:31,314 httpcore.http11 DEBUG response_closed.complete
18:27:31,315 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:27:31,315 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:27:33,16 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nit in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:27:33,26 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:27:33,28 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c2d290>
18:27:33,29 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5df40> server_hostname='api.openai.com' timeout=None
18:27:33,36 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c2c490>
18:27:33,36 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:27:33,38 httpcore.http11 DEBUG send_request_headers.complete
18:27:33,38 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:27:33,39 httpcore.http11 DEBUG send_request_body.complete
18:27:33,39 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:27:33,422 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:27:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'262'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'08187b12569367f7a7977b49a5638613'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RnmsGl7ybGF3j2havTSPbvneG9XfHe7Km00NR8BfLYA-1702250853-1-Ador60hahNlEC0UYPEUZ+oomrsVloKDjmldAbDYf1EQ9SQIAR1D/TSwaQJyH1lBSMJCZ2C18RDfz+obJ6vx59VI=; path=/; expires=Sun, 10-Dec-23 23:57:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3j63d.VkYK2F8TkzRE42hoV85qzD7wDQ1hbPzgj4IH8-1702250853417-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833942577cd33bac-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:27:33,429 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:27:33,429 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:27:33,430 httpcore.http11 DEBUG receive_response_body.complete
18:27:33,431 httpcore.http11 DEBUG response_closed.started
18:27:33,431 httpcore.http11 DEBUG response_closed.complete
18:27:33,431 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:27:43,155 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nit in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:27:43,170 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:27:43,173 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85e6d510>
18:27:43,174 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5e720> server_hostname='api.openai.com' timeout=None
18:27:43,182 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c383d0>
18:27:43,182 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:27:43,183 httpcore.http11 DEBUG send_request_headers.complete
18:27:43,183 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:27:43,184 httpcore.http11 DEBUG send_request_body.complete
18:27:43,184 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:27:43,845 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:27:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'565'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'51710cf6d814b7221366eec87e141aee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ScxEsQMcvsqj0LNxUP4.C8aeibCItNs3eR6wMK22opE-1702250863-1-AT+MFhWg+LN8BXCOjZvXqJjXIS9Tau/QiONzWcH8K5yxcUwO2vaoqDBXGRPX2zfa1XNO9AnalXO7eOySp6FamYs=; path=/; expires=Sun, 10-Dec-23 23:57:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zUFYOLtu3eO.v9UJpAWt1OAa1X5x.9ACeBTAyxk4RiM-1702250863841-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83394296eec84d01-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:27:43,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:27:43,851 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:27:43,852 httpcore.http11 DEBUG receive_response_body.complete
18:27:43,852 httpcore.http11 DEBUG response_closed.started
18:27:43,853 httpcore.http11 DEBUG response_closed.complete
18:27:43,853 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:27:53,411 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:27:53,418 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:27:59,130 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:27:59,143 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:27:59,147 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:03,149 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:03,166 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:03,172 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:05,175 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:05,192 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:05,196 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:08,599 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:08,610 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:08,614 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:14,316 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:14,339 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:14,343 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:18,545 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:18,561 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:28:18,565 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:28:22,767 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:28:22,775 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:28:22,782 httpcore.connection DEBUG close.started
18:28:22,782 httpcore.connection DEBUG close.complete
18:28:22,783 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:28:22,812 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bc5a50>
18:28:22,812 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:28:22,818 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c00550>
18:28:22,819 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:22,820 httpcore.http11 DEBUG send_request_headers.complete
18:28:22,821 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:22,821 httpcore.http11 DEBUG send_request_body.complete
18:28:22,822 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:23,333 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'37a0066913245bad713cdb10900f081a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339438eaa6f4cd5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:23,338 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:28:23,338 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:24,320 httpcore.http11 DEBUG receive_response_body.complete
18:28:24,321 httpcore.http11 DEBUG response_closed.started
18:28:24,322 httpcore.http11 DEBUG response_closed.complete
18:28:24,323 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:28:24,390 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:28:37,52 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:28:37,57 httpcore.connection DEBUG close.started
18:28:37,57 httpcore.connection DEBUG close.complete
18:28:37,58 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:28:37,60 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63e50>
18:28:37,61 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:28:37,66 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63dd0>
18:28:37,66 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:37,67 httpcore.http11 DEBUG send_request_headers.complete
18:28:37,68 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:37,95 httpcore.http11 DEBUG send_request_body.complete
18:28:37,96 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:37,864 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4ff6840067741eb489715e0100963f08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833943e7ae524ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:37,867 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:28:37,868 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:37,868 httpcore.http11 DEBUG receive_response_body.complete
18:28:37,869 httpcore.http11 DEBUG response_closed.started
18:28:37,869 httpcore.http11 DEBUG response_closed.complete
18:28:37,870 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:28:37,870 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:28:37,911 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:28:37,918 httpcore.connection DEBUG close.started
18:28:37,919 httpcore.connection DEBUG close.complete
18:28:37,919 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:28:37,922 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bc56d0>
18:28:37,922 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5df40> server_hostname='api.openai.com' timeout=None
18:28:37,929 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bc4c90>
18:28:37,929 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:37,930 httpcore.http11 DEBUG send_request_headers.complete
18:28:37,931 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:37,931 httpcore.http11 DEBUG send_request_body.complete
18:28:37,931 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:38,116 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3bd0b35cfeb73be88bafb2a5de920d25'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833943ed18544d10-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:38,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:28:38,124 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:38,125 httpcore.http11 DEBUG receive_response_body.complete
18:28:38,126 httpcore.http11 DEBUG response_closed.started
18:28:38,126 httpcore.http11 DEBUG response_closed.complete
18:28:38,127 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:28:38,135 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:28:38,139 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:38,140 httpcore.http11 DEBUG send_request_headers.complete
18:28:38,140 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:38,141 httpcore.http11 DEBUG send_request_body.complete
18:28:38,141 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:38,746 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3125c5142be4667e95e93bc968df00a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833943ee6cf14ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:38,749 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:28:38,750 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:39,796 httpcore.http11 DEBUG receive_response_body.complete
18:28:39,797 httpcore.http11 DEBUG response_closed.started
18:28:39,797 httpcore.http11 DEBUG response_closed.complete
18:28:39,798 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:28:39,869 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:28:52,597 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:28:52,605 httpcore.connection DEBUG close.started
18:28:52,606 httpcore.connection DEBUG close.complete
18:28:52,607 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:28:52,609 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6eb10>
18:28:52,610 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:28:52,617 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6eb90>
18:28:52,618 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:52,619 httpcore.http11 DEBUG send_request_headers.complete
18:28:52,619 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:52,641 httpcore.http11 DEBUG send_request_body.complete
18:28:52,642 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:53,514 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:53 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'405'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e39107a0817e2e283f2c707988603ffc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83394448dad23049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:53,519 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:28:53,520 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:53,521 httpcore.http11 DEBUG receive_response_body.complete
18:28:53,522 httpcore.http11 DEBUG response_closed.started
18:28:53,523 httpcore.http11 DEBUG response_closed.complete
18:28:53,524 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:28:53,525 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:28:53,553 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:28:53,564 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:28:53,567 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a72010>
18:28:53,567 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:28:53,574 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a70a90>
18:28:53,575 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:53,576 httpcore.http11 DEBUG send_request_headers.complete
18:28:53,576 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:53,577 httpcore.http11 DEBUG send_request_body.complete
18:28:53,577 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:53,783 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f857ad7a9b8739c27172ba93662e40f0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EA96UyBcDvl4ueK.X2C0F_tLjgOh8awfDZNul6_d2KI-1702250933-1-AQAOkQfpWFEGEeiE9DjndQxf+4V14lImFKKGFgoOvTYOAf5CA9OjFGwRqqDO1O+ipFFalqqILG4IQvGgF4Tk8p4=; path=/; expires=Sun, 10-Dec-23 23:58:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=iMoN4lCOMzoZEriww95DbHlmbyvai8qe8t0OOOXTq1Q-1702250933778-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339444edad04cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:53,788 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:28:53,789 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:53,790 httpcore.http11 DEBUG receive_response_body.complete
18:28:53,790 httpcore.http11 DEBUG response_closed.started
18:28:53,790 httpcore.http11 DEBUG response_closed.complete
18:28:53,791 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:28:53,823 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:28:53,826 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:28:53,827 httpcore.http11 DEBUG send_request_headers.complete
18:28:53,827 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:28:53,828 httpcore.http11 DEBUG send_request_body.complete
18:28:53,828 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:28:54,35 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:28:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'102'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'211081085895da6e811f2c90399c7f6f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833944506efd4cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:28:54,40 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:28:54,41 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:28:54,42 httpcore.http11 DEBUG receive_response_body.complete
18:28:54,42 httpcore.http11 DEBUG response_closed.started
18:28:54,43 httpcore.http11 DEBUG response_closed.complete
18:28:54,43 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:29:13,947 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:29:13,951 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:29:17,354 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:29:21,931 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:29:21,942 httpcore.connection DEBUG close.started
18:29:21,943 httpcore.connection DEBUG close.complete
18:29:21,943 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:21,946 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6ea50>
18:29:21,946 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:29:21,953 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6ec90>
18:29:21,954 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:21,956 httpcore.http11 DEBUG send_request_headers.complete
18:29:21,956 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:21,957 httpcore.http11 DEBUG send_request_body.complete
18:29:21,958 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:22,389 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:22 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'367'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'979a81f5258f49b4bbbbb4256451c03e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83394500397f3045-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:22,392 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:29:22,392 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:22,903 httpcore.http11 DEBUG receive_response_body.complete
18:29:22,904 httpcore.http11 DEBUG response_closed.started
18:29:22,904 httpcore.http11 DEBUG response_closed.complete
18:29:22,905 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:29:22,970 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:29:32,110 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:29:32,115 httpcore.connection DEBUG close.started
18:29:32,116 httpcore.connection DEBUG close.complete
18:29:32,116 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:32,147 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6f850>
18:29:32,148 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:29:32,155 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6da10>
18:29:32,156 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:32,158 httpcore.http11 DEBUG send_request_headers.complete
18:29:32,158 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:32,182 httpcore.http11 DEBUG send_request_body.complete
18:29:32,182 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:32,975 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:32 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'377'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'08c73bcfc63f87d5da80c04a71fc337f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339453ff91b4cc9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:32,980 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:29:32,982 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:32,982 httpcore.http11 DEBUG receive_response_body.complete
18:29:32,983 httpcore.http11 DEBUG response_closed.started
18:29:32,983 httpcore.http11 DEBUG response_closed.complete
18:29:32,983 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:29:32,984 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:29:34,444 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:29:34,448 httpcore.connection DEBUG close.started
18:29:34,448 httpcore.connection DEBUG close.complete
18:29:34,449 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:29:34,452 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63a90>
18:29:34,452 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:29:34,460 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63250>
18:29:34,461 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:34,462 httpcore.http11 DEBUG send_request_headers.complete
18:29:34,462 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:34,463 httpcore.http11 DEBUG send_request_body.complete
18:29:34,463 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:34,698 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e503836278193ce47638ceda9684a09d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339454e6e4a4d0e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:34,702 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:29:34,703 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:34,704 httpcore.http11 DEBUG receive_response_body.complete
18:29:34,705 httpcore.http11 DEBUG response_closed.started
18:29:34,706 httpcore.http11 DEBUG response_closed.complete
18:29:34,706 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:29:43,979 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:29:43,984 httpcore.connection DEBUG close.started
18:29:43,985 httpcore.connection DEBUG close.complete
18:29:43,986 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:43,989 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c2fe50>
18:29:43,990 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:29:43,997 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c2d510>
18:29:43,998 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:44,1 httpcore.http11 DEBUG send_request_headers.complete
18:29:44,1 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:44,2 httpcore.http11 DEBUG send_request_body.complete
18:29:44,2 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:44,460 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:44 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'383'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb18ba3b82e16f029a1763a5852a3f7c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339458a0f6a4ce4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:44,465 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:29:44,466 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:45,472 httpcore.http11 DEBUG receive_response_body.complete
18:29:45,473 httpcore.http11 DEBUG response_closed.started
18:29:45,474 httpcore.http11 DEBUG response_closed.complete
18:29:45,476 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:29:45,539 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:29:57,247 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:29:57,251 httpcore.connection DEBUG close.started
18:29:57,251 httpcore.connection DEBUG close.complete
18:29:57,252 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:57,254 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62090>
18:29:57,254 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:29:57,260 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63d10>
18:29:57,260 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:57,262 httpcore.http11 DEBUG send_request_headers.complete
18:29:57,262 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:57,286 httpcore.http11 DEBUG send_request_body.complete
18:29:57,287 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:58,91 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:29:58 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'32'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'387'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ba415ca9df9257d4b996207952ca4a72'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833945dce8a14ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:58,96 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:29:58,97 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:58,98 httpcore.http11 DEBUG receive_response_body.complete
18:29:58,98 httpcore.http11 DEBUG response_closed.started
18:29:58,99 httpcore.http11 DEBUG response_closed.complete
18:29:58,99 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:29:58,100 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:30:02,259 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhich way should I move? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nThank you so much for watching!\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:02,262 httpcore.connection DEBUG close.started
18:30:02,263 httpcore.connection DEBUG close.complete
18:30:02,263 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:02,266 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62510>
18:30:02,266 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:30:02,273 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a63490>
18:30:02,274 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:02,275 httpcore.http11 DEBUG send_request_headers.complete
18:30:02,275 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:02,276 httpcore.http11 DEBUG send_request_body.complete
18:30:02,276 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:02,531 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:30:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'158'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1aab0328b03570f532ab88d67a7aba57'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833945fc3b984cf9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:02,537 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:02,538 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:02,540 httpcore.http11 DEBUG receive_response_body.complete
18:30:02,541 httpcore.http11 DEBUG response_closed.started
18:30:02,542 httpcore.http11 DEBUG response_closed.complete
18:30:02,542 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:22,800 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:30:22,807 httpcore.connection DEBUG close.started
18:30:22,808 httpcore.connection DEBUG close.complete
18:30:22,809 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:30:22,812 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62350>
18:30:22,813 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:30:22,820 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62f10>
18:30:22,821 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:22,823 httpcore.http11 DEBUG send_request_headers.complete
18:30:22,824 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:22,825 httpcore.http11 DEBUG send_request_body.complete
18:30:22,826 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:23,446 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:30:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'506'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'268c2f33158358a5d5fdbdb21cfb3759'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339467caee14cf2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:23,450 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:30:23,450 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:24,367 httpcore.http11 DEBUG receive_response_body.complete
18:30:24,368 httpcore.http11 DEBUG response_closed.started
18:30:24,369 httpcore.http11 DEBUG response_closed.complete
18:30:24,370 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:30:24,440 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:30:36,327 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:30:36,334 httpcore.connection DEBUG close.started
18:30:36,334 httpcore.connection DEBUG close.complete
18:30:36,335 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:30:36,364 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6c510>
18:30:36,365 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:30:36,371 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6e410>
18:30:36,372 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:36,374 httpcore.http11 DEBUG send_request_headers.complete
18:30:36,374 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:36,388 httpcore.http11 DEBUG send_request_body.complete
18:30:36,388 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:37,217 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:30:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'385'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1fb7f8c695df8055b51e8638cb6d8316'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833946d15d903bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:37,221 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:30:37,222 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:37,223 httpcore.http11 DEBUG receive_response_body.complete
18:30:37,224 httpcore.http11 DEBUG response_closed.started
18:30:37,225 httpcore.http11 DEBUG response_closed.complete
18:30:37,225 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:30:37,226 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:30:39,616 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhich way should I move? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:39,620 httpcore.connection DEBUG close.started
18:30:39,621 httpcore.connection DEBUG close.complete
18:30:39,621 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:39,624 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62310>
18:30:39,624 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:30:39,628 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62510>
18:30:39,629 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:39,630 httpcore.http11 DEBUG send_request_headers.complete
18:30:39,630 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:39,630 httpcore.http11 DEBUG send_request_body.complete
18:30:39,631 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:39,829 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:30:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'97'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'85c67e224e63e42a38f7b53fac8321ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833946e5baba3ba6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:39,833 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:39,834 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:39,836 httpcore.http11 DEBUG receive_response_body.complete
18:30:39,836 httpcore.http11 DEBUG response_closed.started
18:30:39,837 httpcore.http11 DEBUG response_closed.complete
18:30:39,837 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:49,26 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:49,29 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:30:52,431 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:31:00,38 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:31:00,42 httpcore.connection DEBUG close.started
18:31:00,43 httpcore.connection DEBUG close.complete
18:31:00,43 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:31:00,46 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6e410>
18:31:00,47 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:31:00,57 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a6d090>
18:31:00,58 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:31:00,60 httpcore.http11 DEBUG send_request_headers.complete
18:31:00,60 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:31:00,61 httpcore.http11 DEBUG send_request_body.complete
18:31:00,62 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:31:00,848 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:31:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'495'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c7f9b9e2ff7babd0701c1a033c557ab6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833947656e2b4d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:31:00,852 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:31:00,853 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:31:01,256 httpcore.http11 DEBUG receive_response_body.complete
18:31:01,256 httpcore.http11 DEBUG response_closed.started
18:31:01,257 httpcore.http11 DEBUG response_closed.complete
18:31:01,258 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:31:01,327 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:31:10,539 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:31:10,543 httpcore.connection DEBUG close.started
18:31:10,544 httpcore.connection DEBUG close.complete
18:31:10,544 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:31:10,547 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a5c910>
18:31:10,547 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:31:10,554 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a711d0>
18:31:10,554 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:31:10,556 httpcore.http11 DEBUG send_request_headers.complete
18:31:10,557 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:31:10,576 httpcore.http11 DEBUG send_request_body.complete
18:31:10,576 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:31:11,437 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:31:11 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'385'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'08738ebfc30d414b0fc6e47c54167d0f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833947a6fb224d10-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:31:11,443 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:31:11,443 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:31:11,444 httpcore.http11 DEBUG receive_response_body.complete
18:31:11,444 httpcore.http11 DEBUG response_closed.started
18:31:11,444 httpcore.http11 DEBUG response_closed.complete
18:31:11,445 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:31:11,445 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:31:13,806 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:31:13,810 httpcore.connection DEBUG close.started
18:31:13,810 httpcore.connection DEBUG close.complete
18:31:13,811 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:31:13,814 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85c03150>
18:31:13,814 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5deb0> server_hostname='api.openai.com' timeout=None
18:31:13,823 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a70c90>
18:31:13,824 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:31:13,827 httpcore.http11 DEBUG send_request_headers.complete
18:31:13,827 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:31:13,828 httpcore.http11 DEBUG send_request_body.complete
18:31:13,829 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:31:14,30 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:31:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'badad1bfb12f53b9bede997031f21874'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833947bb693a4d13-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:31:14,33 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:31:14,33 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:31:14,34 httpcore.http11 DEBUG receive_response_body.complete
18:31:14,35 httpcore.http11 DEBUG response_closed.started
18:31:14,35 httpcore.http11 DEBUG response_closed.complete
18:31:14,35 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:32:30,882 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Which way should I move? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:32:30,888 httpcore.connection DEBUG close.started
18:32:30,888 httpcore.connection DEBUG close.complete
18:32:30,889 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:30,918 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85bcc2d0>
18:32:30,919 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:32:30,926 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85e575d0>
18:32:30,927 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:30,929 httpcore.http11 DEBUG send_request_headers.complete
18:32:30,929 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:30,930 httpcore.http11 DEBUG send_request_body.complete
18:32:30,930 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:31,582 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:32:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'528'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'77982bf970461d93a697beabc1ab6d38'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339499d4f4b4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:31,589 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:32:31,589 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:32,516 httpcore.http11 DEBUG receive_response_body.complete
18:32:32,516 httpcore.http11 DEBUG response_closed.started
18:32:32,517 httpcore.http11 DEBUG response_closed.complete
18:32:32,517 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:32:32,587 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:32:44,463 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:32:44,470 httpcore.connection DEBUG close.started
18:32:44,471 httpcore.connection DEBUG close.complete
18:32:44,471 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:44,474 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a5c2d0>
18:32:44,474 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f3b85c5dd90> server_hostname='api.openai.com' timeout=5.0
18:32:44,480 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f3b85a62050>
18:32:44,481 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:44,482 httpcore.http11 DEBUG send_request_headers.complete
18:32:44,482 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:44,503 httpcore.http11 DEBUG send_request_body.complete
18:32:44,503 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:45,414 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:32:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'382'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4aed386639c7dd435f5ed1b59c2957df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833949f20b5c3010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:45,417 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:32:45,417 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:45,418 httpcore.http11 DEBUG receive_response_body.complete
18:32:45,419 httpcore.http11 DEBUG response_closed.started
18:32:45,419 httpcore.http11 DEBUG response_closed.complete
18:32:45,420 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:32:45,420 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:37:21,618 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:21,622 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,443 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,444 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,482 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,483 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,523 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,524 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,561 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,562 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,603 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,604 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,642 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,643 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,684 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,684 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,722 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:22,723 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:22,763 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:37:22,779 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:22,825 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd45f19d0>
18:37:22,826 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:37:22,833 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd452ead0>
18:37:22,834 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:22,835 httpcore.http11 DEBUG send_request_headers.complete
18:37:22,836 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:22,837 httpcore.http11 DEBUG send_request_body.complete
18:37:22,837 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:23,328 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:37:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9fe82e4978f9b0b2b13dac0d61489afb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SrbmLKj5imP1MptlGe5uA5D.hauXlYRW0mYTBl2LBc0-1702251443-1-AaBD3iBrs5q2ArjjgcK1kmmFoQu2zyVWF5CARUTYob7fnA2/FJwg3f8OM6g061HJjhpdYZheFBla7ERjR629KAs=; path=/; expires=Mon, 11-Dec-23 00:07:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=03cG33Du84xOSHL4bSkG5DpSIFHk74PY1ObBmFYVo.U-1702251443323-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833950bdbca94cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:23,333 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:37:23,333 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:23,972 httpcore.http11 DEBUG receive_response_body.complete
18:37:23,973 httpcore.http11 DEBUG response_closed.started
18:37:23,973 httpcore.http11 DEBUG response_closed.complete
18:37:23,974 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:37:24,43 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:37:37,674 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:37:37,681 httpcore.connection DEBUG close.started
18:37:37,682 httpcore.connection DEBUG close.complete
18:37:37,682 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:37,709 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd452ead0>
18:37:37,710 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:37:37,718 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd452ef10>
18:37:37,718 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:37,719 httpcore.http11 DEBUG send_request_headers.complete
18:37:37,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:37,756 httpcore.http11 DEBUG send_request_body.complete
18:37:37,756 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:38,701 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:37:38 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'38f86c4e1b61d05e7998d93ba8677971'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339511aca314cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:38,703 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:37:38,704 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:38,704 httpcore.http11 DEBUG receive_response_body.complete
18:37:38,705 httpcore.http11 DEBUG response_closed.started
18:37:38,705 httpcore.http11 DEBUG response_closed.complete
18:37:38,705 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:37:38,706 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:37:43,673 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:43,685 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:43,688 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4594490>
18:37:43,688 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9f40> server_hostname='api.openai.com' timeout=None
18:37:43,693 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4594450>
18:37:43,694 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:43,695 httpcore.http11 DEBUG send_request_headers.complete
18:37:43,696 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:43,696 httpcore.http11 DEBUG send_request_body.complete
18:37:43,696 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:43,896 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:37:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'98'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1f605846dc7667288f8e849043ff8e99'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5t4.EtCQQYyl4G23CIMifpZlwcITeXRBMlGPwF1n2_o-1702251463-1-AaSkn+O2wUS/cmpsIT295i4aU0My4PKpi0b0oItP7xOSGYPbVCd16cDNdKpPdQDTkeXBKFckUM5XbRHA7oC5Yj4=; path=/; expires=Mon, 11-Dec-23 00:07:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qj183FqzZXWx5dajsA4Trxv7AzUs43SFtUPstZizlHQ-1702251463891-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833951401cfa4d1e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:43,904 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:43,905 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:43,908 httpcore.http11 DEBUG receive_response_body.complete
18:37:43,909 httpcore.http11 DEBUG response_closed.started
18:37:43,909 httpcore.http11 DEBUG response_closed.complete
18:37:43,910 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:45,894 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:45,905 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:45,907 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43a62d0>
18:37:45,907 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45ba720> server_hostname='api.openai.com' timeout=None
18:37:45,913 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43add50>
18:37:45,913 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:45,914 httpcore.http11 DEBUG send_request_headers.complete
18:37:45,914 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:45,914 httpcore.http11 DEBUG send_request_body.complete
18:37:45,914 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:46,710 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:37:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'682'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7020e0386b6828014c96e980496d863d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4AQufKSLvwrIWQwFMjC8IBq_6Y6o0ifPDvK07fxhQdU-1702251466-1-AfhipoLqTEj09xVIYrTKLr3ZwSPOS9pMxkrczDHabNkiV0cPBQJ14J30u80Jq6svn6cxksU/GfBkmaOqFSuGSdk=; path=/; expires=Mon, 11-Dec-23 00:07:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kyAjse6lqUxb46quKzJzkMkdIoqju_rtmUiEICmwOqc-1702251466706-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339514dfda84cc3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:46,713 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:46,714 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:46,714 httpcore.http11 DEBUG receive_response_body.complete
18:37:46,714 httpcore.http11 DEBUG response_closed.started
18:37:46,715 httpcore.http11 DEBUG response_closed.complete
18:37:46,715 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:46,729 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:37:46,732 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:37:52,436 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:37:52,444 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:37:52,447 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:37:56,448 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:37:56,460 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:37:56,463 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:37:58,464 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:37:58,476 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:37:58,479 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:38:01,880 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:38:01,894 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:38:01,897 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:38:07,598 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:38:07,613 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:38:07,616 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:38:11,817 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:38:11,828 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:38:11,832 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:38:16,33 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:38:16,38 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:38:16,43 httpcore.connection DEBUG close.started
18:38:16,43 httpcore.connection DEBUG close.complete
18:38:16,44 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:38:16,46 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd47af0d0>
18:38:16,47 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:38:16,53 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd456f8d0>
18:38:16,53 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:16,54 httpcore.http11 DEBUG send_request_headers.complete
18:38:16,54 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:16,54 httpcore.http11 DEBUG send_request_body.complete
18:38:16,54 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:16,563 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'53064eb61f53afbc0fea5ca429dd07b2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339520a59c53b8d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:16,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:38:16,564 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:17,754 httpcore.http11 DEBUG receive_response_body.complete
18:38:17,754 httpcore.http11 DEBUG response_closed.started
18:38:17,755 httpcore.http11 DEBUG response_closed.complete
18:38:17,755 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:38:17,820 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:38:30,130 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:38:30,135 httpcore.connection DEBUG close.started
18:38:30,135 httpcore.connection DEBUG close.complete
18:38:30,135 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:38:30,150 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43c7590>
18:38:30,150 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:38:30,157 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43c7610>
18:38:30,158 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:30,159 httpcore.http11 DEBUG send_request_headers.complete
18:38:30,159 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:30,182 httpcore.http11 DEBUG send_request_body.complete
18:38:30,182 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:31,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8c425d4ed0b052769f6983fb8ab536c3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952627cfe4cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:31,26 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:38:31,26 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:31,27 httpcore.http11 DEBUG receive_response_body.complete
18:38:31,28 httpcore.http11 DEBUG response_closed.started
18:38:31,28 httpcore.http11 DEBUG response_closed.complete
18:38:31,29 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:38:31,29 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:38:31,42 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:38:31,45 httpcore.connection DEBUG close.started
18:38:31,45 httpcore.connection DEBUG close.complete
18:38:31,46 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:38:31,48 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be7d0>
18:38:31,48 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9f40> server_hostname='api.openai.com' timeout=None
18:38:31,52 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be8d0>
18:38:31,52 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:31,53 httpcore.http11 DEBUG send_request_headers.complete
18:38:31,53 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:31,53 httpcore.http11 DEBUG send_request_body.complete
18:38:31,53 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:31,278 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fbf795989fc47e1389ed699459e96085'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952681ef03b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:31,280 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:38:31,280 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:31,281 httpcore.http11 DEBUG receive_response_body.complete
18:38:31,281 httpcore.http11 DEBUG response_closed.started
18:38:31,281 httpcore.http11 DEBUG response_closed.complete
18:38:31,281 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:38:31,286 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:38:31,288 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:31,288 httpcore.http11 DEBUG send_request_headers.complete
18:38:31,288 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:31,289 httpcore.http11 DEBUG send_request_body.complete
18:38:31,289 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:31,804 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'423'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f0e2bc274abe56f0fd9f1adb2fc8ccc6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952698ae94cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:31,807 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:38:31,807 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:32,884 httpcore.http11 DEBUG receive_response_body.complete
18:38:32,884 httpcore.http11 DEBUG response_closed.started
18:38:32,885 httpcore.http11 DEBUG response_closed.complete
18:38:32,885 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:38:32,952 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:38:45,486 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:38:45,491 httpcore.connection DEBUG close.started
18:38:45,491 httpcore.connection DEBUG close.complete
18:38:45,491 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:38:45,494 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be1d0>
18:38:45,494 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:38:45,500 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d1c90>
18:38:45,500 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:45,501 httpcore.http11 DEBUG send_request_headers.complete
18:38:45,501 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:45,517 httpcore.http11 DEBUG send_request_body.complete
18:38:45,517 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:46,267 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'dd0afa963d3a4bcc2f3c703af7243e4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952c26f7f3051-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:46,269 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:38:46,270 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:46,271 httpcore.http11 DEBUG receive_response_body.complete
18:38:46,271 httpcore.http11 DEBUG response_closed.started
18:38:46,272 httpcore.http11 DEBUG response_closed.complete
18:38:46,272 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:38:46,273 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:38:46,288 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:38:46,297 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:38:46,299 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bebd0>
18:38:46,299 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:38:46,305 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bf8d0>
18:38:46,305 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:38:46,306 httpcore.http11 DEBUG send_request_headers.complete
18:38:46,306 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:38:46,306 httpcore.http11 DEBUG send_request_body.complete
18:38:46,307 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:38:46,533 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:38:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'124'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fb8abba098f686406fba78cff3432ada'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cmmCM_Zo0jVTVtBhkZ_O.VJ37_WIWr6Ho2R5g_JKNKk-1702251526-1-AT3GVX8XfIXYofnQ0FBC+T82uG3pm7JehLtD6DZ2iyc6aYo4tRMiqjhTUm1iUU4XrkeNt+VtSFXFyssd8eXe1iw=; path=/; expires=Mon, 11-Dec-23 00:08:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=hay7yOGDOuAGJjB8aAG2L0epW6Hf8rsiQ6Xv5x6QRus-1702251526530-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833952c76c4a2ffc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:38:46,536 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:38:46,537 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:46,538 httpcore.http11 DEBUG receive_response_body.complete
18:38:46,538 httpcore.http11 DEBUG response_closed.started
18:38:46,539 httpcore.http11 DEBUG response_closed.complete
18:38:46,539 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:39:10,6 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:39:10,10 httpcore.connection DEBUG close.started
18:39:10,11 httpcore.connection DEBUG close.complete
18:39:10,11 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:39:10,13 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d0650>
18:39:10,14 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:39:10,19 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d0f10>
18:39:10,20 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:39:10,22 httpcore.http11 DEBUG send_request_headers.complete
18:39:10,23 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:39:10,24 httpcore.http11 DEBUG send_request_body.complete
18:39:10,24 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:39:10,234 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:39:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'77'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c97d025a7965aa52830a1f71577ecf94'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339535baf8c3b94-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:39:10,241 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:39:10,241 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:39:10,242 httpcore.http11 DEBUG receive_response_body.complete
18:39:10,243 httpcore.http11 DEBUG response_closed.started
18:39:10,243 httpcore.http11 DEBUG response_closed.complete
18:39:10,244 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:39:35,925 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:39:35,930 httpcore.connection DEBUG close.started
18:39:35,931 httpcore.connection DEBUG close.complete
18:39:35,931 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:39:35,962 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43a6ed0>
18:39:35,962 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:39:35,969 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d1c90>
18:39:35,969 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:39:35,970 httpcore.http11 DEBUG send_request_headers.complete
18:39:35,971 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:39:35,971 httpcore.http11 DEBUG send_request_body.complete
18:39:35,971 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:39:36,611 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:39:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3687e1aa2846e253200659e3477bba60'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833953fddbd74ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:39:36,613 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:39:36,614 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:39:37,516 httpcore.http11 DEBUG receive_response_body.complete
18:39:37,516 httpcore.http11 DEBUG response_closed.started
18:39:37,516 httpcore.http11 DEBUG response_closed.complete
18:39:37,516 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:39:37,588 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:39:50,219 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:39:50,222 httpcore.connection DEBUG close.started
18:39:50,222 httpcore.connection DEBUG close.complete
18:39:50,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:39:50,225 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43dc510>
18:39:50,225 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:39:50,230 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43ddfd0>
18:39:50,230 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:39:50,231 httpcore.http11 DEBUG send_request_headers.complete
18:39:50,231 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:39:50,247 httpcore.http11 DEBUG send_request_body.complete
18:39:50,247 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:39:51,41 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:39:51 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e5cdbcb70fcd86e06383d02f403b3828'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83395456fc653071-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:39:51,43 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:39:51,44 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:39:51,45 httpcore.http11 DEBUG receive_response_body.complete
18:39:51,45 httpcore.http11 DEBUG response_closed.started
18:39:51,45 httpcore.http11 DEBUG response_closed.complete
18:39:51,46 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:39:51,47 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:39:51,64 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove down.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:39:51,66 httpcore.connection DEBUG close.started
18:39:51,66 httpcore.connection DEBUG close.complete
18:39:51,66 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:39:51,69 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43c7850>
18:39:51,69 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:39:51,75 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43c6790>
18:39:51,75 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:39:51,76 httpcore.http11 DEBUG send_request_headers.complete
18:39:51,76 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:39:51,76 httpcore.http11 DEBUG send_request_body.complete
18:39:51,76 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:39:51,304 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:39:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b8566eb31ae18bca6b2d35741cbf54b8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339545c3e2b4cdc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:39:51,307 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:39:51,308 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:39:51,310 httpcore.http11 DEBUG receive_response_body.complete
18:39:51,310 httpcore.http11 DEBUG response_closed.started
18:39:51,310 httpcore.http11 DEBUG response_closed.complete
18:39:51,311 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:40:02,882 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:02,887 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:06,290 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:06,293 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:40:06,298 httpcore.connection DEBUG close.started
18:40:06,298 httpcore.connection DEBUG close.complete
18:40:06,298 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:40:06,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d0f10>
18:40:06,301 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:40:06,308 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d32d0>
18:40:06,308 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:06,309 httpcore.http11 DEBUG send_request_headers.complete
18:40:06,309 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:06,309 httpcore.http11 DEBUG send_request_body.complete
18:40:06,309 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:06,716 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:06 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'334'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7941bdc4995452b881d862fa368d6dd2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833954bb683e4cf3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:06,719 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:40:06,720 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:07,189 httpcore.http11 DEBUG receive_response_body.complete
18:40:07,189 httpcore.http11 DEBUG response_closed.started
18:40:07,189 httpcore.http11 DEBUG response_closed.complete
18:40:07,190 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:40:07,256 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:40:16,479 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:40:16,482 httpcore.connection DEBUG close.started
18:40:16,483 httpcore.connection DEBUG close.complete
18:40:16,483 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:40:16,485 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4597910>
18:40:16,485 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:40:16,490 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4597890>
18:40:16,490 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:16,491 httpcore.http11 DEBUG send_request_headers.complete
18:40:16,491 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:16,510 httpcore.http11 DEBUG send_request_body.complete
18:40:16,510 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:17,478 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:17 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'30'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'452'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'88a74919ea39b13d948300e1fb0db2b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833954fb1bbc3035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:17,480 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:40:17,480 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:17,481 httpcore.http11 DEBUG receive_response_body.complete
18:40:17,481 httpcore.http11 DEBUG response_closed.started
18:40:17,482 httpcore.http11 DEBUG response_closed.complete
18:40:17,482 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:40:17,482 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:40:17,499 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes, this is a good location.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:40:17,501 httpcore.connection DEBUG close.started
18:40:17,501 httpcore.connection DEBUG close.complete
18:40:17,501 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:40:17,503 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd475e0d0>
18:40:17,503 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:40:17,508 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4553050>
18:40:17,509 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:17,509 httpcore.http11 DEBUG send_request_headers.complete
18:40:17,509 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:17,510 httpcore.http11 DEBUG send_request_body.complete
18:40:17,510 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:17,729 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9d67205852ae010e6a9417a04cffe500'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833955016c723b7c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:17,731 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:40:17,732 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:17,733 httpcore.http11 DEBUG receive_response_body.complete
18:40:17,733 httpcore.http11 DEBUG response_closed.started
18:40:17,733 httpcore.http11 DEBUG response_closed.complete
18:40:17,734 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:40:17,744 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:17,748 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:21,149 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:21,159 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:21,163 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:23,164 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:23,174 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:23,176 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:26,578 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:26,582 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:40:26,586 httpcore.connection DEBUG close.started
18:40:26,586 httpcore.connection DEBUG close.complete
18:40:26,586 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:40:26,589 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd45976d0>
18:40:26,589 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:40:26,596 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd4597110>
18:40:26,596 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:26,598 httpcore.http11 DEBUG send_request_headers.complete
18:40:26,598 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:26,598 httpcore.http11 DEBUG send_request_body.complete
18:40:26,599 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:27,240 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'492'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'622ae5cc6f0b87915e0ee4303da39355'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339553a395f4cd6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:27,242 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:40:27,243 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:27,712 httpcore.http11 DEBUG receive_response_body.complete
18:40:27,713 httpcore.http11 DEBUG response_closed.started
18:40:27,713 httpcore.http11 DEBUG response_closed.complete
18:40:27,713 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:40:27,782 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:40:39,543 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:40:39,546 httpcore.connection DEBUG close.started
18:40:39,546 httpcore.connection DEBUG close.complete
18:40:39,547 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:40:39,575 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d3e10>
18:40:39,575 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:40:39,584 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d32d0>
18:40:39,584 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:39,586 httpcore.http11 DEBUG send_request_headers.complete
18:40:39,586 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:39,618 httpcore.http11 DEBUG send_request_body.complete
18:40:39,619 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:40,518 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:40 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd209f5f1ab02199868d6c94bf561b52a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339558b6bfc4cee-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:40,520 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:40:40,521 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:40,522 httpcore.http11 DEBUG receive_response_body.complete
18:40:40,522 httpcore.http11 DEBUG response_closed.started
18:40:40,522 httpcore.http11 DEBUG response_closed.complete
18:40:40,522 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:40:40,523 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:40:40,539 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:40:40,542 httpcore.connection DEBUG close.started
18:40:40,542 httpcore.connection DEBUG close.complete
18:40:40,542 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:40:40,545 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bc9d0>
18:40:40,545 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9f40> server_hostname='api.openai.com' timeout=None
18:40:40,550 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43beb50>
18:40:40,550 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:40,551 httpcore.http11 DEBUG send_request_headers.complete
18:40:40,551 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:40,551 httpcore.http11 DEBUG send_request_body.complete
18:40:40,552 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:40,748 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b52b5b9122db231d037f11173ee7c757'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833955917d834ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:40,749 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:40:40,750 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:40,750 httpcore.http11 DEBUG receive_response_body.complete
18:40:40,751 httpcore.http11 DEBUG response_closed.started
18:40:40,751 httpcore.http11 DEBUG response_closed.complete
18:40:40,751 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:40:40,769 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:40:40,771 httpcore.connection DEBUG close.started
18:40:40,771 httpcore.connection DEBUG close.complete
18:40:40,771 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:40:40,773 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43ade10>
18:40:40,774 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45ba720> server_hostname='api.openai.com' timeout=None
18:40:40,779 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bf5d0>
18:40:40,779 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:40:40,780 httpcore.http11 DEBUG send_request_headers.complete
18:40:40,780 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:40:40,781 httpcore.http11 DEBUG send_request_body.complete
18:40:40,781 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:40:41,210 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:40:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'295'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'70bd026149698ecf49dc20ecb4ab9e91'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83395592ed673b7b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:40:41,212 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:40:41,213 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:40:41,214 httpcore.http11 DEBUG receive_response_body.complete
18:40:41,214 httpcore.http11 DEBUG response_closed.started
18:40:41,214 httpcore.http11 DEBUG response_closed.complete
18:40:41,214 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:40:41,321 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:41,323 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:47,25 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:47,36 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:47,40 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:51,41 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:51,54 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:51,58 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:53,59 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:53,73 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:53,77 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:40:56,478 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:40:56,491 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:40:56,494 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:41:02,195 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:41:02,209 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:41:02,212 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:41:05,213 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:41:05,220 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:41:05,222 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:41:08,229 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:41:08,233 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:41:08,236 httpcore.connection DEBUG close.started
18:41:08,237 httpcore.connection DEBUG close.complete
18:41:08,237 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:41:08,240 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43dd990>
18:41:08,240 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:41:08,248 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43d23d0>
18:41:08,248 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:41:08,249 httpcore.http11 DEBUG send_request_headers.complete
18:41:08,249 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:41:08,250 httpcore.http11 DEBUG send_request_body.complete
18:41:08,250 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:41:08,858 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:41:08 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'610a21926a873a7ac5ac84c8b8dd86a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339563e8dd24ce9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:41:08,860 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:41:08,861 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:41:09,738 httpcore.http11 DEBUG receive_response_body.complete
18:41:09,739 httpcore.http11 DEBUG response_closed.started
18:41:09,739 httpcore.http11 DEBUG response_closed.complete
18:41:09,739 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:41:09,810 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:41:22,353 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:41:22,357 httpcore.connection DEBUG close.started
18:41:22,358 httpcore.connection DEBUG close.complete
18:41:22,358 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:41:22,360 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43e0750>
18:41:22,360 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:41:22,366 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43e07d0>
18:41:22,366 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:41:22,367 httpcore.http11 DEBUG send_request_headers.complete
18:41:22,367 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:41:22,388 httpcore.http11 DEBUG send_request_body.complete
18:41:22,388 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:41:23,112 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:41:23 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'6'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'337'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4cb8547939400fc805ce4d960e075c73'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83395696ccc34cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:41:23,115 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:41:23,116 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:41:23,116 httpcore.http11 DEBUG receive_response_body.complete
18:41:23,117 httpcore.http11 DEBUG response_closed.started
18:41:23,117 httpcore.http11 DEBUG response_closed.complete
18:41:23,118 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:41:23,118 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:41:30,562 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNope.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:41:30,565 httpcore.connection DEBUG close.started
18:41:30,565 httpcore.connection DEBUG close.complete
18:41:30,566 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:41:30,568 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43beb50>
18:41:30,569 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9f40> server_hostname='api.openai.com' timeout=None
18:41:30,575 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be950>
18:41:30,575 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:41:30,576 httpcore.http11 DEBUG send_request_headers.complete
18:41:30,577 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:41:30,577 httpcore.http11 DEBUG send_request_body.complete
18:41:30,577 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:41:30,784 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:41:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'24458a8760ba7836c077d48bf5b70b3a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833956ca1fb46ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:41:30,791 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:41:30,792 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:41:30,794 httpcore.http11 DEBUG receive_response_body.complete
18:41:30,794 httpcore.http11 DEBUG response_closed.started
18:41:30,795 httpcore.http11 DEBUG response_closed.complete
18:41:30,795 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:42:50,837 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:42:50,845 httpcore.connection DEBUG close.started
18:42:50,846 httpcore.connection DEBUG close.complete
18:42:50,846 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:42:50,877 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43be410>
18:42:50,877 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:42:50,886 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bef50>
18:42:50,887 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:42:50,889 httpcore.http11 DEBUG send_request_headers.complete
18:42:50,890 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:42:50,891 httpcore.http11 DEBUG send_request_body.complete
18:42:50,892 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:42:51,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:42:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'463'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'31bb36c3a5c14b054f5ebadf2420160f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833958c00d733b8e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:42:51,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:42:51,461 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:42:52,427 httpcore.http11 DEBUG receive_response_body.complete
18:42:52,427 httpcore.http11 DEBUG response_closed.started
18:42:52,428 httpcore.http11 DEBUG response_closed.complete
18:42:52,429 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:42:52,498 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:43:05,221 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:43:05,225 httpcore.connection DEBUG close.started
18:43:05,225 httpcore.connection DEBUG close.complete
18:43:05,225 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:43:05,228 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43ac910>
18:43:05,228 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9d90> server_hostname='api.openai.com' timeout=5.0
18:43:05,234 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43aef50>
18:43:05,235 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:05,236 httpcore.http11 DEBUG send_request_headers.complete
18:43:05,236 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:05,259 httpcore.http11 DEBUG send_request_body.complete
18:43:05,259 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:06,66 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:43:06 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c6ee445f946cfce66fb9adf37669553f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83395919beae4ce3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:06,68 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:43:06,68 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:06,69 httpcore.http11 DEBUG receive_response_body.complete
18:43:06,69 httpcore.http11 DEBUG response_closed.started
18:43:06,70 httpcore.http11 DEBUG response_closed.complete
18:43:06,70 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:43:06,70 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:43:22,85 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:43:22,89 httpcore.connection DEBUG close.started
18:43:22,89 httpcore.connection DEBUG close.complete
18:43:22,89 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:43:22,92 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bf350>
18:43:22,92 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9cd45b9eb0> server_hostname='api.openai.com' timeout=None
18:43:22,97 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9cd43bcf50>
18:43:22,97 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:22,98 httpcore.http11 DEBUG send_request_headers.complete
18:43:22,99 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:22,99 httpcore.http11 DEBUG send_request_body.complete
18:43:22,99 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:22,304 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:43:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a5124994f4f7f476e85b69d699fedc73'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833959831dae4ce7-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:22,310 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:43:22,312 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:22,312 httpcore.http11 DEBUG receive_response_body.complete
18:43:22,313 httpcore.http11 DEBUG response_closed.started
18:43:22,313 httpcore.http11 DEBUG response_closed.complete
18:43:22,313 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:27,702 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:27,705 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,508 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,509 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,560 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,560 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,604 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,605 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,646 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,647 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,694 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,695 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,737 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,738 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,781 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,782 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,821 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:28,822 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:28,864 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:49:28,876 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:49:28,908 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288ddcd0>
18:49:28,908 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:49:28,917 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288de250>
18:49:28,917 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:28,919 httpcore.http11 DEBUG send_request_headers.complete
18:49:28,919 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:28,919 httpcore.http11 DEBUG send_request_body.complete
18:49:28,920 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:29,398 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:49:29 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'562909cfa3600614bf296015dd3528bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=R8DVj9e765PJ5E73YwCNxHht0D4euHt8INkVP6Iy.Sk-1702252169-1-AX89QSbkvhZikxnSCF+a41Wa+Nq/wRr2FehHdKUrVVJjxkUIC0O2kYpbPPYqbWswKilCjF0oYUnxrs4CuP+H0s4=; path=/; expires=Mon, 11-Dec-23 00:19:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=aaGRaB_.b4KkkDv4gNS6ZRQLDVSwaH4F.DojrZXY4_g-1702252169393-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396277cd634ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:29,405 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:49:29,405 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:30,210 httpcore.http11 DEBUG receive_response_body.complete
18:49:30,210 httpcore.http11 DEBUG response_closed.started
18:49:30,211 httpcore.http11 DEBUG response_closed.complete
18:49:30,211 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:49:30,283 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:49:44,67 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:49:44,76 httpcore.connection DEBUG close.started
18:49:44,76 httpcore.connection DEBUG close.complete
18:49:44,76 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:49:44,79 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288de250>
18:49:44,79 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:49:44,86 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288ddb50>
18:49:44,87 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:44,87 httpcore.http11 DEBUG send_request_headers.complete
18:49:44,87 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:44,117 httpcore.http11 DEBUG send_request_body.complete
18:49:44,117 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:44,863 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:49:44 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'409'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd3fe8db6cc52f6baad71ee62db10c84c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833962d68ed34d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:44,866 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:49:44,866 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:44,867 httpcore.http11 DEBUG receive_response_body.complete
18:49:44,867 httpcore.http11 DEBUG response_closed.started
18:49:44,868 httpcore.http11 DEBUG response_closed.complete
18:49:44,868 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:49:44,869 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:49:44,887 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:49:44,895 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:49:44,897 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628933fd0>
18:49:44,897 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:49:44,903 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628932790>
18:49:44,903 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:44,904 httpcore.http11 DEBUG send_request_headers.complete
18:49:44,904 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:44,904 httpcore.http11 DEBUG send_request_body.complete
18:49:44,905 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:45,165 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:49:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'93a3bd3c4d140af64f758301f7792804'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FswVi.q.hr9FshPT72k.FEK2HD5EaTy322RnGtwJ_Gs-1702252185-1-AdUq5I91x2Cr/owyCVBuqNjZ6KmqSErQwf3eHDXyUos+ul0x0sWdExxYpuxOXdypZ3hi/+XHMrHD5gmm/K/uthA=; path=/; expires=Mon, 11-Dec-23 00:19:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NGDr5gXwFzVgZMbHVGrvJh4xkk006WR0oiXIn67Hg.0-1702252185161-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833962dbacd23010-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:45,170 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:49:45,170 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:45,171 httpcore.http11 DEBUG receive_response_body.complete
18:49:45,171 httpcore.http11 DEBUG response_closed.started
18:49:45,171 httpcore.http11 DEBUG response_closed.complete
18:49:45,172 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:45,188 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:49:45,199 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:49:45,201 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289406d0>
18:49:45,201 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628966720> server_hostname='api.openai.com' timeout=None
18:49:45,210 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289408d0>
18:49:45,210 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:49:45,211 httpcore.http11 DEBUG send_request_headers.complete
18:49:45,211 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:49:45,212 httpcore.http11 DEBUG send_request_body.complete
18:49:45,212 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:49:45,840 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:49:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'361'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'eced275818ed6d7d378aa888ac9ca952'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mlmjq7d17hgHkeKAIRG5.KR0sfWuwr1a3sqUat4y5yQ-1702252185-1-AS9dvfIF05lySg0tBLmDbK+umsDSI//6Tv3A29yq0wRLbYNGiesTyOdHZt86jVDSG3NMRNdnxcuWFMvamBaLhTA=; path=/; expires=Mon, 11-Dec-23 00:19:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=hXN1RTWGBD58QAzqISNGshIvVUUeq8A8gM_d9rn6LdE-1702252185837-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833962dd99eb3b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:49:45,841 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:49:45,842 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:49:45,842 httpcore.http11 DEBUG receive_response_body.complete
18:49:45,842 httpcore.http11 DEBUG response_closed.started
18:49:45,843 httpcore.http11 DEBUG response_closed.complete
18:49:45,843 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:45,854 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:49:45,858 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:49:51,564 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:49:51,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:49:51,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:49:55,580 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:49:55,591 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:49:55,594 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:49:57,595 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:49:57,607 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:49:57,610 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:01,12 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:01,26 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:01,30 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:06,731 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:06,746 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:06,749 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:10,152 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:10,158 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:50:10,162 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:50:13,964 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:50:13,969 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:50:13,974 httpcore.connection DEBUG close.started
18:50:13,975 httpcore.connection DEBUG close.complete
18:50:13,976 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:13,979 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288de3d0>
18:50:13,979 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:50:13,985 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628952c90>
18:50:13,985 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:13,986 httpcore.http11 DEBUG send_request_headers.complete
18:50:13,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:13,986 httpcore.http11 DEBUG send_request_body.complete
18:50:13,986 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:14,497 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:14 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'422'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e490463db15c65c574e3526cb0c2aef8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833963916b614cee-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:14,499 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:50:14,500 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:15,517 httpcore.http11 DEBUG receive_response_body.complete
18:50:15,518 httpcore.http11 DEBUG response_closed.started
18:50:15,518 httpcore.http11 DEBUG response_closed.complete
18:50:15,519 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:50:15,590 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:50:28,286 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:50:28,289 httpcore.connection DEBUG close.started
18:50:28,289 httpcore.connection DEBUG close.complete
18:50:28,289 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:28,292 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628775b10>
18:50:28,292 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:50:28,304 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628775b90>
18:50:28,304 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:28,305 httpcore.http11 DEBUG send_request_headers.complete
18:50:28,305 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:28,325 httpcore.http11 DEBUG send_request_body.complete
18:50:28,326 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:29,575 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:29 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'790'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'715130dcc15e153f6611ca70089c7fe5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833963eae8db4cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:29,578 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:50:29,578 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:29,579 httpcore.http11 DEBUG receive_response_body.complete
18:50:29,579 httpcore.http11 DEBUG response_closed.started
18:50:29,580 httpcore.http11 DEBUG response_closed.complete
18:50:29,580 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:50:29,581 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:50:33,207 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:50:33,210 httpcore.connection DEBUG close.started
18:50:33,210 httpcore.connection DEBUG close.complete
18:50:33,211 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:50:33,238 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628932790>
18:50:33,239 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:50:33,246 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628932a50>
18:50:33,247 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:33,248 httpcore.http11 DEBUG send_request_headers.complete
18:50:33,248 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:33,249 httpcore.http11 DEBUG send_request_body.complete
18:50:33,249 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:33,460 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'be78f464628fc3d353a5105b7cff7f9f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396409cae94cff-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:33,466 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:50:33,466 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:33,468 httpcore.http11 DEBUG receive_response_body.complete
18:50:33,468 httpcore.http11 DEBUG response_closed.started
18:50:33,469 httpcore.http11 DEBUG response_closed.complete
18:50:33,470 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:50:41,948 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:50:41,954 httpcore.connection DEBUG close.started
18:50:41,955 httpcore.connection DEBUG close.complete
18:50:41,955 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:41,957 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628775910>
18:50:41,958 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:50:41,965 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287778d0>
18:50:41,966 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:41,967 httpcore.http11 DEBUG send_request_headers.complete
18:50:41,967 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:41,968 httpcore.http11 DEBUG send_request_body.complete
18:50:41,968 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:42,643 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'541'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7f27529b00cadc4f4247c07d6699cef0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833964404f6c3bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:42,648 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:50:42,649 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:43,765 httpcore.http11 DEBUG receive_response_body.complete
18:50:43,766 httpcore.http11 DEBUG response_closed.started
18:50:43,767 httpcore.http11 DEBUG response_closed.complete
18:50:43,768 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:50:43,837 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:50:56,523 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:50:56,528 httpcore.connection DEBUG close.started
18:50:56,529 httpcore.connection DEBUG close.complete
18:50:56,529 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:50:56,532 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877a250>
18:50:56,532 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:50:56,540 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628779d90>
18:50:56,541 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:50:56,542 httpcore.http11 DEBUG send_request_headers.complete
18:50:56,543 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:50:56,569 httpcore.http11 DEBUG send_request_body.complete
18:50:56,570 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:50:59,531 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:50:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'33'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'2577'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0e1ae68e8f06a19e6ebc9ec49b8d6d45'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339649b68494d13-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:50:59,535 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:50:59,536 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:50:59,537 httpcore.http11 DEBUG receive_response_body.complete
18:50:59,538 httpcore.http11 DEBUG response_closed.started
18:50:59,539 httpcore.http11 DEBUG response_closed.complete
18:50:59,539 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:50:59,540 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:51:03,175 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:03,178 httpcore.connection DEBUG close.started
18:51:03,178 httpcore.connection DEBUG close.complete
18:51:03,179 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:03,181 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628775b50>
18:51:03,181 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:51:03,189 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287776d0>
18:51:03,190 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:03,191 httpcore.http11 DEBUG send_request_headers.complete
18:51:03,191 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:03,192 httpcore.http11 DEBUG send_request_body.complete
18:51:03,192 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:03,416 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:51:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0c6ff69d1118effaf32c7b60c56b9862'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833964c4fc414ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:03,419 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:03,419 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:03,420 httpcore.http11 DEBUG receive_response_body.complete
18:51:03,421 httpcore.http11 DEBUG response_closed.started
18:51:03,421 httpcore.http11 DEBUG response_closed.complete
18:51:03,421 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:51:17,985 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:51:17,990 httpcore.connection DEBUG close.started
18:51:17,991 httpcore.connection DEBUG close.complete
18:51:17,991 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:17,994 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287782d0>
18:51:17,994 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:51:18,1 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628779590>
18:51:18,2 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:18,3 httpcore.http11 DEBUG send_request_headers.complete
18:51:18,3 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:18,4 httpcore.http11 DEBUG send_request_body.complete
18:51:18,4 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:18,508 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:51:18 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'64fa82d1920c92aaae945692257005b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833965218c843b69-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:18,512 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:51:18,513 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:19,543 httpcore.http11 DEBUG receive_response_body.complete
18:51:19,544 httpcore.http11 DEBUG response_closed.started
18:51:19,544 httpcore.http11 DEBUG response_closed.complete
18:51:19,545 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:51:19,609 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:51:32,229 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:51:32,237 httpcore.connection DEBUG close.started
18:51:32,238 httpcore.connection DEBUG close.complete
18:51:32,238 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:32,241 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877a290>
18:51:32,241 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:51:32,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628779a10>
18:51:32,252 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:32,254 httpcore.http11 DEBUG send_request_headers.complete
18:51:32,255 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:32,278 httpcore.http11 DEBUG send_request_body.complete
18:51:32,278 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:34,773 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:51:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'1'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'2059'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'222c03c2cb3ab18aebb69ff9551b34d0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339657a9c574d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:34,779 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:51:34,780 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:34,782 httpcore.http11 DEBUG receive_response_body.complete
18:51:34,782 httpcore.http11 DEBUG response_closed.started
18:51:34,783 httpcore.http11 DEBUG response_closed.complete
18:51:34,783 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:51:34,784 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 2 column 1 (char 1)
18:52:58,371 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\n\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:58,379 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:58,408 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962878f6d0>
18:52:58,408 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f96289662a0> server_hostname='api.openai.com' timeout=None
18:52:58,416 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628784f50>
18:52:58,416 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:58,416 httpcore.http11 DEBUG send_request_headers.complete
18:52:58,416 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:58,417 httpcore.http11 DEBUG send_request_body.complete
18:52:58,417 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:58,999 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:52:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'494'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e5e107b4483bdc7757695d1cac6771e2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2Nbu6WKY8fxrypT93HrwCx4m5i2tomieidJBD1JU7xw-1702252378-1-AerYuyZgW018Q0CGixRiwmVsB8i+YgiWldRgTNW4l8gIQbRtwOtQ+a1kGEEWnRsz5W/NbSrVkxdO9V6VkxzqXNM=; path=/; expires=Mon, 11-Dec-23 00:22:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=drqGY2bYdARnWxAN7CcBLa5DU0J35kPVnrhZ.Y2chp4-1702252378996-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833967951f743b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:59,0 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:59,1 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:59,1 httpcore.http11 DEBUG receive_response_body.complete
18:52:59,1 httpcore.http11 DEBUG response_closed.started
18:52:59,1 httpcore.http11 DEBUG response_closed.complete
18:52:59,1 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:56:26,580 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\n\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:56:26,585 httpcore.connection DEBUG close.started
18:56:26,586 httpcore.connection DEBUG close.complete
18:56:26,586 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:56:26,618 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288dd650>
18:56:26,619 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:56:26,625 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96288dcd90>
18:56:26,626 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:26,628 httpcore.http11 DEBUG send_request_headers.complete
18:56:26,629 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:26,629 httpcore.http11 DEBUG send_request_body.complete
18:56:26,630 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:26,919 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6425257f1ddea36910a5939992c8d4c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396caa6a5c4ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:26,925 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:56:26,926 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:26,927 httpcore.http11 DEBUG receive_response_body.complete
18:56:26,928 httpcore.http11 DEBUG response_closed.started
18:56:26,928 httpcore.http11 DEBUG response_closed.complete
18:56:26,929 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:56:32,656 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:56:32,660 httpcore.connection DEBUG close.started
18:56:32,661 httpcore.connection DEBUG close.complete
18:56:32,661 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:56:32,664 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628777110>
18:56:32,664 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:56:32,669 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628774e50>
18:56:32,669 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:32,670 httpcore.http11 DEBUG send_request_headers.complete
18:56:32,670 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:32,670 httpcore.http11 DEBUG send_request_body.complete
18:56:32,670 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:33,163 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:33 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'423'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a49c54822889dad1c2a4fe00e0130e4d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396cd039524d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:33,164 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:56:33,165 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:34,319 httpcore.http11 DEBUG receive_response_body.complete
18:56:34,320 httpcore.http11 DEBUG response_closed.started
18:56:34,320 httpcore.http11 DEBUG response_closed.complete
18:56:34,320 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:56:34,386 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:56:47,119 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:56:47,122 httpcore.connection DEBUG close.started
18:56:47,122 httpcore.connection DEBUG close.complete
18:56:47,122 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:56:47,125 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877bad0>
18:56:47,125 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:56:47,130 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877a650>
18:56:47,130 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:47,131 httpcore.http11 DEBUG send_request_headers.complete
18:56:47,131 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:47,148 httpcore.http11 DEBUG send_request_body.complete
18:56:47,149 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:47,882 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:47 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'abd0a6dcdedeb780f8ad9f091e18289c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396d2a99914d12-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:47,884 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:56:47,885 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:47,885 httpcore.http11 DEBUG receive_response_body.complete
18:56:47,886 httpcore.http11 DEBUG response_closed.started
18:56:47,886 httpcore.http11 DEBUG response_closed.complete
18:56:47,887 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:56:47,887 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:56:47,901 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:56:47,903 httpcore.connection DEBUG close.started
18:56:47,903 httpcore.connection DEBUG close.complete
18:56:47,904 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:56:47,906 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628794c10>
18:56:47,906 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:56:47,916 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628795d90>
18:56:47,917 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:47,917 httpcore.http11 DEBUG send_request_headers.complete
18:56:47,917 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:47,918 httpcore.http11 DEBUG send_request_body.complete
18:56:47,918 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:48,120 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7a8196d2b12ce1ae20bff665e08be803'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396d2f79c44cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:48,123 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:56:48,123 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:48,124 httpcore.http11 DEBUG receive_response_body.complete
18:56:48,125 httpcore.http11 DEBUG response_closed.started
18:56:48,125 httpcore.http11 DEBUG response_closed.complete
18:56:48,125 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:56:48,143 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:56:48,152 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:56:48,154 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628797550>
18:56:48,155 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965eb0> server_hostname='api.openai.com' timeout=None
18:56:48,163 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628797510>
18:56:48,163 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:56:48,164 httpcore.http11 DEBUG send_request_headers.complete
18:56:48,164 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:56:48,165 httpcore.http11 DEBUG send_request_body.complete
18:56:48,165 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:56:48,410 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:56:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'de02c87569ed0c5a0120e69c5b3bcfff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=l1b0gmDk1KUQNpG2iqy9jcISzeIYQfuQjBRe4pBes8M-1702252608-1-ATaR8grI+hXMLb98/oAdTT2NFuYBIEjktYg5wGmxzANkGDnCXhRdezXtPTLGDp5SDFS5TuxA/83lNfS8N4rfseQ=; path=/; expires=Mon, 11-Dec-23 00:26:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=hxNJEysRqiJA8M_O5Lyfp0_nj2JFJdECzP3curslDKY-1702252608406-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396d3108804d10-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:56:48,414 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:56:48,415 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:56:48,416 httpcore.http11 DEBUG receive_response_body.complete
18:56:48,417 httpcore.http11 DEBUG response_closed.started
18:56:48,417 httpcore.http11 DEBUG response_closed.complete
18:56:48,417 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:56:56,848 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:56:56,851 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:00,254 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:00,273 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:00,277 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:02,279 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:02,297 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:02,301 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:05,703 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:17,134 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:57:17,139 httpcore.connection DEBUG close.started
18:57:17,139 httpcore.connection DEBUG close.complete
18:57:17,140 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:57:17,142 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287581d0>
18:57:17,143 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:57:17,151 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962875bbd0>
18:57:17,151 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:17,152 httpcore.http11 DEBUG send_request_headers.complete
18:57:17,152 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:17,153 httpcore.http11 DEBUG send_request_body.complete
18:57:17,153 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:17,643 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:57:17 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'34e013a52f342d0cfe4bb0e430087ffe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396de63f104d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:17,645 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:57:17,646 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:18,0 httpcore.http11 DEBUG receive_response_body.complete
18:57:18,1 httpcore.http11 DEBUG response_closed.started
18:57:18,1 httpcore.http11 DEBUG response_closed.complete
18:57:18,1 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:57:18,66 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:57:29,564 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:57:29,567 httpcore.connection DEBUG close.started
18:57:29,568 httpcore.connection DEBUG close.complete
18:57:29,568 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:57:29,596 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628941a50>
18:57:29,596 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:57:29,604 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289405d0>
18:57:29,605 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:29,606 httpcore.http11 DEBUG send_request_headers.complete
18:57:29,606 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:29,632 httpcore.http11 DEBUG send_request_body.complete
18:57:29,632 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:30,528 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:57:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'446'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2b3dd893561ff0b8d9b39ab8d84d485f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396e3408de2ffc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:30,530 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:57:30,530 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:30,530 httpcore.http11 DEBUG receive_response_body.complete
18:57:30,530 httpcore.http11 DEBUG response_closed.started
18:57:30,531 httpcore.http11 DEBUG response_closed.complete
18:57:30,531 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:57:30,531 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:57:30,546 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:57:30,548 httpcore.connection DEBUG close.started
18:57:30,549 httpcore.connection DEBUG close.complete
18:57:30,549 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:57:30,552 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628796710>
18:57:30,552 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:57:30,558 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628795350>
18:57:30,558 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:30,559 httpcore.http11 DEBUG send_request_headers.complete
18:57:30,559 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:30,560 httpcore.http11 DEBUG send_request_body.complete
18:57:30,560 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:30,764 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:57:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7d598fbbec85f3156b902bb4652c2920'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396e39fc594d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:30,765 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:57:30,766 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:30,766 httpcore.http11 DEBUG receive_response_body.complete
18:57:30,767 httpcore.http11 DEBUG response_closed.started
18:57:30,767 httpcore.http11 DEBUG response_closed.complete
18:57:30,767 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:57:30,784 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:57:30,786 httpcore.connection DEBUG close.started
18:57:30,787 httpcore.connection DEBUG close.complete
18:57:30,787 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:57:30,789 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289408d0>
18:57:30,789 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628966720> server_hostname='api.openai.com' timeout=None
18:57:30,795 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628942690>
18:57:30,795 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:30,796 httpcore.http11 DEBUG send_request_headers.complete
18:57:30,796 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:30,796 httpcore.http11 DEBUG send_request_body.complete
18:57:30,797 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:31,238 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:57:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'313'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3984d6a4ef232d7144898f63c420794b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396e3b7bf14cc3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:31,240 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:57:31,242 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:31,243 httpcore.http11 DEBUG receive_response_body.complete
18:57:31,243 httpcore.http11 DEBUG response_closed.started
18:57:31,244 httpcore.http11 DEBUG response_closed.complete
18:57:31,244 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:57:31,256 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:31,259 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:36,960 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:36,972 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:36,975 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:40,977 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:40,989 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:40,992 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:42,994 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:43,8 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:43,11 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:46,413 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:46,425 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:46,428 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:52,129 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:52,136 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:52,140 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:56,741 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:56,752 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:57:56,755 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:57:59,757 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:57:59,760 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:57:59,765 httpcore.connection DEBUG close.started
18:57:59,765 httpcore.connection DEBUG close.complete
18:57:59,766 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:57:59,768 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628944190>
18:57:59,769 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:57:59,775 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628944d90>
18:57:59,776 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:59,776 httpcore.http11 DEBUG send_request_headers.complete
18:57:59,776 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:59,777 httpcore.http11 DEBUG send_request_body.complete
18:57:59,777 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:00,306 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'440'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8098998e25183ca8d93ef168300ff4a3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396ef098273b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:00,309 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:58:00,309 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:01,192 httpcore.http11 DEBUG receive_response_body.complete
18:58:01,192 httpcore.http11 DEBUG response_closed.started
18:58:01,192 httpcore.http11 DEBUG response_closed.complete
18:58:01,193 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:58:01,257 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:58:13,699 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:58:13,704 httpcore.connection DEBUG close.started
18:58:13,704 httpcore.connection DEBUG close.complete
18:58:13,704 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:58:13,739 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289419d0>
18:58:13,739 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:58:13,747 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289427d0>
18:58:13,747 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:13,747 httpcore.http11 DEBUG send_request_headers.complete
18:58:13,748 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:13,769 httpcore.http11 DEBUG send_request_body.complete
18:58:13,769 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:14,470 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a4b14359589a2e376aab6f7e3314b24e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396f47ea604cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:14,472 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:58:14,473 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:14,474 httpcore.http11 DEBUG receive_response_body.complete
18:58:14,474 httpcore.http11 DEBUG response_closed.started
18:58:14,474 httpcore.http11 DEBUG response_closed.complete
18:58:14,474 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:58:14,475 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:58:17,975 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:17,979 httpcore.connection DEBUG close.started
18:58:17,979 httpcore.connection DEBUG close.complete
18:58:17,980 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:17,982 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628796710>
18:58:17,982 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:58:17,987 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628794d10>
18:58:17,987 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:17,988 httpcore.http11 DEBUG send_request_headers.complete
18:58:17,989 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:17,989 httpcore.http11 DEBUG send_request_body.complete
18:58:17,989 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:18,258 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e7d22cb339715ace6dca206daf2ea18e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396f626d0c4d10-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:18,260 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:18,261 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:18,262 httpcore.http11 DEBUG receive_response_body.complete
18:58:18,263 httpcore.http11 DEBUG response_closed.started
18:58:18,263 httpcore.http11 DEBUG response_closed.complete
18:58:18,264 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:20,197 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:20,202 httpcore.connection DEBUG close.started
18:58:20,203 httpcore.connection DEBUG close.complete
18:58:20,203 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:20,206 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877ba10>
18:58:20,206 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965eb0> server_hostname='api.openai.com' timeout=None
18:58:20,212 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628778350>
18:58:20,213 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:20,214 httpcore.http11 DEBUG send_request_headers.complete
18:58:20,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:20,215 httpcore.http11 DEBUG send_request_body.complete
18:58:20,215 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:20,430 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'13009fd7eb152147d2a0e11aa80e2ed1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396f7058913b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:20,437 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:20,438 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:20,440 httpcore.http11 DEBUG receive_response_body.complete
18:58:20,441 httpcore.http11 DEBUG response_closed.started
18:58:20,442 httpcore.http11 DEBUG response_closed.complete
18:58:20,442 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:26,995 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:58:26,999 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:58:30,401 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:58:34,901 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:58:34,905 httpcore.connection DEBUG close.started
18:58:34,906 httpcore.connection DEBUG close.complete
18:58:34,906 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:58:34,935 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289419d0>
18:58:34,936 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:58:34,943 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628940a90>
18:58:34,944 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:34,946 httpcore.http11 DEBUG send_request_headers.complete
18:58:34,946 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:34,948 httpcore.http11 DEBUG send_request_body.complete
18:58:34,948 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:35,439 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'369'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3c63ce22d66981555ff82bb92ad56b1b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83396fcc6def4d16-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:35,446 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:58:35,447 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:35,926 httpcore.http11 DEBUG receive_response_body.complete
18:58:35,927 httpcore.http11 DEBUG response_closed.started
18:58:35,928 httpcore.http11 DEBUG response_closed.complete
18:58:35,929 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:58:36,2 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:58:45,102 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:58:45,108 httpcore.connection DEBUG close.started
18:58:45,109 httpcore.connection DEBUG close.complete
18:58:45,109 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:58:45,112 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962878f2d0>
18:58:45,112 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:58:45,119 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628785990>
18:58:45,119 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:45,121 httpcore.http11 DEBUG send_request_headers.complete
18:58:45,121 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:45,147 httpcore.http11 DEBUG send_request_body.complete
18:58:45,148 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:45,910 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9f58fe9f78da98dbf5db6b8fc123faf3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339700c0a154cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:45,915 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:58:45,915 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:45,916 httpcore.http11 DEBUG receive_response_body.complete
18:58:45,917 httpcore.http11 DEBUG response_closed.started
18:58:45,917 httpcore.http11 DEBUG response_closed.complete
18:58:45,918 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:58:45,918 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:58:49,216 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:49,222 httpcore.connection DEBUG close.started
18:58:49,223 httpcore.connection DEBUG close.complete
18:58:49,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:49,225 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628778350>
18:58:49,226 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965eb0> server_hostname='api.openai.com' timeout=None
18:58:49,231 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877ae50>
18:58:49,231 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:49,232 httpcore.http11 DEBUG send_request_headers.complete
18:58:49,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:49,233 httpcore.http11 DEBUG send_request_body.complete
18:58:49,233 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:49,470 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:58:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'143'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'144c1025b1cb1e8332569fddc4583776'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397025bb634cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:49,474 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:49,475 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:49,476 httpcore.http11 DEBUG receive_response_body.complete
18:58:49,476 httpcore.http11 DEBUG response_closed.started
18:58:49,477 httpcore.http11 DEBUG response_closed.complete
18:58:49,478 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:59:23,890 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nno\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:59:23,891 httpcore.connection DEBUG close.started
18:59:23,891 httpcore.connection DEBUG close.complete
18:59:23,891 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:59:23,893 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877b190>
18:59:23,893 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965f40> server_hostname='api.openai.com' timeout=None
18:59:23,899 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628942ed0>
18:59:23,899 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:59:23,899 httpcore.http11 DEBUG send_request_headers.complete
18:59:23,899 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:59:23,899 httpcore.http11 DEBUG send_request_body.complete
18:59:23,899 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:59:24,121 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:59:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b199193e30ec727f363c2298fe490b97'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833970fe69b24cdc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:59:24,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:59:24,122 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:59:24,123 httpcore.http11 DEBUG receive_response_body.complete
18:59:24,123 httpcore.http11 DEBUG response_closed.started
18:59:24,123 httpcore.http11 DEBUG response_closed.complete
18:59:24,123 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:59:49,237 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:59:49,242 httpcore.connection DEBUG close.started
18:59:49,243 httpcore.connection DEBUG close.complete
18:59:49,244 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:59:49,272 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628922710>
18:59:49,273 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
18:59:49,283 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289024d0>
18:59:49,284 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:59:49,285 httpcore.http11 DEBUG send_request_headers.complete
18:59:49,285 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:59:49,285 httpcore.http11 DEBUG send_request_body.complete
18:59:49,285 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:59:49,860 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 10 Dec 2023 23:59:49 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6feaa47a260ac3fbf86e01074fc1dabe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339719d0eb94d02-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:59:49,862 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:59:49,863 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:59:51,145 httpcore.http11 DEBUG receive_response_body.complete
18:59:51,146 httpcore.http11 DEBUG response_closed.started
18:59:51,146 httpcore.http11 DEBUG response_closed.complete
18:59:51,147 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:59:51,213 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:00:04,443 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:00:04,445 httpcore.connection DEBUG close.started
19:00:04,445 httpcore.connection DEBUG close.complete
19:00:04,446 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:00:04,448 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289420d0>
19:00:04,448 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
19:00:04,454 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96289416d0>
19:00:04,454 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:00:04,455 httpcore.http11 DEBUG send_request_headers.complete
19:00:04,455 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:00:04,479 httpcore.http11 DEBUG send_request_body.complete
19:00:04,479 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:00:06,189 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:00:06 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1210'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'41f2b3ffc6195944e30d574d9b33160e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833971fbdf0c4d16-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:00:06,191 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:00:06,192 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:00:06,192 httpcore.http11 DEBUG receive_response_body.complete
19:00:06,193 httpcore.http11 DEBUG response_closed.started
19:00:06,193 httpcore.http11 DEBUG response_closed.complete
19:00:06,194 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:00:06,194 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:00:06,209 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:00:06,211 httpcore.connection DEBUG close.started
19:00:06,211 httpcore.connection DEBUG close.complete
19:00:06,212 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:00:06,214 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f96287787d0>
19:00:06,214 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965eb0> server_hostname='api.openai.com' timeout=None
19:00:06,221 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877ad10>
19:00:06,222 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:00:06,222 httpcore.http11 DEBUG send_request_headers.complete
19:00:06,223 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:00:06,224 httpcore.http11 DEBUG send_request_body.complete
19:00:06,224 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:00:06,469 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:00:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fd26bf6744d78ec7a7cfea440cfbcd97'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397206e9863b6f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:00:06,472 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:00:06,472 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:00:06,473 httpcore.http11 DEBUG receive_response_body.complete
19:00:06,474 httpcore.http11 DEBUG response_closed.started
19:00:06,474 httpcore.http11 DEBUG response_closed.complete
19:00:06,474 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:00:41,349 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit? You can say move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:00:41,355 httpcore.connection DEBUG close.started
19:00:41,356 httpcore.connection DEBUG close.complete
19:00:41,356 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:00:41,359 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9628796590>
19:00:41,360 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9628965d90> server_hostname='api.openai.com' timeout=5.0
19:00:41,368 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f962877a490>
19:00:41,369 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:00:41,370 httpcore.http11 DEBUG send_request_headers.complete
19:00:41,370 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:00:41,371 httpcore.http11 DEBUG send_request_body.complete
19:00:41,371 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:00:42,64 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:00:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'554'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ff266b7e5b619e675155c96a34d4d8ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833972e29d7c6ac5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:00:42,69 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:00:42,70 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:00:43,165 httpcore.http11 DEBUG receive_response_body.complete
19:00:43,166 httpcore.http11 DEBUG response_closed.started
19:00:43,167 httpcore.http11 DEBUG response_closed.complete
19:00:43,168 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:00:43,238 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:04:52,65 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,68 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:52,863 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,864 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:52,904 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,905 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:52,948 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,949 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:52,990 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:52,991 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,39 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:53,40 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,78 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:53,79 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,120 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:53,121 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,158 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:04:53,158 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:04:53,199 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:04:53,212 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:04:53,242 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646adf2250>
19:04:53,242 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:04:53,252 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646adf2810>
19:04:53,253 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:53,254 httpcore.http11 DEBUG send_request_headers.complete
19:04:53,254 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:53,255 httpcore.http11 DEBUG send_request_body.complete
19:04:53,255 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:53,724 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:04:53 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'01614ab28a0763ded7a2cfd79fbbd4ed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dESuM6846RyfB.hkjjnVnyGPkbDEMLXZ694ApVICkWk-1702253093-1-AQznIs2m4B1gYs8bwcefcEJBxAIuOm2kkT2O31utPeOF+sU2JDIpmwBHcMXqyH8lB+4qMq7utqpSbZJGls2IBiI=; path=/; expires=Mon, 11-Dec-23 00:34:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=W4iiWQ.QBaNdeHOB4fr9UjOUK9s9Qr1YHTRQAbd5Aiw-1702253093718-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397908dc463b7c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:53,730 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:04:53,731 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:54,322 httpcore.http11 DEBUG receive_response_body.complete
19:04:54,323 httpcore.http11 DEBUG response_closed.started
19:04:54,323 httpcore.http11 DEBUG response_closed.complete
19:04:54,324 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:04:54,396 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:05:07,540 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:05:07,549 httpcore.connection DEBUG close.started
19:05:07,549 httpcore.connection DEBUG close.complete
19:05:07,550 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:07,552 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646adf2b50>
19:05:07,552 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:05:07,560 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646adf29d0>
19:05:07,560 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:07,561 httpcore.http11 DEBUG send_request_headers.complete
19:05:07,561 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:07,591 httpcore.http11 DEBUG send_request_body.complete
19:05:07,591 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:08,522 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:08 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'35'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'443'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'981891826e3e5296916c85c8d4fbfa08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833979624a4e3010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:08,524 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:05:08,525 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:08,525 httpcore.http11 DEBUG receive_response_body.complete
19:05:08,526 httpcore.http11 DEBUG response_closed.started
19:05:08,526 httpcore.http11 DEBUG response_closed.complete
19:05:08,526 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:05:08,527 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:05:08,545 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\ncut it on the top side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:08,553 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:08,555 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae47f90>
19:05:08,555 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81f40> server_hostname='api.openai.com' timeout=None
19:05:08,561 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae46650>
19:05:08,562 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:08,562 httpcore.http11 DEBUG send_request_headers.complete
19:05:08,562 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:08,563 httpcore.http11 DEBUG send_request_body.complete
19:05:08,563 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:08,802 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5945d6a6abe356cd61c26b002235acc4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ItZGKj4_iuKzLzArP9GKrwnuCvkor454v1XT2CveRCQ-1702253108-1-AVCPhtaW4t7yi+pfPJbQO57oAdVmMRrdlYyBu9ZJg4T9j3gLzOCuyuOWJ4Wf5FHcKiw4K34NkkjSYlpMcmxXkAU=; path=/; expires=Mon, 11-Dec-23 00:35:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=iMjtDbae7eW7Jkt3D._jO.8Al4mK3DZJKekBO38FKaw-1702253108798-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397968880c4cde-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:08,805 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:08,806 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:08,807 httpcore.http11 DEBUG receive_response_body.complete
19:05:08,808 httpcore.http11 DEBUG response_closed.started
19:05:08,808 httpcore.http11 DEBUG response_closed.complete
19:05:08,809 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:08,825 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\ncut it on the top side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:08,833 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:08,835 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae33390>
19:05:08,835 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae82720> server_hostname='api.openai.com' timeout=None
19:05:08,840 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae330d0>
19:05:08,840 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:08,841 httpcore.http11 DEBUG send_request_headers.complete
19:05:08,841 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:08,841 httpcore.http11 DEBUG send_request_body.complete
19:05:08,842 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:09,276 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'333'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6fcd2763f6dbaba60f6fea777bdbcd57'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aetaN_7AzM4xIzp5BgKomDridy1Z7dZI2sk6OQBWx94-1702253109-1-ASHVdXjw0WlVFxI+SKtiL6T8rTV/HjsnhqG2OAvJg849NohdDlcBm7qYyRGj8u6Al+8V5Fz0Ujb2L/0t1uY+yLA=; path=/; expires=Mon, 11-Dec-23 00:35:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=DU0NwkrszD9FxxQn_.OhZ9ZcnUWeDC64iKVTZwl5IfI-1702253109272-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339796a48a04d0e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:09,279 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:09,279 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:09,281 httpcore.http11 DEBUG receive_response_body.complete
19:05:09,281 httpcore.http11 DEBUG response_closed.started
19:05:09,281 httpcore.http11 DEBUG response_closed.complete
19:05:09,282 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:09,293 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:09,297 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:15,3 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:15,14 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:15,20 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:19,21 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:19,32 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:19,35 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:21,36 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:21,47 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:21,51 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:24,453 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:24,462 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:24,466 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:30,168 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:30,183 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:30,185 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:33,586 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:33,598 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:33,601 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:38,202 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:38,205 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:05:38,210 httpcore.connection DEBUG close.started
19:05:38,210 httpcore.connection DEBUG close.complete
19:05:38,211 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:38,213 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646cc20b50>
19:05:38,214 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:05:38,220 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac77d10>
19:05:38,220 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:38,221 httpcore.http11 DEBUG send_request_headers.complete
19:05:38,221 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:38,221 httpcore.http11 DEBUG send_request_body.complete
19:05:38,221 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:38,775 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'479'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'649a1c477a4b09aabbc12d8b7934d0c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397a21e8323b69-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:38,777 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:05:38,777 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:39,987 httpcore.http11 DEBUG receive_response_body.complete
19:05:39,988 httpcore.http11 DEBUG response_closed.started
19:05:39,988 httpcore.http11 DEBUG response_closed.complete
19:05:39,989 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:05:40,55 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:05:52,967 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:05:52,970 httpcore.connection DEBUG close.started
19:05:52,970 httpcore.connection DEBUG close.complete
19:05:52,971 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:52,973 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac85d10>
19:05:52,973 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:05:52,980 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac85d90>
19:05:52,981 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:52,981 httpcore.http11 DEBUG send_request_headers.complete
19:05:52,981 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:53,18 httpcore.http11 DEBUG send_request_body.complete
19:05:53,19 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:53,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:53 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'405'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ef68ed35dc140ff690f2103ede31794a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397a7e2f704d07-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:53,823 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:05:53,823 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:53,824 httpcore.http11 DEBUG receive_response_body.complete
19:05:53,824 httpcore.http11 DEBUG response_closed.started
19:05:53,825 httpcore.http11 DEBUG response_closed.complete
19:05:53,825 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:05:53,826 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:05:57,210 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nOh.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:57,213 httpcore.connection DEBUG close.started
19:05:57,213 httpcore.connection DEBUG close.complete
19:05:57,214 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:57,243 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae5bc90>
19:05:57,244 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81f40> server_hostname='api.openai.com' timeout=None
19:05:57,252 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae58790>
19:05:57,252 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:57,254 httpcore.http11 DEBUG send_request_headers.complete
19:05:57,255 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:57,256 httpcore.http11 DEBUG send_request_body.complete
19:05:57,256 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:57,468 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:05:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1f20efe55a5d1e0345b937078f96611d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397a98d8c24ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:57,470 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:57,471 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:57,471 httpcore.http11 DEBUG receive_response_body.complete
19:05:57,472 httpcore.http11 DEBUG response_closed.started
19:05:57,472 httpcore.http11 DEBUG response_closed.complete
19:05:57,472 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:02,661 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nOh.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:02,675 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:02,678 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac903d0>
19:06:02,679 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae822a0> server_hostname='api.openai.com' timeout=None
19:06:02,684 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac91050>
19:06:02,684 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:02,685 httpcore.http11 DEBUG send_request_headers.complete
19:06:02,685 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:02,686 httpcore.http11 DEBUG send_request_body.complete
19:06:02,686 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:03,788 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1001'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c44e1303a4034029e11d2ac0cdc146c2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0npIv6NSko5cMLcvxuaJNli2IjCUECXPVCCeDEgppw8-1702253163-1-AUpw/cGcdGii3vElQgkWsjswCx6Jry4LMzS8sWvSThYYeJNPaEzZKP2NFQHSTRvseBKhDeDd9ACPk2YWcy5u5cs=; path=/; expires=Mon, 11-Dec-23 00:36:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fXnQVEzXI2CaEfRmE7apDqRly4HJKj3N6xV3M2i5ahE-1702253163784-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397abacdb13b7c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:03,795 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:03,795 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:03,796 httpcore.http11 DEBUG receive_response_body.complete
19:06:03,797 httpcore.http11 DEBUG response_closed.started
19:06:03,797 httpcore.http11 DEBUG response_closed.complete
19:06:03,797 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:05,38 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:05,47 httpcore.connection DEBUG close.started
19:06:05,48 httpcore.connection DEBUG close.complete
19:06:05,48 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:05,51 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac85c50>
19:06:05,52 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:06:05,60 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac85e90>
19:06:05,61 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:05,63 httpcore.http11 DEBUG send_request_headers.complete
19:06:05,63 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:05,64 httpcore.http11 DEBUG send_request_body.complete
19:06:05,65 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:05,847 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'564'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b9add2be188b537381b5ccd8fa317bd9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397ac9ae394cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:05,853 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:05,854 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:06,803 httpcore.http11 DEBUG receive_response_body.complete
19:06:06,804 httpcore.http11 DEBUG response_closed.started
19:06:06,805 httpcore.http11 DEBUG response_closed.complete
19:06:06,805 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:06,872 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:19,598 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:19,603 httpcore.connection DEBUG close.started
19:06:19,603 httpcore.connection DEBUG close.complete
19:06:19,603 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:19,606 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae47a90>
19:06:19,606 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:06:19,612 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae44810>
19:06:19,612 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:19,613 httpcore.http11 DEBUG send_request_headers.complete
19:06:19,614 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:19,637 httpcore.http11 DEBUG send_request_body.complete
19:06:19,637 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:20,644 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:20 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'8'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'609'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'adceeb6d508d75fd45d5497b71effa72'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397b2498d34cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:20,650 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:20,650 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:20,651 httpcore.http11 DEBUG receive_response_body.complete
19:06:20,651 httpcore.http11 DEBUG response_closed.started
19:06:20,652 httpcore.http11 DEBUG response_closed.complete
19:06:20,652 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:20,652 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:24,513 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nUh, no.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:24,517 httpcore.connection DEBUG close.started
19:06:24,518 httpcore.connection DEBUG close.complete
19:06:24,518 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:24,521 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae5abd0>
19:06:24,521 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81f40> server_hostname='api.openai.com' timeout=None
19:06:24,525 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae5aa50>
19:06:24,526 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:24,527 httpcore.http11 DEBUG send_request_headers.complete
19:06:24,527 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:24,528 httpcore.http11 DEBUG send_request_body.complete
19:06:24,528 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:24,741 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7de66aacde0adf9cc07b444d138ba67a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397b434b6e3074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:24,747 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:24,747 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:24,749 httpcore.http11 DEBUG receive_response_body.complete
19:06:24,749 httpcore.http11 DEBUG response_closed.started
19:06:24,749 httpcore.http11 DEBUG response_closed.complete
19:06:24,750 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:26,789 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, no, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nUh, no.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:26,801 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:26,804 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac90e90>
19:06:26,804 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81eb0> server_hostname='api.openai.com' timeout=None
19:06:26,813 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac922d0>
19:06:26,813 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:26,814 httpcore.http11 DEBUG send_request_headers.complete
19:06:26,815 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:26,815 httpcore.http11 DEBUG send_request_body.complete
19:06:26,816 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:27,40 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b23a57b1b0251625c1d98df71dfde876'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=eLZwTFFPiSLwRnPkFp0PFKZZT9RRbiJngEUjxEd7Gwg-1702253187-1-ATwMl4PmTrW9Yd3jhEA+qdKONou/s9/1LJ/fvNaxwy7Uf3jT5EDml0lAE6HLX+mkQZUpuvLrLMvR9QCPtEQbxVU=; path=/; expires=Mon, 11-Dec-23 00:36:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=6MiRwbsX26ULPrnemN6iY.ex.nIWfqaUArcnuhhcA7M-1702253187034-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397b519cc63049-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:27,46 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:27,47 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:27,48 httpcore.http11 DEBUG receive_response_body.complete
19:06:27,48 httpcore.http11 DEBUG response_closed.started
19:06:27,49 httpcore.http11 DEBUG response_closed.complete
19:06:27,49 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:35,32 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit (You can say move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:35,40 httpcore.connection DEBUG close.started
19:06:35,41 httpcore.connection DEBUG close.complete
19:06:35,42 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:35,44 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae44810>
19:06:35,44 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:06:35,48 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae47850>
19:06:35,49 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:35,50 httpcore.http11 DEBUG send_request_headers.complete
19:06:35,50 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:35,50 httpcore.http11 DEBUG send_request_body.complete
19:06:35,51 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:35,566 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a9abb3bb5abb82b9dea3e723652ca976'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397b851be53045-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:35,571 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:35,572 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:36,823 httpcore.http11 DEBUG receive_response_body.complete
19:06:36,824 httpcore.http11 DEBUG response_closed.started
19:06:36,825 httpcore.http11 DEBUG response_closed.complete
19:06:36,826 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:36,897 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:50,5 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:50,9 httpcore.connection DEBUG close.started
19:06:50,10 httpcore.connection DEBUG close.complete
19:06:50,10 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:50,13 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac975d0>
19:06:50,13 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:06:50,19 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac97650>
19:06:50,19 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:50,20 httpcore.http11 DEBUG send_request_headers.complete
19:06:50,21 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:50,45 httpcore.http11 DEBUG send_request_body.complete
19:06:50,45 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:50,931 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:50 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'345'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'098c19f748ac1ec7cc5322b29d2ebb6b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397be2ac786aca-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:50,935 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:50,936 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:50,937 httpcore.http11 DEBUG receive_response_body.complete
19:06:50,937 httpcore.http11 DEBUG response_closed.started
19:06:50,938 httpcore.http11 DEBUG response_closed.complete
19:06:50,938 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:50,939 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:53,491 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit (You can say move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:53,495 httpcore.connection DEBUG close.started
19:06:53,495 httpcore.connection DEBUG close.complete
19:06:53,496 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:53,498 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac954d0>
19:06:53,498 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81eb0> server_hostname='api.openai.com' timeout=None
19:06:53,509 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac94310>
19:06:53,510 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:53,511 httpcore.http11 DEBUG send_request_headers.complete
19:06:53,511 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:53,512 httpcore.http11 DEBUG send_request_body.complete
19:06:53,512 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:53,745 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:06:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'192b9517dbf3538510b63ac62462e5b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397bf878384cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:53,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:53,752 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:53,753 httpcore.http11 DEBUG receive_response_body.complete
19:06:53,754 httpcore.http11 DEBUG response_closed.started
19:06:53,754 httpcore.http11 DEBUG response_closed.complete
19:06:53,755 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:58,940 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:58,944 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:02,347 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:07:02,349 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location or should I move a bit?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:07:02,351 httpcore.connection DEBUG close.started
19:07:02,351 httpcore.connection DEBUG close.complete
19:07:02,352 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:07:02,381 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac97510>
19:07:02,382 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:07:02,390 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac95e10>
19:07:02,390 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:02,391 httpcore.http11 DEBUG send_request_headers.complete
19:07:02,392 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:02,392 httpcore.http11 DEBUG send_request_body.complete
19:07:02,392 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:03,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:07:03 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'546'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'aea29359e8c3026e1afb29a2b4d70471'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397c2ff94d3008-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:03,25 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:07:03,26 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:03,538 httpcore.http11 DEBUG receive_response_body.complete
19:07:03,539 httpcore.http11 DEBUG response_closed.started
19:07:03,539 httpcore.http11 DEBUG response_closed.complete
19:07:03,540 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:07:03,610 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:07:12,863 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:07:12,868 httpcore.connection DEBUG close.started
19:07:12,868 httpcore.connection DEBUG close.complete
19:07:12,868 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:07:12,871 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646b07a010>
19:07:12,871 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81d90> server_hostname='api.openai.com' timeout=5.0
19:07:12,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae336d0>
19:07:12,876 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:12,877 httpcore.http11 DEBUG send_request_headers.complete
19:07:12,877 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:12,896 httpcore.http11 DEBUG send_request_body.complete
19:07:12,897 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:13,687 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:07:13 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'335'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'118fd1932b830071819641c7395c6af0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397c717b1c4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:13,689 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:07:13,690 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:13,690 httpcore.http11 DEBUG receive_response_body.complete
19:07:13,691 httpcore.http11 DEBUG response_closed.started
19:07:13,691 httpcore.http11 DEBUG response_closed.complete
19:07:13,692 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:07:13,692 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:07:13,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location or should I move a bit?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:07:13,709 httpcore.connection DEBUG close.started
19:07:13,710 httpcore.connection DEBUG close.complete
19:07:13,710 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:07:13,712 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ac96ad0>
19:07:13,712 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f646ae81eb0> server_hostname='api.openai.com' timeout=None
19:07:13,719 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f646ae474d0>
19:07:13,719 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:13,720 httpcore.http11 DEBUG send_request_headers.complete
19:07:13,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:13,720 httpcore.http11 DEBUG send_request_body.complete
19:07:13,720 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:13,960 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:07:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'142'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'35d0d7388bb26d42af9cb47949ae1b31'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83397c76ca594cee-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:13,963 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:07:13,964 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:13,965 httpcore.http11 DEBUG receive_response_body.complete
19:07:13,965 httpcore.http11 DEBUG response_closed.started
19:07:13,965 httpcore.http11 DEBUG response_closed.complete
19:07:13,966 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:10:17,213 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:17,217 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,31 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,32 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,71 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,72 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,113 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,114 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,150 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,151 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,191 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,192 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,229 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,230 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,270 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,271 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,307 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:10:18,308 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:10:18,347 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:10:18,358 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:10:18,390 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb0a610>
19:10:18,390 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:10:18,401 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb0ab90>
19:10:18,402 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:10:18,404 httpcore.http11 DEBUG send_request_headers.complete
19:10:18,404 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:10:18,404 httpcore.http11 DEBUG send_request_body.complete
19:10:18,405 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:10:18,915 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:10:18 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'402'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5d490dfa44f6f14a787a936e69922df4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LZJybGucfFmLR5hBp_eUm8WSZm5L65ZUt9g7LmKD4Ek-1702253418-1-ASDC2EsgNJRJ193GXXbPKX+ypUUbL3LaleFTbToMPpblsdjNNa+58GZqK8pcg7e3ERO562xAPnetBvsOGZzaNYc=; path=/; expires=Mon, 11-Dec-23 00:40:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=swQjQTXv6Y1v_ThahLWut_wLr4EYnrh0Tj5FLfBoWiQ-1702253418909-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833980f90b394cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:10:18,922 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:10:18,923 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:10:19,421 httpcore.http11 DEBUG receive_response_body.complete
19:10:19,421 httpcore.http11 DEBUG response_closed.started
19:10:19,422 httpcore.http11 DEBUG response_closed.complete
19:10:19,422 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:10:19,494 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:10:33,117 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:10:33,128 httpcore.connection DEBUG close.started
19:10:33,128 httpcore.connection DEBUG close.complete
19:10:33,128 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:10:33,131 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb0ac90>
19:10:33,131 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:10:33,136 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb09fd0>
19:10:33,137 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:10:33,137 httpcore.http11 DEBUG send_request_headers.complete
19:10:33,137 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:10:33,175 httpcore.http11 DEBUG send_request_body.complete
19:10:33,176 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:10:34,9 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:10:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'373'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'84d01f3ec7031c2ae88951640902b94e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339815519594cf5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:10:34,12 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:10:34,12 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:10:34,13 httpcore.http11 DEBUG receive_response_body.complete
19:10:34,14 httpcore.http11 DEBUG response_closed.started
19:10:34,14 httpcore.http11 DEBUG response_closed.complete
19:10:34,14 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:10:34,15 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:10:34,36 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:10:34,46 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:10:34,49 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb5fa90>
19:10:34,49 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99fd0> server_hostname='api.openai.com' timeout=None
19:10:34,54 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb5f210>
19:10:34,54 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:10:34,54 httpcore.http11 DEBUG send_request_headers.complete
19:10:34,55 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:10:34,55 httpcore.http11 DEBUG send_request_body.complete
19:10:34,55 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:10:34,262 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:10:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd2c312ecd0fd90d2f92088f2c5691559'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XZ._7QVjqThqBzCZc7I4QYdw6Y09Id.CraUDJNOi4IQ-1702253434-1-AWnH1nS6NOYyNcEvfwHRnVTMQj1nZNMyFMXYDcVGyDc/lMfRIaYBZ7UeEKIBCmwhaZD+1R7g1XRjEReUMawky8I=; path=/; expires=Mon, 11-Dec-23 00:40:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=hxw_U_uC4RfkR5HM3Bse4DwfnWVjvSvk_LAnuge9Sxo-1702253434257-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339815ad9c84ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:10:34,265 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:10:34,266 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:10:34,266 httpcore.http11 DEBUG receive_response_body.complete
19:10:34,267 httpcore.http11 DEBUG response_closed.started
19:10:34,267 httpcore.http11 DEBUG response_closed.complete
19:10:34,267 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:10:34,285 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:10:34,295 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:10:34,298 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb02d90>
19:10:34,298 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd9a7b0> server_hostname='api.openai.com' timeout=None
19:10:34,308 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb4bf90>
19:10:34,308 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:10:34,309 httpcore.http11 DEBUG send_request_headers.complete
19:10:34,309 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:10:34,309 httpcore.http11 DEBUG send_request_body.complete
19:10:34,310 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:10:35,118 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:10:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'704'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fc56da9d1ef2c819507d3e33fb62c078'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=USq6VtGe5hn_6gjxC9o0.USFNHcNTTUbfzVb8FKeFHM-1702253435-1-AUIq1Oe2SX4c8BeGyG5VSMwz7WBk/3tV7UfvEyWw0N6t7WSchvLvzBvv30DIPCvmqae0yUYcJA/L1hxohz4nm2g=; path=/; expires=Mon, 11-Dec-23 00:40:35 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RHwP0.OkQDnX07ou3aWMe72tXeLMBZx_0._GsbX75oU-1702253435114-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339815c6f524cf6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:10:35,122 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:10:35,122 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:10:35,122 httpcore.http11 DEBUG receive_response_body.complete
19:10:35,123 httpcore.http11 DEBUG response_closed.started
19:10:35,123 httpcore.http11 DEBUG response_closed.complete
19:10:35,123 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:10:35,135 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:35,138 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:40,844 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:40,856 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:40,858 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:44,859 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:44,871 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:44,875 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:46,877 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:46,889 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:46,893 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:50,294 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:50,305 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:50,307 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:10:56,8 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:10:56,20 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:10:56,22 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:11:00,223 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:11:00,235 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:11:00,239 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:11:04,440 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:11:04,444 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:11:04,448 httpcore.connection DEBUG close.started
19:11:04,448 httpcore.connection DEBUG close.complete
19:11:04,449 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:04,451 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb09fd0>
19:11:04,451 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:04,458 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb4b610>
19:11:04,459 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:04,460 httpcore.http11 DEBUG send_request_headers.complete
19:11:04,460 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:04,461 httpcore.http11 DEBUG send_request_body.complete
19:11:04,461 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:05,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'545'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4c0412f9f2d4fafd5ddcb53ce48941dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398218ed1a4ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:05,128 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:11:05,128 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:06,235 httpcore.http11 DEBUG receive_response_body.complete
19:11:06,235 httpcore.http11 DEBUG response_closed.started
19:11:06,236 httpcore.http11 DEBUG response_closed.complete
19:11:06,236 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:11:06,301 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:11:19,286 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:11:19,292 httpcore.connection DEBUG close.started
19:11:19,293 httpcore.connection DEBUG close.complete
19:11:19,294 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:19,324 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9de90>
19:11:19,324 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:19,333 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9df10>
19:11:19,333 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:19,334 httpcore.http11 DEBUG send_request_headers.complete
19:11:19,335 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:19,355 httpcore.http11 DEBUG send_request_body.complete
19:11:19,356 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:19,971 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:19 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'354'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1ed6cdaffce3d60a68b7786c24da913c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398275d96b3010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:19,974 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:11:19,974 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:19,975 httpcore.http11 DEBUG receive_response_body.complete
19:11:19,975 httpcore.http11 DEBUG response_closed.started
19:11:19,975 httpcore.http11 DEBUG response_closed.complete
19:11:19,976 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:11:19,976 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:11:22,314 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nOh.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:11:22,318 httpcore.connection DEBUG close.started
19:11:22,318 httpcore.connection DEBUG close.complete
19:11:22,319 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:11:22,321 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb6d090>
19:11:22,321 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99fd0> server_hostname='api.openai.com' timeout=None
19:11:22,326 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb6e3d0>
19:11:22,327 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:22,328 httpcore.http11 DEBUG send_request_headers.complete
19:11:22,328 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:22,329 httpcore.http11 DEBUG send_request_body.complete
19:11:22,329 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:22,531 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5730482f489141ec295f76bba0075e4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833982888a233b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:22,535 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:11:22,536 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:22,537 httpcore.http11 DEBUG receive_response_body.complete
19:11:22,538 httpcore.http11 DEBUG response_closed.started
19:11:22,538 httpcore.http11 DEBUG response_closed.complete
19:11:22,538 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:11:24,759 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nOh.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:11:24,770 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:11:24,773 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9a85d0>
19:11:24,773 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd9a330> server_hostname='api.openai.com' timeout=None
19:11:24,781 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9a8550>
19:11:24,782 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:24,784 httpcore.http11 DEBUG send_request_headers.complete
19:11:24,784 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:24,785 httpcore.http11 DEBUG send_request_body.complete
19:11:24,785 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:26,6 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ebc1359c965e011a6fa1bb5e6d8e7ba2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mhuKJsxI_0iL.juMxcOFpM92dL0037qBgi.0MCaWuuM-1702253486-1-AUsUIWTeeEPgfUsrMn2rS87dAv1Awj9MB8kMt9wk9fKsnwc/xDxs0/GgptdNQ91khKpUR+1foS7dtUpQplE53+s=; path=/; expires=Mon, 11-Dec-23 00:41:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=95Sa335F2n9dF_YueM6XNRKuW22uN07m8g5Kh4UUOLE-1702253486001-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398297ee744cef-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:26,14 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:11:26,15 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:26,17 httpcore.http11 DEBUG receive_response_body.complete
19:11:26,18 httpcore.http11 DEBUG response_closed.started
19:11:26,18 httpcore.http11 DEBUG response_closed.complete
19:11:26,18 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:11:27,383 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:11:27,387 httpcore.connection DEBUG close.started
19:11:27,387 httpcore.connection DEBUG close.complete
19:11:27,388 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:27,390 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb5f3d0>
19:11:27,390 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:27,396 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb5f790>
19:11:27,396 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:27,397 httpcore.http11 DEBUG send_request_headers.complete
19:11:27,398 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:27,398 httpcore.http11 DEBUG send_request_body.complete
19:11:27,398 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:28,95 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:28 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'571'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c4a563a85d747358f9a6f46debcdb37f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833982a838a83031-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:28,99 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:11:28,99 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:29,127 httpcore.http11 DEBUG receive_response_body.complete
19:11:29,128 httpcore.http11 DEBUG response_closed.started
19:11:29,129 httpcore.http11 DEBUG response_closed.complete
19:11:29,130 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:11:29,199 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:11:42,93 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:11:42,98 httpcore.connection DEBUG close.started
19:11:42,99 httpcore.connection DEBUG close.complete
19:11:42,99 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:42,101 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9e250>
19:11:42,102 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:42,107 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9e0d0>
19:11:42,107 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:42,108 httpcore.http11 DEBUG send_request_headers.complete
19:11:42,109 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:42,130 httpcore.http11 DEBUG send_request_body.complete
19:11:42,131 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:42,929 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:42 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'402'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2ea10db861527f1d4492dd03a68b8296'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833983042a4a6ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:42,935 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:11:42,936 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:42,937 httpcore.http11 DEBUG receive_response_body.complete
19:11:42,937 httpcore.http11 DEBUG response_closed.started
19:11:42,938 httpcore.http11 DEBUG response_closed.complete
19:11:42,938 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:11:42,938 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:11:44,745 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:11:44,748 httpcore.connection DEBUG close.started
19:11:44,749 httpcore.connection DEBUG close.complete
19:11:44,749 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:11:44,751 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb6de90>
19:11:44,752 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99fd0> server_hostname='api.openai.com' timeout=None
19:11:44,757 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb6cd50>
19:11:44,758 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:44,759 httpcore.http11 DEBUG send_request_headers.complete
19:11:44,759 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:44,760 httpcore.http11 DEBUG send_request_body.complete
19:11:44,760 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:44,987 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a3ba143a16836bb44b8a444b1eb22896'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398314ba343049-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:44,994 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:11:44,994 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:44,995 httpcore.http11 DEBUG receive_response_body.complete
19:11:44,995 httpcore.http11 DEBUG response_closed.started
19:11:44,996 httpcore.http11 DEBUG response_closed.complete
19:11:44,996 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:11:47,338 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:11:47,349 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:11:47,352 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9f610>
19:11:47,352 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99f40> server_hostname='api.openai.com' timeout=None
19:11:47,359 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb1b510>
19:11:47,359 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:47,361 httpcore.http11 DEBUG send_request_headers.complete
19:11:47,361 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:47,361 httpcore.http11 DEBUG send_request_body.complete
19:11:47,362 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:11:47,633 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:11:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ade5b778b8ad7a61eb56a96fdb69289b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GRcshvpM7rmVWC_BRwWKoIjRONantNguu7AHtEDDBPU-1702253507-1-AY/rIszYphaZU2HMpPuit6LO9RMrGTM48W+QcFGqvWRsDJhyhPWuBouBTG1jBwIru49MjxragjdwYUBMdAHCvTc=; path=/; expires=Mon, 11-Dec-23 00:41:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3BjPo21y.M24TEVsVScq_JbAH0v1h8.kMZ8OHBIOOM4-1702253507628-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833983250c983b7b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:11:47,641 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:11:47,642 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:11:47,643 httpcore.http11 DEBUG receive_response_body.complete
19:11:47,643 httpcore.http11 DEBUG response_closed.started
19:11:47,643 httpcore.http11 DEBUG response_closed.complete
19:11:47,644 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:11:59,601 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:11:59,607 httpcore.connection DEBUG close.started
19:11:59,607 httpcore.connection DEBUG close.complete
19:11:59,608 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:11:59,610 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb71550>
19:11:59,611 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:11:59,616 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb70310>
19:11:59,616 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:11:59,617 httpcore.http11 DEBUG send_request_headers.complete
19:11:59,617 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:11:59,618 httpcore.http11 DEBUG send_request_body.complete
19:11:59,618 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:00,74 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'24e828a0f6c7c08a9de6fddb1dc717d8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833983719c04304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:00,79 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:12:00,80 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:01,152 httpcore.http11 DEBUG receive_response_body.complete
19:12:01,152 httpcore.http11 DEBUG response_closed.started
19:12:01,153 httpcore.http11 DEBUG response_closed.complete
19:12:01,153 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:12:01,223 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:12:13,52 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:12:13,58 httpcore.connection DEBUG close.started
19:12:13,58 httpcore.connection DEBUG close.complete
19:12:13,59 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:12:13,61 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3b10>
19:12:13,61 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:12:13,69 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3310>
19:12:13,70 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:13,71 httpcore.http11 DEBUG send_request_headers.complete
19:12:13,71 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:13,95 httpcore.http11 DEBUG send_request_body.complete
19:12:13,96 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:14,152 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'342'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5e44b9cfa208a8540e6f19041f929e3f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833983c5b8033068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:14,158 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:12:14,159 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:14,161 httpcore.http11 DEBUG receive_response_body.complete
19:12:14,161 httpcore.http11 DEBUG response_closed.started
19:12:14,162 httpcore.http11 DEBUG response_closed.complete
19:12:14,162 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:12:14,163 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:12:28,338 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:12:28,344 httpcore.connection DEBUG close.started
19:12:28,344 httpcore.connection DEBUG close.complete
19:12:28,345 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:12:28,374 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb9e1d0>
19:12:28,375 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99f40> server_hostname='api.openai.com' timeout=None
19:12:28,381 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb1b510>
19:12:28,381 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:28,382 httpcore.http11 DEBUG send_request_headers.complete
19:12:28,382 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:28,383 httpcore.http11 DEBUG send_request_body.complete
19:12:28,383 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:28,594 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ef5030c7d9f51b81fa96ef83cbf72b64'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833984256a7d3ba0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:28,598 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:12:28,598 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:28,599 httpcore.http11 DEBUG receive_response_body.complete
19:12:28,599 httpcore.http11 DEBUG response_closed.started
19:12:28,600 httpcore.http11 DEBUG response_closed.complete
19:12:28,600 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:12:34,451 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:12:34,455 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:12:37,857 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:12:37,861 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:12:37,864 httpcore.connection DEBUG close.started
19:12:37,865 httpcore.connection DEBUG close.complete
19:12:37,865 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:12:37,868 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3310>
19:12:37,868 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:12:37,875 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3b50>
19:12:37,875 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:37,876 httpcore.http11 DEBUG send_request_headers.complete
19:12:37,876 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:37,877 httpcore.http11 DEBUG send_request_body.complete
19:12:37,877 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:38,357 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd05c351da20fed9b38cf9b7513cc7c89'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398460b95d4cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:38,360 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:12:38,360 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:39,220 httpcore.http11 DEBUG receive_response_body.complete
19:12:39,221 httpcore.http11 DEBUG response_closed.started
19:12:39,221 httpcore.http11 DEBUG response_closed.complete
19:12:39,222 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:12:39,292 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:12:51,198 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:12:51,200 httpcore.connection DEBUG close.started
19:12:51,200 httpcore.connection DEBUG close.complete
19:12:51,201 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:12:51,203 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9a8ed0>
19:12:51,204 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:12:51,214 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9a8c90>
19:12:51,215 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:51,216 httpcore.http11 DEBUG send_request_headers.complete
19:12:51,216 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:51,244 httpcore.http11 DEBUG send_request_body.complete
19:12:51,245 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:52,111 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:52 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'542'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e2c0aed319c3e168b4c7a4e9b73ef76d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833984b418b34cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:52,113 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:12:52,114 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:52,115 httpcore.http11 DEBUG receive_response_body.complete
19:12:52,116 httpcore.http11 DEBUG response_closed.started
19:12:52,116 httpcore.http11 DEBUG response_closed.complete
19:12:52,116 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:12:52,117 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:12:52,133 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:12:52,135 httpcore.connection DEBUG close.started
19:12:52,135 httpcore.connection DEBUG close.complete
19:12:52,135 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:12:52,137 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3c50>
19:12:52,138 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99f40> server_hostname='api.openai.com' timeout=None
19:12:52,143 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb1b510>
19:12:52,143 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:12:52,144 httpcore.http11 DEBUG send_request_headers.complete
19:12:52,144 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:12:52,145 httpcore.http11 DEBUG send_request_body.complete
19:12:52,145 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:12:52,356 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:12:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fb32e7d05e8acb036f731468012e7bb8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833984b9e97e3061-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:12:52,358 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:12:52,359 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:12:52,360 httpcore.http11 DEBUG receive_response_body.complete
19:12:52,361 httpcore.http11 DEBUG response_closed.started
19:12:52,361 httpcore.http11 DEBUG response_closed.complete
19:12:52,361 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:13:08,601 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:13:08,606 httpcore.connection DEBUG close.started
19:13:08,606 httpcore.connection DEBUG close.complete
19:13:08,607 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:13:08,609 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3610>
19:13:08,610 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:13:08,616 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9b3150>
19:13:08,616 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:13:08,617 httpcore.http11 DEBUG send_request_headers.complete
19:13:08,618 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:13:08,618 httpcore.http11 DEBUG send_request_body.complete
19:13:08,618 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:13:09,59 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:13:09 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'355'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6d1a40e83bd7f98a844a56896f4e1552'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398520dd7c4d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:13:09,64 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:13:09,65 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:13:09,877 httpcore.http11 DEBUG receive_response_body.complete
19:13:09,878 httpcore.http11 DEBUG response_closed.started
19:13:09,879 httpcore.http11 DEBUG response_closed.complete
19:13:09,879 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:13:09,948 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:13:21,865 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:13:21,869 httpcore.connection DEBUG close.started
19:13:21,869 httpcore.connection DEBUG close.complete
19:13:21,869 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:13:21,872 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9ab510>
19:13:21,873 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99e20> server_hostname='api.openai.com' timeout=5.0
19:13:21,880 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cb9aba50>
19:13:21,880 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:13:21,881 httpcore.http11 DEBUG send_request_headers.complete
19:13:21,881 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:13:21,904 httpcore.http11 DEBUG send_request_body.complete
19:13:21,905 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:13:22,635 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:13:22 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'340'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd51c3d7026d38ca65afc534889edb400'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398573ce0d4cc3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:13:22,639 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:13:22,640 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:13:22,641 httpcore.http11 DEBUG receive_response_body.complete
19:13:22,641 httpcore.http11 DEBUG response_closed.started
19:13:22,641 httpcore.http11 DEBUG response_closed.complete
19:13:22,642 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:13:22,643 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:13:25,132 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:13:25,136 httpcore.connection DEBUG close.started
19:13:25,136 httpcore.connection DEBUG close.complete
19:13:25,136 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:13:25,139 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb0ac90>
19:13:25,140 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe3cbd99f40> server_hostname='api.openai.com' timeout=None
19:13:25,146 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe3cbb08290>
19:13:25,146 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:13:25,148 httpcore.http11 DEBUG send_request_headers.complete
19:13:25,148 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:13:25,149 httpcore.http11 DEBUG send_request_body.complete
19:13:25,149 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:13:25,312 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:13:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'76'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cdeccef7287b26585fdf74274d592a1a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833985882b483074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:13:25,318 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:13:25,319 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:13:25,320 httpcore.http11 DEBUG receive_response_body.complete
19:13:25,320 httpcore.http11 DEBUG response_closed.started
19:13:25,320 httpcore.http11 DEBUG response_closed.complete
19:13:25,321 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:14:49,282 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:49,285 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,99 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,100 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,141 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,141 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,183 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,183 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,221 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,222 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,267 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,268 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,307 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,308 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,351 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,352 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,391 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:14:50,391 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:14:50,433 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:14:50,448 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:14:50,479 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b3033390>
19:14:50,479 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:14:50,489 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2daac90>
19:14:50,489 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:14:50,491 httpcore.http11 DEBUG send_request_headers.complete
19:14:50,491 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:14:50,491 httpcore.http11 DEBUG send_request_body.complete
19:14:50,491 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:14:50,954 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:14:50 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2ab7c188f138885146ed4c3be65b7dca'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=MkFQP08Uw6yJripRKehqDralaYB16igcPEKQFoyZJ70-1702253690-1-AT3m5NDKRq49JxMBkFDhOz0RfjanJQ4UR/ghdIkYpVlnNTVf7s8BPLGdiF+/laKYhwD7isjjViP2RA+76ddMjSE=; path=/; expires=Mon, 11-Dec-23 00:44:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pr3SgU94luGhMpAXfS1JiZS9wgAA4xwky8cT5mTpdeI-1702253690949-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339879d9dea4d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:14:50,961 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:14:50,962 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:14:51,572 httpcore.http11 DEBUG receive_response_body.complete
19:14:51,573 httpcore.http11 DEBUG response_closed.started
19:14:51,574 httpcore.http11 DEBUG response_closed.complete
19:14:51,575 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:14:51,648 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:15:05,164 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:15:05,173 httpcore.connection DEBUG close.started
19:15:05,173 httpcore.connection DEBUG close.complete
19:15:05,174 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:15:05,176 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2daac90>
19:15:05,176 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:15:05,183 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2daa990>
19:15:05,183 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:05,184 httpcore.http11 DEBUG send_request_headers.complete
19:15:05,184 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:05,210 httpcore.http11 DEBUG send_request_body.complete
19:15:05,210 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:07,524 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1808'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6226f6ae3edb71631d27edfafded7ee5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833987f96b354cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:07,526 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:15:07,527 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:07,528 httpcore.http11 DEBUG receive_response_body.complete
19:15:07,528 httpcore.http11 DEBUG response_closed.started
19:15:07,528 httpcore.http11 DEBUG response_closed.complete
19:15:07,529 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:15:07,530 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:15:07,550 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:15:07,557 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:15:07,559 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0d150>
19:15:07,559 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39f40> server_hostname='api.openai.com' timeout=None
19:15:07,567 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0cc90>
19:15:07,567 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:07,568 httpcore.http11 DEBUG send_request_headers.complete
19:15:07,568 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:07,568 httpcore.http11 DEBUG send_request_body.complete
19:15:07,569 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:07,778 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c1e4e4bdfafb70485a87552245475ecc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QjcF4JWv0JZVbMIPsaZVkmrotLCKWaxf5zSSAr_7Bao-1702253707-1-AenMVS26+NpoPRWH3P3KMxd6f8Fqy9R6odzIHKCto1J2T7DGnQvGpKvfZ3PINnb4b7LxzSs5VDKRdBPCOxxz5bE=; path=/; expires=Mon, 11-Dec-23 00:45:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=L.kIw4Byf9LMsdiGLoM.YQsgTWDeHodYhYEihqOoRbE-1702253707775-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833988084b974d16-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:07,780 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:15:07,780 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:07,781 httpcore.http11 DEBUG receive_response_body.complete
19:15:07,782 httpcore.http11 DEBUG response_closed.started
19:15:07,782 httpcore.http11 DEBUG response_closed.complete
19:15:07,782 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:15:07,804 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:15:07,815 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:15:07,817 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0e1d0>
19:15:07,817 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e3a720> server_hostname='api.openai.com' timeout=None
19:15:07,825 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e1c110>
19:15:07,825 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:07,826 httpcore.http11 DEBUG send_request_headers.complete
19:15:07,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:07,827 httpcore.http11 DEBUG send_request_body.complete
19:15:07,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:08,226 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'298'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a596540673445f7b28949a394805e5e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4nllwFMRUrmN2G40MDsL3hP9n0p3ItqtnrKhHNaU_js-1702253708-1-AQjUhwlCT7Kwq8+Y9poozh09pgF6GW9XgqtiwFc/Fkz0ynZCUAij81pVGedb8poJf5Eo3E1eptjEO7SWpXqSDd4=; path=/; expires=Mon, 11-Dec-23 00:45:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=x5SBT_napHMaRMAlUqXqqaW5bs5DYGuEfFSJCTfhY9A-1702253708222-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398809ec624ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:08,229 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:15:08,230 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:08,231 httpcore.http11 DEBUG receive_response_body.complete
19:15:08,231 httpcore.http11 DEBUG response_closed.started
19:15:08,232 httpcore.http11 DEBUG response_closed.complete
19:15:08,232 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:15:08,245 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:08,248 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:13,954 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:13,966 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:13,968 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:17,970 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:17,981 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:17,983 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:19,985 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:19,997 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:20,0 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:23,401 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:23,416 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:23,419 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:29,121 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:29,134 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:29,137 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:32,538 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:32,551 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:15:32,554 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:15:36,755 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:15:36,759 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:15:36,764 httpcore.connection DEBUG close.started
19:15:36,764 httpcore.connection DEBUG close.complete
19:15:36,765 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:15:36,781 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2dcadd0>
19:15:36,782 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:15:36,789 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2daa410>
19:15:36,790 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:36,791 httpcore.http11 DEBUG send_request_headers.complete
19:15:36,791 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:36,792 httpcore.http11 DEBUG send_request_body.complete
19:15:36,792 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:37,457 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:37 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'529'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b1dc3c65b35d475ae98df22c095489e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833988bef8cc4ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:37,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:15:37,460 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:38,476 httpcore.http11 DEBUG receive_response_body.complete
19:15:38,477 httpcore.http11 DEBUG response_closed.started
19:15:38,477 httpcore.http11 DEBUG response_closed.complete
19:15:38,478 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:15:38,542 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:15:51,462 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:15:51,464 httpcore.connection DEBUG close.started
19:15:51,465 httpcore.connection DEBUG close.complete
19:15:51,465 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:15:51,493 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c3e150>
19:15:51,494 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:15:51,503 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c3e1d0>
19:15:51,503 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:51,505 httpcore.http11 DEBUG send_request_headers.complete
19:15:51,505 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:51,516 httpcore.http11 DEBUG send_request_body.complete
19:15:51,516 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:52,457 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:52 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'33'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9b9dace439fd456959227a6cc89d8129'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339891ae8323b9f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:52,460 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:15:52,460 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:52,461 httpcore.http11 DEBUG receive_response_body.complete
19:15:52,462 httpcore.http11 DEBUG response_closed.started
19:15:52,462 httpcore.http11 DEBUG response_closed.complete
19:15:52,462 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:15:52,463 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:15:54,709 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:15:54,713 httpcore.connection DEBUG close.started
19:15:54,713 httpcore.connection DEBUG close.complete
19:15:54,714 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:15:54,716 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0cc90>
19:15:54,717 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39f40> server_hostname='api.openai.com' timeout=None
19:15:54,723 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2e0cd50>
19:15:54,723 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:54,724 httpcore.http11 DEBUG send_request_headers.complete
19:15:54,725 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:54,725 httpcore.http11 DEBUG send_request_body.complete
19:15:54,726 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:54,944 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd595857be0774895d4acf0888fab8a8f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339892f098f4cc8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:54,951 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:15:54,952 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:54,954 httpcore.http11 DEBUG receive_response_body.complete
19:15:54,954 httpcore.http11 DEBUG response_closed.started
19:15:54,955 httpcore.http11 DEBUG response_closed.complete
19:15:54,955 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:15:57,772 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:15:57,785 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:15:57,788 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c49c90>
19:15:57,789 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e3a2a0> server_hostname='api.openai.com' timeout=None
19:15:57,796 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c49d10>
19:15:57,797 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:15:57,798 httpcore.http11 DEBUG send_request_headers.complete
19:15:57,799 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:15:57,799 httpcore.http11 DEBUG send_request_body.complete
19:15:57,799 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:15:58,788 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:15:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'900'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'81b42bdc118286991e0163fc79559690'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lq47OOELNs_4CK8WS3cCn4PE7a1IpOvaqKqSMj5SSq4-1702253758-1-AUMD33gPBIZS28dZ1YVZa+3BCwE8VW6/vi/Jae/+kXTknCqBeus435FLLucfhy6Ybj2GEiUKLMQ7SaN8tu8BEz4=; path=/; expires=Mon, 11-Dec-23 00:45:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qHiD3sEYWFoTfe5uFFNlocb99IqZ.KLXYAsrjpDHtaA-1702253758784-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833989423cfb4d06-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:15:58,794 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:15:58,795 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:15:58,797 httpcore.http11 DEBUG receive_response_body.complete
19:15:58,797 httpcore.http11 DEBUG response_closed.started
19:15:58,798 httpcore.http11 DEBUG response_closed.complete
19:15:58,798 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:16:00,825 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:16:00,831 httpcore.connection DEBUG close.started
19:16:00,831 httpcore.connection DEBUG close.complete
19:16:00,832 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:16:00,834 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c3e090>
19:16:00,834 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:16:00,842 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2c499d0>
19:16:00,843 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:16:00,845 httpcore.http11 DEBUG send_request_headers.complete
19:16:00,845 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:16:00,846 httpcore.http11 DEBUG send_request_body.complete
19:16:00,846 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:16:01,368 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:16:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'036538c30ee0178d8eb7e7ba1bbbcd6a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833989554b804d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:16:01,373 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:16:01,374 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:16:02,511 httpcore.http11 DEBUG receive_response_body.complete
19:16:02,512 httpcore.http11 DEBUG response_closed.started
19:16:02,513 httpcore.http11 DEBUG response_closed.complete
19:16:02,514 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:16:02,583 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:16:15,477 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:16:15,483 httpcore.connection DEBUG close.started
19:16:15,483 httpcore.connection DEBUG close.complete
19:16:15,484 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:16:15,486 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2dd9990>
19:16:15,487 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f92b2e39d90> server_hostname='api.openai.com' timeout=5.0
19:16:15,493 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f92b2dd8150>
19:16:15,494 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:16:15,495 httpcore.http11 DEBUG send_request_headers.complete
19:16:15,495 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:16:15,520 httpcore.http11 DEBUG send_request_body.complete
19:16:15,521 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:16:16,337 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:16:16 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'32'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'344'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7f77996282e38619049111b771844d01'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833989b0df824ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:16:16,341 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:16:16,342 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:16:16,344 httpcore.http11 DEBUG receive_response_body.complete
19:16:16,344 httpcore.http11 DEBUG response_closed.started
19:16:16,345 httpcore.http11 DEBUG response_closed.complete
19:16:16,346 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:16:16,346 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:17:39,730 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:39,734 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,549 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,550 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,592 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,593 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,641 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,642 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,682 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,683 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,732 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,733 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,773 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,774 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,821 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,822 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:40,863 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:17:40,864 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:17:41,649 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:17:41,669 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:17:41,700 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c9c9a50>
19:17:41,701 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:17:41,709 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c753cd0>
19:17:41,711 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:17:41,714 httpcore.http11 DEBUG send_request_headers.complete
19:17:41,715 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:17:41,716 httpcore.http11 DEBUG send_request_body.complete
19:17:41,716 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:17:42,234 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:17:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'401'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'eb0bdf9975b090f4aaa0b093f55da1d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ZexuZSwdSjJeteQNxZAv5ilk5tzrJFUjA5Lqg.RKnL4-1702253862-1-AS5OpTK9E7cqQtL+umZgPkQ8+O8/tevcHJxDAGeh0cPEiXPljDFx2ZBwWofyzk10dqren9VnbV+TOvINHwLthrA=; path=/; expires=Mon, 11-Dec-23 00:47:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=02KGEy0lMVmBQwRFm3L4YknJTAE2VWymN1I7K2JJWmA-1702253862228-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398bcbbc2f4ce2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:17:42,244 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:17:42,244 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:17:43,47 httpcore.http11 DEBUG receive_response_body.complete
19:17:43,48 httpcore.http11 DEBUG response_closed.started
19:17:43,49 httpcore.http11 DEBUG response_closed.complete
19:17:43,50 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:17:43,134 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:17:56,912 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:17:56,923 httpcore.connection DEBUG close.started
19:17:56,924 httpcore.connection DEBUG close.complete
19:17:56,924 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:17:56,927 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c753cd0>
19:17:56,927 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:17:56,935 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c752f90>
19:17:56,935 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:17:56,936 httpcore.http11 DEBUG send_request_headers.complete
19:17:56,937 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:17:56,967 httpcore.http11 DEBUG send_request_body.complete
19:17:56,968 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:17:57,849 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:17:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'db9f1e608dd6c1c63a4d512e90870d89'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398c2adc814cf2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:17:57,854 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:17:57,855 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:17:57,855 httpcore.http11 DEBUG receive_response_body.complete
19:17:57,856 httpcore.http11 DEBUG response_closed.started
19:17:57,856 httpcore.http11 DEBUG response_closed.complete
19:17:57,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:17:57,857 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:17:57,892 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:17:57,903 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:17:57,906 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0d10>
19:17:57,906 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5fd0> server_hostname='api.openai.com' timeout=None
19:17:57,913 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0cd0>
19:17:57,914 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:17:57,915 httpcore.http11 DEBUG send_request_headers.complete
19:17:57,915 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:17:57,916 httpcore.http11 DEBUG send_request_body.complete
19:17:57,916 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:17:58,113 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:17:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9688e1c2594d97a7a7d401ffdc3a3ad3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=oJb0mPIgSqi7sXkdmWaHtLNsCpI66VBdOV8IxiH6fCk-1702253878-1-AalAJJQskCThZNASThGpq3XQh3hBVFMBcdlAS7xF+dTGl5mxW6EFPy2jbFVQiuEOqvefwRyh1z3iUsLFwF6Y5Bg=; path=/; expires=Mon, 11-Dec-23 00:47:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=PkshBTyzcP4hT77dfrgI0pOHQITLnF5jnTPYtDMwwoE-1702253878108-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398c30ff134ced-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:17:58,120 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:17:58,121 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:17:58,122 httpcore.http11 DEBUG receive_response_body.complete
19:17:58,122 httpcore.http11 DEBUG response_closed.started
19:17:58,123 httpcore.http11 DEBUG response_closed.complete
19:17:58,123 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:17:58,159 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:17:58,169 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:17:58,172 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b83d0>
19:17:58,173 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d67b0> server_hostname='api.openai.com' timeout=None
19:17:58,178 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b1890>
19:17:58,179 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:17:58,180 httpcore.http11 DEBUG send_request_headers.complete
19:17:58,180 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:17:58,181 httpcore.http11 DEBUG send_request_body.complete
19:17:58,181 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:17:58,939 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:17:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'645'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'56f74994df1f38cb6b9053c32d8e8332'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=wHFZcABNZBB97UhqangS6hDpjVzabA86dCJ1ADYdmQY-1702253878-1-AT//g3lV/EvEBn3j0twAydTJb0A9Q/ZjYhqtTM5XKqQA5lq/QxH/crkXRpyGCc0k2zW+jRFrsGETNa9uu76TZ6Q=; path=/; expires=Mon, 11-Dec-23 00:47:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=5FEgdi_fCco6jTJ29VK_Ycmb_rwXaU61mHF.0GTNjrs-1702253878936-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398c32af124ce0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:17:58,946 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:17:58,947 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:17:58,949 httpcore.http11 DEBUG receive_response_body.complete
19:17:58,950 httpcore.http11 DEBUG response_closed.started
19:17:58,950 httpcore.http11 DEBUG response_closed.complete
19:17:58,951 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:17:58,970 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:17:58,974 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:04,682 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:04,695 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:04,698 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:09,400 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:09,421 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:09,424 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:11,426 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:11,443 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:11,446 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:14,851 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:14,864 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:14,868 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:20,570 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:20,589 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:20,592 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:24,794 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:24,808 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:18:24,811 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:18:29,13 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:18:29,21 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:18:29,27 httpcore.connection DEBUG close.started
19:18:29,28 httpcore.connection DEBUG close.complete
19:18:29,28 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:18:29,31 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1e44ac10>
19:18:29,31 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:18:29,37 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7cf290>
19:18:29,37 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:29,38 httpcore.http11 DEBUG send_request_headers.complete
19:18:29,39 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:29,39 httpcore.http11 DEBUG send_request_body.complete
19:18:29,40 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:29,712 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:29 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'430'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'70b4873c27fb044d9d3ccc9481b77cf2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398cf37b764d02-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:29,716 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:18:29,718 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:30,802 httpcore.http11 DEBUG receive_response_body.complete
19:18:30,803 httpcore.http11 DEBUG response_closed.started
19:18:30,803 httpcore.http11 DEBUG response_closed.complete
19:18:30,804 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:18:30,869 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:18:43,754 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:18:43,759 httpcore.connection DEBUG close.started
19:18:43,760 httpcore.connection DEBUG close.complete
19:18:43,760 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:18:43,789 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e2750>
19:18:43,790 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:18:43,799 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e27d0>
19:18:43,800 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:43,802 httpcore.http11 DEBUG send_request_headers.complete
19:18:43,802 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:43,821 httpcore.http11 DEBUG send_request_body.complete
19:18:43,822 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:44,564 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:44 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'33'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'faec38cb6db2a3482cfa457d68be4167'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398d4fce383b7c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:44,569 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:18:44,570 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:44,572 httpcore.http11 DEBUG receive_response_body.complete
19:18:44,572 httpcore.http11 DEBUG response_closed.started
19:18:44,573 httpcore.http11 DEBUG response_closed.complete
19:18:44,574 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:18:44,575 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:18:47,48 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:18:47,52 httpcore.connection DEBUG close.started
19:18:47,52 httpcore.connection DEBUG close.complete
19:18:47,52 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:18:47,55 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0cd0>
19:18:47,55 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5fd0> server_hostname='api.openai.com' timeout=None
19:18:47,61 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b02d0>
19:18:47,62 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:47,63 httpcore.http11 DEBUG send_request_headers.complete
19:18:47,63 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:47,63 httpcore.http11 DEBUG send_request_body.complete
19:18:47,64 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:47,271 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dd414abcf9a0ed1c66411810cdac394c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398d642ae64d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:47,277 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:18:47,278 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:47,279 httpcore.http11 DEBUG receive_response_body.complete
19:18:47,279 httpcore.http11 DEBUG response_closed.started
19:18:47,280 httpcore.http11 DEBUG response_closed.complete
19:18:47,280 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:18:49,706 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:18:49,719 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:18:49,722 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7f1450>
19:18:49,722 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d6330> server_hostname='api.openai.com' timeout=None
19:18:49,729 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7f1410>
19:18:49,730 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:49,731 httpcore.http11 DEBUG send_request_headers.complete
19:18:49,731 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:49,732 httpcore.http11 DEBUG send_request_body.complete
19:18:49,732 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:50,905 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1076'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'76e54168b06c28d57d444b7efd3c9cb6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fOgOuYfcz2M3jhVwrJZvRPRDpmKfye.lkxa62YBcO8s-1702253930-1-Aej5ptzgMFdtQEvYP5lD5pNcPP0/khTUoHKM8rb0D9dWKJV4SttZKcbGzEtm2y+Plt5iEM43GykQwVLIEsyh1qY=; path=/; expires=Mon, 11-Dec-23 00:48:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=cqU5YGvwHGPTfIyrj4bBcJMm.Yr4W.bHATFjUSNdHpM-1702253930901-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398d74ddc93b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:50,912 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:18:50,913 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:50,914 httpcore.http11 DEBUG receive_response_body.complete
19:18:50,914 httpcore.http11 DEBUG response_closed.started
19:18:50,915 httpcore.http11 DEBUG response_closed.complete
19:18:50,915 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:18:51,677 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:18:51,682 httpcore.connection DEBUG close.started
19:18:51,682 httpcore.connection DEBUG close.complete
19:18:51,683 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:18:51,686 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e2690>
19:18:51,686 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:18:51,692 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e3d10>
19:18:51,693 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:18:51,694 httpcore.http11 DEBUG send_request_headers.complete
19:18:51,694 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:18:51,694 httpcore.http11 DEBUG send_request_body.complete
19:18:51,695 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:18:52,252 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:18:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'462'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2788f663dc024e6fbcf76c4fd8cbac45'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398d81191f4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:18:52,256 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:18:52,256 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:18:53,918 httpcore.http11 DEBUG receive_response_body.complete
19:18:53,919 httpcore.http11 DEBUG response_closed.started
19:18:53,920 httpcore.http11 DEBUG response_closed.complete
19:18:53,921 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:18:53,986 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:19:10,26 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:19:10,31 httpcore.connection DEBUG close.started
19:19:10,31 httpcore.connection DEBUG close.complete
19:19:10,31 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:19:10,34 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7ccfd0>
19:19:10,34 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:19:10,44 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7cf090>
19:19:10,44 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:10,45 httpcore.http11 DEBUG send_request_headers.complete
19:19:10,46 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:10,66 httpcore.http11 DEBUG send_request_body.complete
19:19:10,66 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:10,899 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:10 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'93df7b9ba2ebb651d45f32d791342c40'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398df3cd0d3b8d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:10,904 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:19:10,905 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:10,906 httpcore.http11 DEBUG receive_response_body.complete
19:19:10,907 httpcore.http11 DEBUG response_closed.started
19:19:10,907 httpcore.http11 DEBUG response_closed.complete
19:19:10,908 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:19:10,909 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:19:13,966 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:19:13,973 httpcore.connection DEBUG close.started
19:19:13,974 httpcore.connection DEBUG close.complete
19:19:13,974 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:19:13,977 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0d90>
19:19:13,978 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5fd0> server_hostname='api.openai.com' timeout=None
19:19:13,986 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7b0c90>
19:19:13,986 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:13,987 httpcore.http11 DEBUG send_request_headers.complete
19:19:13,987 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:13,988 httpcore.http11 DEBUG send_request_body.complete
19:19:13,988 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:14,201 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c5fdc8af31e21b5d3ecab103986ded4b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398e0c6c3a4d1d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:14,205 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:19:14,206 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:14,207 httpcore.http11 DEBUG receive_response_body.complete
19:19:14,208 httpcore.http11 DEBUG response_closed.started
19:19:14,208 httpcore.http11 DEBUG response_closed.complete
19:19:14,209 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:19:16,492 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:19:16,505 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:19:16,508 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7bbd10>
19:19:16,508 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5f40> server_hostname='api.openai.com' timeout=None
19:19:16,514 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7badd0>
19:19:16,514 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:16,515 httpcore.http11 DEBUG send_request_headers.complete
19:19:16,515 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:16,516 httpcore.http11 DEBUG send_request_body.complete
19:19:16,516 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:16,708 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'96'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'487bb9ae7187fa669bb9d1d7071fc042'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pQyNsUp0OZb3YrNYuO3V8WzYl00FZ29zCpxaBtpJdxk-1702253956-1-AV3RshiYZF13x0xMQOT4taWsQrmxTuWYOaZhhFRoWmI64FGvlluKGaMKK9aMFFkQx6DL38cmruHANNaRAVX1ASI=; path=/; expires=Mon, 11-Dec-23 00:49:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1Wf6LzaSDfzPte2d57LYXG6PP3eJClXV_PRiUG1jwh8-1702253956704-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398e1c3fee4cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:16,716 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:19:16,717 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:16,720 httpcore.http11 DEBUG receive_response_body.complete
19:19:16,721 httpcore.http11 DEBUG response_closed.started
19:19:16,722 httpcore.http11 DEBUG response_closed.complete
19:19:16,722 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:19:24,441 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:19:24,444 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:19:27,845 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:19:27,849 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:19:27,853 httpcore.connection DEBUG close.started
19:19:27,853 httpcore.connection DEBUG close.complete
19:19:27,853 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:19:27,856 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c79ddd0>
19:19:27,856 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:19:27,863 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c79fd10>
19:19:27,864 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:27,864 httpcore.http11 DEBUG send_request_headers.complete
19:19:27,864 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:27,865 httpcore.http11 DEBUG send_request_body.complete
19:19:27,865 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:28,395 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:28 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a216955114d1b8a768f9da8258f34c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398e6328b64cd2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:28,397 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:19:28,398 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:29,387 httpcore.http11 DEBUG receive_response_body.complete
19:19:29,388 httpcore.http11 DEBUG response_closed.started
19:19:29,388 httpcore.http11 DEBUG response_closed.complete
19:19:29,389 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:19:29,453 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:19:42,481 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:19:42,485 httpcore.connection DEBUG close.started
19:19:42,485 httpcore.connection DEBUG close.complete
19:19:42,486 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:19:42,488 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e1410>
19:19:42,489 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:19:42,498 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7e3410>
19:19:42,498 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:42,499 httpcore.http11 DEBUG send_request_headers.complete
19:19:42,499 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:42,519 httpcore.http11 DEBUG send_request_body.complete
19:19:42,519 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:43,301 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:43 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'375'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b13dd1940fee99287c27d0ed5f9c6cd7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398ebe9aef4ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:43,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:19:43,304 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:43,305 httpcore.http11 DEBUG receive_response_body.complete
19:19:43,305 httpcore.http11 DEBUG response_closed.started
19:19:43,306 httpcore.http11 DEBUG response_closed.complete
19:19:43,306 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:19:43,306 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:19:43,322 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:19:43,324 httpcore.connection DEBUG close.started
19:19:43,324 httpcore.connection DEBUG close.complete
19:19:43,324 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:19:43,326 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7ee6d0>
19:19:43,327 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5f40> server_hostname='api.openai.com' timeout=None
19:19:43,333 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7eeb10>
19:19:43,333 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:43,334 httpcore.http11 DEBUG send_request_headers.complete
19:19:43,334 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:43,334 httpcore.http11 DEBUG send_request_body.complete
19:19:43,334 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:43,562 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'114'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e2fd3f926691a60009aaff9a62f400b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398ec3db6b4ce0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:43,565 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:19:43,565 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:43,566 httpcore.http11 DEBUG receive_response_body.complete
19:19:43,567 httpcore.http11 DEBUG response_closed.started
19:19:43,567 httpcore.http11 DEBUG response_closed.complete
19:19:43,567 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:19:43,577 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:19:43,581 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:19:46,982 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:19:46,996 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:19:46,998 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:19:48,999 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:19:49,12 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:19:49,14 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:19:52,416 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:19:52,420 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:19:52,424 httpcore.connection DEBUG close.started
19:19:52,425 httpcore.connection DEBUG close.complete
19:19:52,425 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:19:52,454 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7ee9d0>
19:19:52,455 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fae1c9d5e20> server_hostname='api.openai.com' timeout=5.0
19:19:52,461 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fae1c7ef290>
19:19:52,461 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:19:52,462 httpcore.http11 DEBUG send_request_headers.complete
19:19:52,463 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:19:52,463 httpcore.http11 DEBUG send_request_body.complete
19:19:52,463 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:19:52,892 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:19:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e48af9c5f7d6b3a1e7a4a972085c29db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83398efcedd34ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:19:52,894 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:19:52,895 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:19:53,244 httpcore.http11 DEBUG receive_response_body.complete
19:19:53,245 httpcore.http11 DEBUG response_closed.started
19:19:53,245 httpcore.http11 DEBUG response_closed.complete
19:19:53,246 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:19:53,317 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:22:01,267 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:01,272 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,100 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,101 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,141 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,142 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,182 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,183 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,220 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,221 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,262 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,263 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,301 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,302 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,344 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,345 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,382 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:02,383 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:02,424 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:22:02,436 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:22:02,467 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5659f39f10>
19:22:02,468 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f5659d41d90> server_hostname='api.openai.com' timeout=5.0
19:22:02,474 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f5659cb6990>
19:22:02,475 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:02,478 httpcore.http11 DEBUG send_request_headers.complete
19:22:02,478 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:02,479 httpcore.http11 DEBUG send_request_body.complete
19:22:02,479 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:02,939 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:02 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4e846bf9d38ea6f9c1ef454758339dc5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=d01v3Cv4aF0lUkU1tTWMeRjjNI4p5j5v63fu6oKmSsU-1702254122-1-AViGSdFZL7JuRsSWw4VEKDD8hDZcVOT5LQf/rnUc19dUx9Cmdmlk+GML6vaXFK5wey1tK4j20yRkAoC4bNqOF1U=; path=/; expires=Mon, 11-Dec-23 00:52:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=jt00WE01edee3u8RN.zl5fILhhX5nXnr_aQXFPT7rEI-1702254122934-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833992297df63b8e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:02,946 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:22:02,947 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:03,836 httpcore.http11 DEBUG receive_response_body.complete
19:22:03,836 httpcore.http11 DEBUG response_closed.started
19:22:03,837 httpcore.http11 DEBUG response_closed.complete
19:22:03,838 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:22:03,911 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:22:20,706 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:20,708 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,520 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,521 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,563 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,564 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,611 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,612 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,652 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,653 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,700 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,701 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,742 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,743 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,791 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,792 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:21,833 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:22:21,834 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:22:39,802 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:22:39,818 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:22:39,821 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff7050>
19:22:39,821 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:22:39,827 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff7690>
19:22:39,828 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:39,829 httpcore.http11 DEBUG send_request_headers.complete
19:22:39,829 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:39,829 httpcore.http11 DEBUG send_request_body.complete
19:22:39,829 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:40,320 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2177fa04c2e624c9f627d40207e6b1c5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9WncUoexr8J_zQBKTiPzmzk7qKc8KmERYdmUprhELgA-1702254160-1-AQCBMXVhQUtuK5CT8r/MFWFuFJCXbrUnUayiUSoHj3UpC9v0WmBNHkIPIOnDeZQUcM1oJiHrIjRSjiC6K51IdoI=; path=/; expires=Mon, 11-Dec-23 00:52:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1RaLLMnsB236E.R6unv5znE36df_fKslyLBZFL2W0ww-1702254160314-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399312eb2e3bab-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:40,327 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:22:40,328 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:41,95 httpcore.http11 DEBUG receive_response_body.complete
19:22:41,96 httpcore.http11 DEBUG response_closed.started
19:22:41,96 httpcore.http11 DEBUG response_closed.complete
19:22:41,97 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:22:41,169 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:22:54,924 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:22:54,931 httpcore.connection DEBUG close.started
19:22:54,931 httpcore.connection DEBUG close.complete
19:22:54,931 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:22:54,934 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff7710>
19:22:54,934 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:22:54,946 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff6790>
19:22:54,947 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:54,948 httpcore.http11 DEBUG send_request_headers.complete
19:22:54,948 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:55,0 httpcore.http11 DEBUG send_request_body.complete
19:22:55,0 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:55,984 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:55 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'420'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'85b02cc36aab6aa657173fdbe2559628'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833993716a6a4d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:55,987 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:22:55,987 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:55,988 httpcore.http11 DEBUG receive_response_body.complete
19:22:55,988 httpcore.http11 DEBUG response_closed.started
19:22:55,989 httpcore.http11 DEBUG response_closed.complete
19:22:55,989 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:22:55,990 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:22:56,7 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:22:56,16 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:22:56,18 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e45090>
19:22:56,18 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:22:56,22 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e45050>
19:22:56,22 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:56,23 httpcore.http11 DEBUG send_request_headers.complete
19:22:56,23 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:56,23 httpcore.http11 DEBUG send_request_body.complete
19:22:56,23 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:56,233 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6f2f90e4cb38b2b6250715b136015ffc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=p8B8aPrnMjTtTRY72SCYfnWH.eROApi6jjJfy6fIvxc-1702254176-1-AeaJsCWQ+mIhYr3nDe1ewNbpZNikkbMcEyTDdWVSzK6ZbYXEJinOxGNPxhtXIVDW8YyFXVAJEWu3tjV+k0jepVE=; path=/; expires=Mon, 11-Dec-23 00:52:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=bd0SUxcrqq4czscH5xSnqGoikz7aUISD2QIdrwas1Ik-1702254176230-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833993782ccc6ac9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:56,236 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:22:56,237 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:56,238 httpcore.http11 DEBUG receive_response_body.complete
19:22:56,238 httpcore.http11 DEBUG response_closed.started
19:22:56,238 httpcore.http11 DEBUG response_closed.complete
19:22:56,238 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:22:56,257 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:22:56,265 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:22:56,267 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5d150>
19:22:56,267 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308072720> server_hostname='api.openai.com' timeout=None
19:22:56,273 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5dd50>
19:22:56,273 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:22:56,274 httpcore.http11 DEBUG send_request_headers.complete
19:22:56,274 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:22:56,274 httpcore.http11 DEBUG send_request_body.complete
19:22:56,275 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:22:57,26 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:22:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'641'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'404252409f32fccf882558f3c1480963'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=x5yfz7Y9bTkVW6ShymPwM7MnLeb2ydVmd7wwuqAp5yg-1702254177-1-AaMVe9qqlrnO4WeUxvQmEjlc2bLKSlTVPV067EX1UF8ToQoBfNpCdPXplP51fPrvaKEunzkhIDrxvZyhy21BmYc=; path=/; expires=Mon, 11-Dec-23 00:52:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=o0ujnLAAPSgGiUFQ8paHQIeiP6Yw1.sZTYwR3qtKPJw-1702254177022-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399379bf0e4cf8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:22:57,29 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:22:57,30 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:22:57,31 httpcore.http11 DEBUG receive_response_body.complete
19:22:57,32 httpcore.http11 DEBUG response_closed.started
19:22:57,32 httpcore.http11 DEBUG response_closed.complete
19:22:57,32 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:22:57,45 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:22:57,49 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:02,757 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:02,767 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:02,770 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:07,472 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:07,484 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:07,487 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:09,488 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:09,501 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:09,502 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:12,904 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:12,916 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:12,918 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:18,619 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:18,630 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:18,634 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:22,835 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:22,846 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:23:22,849 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:23:27,50 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:23:27,54 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:23:27,58 httpcore.connection DEBUG close.started
19:23:27,58 httpcore.connection DEBUG close.complete
19:23:27,58 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:23:27,88 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ff6790>
19:23:27,88 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:23:27,98 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e35990>
19:23:27,99 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:27,100 httpcore.http11 DEBUG send_request_headers.complete
19:23:27,100 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:27,101 httpcore.http11 DEBUG send_request_body.complete
19:23:27,101 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:27,614 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7c94656bea0a69da7cc439af74b9fa7a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339943a68204d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:27,615 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:23:27,616 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:28,643 httpcore.http11 DEBUG receive_response_body.complete
19:23:28,644 httpcore.http11 DEBUG response_closed.started
19:23:28,644 httpcore.http11 DEBUG response_closed.complete
19:23:28,645 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:23:28,715 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:23:41,690 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:23:41,692 httpcore.connection DEBUG close.started
19:23:41,692 httpcore.connection DEBUG close.complete
19:23:41,693 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:23:41,695 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7bd50>
19:23:41,695 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:23:41,702 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7bdd0>
19:23:41,702 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:41,703 httpcore.http11 DEBUG send_request_headers.complete
19:23:41,703 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:41,723 httpcore.http11 DEBUG send_request_body.complete
19:23:41,724 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:42,616 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:42 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'33'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'444'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1657bdc658cf694c25d822fb73de5851'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399495adcc4ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:42,618 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:23:42,618 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:42,619 httpcore.http11 DEBUG receive_response_body.complete
19:23:42,619 httpcore.http11 DEBUG response_closed.started
19:23:42,620 httpcore.http11 DEBUG response_closed.complete
19:23:42,620 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:23:42,621 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:23:42,638 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:23:42,640 httpcore.connection DEBUG close.started
19:23:42,640 httpcore.connection DEBUG close.complete
19:23:42,640 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:23:42,643 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e45050>
19:23:42,643 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:23:42,650 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e450d0>
19:23:42,650 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:42,651 httpcore.http11 DEBUG send_request_headers.complete
19:23:42,651 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:42,651 httpcore.http11 DEBUG send_request_body.complete
19:23:42,652 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:42,869 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a6ab88b62a3985c8fbc778409a71a479'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339949b9adc3068-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:42,873 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:23:42,873 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:42,874 httpcore.http11 DEBUG receive_response_body.complete
19:23:42,874 httpcore.http11 DEBUG response_closed.started
19:23:42,875 httpcore.http11 DEBUG response_closed.complete
19:23:42,875 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:23:42,892 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nI don't know, what do you think?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:23:42,902 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:23:42,905 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7e5d0>
19:23:42,905 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff3080722a0> server_hostname='api.openai.com' timeout=None
19:23:42,912 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7e0d0>
19:23:42,912 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:42,913 httpcore.http11 DEBUG send_request_headers.complete
19:23:42,913 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:42,913 httpcore.http11 DEBUG send_request_body.complete
19:23:42,913 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:43,878 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'867'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'eec537e554c3cabafd4bebea5f94292b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=f2xuTtTueZZUvb6LbbiNWGc4RfghtmhR_q5RzawNO5w-1702254223-1-Afnj5zbRlfPocz5NRjkZ1IsySMVm6kI7fGVgPMCdjGmBrme3PBstMPyFaSn37ed+17pUICbs2AlotF5nz0xbvgA=; path=/; expires=Mon, 11-Dec-23 00:53:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kxnHky3QXOcgmuOuV7Nrba3eg2hUcyh4nayBhhvwQTc-1702254223874-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339949d3f544d14-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:43,882 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:23:43,882 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:43,883 httpcore.http11 DEBUG receive_response_body.complete
19:23:43,884 httpcore.http11 DEBUG response_closed.started
19:23:43,884 httpcore.http11 DEBUG response_closed.complete
19:23:43,884 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:23:43,888 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:23:43,890 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:23:43,891 httpcore.http11 DEBUG send_request_headers.complete
19:23:43,891 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:23:43,891 httpcore.http11 DEBUG send_request_body.complete
19:23:43,891 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:23:44,453 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:23:44 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'486'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd2777b978b6a85b045248da1b5c15d13'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833994a35cf74ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:23:44,455 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:23:44,455 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:23:46,206 httpcore.http11 DEBUG receive_response_body.complete
19:23:46,206 httpcore.http11 DEBUG response_closed.started
19:23:46,207 httpcore.http11 DEBUG response_closed.complete
19:23:46,207 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:23:46,279 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:24:02,277 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:24:02,280 httpcore.connection DEBUG close.started
19:24:02,280 httpcore.connection DEBUG close.complete
19:24:02,280 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:24:02,283 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89990>
19:24:02,283 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:24:02,291 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89a10>
19:24:02,291 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:02,292 httpcore.http11 DEBUG send_request_headers.complete
19:24:02,292 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:02,313 httpcore.http11 DEBUG send_request_body.complete
19:24:02,313 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:03,291 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:03 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'553'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b6458e1a8ead35edfe254344603eafa5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833995165e454d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:03,293 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:24:03,294 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:03,295 httpcore.http11 DEBUG receive_response_body.complete
19:24:03,295 httpcore.http11 DEBUG response_closed.started
19:24:03,296 httpcore.http11 DEBUG response_closed.complete
19:24:03,296 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:24:03,297 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:24:03,313 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nOK.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:03,315 httpcore.connection DEBUG close.started
19:24:03,316 httpcore.connection DEBUG close.complete
19:24:03,316 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:03,318 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8cb50>
19:24:03,319 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:24:03,329 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8cbd0>
19:24:03,330 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:03,331 httpcore.http11 DEBUG send_request_headers.complete
19:24:03,331 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:03,331 httpcore.http11 DEBUG send_request_body.complete
19:24:03,332 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:03,549 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'96'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b87b3d0c9b1379604fdce6f0dd6c2fe7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339951cd9204cf4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:03,551 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:03,552 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:03,553 httpcore.http11 DEBUG receive_response_body.complete
19:24:03,554 httpcore.http11 DEBUG response_closed.started
19:24:03,554 httpcore.http11 DEBUG response_closed.complete
19:24:03,554 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:03,575 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI think this is a good location, but it's up to you. Let's try it out and if you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nOK.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:03,577 httpcore.connection DEBUG close.started
19:24:03,577 httpcore.connection DEBUG close.complete
19:24:03,577 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:03,579 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8a810>
19:24:03,580 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff3080722a0> server_hostname='api.openai.com' timeout=None
19:24:03,585 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89f10>
19:24:03,585 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:03,586 httpcore.http11 DEBUG send_request_headers.complete
19:24:03,586 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:03,586 httpcore.http11 DEBUG send_request_body.complete
19:24:03,586 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:04,683 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1003'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ee5309ca4c5cd9893f2a3b7b344a0748'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339951e6c403b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:04,685 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:04,686 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:04,687 httpcore.http11 DEBUG receive_response_body.complete
19:24:04,688 httpcore.http11 DEBUG response_closed.started
19:24:04,688 httpcore.http11 DEBUG response_closed.complete
19:24:04,688 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:04,695 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Great! Let's give it a try. Can you please place the candle in this spot? If you don't like it, we can move it to the left, right, up, or down. What do you think?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:24:04,697 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:04,697 httpcore.http11 DEBUG send_request_headers.complete
19:24:04,697 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:04,698 httpcore.http11 DEBUG send_request_body.complete
19:24:04,698 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:05,407 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'586'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2aacc8f272f97faa5b834d6f5ef174d5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833995255c744d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:05,409 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:24:05,410 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:06,874 httpcore.http11 DEBUG receive_response_body.complete
19:24:06,874 httpcore.http11 DEBUG response_closed.started
19:24:06,874 httpcore.http11 DEBUG response_closed.complete
19:24:06,875 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:24:06,945 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:24:22,510 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:24:22,512 httpcore.connection DEBUG close.started
19:24:22,512 httpcore.connection DEBUG close.complete
19:24:22,513 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:24:22,515 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7f050>
19:24:22,515 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:24:22,521 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7f090>
19:24:22,522 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:22,522 httpcore.http11 DEBUG send_request_headers.complete
19:24:22,523 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:22,544 httpcore.http11 DEBUG send_request_body.complete
19:24:22,545 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:23,490 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:23 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'488'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'202f8b982926c3929b6bf364e33488bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399594cc2d6ac9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:23,492 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:24:23,492 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:23,493 httpcore.http11 DEBUG receive_response_body.complete
19:24:23,494 httpcore.http11 DEBUG response_closed.started
19:24:23,494 httpcore.http11 DEBUG response_closed.complete
19:24:23,494 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:24:23,495 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:24:23,512 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nGreat! Let's give it a try. Can you please place the candle in this spot? If you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nYes, let's put it here.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:23,515 httpcore.connection DEBUG close.started
19:24:23,515 httpcore.connection DEBUG close.complete
19:24:23,515 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:23,518 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e650>
19:24:23,518 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:24:23,524 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e510>
19:24:23,525 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:23,525 httpcore.http11 DEBUG send_request_headers.complete
19:24:23,525 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:23,526 httpcore.http11 DEBUG send_request_body.complete
19:24:23,526 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:23,766 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6d6853fb64f8b5315898f5a81ad65e85'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339959b09874d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:23,767 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:23,768 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:23,768 httpcore.http11 DEBUG receive_response_body.complete
19:24:23,768 httpcore.http11 DEBUG response_closed.started
19:24:23,768 httpcore.http11 DEBUG response_closed.complete
19:24:23,769 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:23,784 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nGreat! Let's give it a try. Can you please place the candle in this spot? If you don't like it, we can move it to the left, right, up, or down. What do you think?\n'''\nAnd the human answered\n'''\nYes, let's put it here.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:23,795 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:23,797 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9ce10>
19:24:23,798 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:24:23,806 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9c2d0>
19:24:23,806 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:23,807 httpcore.http11 DEBUG send_request_headers.complete
19:24:23,807 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:23,809 httpcore.http11 DEBUG send_request_body.complete
19:24:23,809 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:24,10 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'100'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b0d275018ffd448704535395825e5e21'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=1d.2truoJQQlBjLLgF3tsadu7_eHS4bAYBwdIP_m1VU-1702254264-1-AZZwKwmpLtShBG7Qzyrl1OQOONK9u1CHzyc77In7pi5J8F1rHWz+wSWcRpzaHCap1HgjcA4JLNQP9dKkKJX+uac=; path=/; expires=Mon, 11-Dec-23 00:54:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zpuD9WEyjvI0avTRnFUXAe6sbEX4Z_Eb27PMBD7sV.k-1702254264007-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339959ccece4d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:24,14 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:24,14 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:24,15 httpcore.http11 DEBUG receive_response_body.complete
19:24:24,15 httpcore.http11 DEBUG response_closed.started
19:24:24,15 httpcore.http11 DEBUG response_closed.complete
19:24:24,16 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:24,28 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:24,31 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:27,432 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:27,439 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:27,442 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:29,443 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:29,456 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:29,458 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:32,859 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:32,863 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:24:32,868 httpcore.connection DEBUG close.started
19:24:32,869 httpcore.connection DEBUG close.complete
19:24:32,870 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:24:32,898 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7d050>
19:24:32,899 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:24:32,905 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7d850>
19:24:32,905 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:32,906 httpcore.http11 DEBUG send_request_headers.complete
19:24:32,907 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:32,907 httpcore.http11 DEBUG send_request_body.complete
19:24:32,907 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:33,331 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:33 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'351'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'18814dd6c98af4f85c98269c5f1c0846'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833995d5ab5c4ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:33,333 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:24:33,333 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:33,775 httpcore.http11 DEBUG receive_response_body.complete
19:24:33,776 httpcore.http11 DEBUG response_closed.started
19:24:33,776 httpcore.http11 DEBUG response_closed.complete
19:24:33,776 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:24:33,841 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:24:45,352 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:24:45,355 httpcore.connection DEBUG close.started
19:24:45,356 httpcore.connection DEBUG close.complete
19:24:45,356 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:24:45,358 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e4d0>
19:24:45,358 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:24:45,363 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8f2d0>
19:24:45,363 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:45,364 httpcore.http11 DEBUG send_request_headers.complete
19:24:45,364 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:45,389 httpcore.http11 DEBUG send_request_body.complete
19:24:45,389 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:46,594 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'40'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'694'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'127a1705b528c357eb42c6c5ea8e28f7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833996238e106ac6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:46,596 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:24:46,597 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:46,598 httpcore.http11 DEBUG receive_response_body.complete
19:24:46,598 httpcore.http11 DEBUG response_closed.started
19:24:46,598 httpcore.http11 DEBUG response_closed.complete
19:24:46,599 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:24:46,599 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:24:46,613 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:46,615 httpcore.connection DEBUG close.started
19:24:46,615 httpcore.connection DEBUG close.complete
19:24:46,616 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:46,618 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e510>
19:24:46,618 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:24:46,623 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8d6d0>
19:24:46,623 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:46,624 httpcore.http11 DEBUG send_request_headers.complete
19:24:46,624 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:46,624 httpcore.http11 DEBUG send_request_body.complete
19:24:46,624 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:46,799 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'91'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7dda8eaaa9b867fc53c17234f7db5309'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339962b68aa4d01-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:46,800 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:46,801 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:46,801 httpcore.http11 DEBUG receive_response_body.complete
19:24:46,802 httpcore.http11 DEBUG response_closed.started
19:24:46,802 httpcore.http11 DEBUG response_closed.complete
19:24:46,802 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:46,818 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:24:46,820 httpcore.connection DEBUG close.started
19:24:46,820 httpcore.connection DEBUG close.complete
19:24:46,820 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:24:46,823 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5de90>
19:24:46,823 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308072720> server_hostname='api.openai.com' timeout=None
19:24:46,828 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5cd50>
19:24:46,828 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:24:46,829 httpcore.http11 DEBUG send_request_headers.complete
19:24:46,829 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:24:46,829 httpcore.http11 DEBUG send_request_body.complete
19:24:46,829 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:24:47,214 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:24:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'289'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'16e18f53dbfad557d18c1a402bc02d82'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339962caafe4d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:24:47,216 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:24:47,217 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:24:47,218 httpcore.http11 DEBUG receive_response_body.complete
19:24:47,219 httpcore.http11 DEBUG response_closed.started
19:24:47,219 httpcore.http11 DEBUG response_closed.complete
19:24:47,219 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:24:47,229 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:47,231 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:52,933 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:52,944 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:52,947 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:57,648 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:57,660 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:57,663 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:24:59,664 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:24:59,675 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:24:59,678 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:03,80 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:03,91 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:25:03,94 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:08,796 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:08,808 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:25:08,811 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:12,616 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:12,627 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:25:12,630 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:16,432 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:16,435 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:25:16,439 httpcore.connection DEBUG close.started
19:25:16,439 httpcore.connection DEBUG close.complete
19:25:16,439 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:25:16,442 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8a490>
19:25:16,442 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:25:16,450 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89ad0>
19:25:16,450 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:16,451 httpcore.http11 DEBUG send_request_headers.complete
19:25:16,451 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:16,452 httpcore.http11 DEBUG send_request_body.complete
19:25:16,452 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:16,955 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'418'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'57066f5a577cbdb7cb0e6fc26bd56cd7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833996e5de344cd5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:16,957 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:25:16,957 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:18,110 httpcore.http11 DEBUG receive_response_body.complete
19:25:18,111 httpcore.http11 DEBUG response_closed.started
19:25:18,111 httpcore.http11 DEBUG response_closed.complete
19:25:18,111 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:25:18,170 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:25:31,192 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:25:31,195 httpcore.connection DEBUG close.started
19:25:31,195 httpcore.connection DEBUG close.complete
19:25:31,195 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:25:31,198 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9da10>
19:25:31,198 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:25:31,206 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9d450>
19:25:31,206 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:31,207 httpcore.http11 DEBUG send_request_headers.complete
19:25:31,207 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:31,222 httpcore.http11 DEBUG send_request_body.complete
19:25:31,222 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:32,42 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:32 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'358'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f4f5280b35026594bc9422dff6422924'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399742080f4cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:32,44 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:25:32,45 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:32,46 httpcore.http11 DEBUG receive_response_body.complete
19:25:32,46 httpcore.http11 DEBUG response_closed.started
19:25:32,46 httpcore.http11 DEBUG response_closed.complete
19:25:32,46 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:25:32,47 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:25:32,64 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:25:32,65 httpcore.connection DEBUG close.started
19:25:32,66 httpcore.connection DEBUG close.complete
19:25:32,66 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:25:32,68 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7afd0>
19:25:32,68 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:25:32,73 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7aa10>
19:25:32,73 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:32,74 httpcore.http11 DEBUG send_request_headers.complete
19:25:32,74 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:32,74 httpcore.http11 DEBUG send_request_body.complete
19:25:32,74 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:32,292 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ed1e78da6c426a87c42e5f31c2553fc7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997477d0b305d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:32,295 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:25:32,296 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:32,297 httpcore.http11 DEBUG receive_response_body.complete
19:25:32,297 httpcore.http11 DEBUG response_closed.started
19:25:32,298 httpcore.http11 DEBUG response_closed.complete
19:25:32,298 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:25:32,313 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:25:32,315 httpcore.connection DEBUG close.started
19:25:32,316 httpcore.connection DEBUG close.complete
19:25:32,316 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:25:32,318 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7e5d0>
19:25:32,318 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:25:32,324 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7f590>
19:25:32,325 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:32,325 httpcore.http11 DEBUG send_request_headers.complete
19:25:32,325 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:32,326 httpcore.http11 DEBUG send_request_body.complete
19:25:32,326 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:32,565 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'783600ed48e329b3d39480425dfaa50b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997490a6e4cde-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:32,568 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:25:32,568 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:32,569 httpcore.http11 DEBUG receive_response_body.complete
19:25:32,569 httpcore.http11 DEBUG response_closed.started
19:25:32,570 httpcore.http11 DEBUG response_closed.complete
19:25:32,570 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:25:32,580 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:25:32,583 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:25:35,984 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:25:35,987 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:25:35,992 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:35,993 httpcore.http11 DEBUG send_request_headers.complete
19:25:35,994 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:35,994 httpcore.http11 DEBUG send_request_body.complete
19:25:35,994 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:36,665 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'546'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd3b7bfdc74474a4634533790d0ac82f3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339975ffc1c4cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:36,667 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:25:36,668 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:37,673 httpcore.http11 DEBUG receive_response_body.complete
19:25:37,674 httpcore.http11 DEBUG response_closed.started
19:25:37,674 httpcore.http11 DEBUG response_closed.complete
19:25:37,675 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:25:37,741 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:25:50,595 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:25:50,597 httpcore.connection DEBUG close.started
19:25:50,598 httpcore.connection DEBUG close.complete
19:25:50,598 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:25:50,627 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8c090>
19:25:50,628 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:25:50,634 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8f0d0>
19:25:50,634 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:50,635 httpcore.http11 DEBUG send_request_headers.complete
19:25:50,636 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:50,661 httpcore.http11 DEBUG send_request_body.complete
19:25:50,661 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:51,500 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:51 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'353'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'13eddda7ba892c4ee5650bb640b76f40'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997bb78094cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:51,503 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:25:51,503 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:51,504 httpcore.http11 DEBUG receive_response_body.complete
19:25:51,505 httpcore.http11 DEBUG response_closed.started
19:25:51,505 httpcore.http11 DEBUG response_closed.complete
19:25:51,505 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:25:51,506 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:25:51,519 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nThank you for watching!\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:25:51,521 httpcore.connection DEBUG close.started
19:25:51,521 httpcore.connection DEBUG close.complete
19:25:51,522 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:25:51,524 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9e190>
19:25:51,524 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:25:51,531 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9fc10>
19:25:51,531 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:51,532 httpcore.http11 DEBUG send_request_headers.complete
19:25:51,532 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:51,532 httpcore.http11 DEBUG send_request_body.complete
19:25:51,532 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:51,772 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'137'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4b0c0e878b02125b407de79dff4134a1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997c1186c4d0b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:51,773 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:25:51,774 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:51,774 httpcore.http11 DEBUG receive_response_body.complete
19:25:51,775 httpcore.http11 DEBUG response_closed.started
19:25:51,775 httpcore.http11 DEBUG response_closed.complete
19:25:51,775 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:25:51,781 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:25:51,784 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:25:51,785 httpcore.http11 DEBUG send_request_headers.complete
19:25:51,786 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:25:51,786 httpcore.http11 DEBUG send_request_body.complete
19:25:51,786 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:25:52,425 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:25:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'521'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b45148ba6d6efe31e8506d0c542b26cb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833997c2aeed4cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:25:52,427 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:25:52,427 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:25:53,525 httpcore.http11 DEBUG receive_response_body.complete
19:25:53,526 httpcore.http11 DEBUG response_closed.started
19:25:53,526 httpcore.http11 DEBUG response_closed.complete
19:25:53,526 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:25:53,590 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:26:06,543 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:26:06,547 httpcore.connection DEBUG close.started
19:26:06,547 httpcore.connection DEBUG close.complete
19:26:06,547 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:26:06,550 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e80190>
19:26:06,550 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:26:06,555 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e80290>
19:26:06,556 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:06,556 httpcore.http11 DEBUG send_request_headers.complete
19:26:06,556 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:06,577 httpcore.http11 DEBUG send_request_body.complete
19:26:06,577 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:07,413 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'24678155cb2d72eab145ab367efb8b02'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339981efb503025-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:07,415 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:26:07,416 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:07,417 httpcore.http11 DEBUG receive_response_body.complete
19:26:07,417 httpcore.http11 DEBUG response_closed.started
19:26:07,418 httpcore.http11 DEBUG response_closed.complete
19:26:07,418 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:26:07,418 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:26:07,434 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:07,436 httpcore.connection DEBUG close.started
19:26:07,437 httpcore.connection DEBUG close.complete
19:26:07,437 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:07,439 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9fc10>
19:26:07,439 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:26:07,444 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9e490>
19:26:07,444 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:07,444 httpcore.http11 DEBUG send_request_headers.complete
19:26:07,444 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:07,445 httpcore.http11 DEBUG send_request_body.complete
19:26:07,445 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:07,622 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'77'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'02aea47d129f69e09b0c4647e639b76b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998248f953b94-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:07,624 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:26:07,625 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:07,626 httpcore.http11 DEBUG receive_response_body.complete
19:26:07,627 httpcore.http11 DEBUG response_closed.started
19:26:07,627 httpcore.http11 DEBUG response_closed.complete
19:26:07,627 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:26:07,639 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:26:07,641 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:26:11,42 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:26:11,55 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:26:11,59 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:26:13,62 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:26:13,72 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:26:13,76 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:26:16,478 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:26:16,481 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:26:16,485 httpcore.connection DEBUG close.started
19:26:16,485 httpcore.connection DEBUG close.complete
19:26:16,486 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:26:16,488 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8d690>
19:26:16,489 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:26:16,495 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9d750>
19:26:16,495 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:16,496 httpcore.http11 DEBUG send_request_headers.complete
19:26:16,496 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:16,497 httpcore.http11 DEBUG send_request_body.complete
19:26:16,497 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:17,172 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:17 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'512'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6dd37640c7b4525d519b0265c802fbd5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339985d1a5d304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:17,175 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:26:17,175 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:17,536 httpcore.http11 DEBUG receive_response_body.complete
19:26:17,536 httpcore.http11 DEBUG response_closed.started
19:26:17,537 httpcore.http11 DEBUG response_closed.complete
19:26:17,537 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:26:17,611 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:26:28,898 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:26:28,901 httpcore.connection DEBUG close.started
19:26:28,901 httpcore.connection DEBUG close.complete
19:26:28,901 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:26:28,903 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8fed0>
19:26:28,904 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:26:28,911 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8ecd0>
19:26:28,911 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:28,912 httpcore.http11 DEBUG send_request_headers.complete
19:26:28,912 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:28,939 httpcore.http11 DEBUG send_request_body.complete
19:26:28,939 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:30,41 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'25'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb4052a16f81e2381d7d70e97e2e7080'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998aabf7d3074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:30,43 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:26:30,43 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:30,44 httpcore.http11 DEBUG receive_response_body.complete
19:26:30,45 httpcore.http11 DEBUG response_closed.started
19:26:30,45 httpcore.http11 DEBUG response_closed.complete
19:26:30,45 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:26:30,46 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:26:30,61 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nDo you have suggestions?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:30,62 httpcore.connection DEBUG close.started
19:26:30,63 httpcore.connection DEBUG close.complete
19:26:30,63 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:30,65 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8add0>
19:26:30,65 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:26:30,72 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89c50>
19:26:30,72 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:30,73 httpcore.http11 DEBUG send_request_headers.complete
19:26:30,73 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:30,73 httpcore.http11 DEBUG send_request_body.complete
19:26:30,73 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:30,283 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c01fa7420b3c66b684dc96c7c15693ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998b1fbfb4cec-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:30,286 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:26:30,286 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:30,287 httpcore.http11 DEBUG receive_response_body.complete
19:26:30,287 httpcore.http11 DEBUG response_closed.started
19:26:30,288 httpcore.http11 DEBUG response_closed.complete
19:26:30,288 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:26:30,306 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nDo you have suggestions?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:30,308 httpcore.connection DEBUG close.started
19:26:30,308 httpcore.connection DEBUG close.complete
19:26:30,308 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:30,311 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e897d0>
19:26:30,311 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff3080722a0> server_hostname='api.openai.com' timeout=None
19:26:30,316 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5e850>
19:26:30,316 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:30,317 httpcore.http11 DEBUG send_request_headers.complete
19:26:30,317 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:30,317 httpcore.http11 DEBUG send_request_body.complete
19:26:30,317 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:31,494 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1068'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a27aa1af5a65621e54e0290fec79ef28'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998b3783c4cc9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:31,497 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:26:31,497 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:31,499 httpcore.http11 DEBUG receive_response_body.complete
19:26:31,499 httpcore.http11 DEBUG response_closed.started
19:26:31,499 httpcore.http11 DEBUG response_closed.complete
19:26:31,499 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:26:31,505 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'I suggest placing the third candle in the center of the cake. Would you like me to place it there for you? If so, I can do that for you. Otherwise, please let me know where you would like me to place the third candle.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:26:31,508 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:31,509 httpcore.http11 DEBUG send_request_headers.complete
19:26:31,509 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:31,510 httpcore.http11 DEBUG send_request_body.complete
19:26:31,510 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:32,138 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:32 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'516'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'02e6296107af7026456231f35f0160aa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833998baea623074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:32,140 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:26:32,141 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:34,547 httpcore.http11 DEBUG receive_response_body.complete
19:26:34,547 httpcore.http11 DEBUG response_closed.started
19:26:34,547 httpcore.http11 DEBUG response_closed.complete
19:26:34,548 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:26:34,619 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:26:57,473 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen9.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:26:57,477 httpcore.connection DEBUG close.started
19:26:57,478 httpcore.connection DEBUG close.complete
19:26:57,478 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:26:57,507 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e82d90>
19:26:57,507 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:26:57,516 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e82e90>
19:26:57,516 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:57,517 httpcore.http11 DEBUG send_request_headers.complete
19:26:57,518 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:57,555 httpcore.http11 DEBUG send_request_body.complete
19:26:57,556 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:59,412 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c8b5b6bfd7cbe1fa5907edce57654d3d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339995d79054cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:59,414 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:26:59,414 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:59,415 httpcore.http11 DEBUG receive_response_body.complete
19:26:59,415 httpcore.http11 DEBUG response_closed.started
19:26:59,415 httpcore.http11 DEBUG response_closed.complete
19:26:59,415 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:26:59,416 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:26:59,430 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nI suggest placing the third candle in the center of the cake. Would you like me to place it there for you? If so, I can do that for you. Otherwise, please let me know where you would like me to place the third candle.\n'''\nAnd the human answered\n'''\nNo, the first candle is in the center. Place it to the right of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:59,432 httpcore.connection DEBUG close.started
19:26:59,433 httpcore.connection DEBUG close.complete
19:26:59,433 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:59,435 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8bc50>
19:26:59,436 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:26:59,441 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8a310>
19:26:59,441 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:59,442 httpcore.http11 DEBUG send_request_headers.complete
19:26:59,442 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:59,442 httpcore.http11 DEBUG send_request_body.complete
19:26:59,442 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:26:59,650 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:26:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'de1531f8455db1c73c3ddc8b5441b70b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833999698d5b4ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:26:59,651 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:26:59,652 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:26:59,652 httpcore.http11 DEBUG receive_response_body.complete
19:26:59,653 httpcore.http11 DEBUG response_closed.started
19:26:59,653 httpcore.http11 DEBUG response_closed.complete
19:26:59,653 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:26:59,673 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nI suggest placing the third candle in the center of the cake. Would you like me to place it there for you? If so, I can do that for you. Otherwise, please let me know where you would like me to place the third candle.\n'''\nAnd the human answered\n'''\nNo, the first candle is in the center. Place it to the right of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:26:59,675 httpcore.connection DEBUG close.started
19:26:59,675 httpcore.connection DEBUG close.complete
19:26:59,676 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:26:59,678 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e50890>
19:26:59,678 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308072720> server_hostname='api.openai.com' timeout=None
19:26:59,685 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e5cd50>
19:26:59,685 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:26:59,686 httpcore.http11 DEBUG send_request_headers.complete
19:26:59,686 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:26:59,686 httpcore.http11 DEBUG send_request_body.complete
19:26:59,686 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:00,385 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'587'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c3175a9b546a60622de85ca067168b7b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8339996b0fab4d04-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:00,388 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:27:00,388 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:00,390 httpcore.http11 DEBUG receive_response_body.complete
19:27:00,390 httpcore.http11 DEBUG response_closed.started
19:27:00,390 httpcore.http11 DEBUG response_closed.complete
19:27:00,391 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:27:00,403 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:00,407 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:06,108 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:06,122 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:06,125 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:10,826 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:10,835 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:10,839 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:12,840 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:12,852 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:12,855 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:16,256 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:16,270 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:16,272 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:21,973 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:21,984 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:21,987 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:26,589 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:26,601 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:26,604 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:30,806 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:30,809 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:27:30,814 httpcore.connection DEBUG close.started
19:27:30,814 httpcore.connection DEBUG close.complete
19:27:30,815 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:27:30,855 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e7d6d0>
19:27:30,855 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:27:30,863 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8d950>
19:27:30,864 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:30,864 httpcore.http11 DEBUG send_request_headers.complete
19:27:30,865 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:30,865 httpcore.http11 DEBUG send_request_body.complete
19:27:30,865 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:31,378 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2ccb698828b08263cd36a8ba8636fa38'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399a2dee4d3b99-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:31,380 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:27:31,381 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:32,470 httpcore.http11 DEBUG receive_response_body.complete
19:27:32,471 httpcore.http11 DEBUG response_closed.started
19:27:32,471 httpcore.http11 DEBUG response_closed.complete
19:27:32,472 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:27:32,536 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen10.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:27:45,399 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen10.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:27:45,402 httpcore.connection DEBUG close.started
19:27:45,402 httpcore.connection DEBUG close.complete
19:27:45,403 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:27:45,405 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9d410>
19:27:45,405 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:27:45,413 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9c290>
19:27:45,413 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:45,414 httpcore.http11 DEBUG send_request_headers.complete
19:27:45,414 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:45,423 httpcore.http11 DEBUG send_request_body.complete
19:27:45,423 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:46,192 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'16'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2e1a63fa118c564811b04744796fa3fa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399a88dd164ce3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:46,194 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:27:46,195 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:46,196 httpcore.http11 DEBUG receive_response_body.complete
19:27:46,196 httpcore.http11 DEBUG response_closed.started
19:27:46,196 httpcore.http11 DEBUG response_closed.complete
19:27:46,197 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:27:46,197 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:27:46,213 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nUh, move right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:27:46,215 httpcore.connection DEBUG close.started
19:27:46,215 httpcore.connection DEBUG close.complete
19:27:46,215 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:27:46,218 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e826d0>
19:27:46,218 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071f40> server_hostname='api.openai.com' timeout=None
19:27:46,224 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e81f10>
19:27:46,224 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:46,225 httpcore.http11 DEBUG send_request_headers.complete
19:27:46,225 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:46,226 httpcore.http11 DEBUG send_request_body.complete
19:27:46,226 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:46,427 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7a9c9bf7f7c0dd57c526c4a4d83e1736'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399a8dec1c4d17-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:46,429 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:27:46,429 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:46,430 httpcore.http11 DEBUG receive_response_body.complete
19:27:46,430 httpcore.http11 DEBUG response_closed.started
19:27:46,430 httpcore.http11 DEBUG response_closed.complete
19:27:46,430 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:27:46,445 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nUh, move right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:27:46,447 httpcore.connection DEBUG close.started
19:27:46,447 httpcore.connection DEBUG close.complete
19:27:46,447 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:27:46,449 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9e6d0>
19:27:46,449 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:27:46,457 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9c210>
19:27:46,458 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:46,458 httpcore.http11 DEBUG send_request_headers.complete
19:27:46,458 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:46,459 httpcore.http11 DEBUG send_request_body.complete
19:27:46,459 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:46,681 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8c9b318084ce63b46e5659c1ba6df5b8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399a8f5fa04ce8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:46,684 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:27:46,685 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:46,686 httpcore.http11 DEBUG receive_response_body.complete
19:27:46,687 httpcore.http11 DEBUG response_closed.started
19:27:46,688 httpcore.http11 DEBUG response_closed.complete
19:27:46,688 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:27:46,697 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:27:46,700 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:27:50,101 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:27:50,105 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:27:50,110 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:27:50,111 httpcore.http11 DEBUG send_request_headers.complete
19:27:50,111 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:27:50,112 httpcore.http11 DEBUG send_request_body.complete
19:27:50,112 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:27:50,624 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:27:50 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'385c57c4c50c534871ce9dbd3382221d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399aa639514ce3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:27:50,626 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:27:50,626 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:27:51,724 httpcore.http11 DEBUG receive_response_body.complete
19:27:51,725 httpcore.http11 DEBUG response_closed.started
19:27:51,725 httpcore.http11 DEBUG response_closed.complete
19:27:51,726 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:27:51,794 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen11.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:28:04,788 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen11.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:28:04,792 httpcore.connection DEBUG close.started
19:28:04,792 httpcore.connection DEBUG close.complete
19:28:04,793 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:28:04,823 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9e910>
19:28:04,824 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:28:04,831 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9f0d0>
19:28:04,832 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:04,833 httpcore.http11 DEBUG send_request_headers.complete
19:28:04,833 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:04,866 httpcore.http11 DEBUG send_request_body.complete
19:28:04,866 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:05,823 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:05 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'446'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'73e5ffea3597d626ff1f8af3923ad92a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b0239f34cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:05,825 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:28:05,825 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:05,826 httpcore.http11 DEBUG receive_response_body.complete
19:28:05,826 httpcore.http11 DEBUG response_closed.started
19:28:05,826 httpcore.http11 DEBUG response_closed.complete
19:28:05,827 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:28:05,827 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:28:05,845 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nThank you for watching!\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:28:05,847 httpcore.connection DEBUG close.started
19:28:05,847 httpcore.connection DEBUG close.complete
19:28:05,847 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:28:05,849 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e7d0>
19:28:05,850 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:28:05,856 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8e6d0>
19:28:05,856 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:05,857 httpcore.http11 DEBUG send_request_headers.complete
19:28:05,857 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:05,857 httpcore.http11 DEBUG send_request_body.complete
19:28:05,857 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:06,61 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'91'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'947e530137a112c992c99df058803682'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b089cec4ce2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:06,64 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:28:06,65 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:06,66 httpcore.http11 DEBUG receive_response_body.complete
19:28:06,66 httpcore.http11 DEBUG response_closed.started
19:28:06,66 httpcore.http11 DEBUG response_closed.complete
19:28:06,67 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:28:06,73 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:28:06,77 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:06,78 httpcore.http11 DEBUG send_request_headers.complete
19:28:06,78 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:06,78 httpcore.http11 DEBUG send_request_body.complete
19:28:06,78 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:06,590 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:06 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'432'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fa2ffa16792fa9ac377bdf113be8fb80'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b09fa4b4cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:06,592 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:28:06,593 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:07,833 httpcore.http11 DEBUG receive_response_body.complete
19:28:07,833 httpcore.http11 DEBUG response_closed.started
19:28:07,834 httpcore.http11 DEBUG response_closed.complete
19:28:07,834 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:28:07,903 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen12.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:28:20,931 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen12.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:28:20,938 httpcore.connection DEBUG close.started
19:28:20,938 httpcore.connection DEBUG close.complete
19:28:20,939 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:28:20,941 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89910>
19:28:20,941 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:28:20,947 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e89250>
19:28:20,947 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:20,948 httpcore.http11 DEBUG send_request_headers.complete
19:28:20,948 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:20,968 httpcore.http11 DEBUG send_request_body.complete
19:28:20,969 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:21,835 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'3'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'374'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b65a28209f153d0a0c7cbcae94687b05'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b66efe04cd2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:21,837 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:28:21,838 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:21,838 httpcore.http11 DEBUG receive_response_body.complete
19:28:21,838 httpcore.http11 DEBUG response_closed.started
19:28:21,839 httpcore.http11 DEBUG response_closed.complete
19:28:21,839 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:28:21,839 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:28:21,856 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\n. \n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:28:21,858 httpcore.connection DEBUG close.started
19:28:21,858 httpcore.connection DEBUG close.complete
19:28:21,858 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:28:21,861 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ea5550>
19:28:21,861 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:28:21,867 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307ea4190>
19:28:21,867 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:21,868 httpcore.http11 DEBUG send_request_headers.complete
19:28:21,868 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:21,868 httpcore.http11 DEBUG send_request_body.complete
19:28:21,868 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:22,101 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'131'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4edfc78154eed74f563c97880a9c9f51'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b6cace94cc8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:22,104 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:28:22,105 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:22,106 httpcore.http11 DEBUG receive_response_body.complete
19:28:22,106 httpcore.http11 DEBUG response_closed.started
19:28:22,107 httpcore.http11 DEBUG response_closed.complete
19:28:22,107 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:28:22,115 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:28:22,117 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:22,117 httpcore.http11 DEBUG send_request_headers.complete
19:28:22,117 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:22,118 httpcore.http11 DEBUG send_request_body.complete
19:28:22,118 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:22,623 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:22 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'416'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2066db80d0438168871f47e3e705f269'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399b6e39a34cd2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:22,626 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:28:22,626 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:23,810 httpcore.http11 DEBUG receive_response_body.complete
19:28:23,811 httpcore.http11 DEBUG response_closed.started
19:28:23,811 httpcore.http11 DEBUG response_closed.complete
19:28:23,811 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:28:23,879 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen13.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:28:36,825 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen13.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:28:36,829 httpcore.connection DEBUG close.started
19:28:36,829 httpcore.connection DEBUG close.complete
19:28:36,830 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:28:36,833 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8de50>
19:28:36,833 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071d90> server_hostname='api.openai.com' timeout=5.0
19:28:36,841 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e8d3d0>
19:28:36,842 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:36,843 httpcore.http11 DEBUG send_request_headers.complete
19:28:36,843 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:36,862 httpcore.http11 DEBUG send_request_body.complete
19:28:36,863 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:37,640 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'383a9930b8c2a31eb3fdb3f36d410eee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399bca4e074d04-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:37,642 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:28:37,643 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:37,644 httpcore.http11 DEBUG receive_response_body.complete
19:28:37,644 httpcore.http11 DEBUG response_closed.started
19:28:37,644 httpcore.http11 DEBUG response_closed.complete
19:28:37,645 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:28:37,645 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:28:37,662 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:28:37,664 httpcore.connection DEBUG close.started
19:28:37,664 httpcore.connection DEBUG close.complete
19:28:37,664 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:28:37,667 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9fe50>
19:28:37,667 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff308071eb0> server_hostname='api.openai.com' timeout=None
19:28:37,672 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff307e9ebd0>
19:28:37,673 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:28:37,673 httpcore.http11 DEBUG send_request_headers.complete
19:28:37,673 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:28:37,674 httpcore.http11 DEBUG send_request_body.complete
19:28:37,674 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:28:37,849 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 00:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'55'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fe463c78e55c5d98cf4eb20f763e5631'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83399bcf7e5b4d0c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:28:37,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:28:37,852 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:28:37,853 httpcore.http11 DEBUG receive_response_body.complete
19:28:37,854 httpcore.http11 DEBUG response_closed.started
19:28:37,854 httpcore.http11 DEBUG response_closed.complete
19:28:37,854 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:28:37,864 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:28:37,868 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:28:41,269 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:28:41,280 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:28:41,284 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:28:43,286 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:28:43,302 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:28:43,306 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:28:46,708 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:26:09,613 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:09,617 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,457 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,458 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,499 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,501 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,548 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,549 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,589 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,590 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,637 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,638 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,679 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,680 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,728 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,729 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:10,769 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:26:10,770 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:26:16,250 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:26:16,268 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:26:16,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f61ca68e290>
21:26:16,301 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f61ca4e1d00> server_hostname='api.openai.com' timeout=5.0
21:26:16,310 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f61ca463210>
21:26:16,311 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:26:16,313 httpcore.http11 DEBUG send_request_headers.complete
21:26:16,314 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:26:16,314 httpcore.http11 DEBUG send_request_body.complete
21:26:16,314 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:26:16,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Mon, 11 Dec 2023 02:26:16 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'301'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'd6de30f7f00cc1bcf6f2f234c349293c'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JJB9INgJeSl5LoDG03GJPlyI9VXvKVUUNhbAOVLFvU8-1702261576-1-AYUsGCgwi8BibGVipcg/fi4He0C+LR7MlVL6vP9ELROa10I6bnYF6axq8Sf/ykbP2v4C0gO4J5ucsfH1Fs46iRY=; path=/; expires=Mon, 11-Dec-23 02:56:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1mU5YpNIzMJVAynjtDln4ZQoiwxEARrRbvdBP2cCPmE-1702261576448-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4823fca74d13-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:26:16,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 401 Unauthorized"
21:26:16,459 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:26:16,460 httpcore.http11 DEBUG receive_response_body.complete
21:26:16,460 httpcore.http11 DEBUG response_closed.started
21:26:16,460 httpcore.http11 DEBUG response_closed.complete
21:26:16,461 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "401 Unauthorized"
21:30:53,645 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:53,649 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,479 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,481 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,528 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,529 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,581 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,582 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,626 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,627 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,680 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,681 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,725 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,726 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,779 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,780 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:54,823 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:30:54,825 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:30:56,620 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:30:56,651 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:30:56,681 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee7decd0>
21:30:56,681 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:30:56,693 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee563350>
21:30:56,694 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:30:56,697 httpcore.http11 DEBUG send_request_headers.complete
21:30:56,698 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:30:56,699 httpcore.http11 DEBUG send_request_body.complete
21:30:56,699 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:30:57,248 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:30:57 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a5fdd0405b088fe85bce202263e25342'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SL1dtDakfruMYlYTGJA4Hsfb9pIBBNMMExE8jT9Y5hM-1702261857-1-ATMGs8iwUmqKODgBlqat3oFAKzw6qFbJjR0R2kIejazX7zQx9fOQsaCnOALu5aVxQe6yo/j5F3rmkAC4KMvzmZ8=; path=/; expires=Mon, 11-Dec-23 03:00:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=9W7jy0qiL.SNtSqG4uAbj1vwrGqRHlvRpp5YzXRRtQQ-1702261857242-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4efc5ad73074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:30:57,257 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:30:57,258 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:30:58,75 httpcore.http11 DEBUG receive_response_body.complete
21:30:58,76 httpcore.http11 DEBUG response_closed.started
21:30:58,77 httpcore.http11 DEBUG response_closed.complete
21:30:58,78 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:30:58,174 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:31:11,470 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:31:11,480 httpcore.connection DEBUG close.started
21:31:11,480 httpcore.connection DEBUG close.complete
21:31:11,481 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:31:11,483 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee563350>
21:31:11,484 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:31:11,490 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee563450>
21:31:11,490 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:11,491 httpcore.http11 DEBUG send_request_headers.complete
21:31:11,492 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:11,521 httpcore.http11 DEBUG send_request_body.complete
21:31:11,522 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:12,407 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:12 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'358'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'09bf72f5b1fcfab0837e996032cd520d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4f58d8e64cf2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:12,412 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:31:12,413 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:12,414 httpcore.http11 DEBUG receive_response_body.complete
21:31:12,414 httpcore.http11 DEBUG response_closed.started
21:31:12,414 httpcore.http11 DEBUG response_closed.complete
21:31:12,414 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:31:12,415 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:31:12,448 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:31:12,460 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:31:12,462 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3c4750>
21:31:12,462 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:31:12,475 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee587510>
21:31:12,476 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:12,477 httpcore.http11 DEBUG send_request_headers.complete
21:31:12,478 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:12,479 httpcore.http11 DEBUG send_request_body.complete
21:31:12,479 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:12,794 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'104'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e26d9c4bd9db007c4f8ff7f44c59d988'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uNHjk5DBjFfh93cDtHiXrv2zQcjEwWZIfyOxvQUTJEs-1702261872-1-Ae6SsFXsVivMNMMaGAjcJ79viWFVWV0N8FSU9qLlWW/90XIsumH7SlRMHTpQuEooeEKpa7TT8Gp4BRI+DifsxZo=; path=/; expires=Mon, 11-Dec-23 03:01:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=uHjIHkk3TITcczHFyROvfwJhtClgT9qBfyhsQJKPTy8-1702261872789-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4f5efa203b70-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:12,798 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:31:12,799 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:12,800 httpcore.http11 DEBUG receive_response_body.complete
21:31:12,801 httpcore.http11 DEBUG response_closed.started
21:31:12,801 httpcore.http11 DEBUG response_closed.complete
21:31:12,802 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:31:12,837 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:31:12,848 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:31:12,851 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3cb7d0>
21:31:12,851 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e2690> server_hostname='api.openai.com' timeout=None
21:31:12,857 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3cb750>
21:31:12,857 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:12,859 httpcore.http11 DEBUG send_request_headers.complete
21:31:12,859 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:12,860 httpcore.http11 DEBUG send_request_body.complete
21:31:12,860 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:13,661 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'685'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b1d22c5325860909301a20abf0e939cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ZH0cPMaAXqMKrsfL0pBa.pYZlfYO.SShdhyRGfqdWIY-1702261873-1-AduAyOlpfCDeFcqjqvHR8aDtePV0qT+bxwCF1XCgDbFvpbax2guebkiw5TXyxIZUeujju0yPZkq/ZmGwq0CXGrI=; path=/; expires=Mon, 11-Dec-23 03:01:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=vYkGchIG5PfFfVYflJtGWNph9bk1nr.2z7Gyvgol9Ko-1702261873656-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a4f615eff4d02-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:13,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:31:13,671 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:13,672 httpcore.http11 DEBUG receive_response_body.complete
21:31:13,672 httpcore.http11 DEBUG response_closed.started
21:31:13,673 httpcore.http11 DEBUG response_closed.complete
21:31:13,673 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:31:13,692 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:13,696 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:20,204 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:20,217 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:20,220 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:25,222 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:25,240 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:25,242 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:27,245 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:27,261 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:27,264 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:30,666 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:30,684 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:30,688 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:37,190 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:37,207 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:37,211 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:41,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:41,32 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:31:41,35 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:31:44,837 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:31:44,843 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:31:44,849 httpcore.connection DEBUG close.started
21:31:44,850 httpcore.connection DEBUG close.complete
21:31:44,850 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:31:44,868 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee563450>
21:31:44,868 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:31:44,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee562590>
21:31:44,876 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:44,878 httpcore.http11 DEBUG send_request_headers.complete
21:31:44,879 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:44,880 httpcore.http11 DEBUG send_request_body.complete
21:31:44,880 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:45,469 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'426'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'45442f37e0d4469cabfc53d8f4de84c7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50297d814d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:45,474 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:31:45,475 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:46,585 httpcore.http11 DEBUG receive_response_body.complete
21:31:46,586 httpcore.http11 DEBUG response_closed.started
21:31:46,587 httpcore.http11 DEBUG response_closed.complete
21:31:46,588 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:31:46,654 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:31:59,39 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:31:59,43 httpcore.connection DEBUG close.started
21:31:59,43 httpcore.connection DEBUG close.complete
21:31:59,44 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:31:59,73 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee3d0>
21:31:59,73 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:31:59,83 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee450>
21:31:59,83 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:59,85 httpcore.http11 DEBUG send_request_headers.complete
21:31:59,86 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:59,103 httpcore.http11 DEBUG send_request_body.complete
21:31:59,103 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:31:59,854 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:31:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'03858aa243573cbbe100af37f8262101'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50825b414ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:31:59,859 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:31:59,859 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:31:59,860 httpcore.http11 DEBUG receive_response_body.complete
21:31:59,861 httpcore.http11 DEBUG response_closed.started
21:31:59,861 httpcore.http11 DEBUG response_closed.complete
21:31:59,862 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:31:59,863 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:31:59,903 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:31:59,908 httpcore.connection DEBUG close.started
21:31:59,909 httpcore.connection DEBUG close.complete
21:31:59,910 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:31:59,912 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee585b50>
21:31:59,913 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:31:59,924 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee587390>
21:31:59,925 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:31:59,926 httpcore.http11 DEBUG send_request_headers.complete
21:31:59,926 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:31:59,926 httpcore.http11 DEBUG send_request_body.complete
21:31:59,927 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:00,173 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'110'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9987e9dc2e9045af592d203016bbbc82'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50878e694d10-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:00,179 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:00,179 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:00,181 httpcore.http11 DEBUG receive_response_body.complete
21:32:00,182 httpcore.http11 DEBUG response_closed.started
21:32:00,182 httpcore.http11 DEBUG response_closed.complete
21:32:00,182 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:00,215 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:00,226 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:00,229 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee010>
21:32:00,229 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:32:00,236 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3edd90>
21:32:00,236 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:00,237 httpcore.http11 DEBUG send_request_headers.complete
21:32:00,238 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:00,238 httpcore.http11 DEBUG send_request_body.complete
21:32:00,239 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:00,470 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'40a1d7476bf510b4016dc12fba20c804'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=m0stj1GetuehKfRK6KIZYbAzsOm27YLXKaZqggl0V4g-1702261920-1-AWI2u1KRqvk7NCZnnSrXzLD64W985f9HCXlERIblnYYFHIprDZGFLA47moL4vq1CY7knnRQSJ3xZpTXZXpvqDyE=; path=/; expires=Mon, 11-Dec-23 03:02:00 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LkIcgm4ZVOc8zcNQnJaUtkjpm8dn.kUkW4nYZno4q_U-1702261920466-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50897bd24cf9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:00,479 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:00,480 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:00,482 httpcore.http11 DEBUG receive_response_body.complete
21:32:00,482 httpcore.http11 DEBUG response_closed.started
21:32:00,482 httpcore.http11 DEBUG response_closed.complete
21:32:00,483 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:00,498 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:00,501 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:03,903 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:03,910 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:32:03,916 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:03,916 httpcore.http11 DEBUG send_request_headers.complete
21:32:03,917 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:03,917 httpcore.http11 DEBUG send_request_body.complete
21:32:03,917 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:04,472 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:04 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'431'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'087732f4f4a4b1206066619d5f0fc89f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50a07d1b4ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:04,477 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:32:04,478 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:05,697 httpcore.http11 DEBUG receive_response_body.complete
21:32:05,698 httpcore.http11 DEBUG response_closed.started
21:32:05,699 httpcore.http11 DEBUG response_closed.complete
21:32:05,699 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:32:05,765 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:32:18,174 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:32:18,178 httpcore.connection DEBUG close.started
21:32:18,178 httpcore.connection DEBUG close.complete
21:32:18,178 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:32:18,181 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fe350>
21:32:18,182 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:32:18,187 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fe3d0>
21:32:18,188 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:18,189 httpcore.http11 DEBUG send_request_headers.complete
21:32:18,189 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:18,212 httpcore.http11 DEBUG send_request_body.complete
21:32:18,213 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:18,949 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'8'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'334'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5643c38069bf148ebb0f591e549fba13'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50f9a94a3035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:18,955 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:32:18,956 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:18,957 httpcore.http11 DEBUG receive_response_body.complete
21:32:18,958 httpcore.http11 DEBUG response_closed.started
21:32:18,958 httpcore.http11 DEBUG response_closed.complete
21:32:18,959 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:32:18,959 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:32:18,989 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nmove up\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:18,992 httpcore.connection DEBUG close.started
21:32:18,992 httpcore.connection DEBUG close.complete
21:32:18,993 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:18,995 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee409610>
21:32:18,995 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:32:19,1 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee409690>
21:32:19,2 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:19,2 httpcore.http11 DEBUG send_request_headers.complete
21:32:19,3 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:19,3 httpcore.http11 DEBUG send_request_body.complete
21:32:19,3 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:19,226 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'46e3b63a19c4ffb23d4feb1ba59f17d0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a50fecd456ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:19,232 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:19,232 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:19,234 httpcore.http11 DEBUG receive_response_body.complete
21:32:19,235 httpcore.http11 DEBUG response_closed.started
21:32:19,235 httpcore.http11 DEBUG response_closed.complete
21:32:19,236 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:19,254 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:19,259 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:22,662 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:22,669 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:32:22,675 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:22,676 httpcore.http11 DEBUG send_request_headers.complete
21:32:22,677 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:22,677 httpcore.http11 DEBUG send_request_body.complete
21:32:22,678 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:23,221 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'448'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a75956324677a633cf0e596b3b6886fc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5115bd803035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:23,226 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:32:23,227 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:24,186 httpcore.http11 DEBUG receive_response_body.complete
21:32:24,187 httpcore.http11 DEBUG response_closed.started
21:32:24,188 httpcore.http11 DEBUG response_closed.complete
21:32:24,189 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:32:24,258 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:32:36,297 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:32:36,303 httpcore.connection DEBUG close.started
21:32:36,303 httpcore.connection DEBUG close.complete
21:32:36,304 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:32:36,307 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed750>
21:32:36,307 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:32:36,313 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fea10>
21:32:36,314 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:36,315 httpcore.http11 DEBUG send_request_headers.complete
21:32:36,315 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:36,341 httpcore.http11 DEBUG send_request_body.complete
21:32:36,341 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:37,57 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:37 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'319'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9ae297fcd419e06615cc46f293fb15f7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a516afb364d1d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:37,62 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:32:37,63 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:37,65 httpcore.http11 DEBUG receive_response_body.complete
21:32:37,65 httpcore.http11 DEBUG response_closed.started
21:32:37,66 httpcore.http11 DEBUG response_closed.complete
21:32:37,66 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:32:37,67 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:32:37,93 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:37,97 httpcore.connection DEBUG close.started
21:32:37,97 httpcore.connection DEBUG close.complete
21:32:37,97 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:37,100 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed4d0>
21:32:37,100 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:32:37,106 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed950>
21:32:37,106 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:37,107 httpcore.http11 DEBUG send_request_headers.complete
21:32:37,107 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:37,108 httpcore.http11 DEBUG send_request_body.complete
21:32:37,108 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:37,321 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dfc18c62139e352ad66e78d2393b4c6a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a516fefcb4ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:37,325 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:37,325 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:37,326 httpcore.http11 DEBUG receive_response_body.complete
21:32:37,327 httpcore.http11 DEBUG response_closed.started
21:32:37,327 httpcore.http11 DEBUG response_closed.complete
21:32:37,328 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:37,346 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:37,349 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:40,751 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:40,769 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:40,771 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:42,774 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:42,790 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:32:42,794 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:32:46,197 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:32:46,204 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:32:46,213 httpcore.connection DEBUG close.started
21:32:46,213 httpcore.connection DEBUG close.complete
21:32:46,214 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:32:46,217 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed210>
21:32:46,217 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:32:46,224 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee350>
21:32:46,224 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:46,226 httpcore.http11 DEBUG send_request_headers.complete
21:32:46,226 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:46,227 httpcore.http11 DEBUG send_request_body.complete
21:32:46,227 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:46,666 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:46 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'365'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ed9a0e954a06bd6ee7073bfe5db5c5cb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a51a8ea853b69-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:46,671 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:32:46,671 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:47,44 httpcore.http11 DEBUG receive_response_body.complete
21:32:47,45 httpcore.http11 DEBUG response_closed.started
21:32:47,46 httpcore.http11 DEBUG response_closed.complete
21:32:47,47 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:32:47,122 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:32:58,70 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:32:58,74 httpcore.connection DEBUG close.started
21:32:58,74 httpcore.connection DEBUG close.complete
21:32:58,75 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:32:58,77 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40ba10>
21:32:58,78 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:32:58,84 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40ba90>
21:32:58,84 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:58,85 httpcore.http11 DEBUG send_request_headers.complete
21:32:58,86 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:58,119 httpcore.http11 DEBUG send_request_body.complete
21:32:58,120 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:59,68 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:59 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'34'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'453'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cbd31d82cf83385b432ec196181a6ab1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a51f30a693b8d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:59,73 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:32:59,74 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:59,75 httpcore.http11 DEBUG receive_response_body.complete
21:32:59,76 httpcore.http11 DEBUG response_closed.started
21:32:59,77 httpcore.http11 DEBUG response_closed.complete
21:32:59,77 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:32:59,78 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:32:59,106 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTo the right of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:59,109 httpcore.connection DEBUG close.started
21:32:59,109 httpcore.connection DEBUG close.complete
21:32:59,110 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:59,140 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3c8f90>
21:32:59,141 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:32:59,147 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee5870d0>
21:32:59,148 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:59,149 httpcore.http11 DEBUG send_request_headers.complete
21:32:59,150 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:59,150 httpcore.http11 DEBUG send_request_body.complete
21:32:59,150 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:32:59,369 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:32:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0c76573e1ba7b0ef84386376a4508467'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a51f9ac603b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:32:59,376 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:32:59,377 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:32:59,378 httpcore.http11 DEBUG receive_response_body.complete
21:32:59,379 httpcore.http11 DEBUG response_closed.started
21:32:59,379 httpcore.http11 DEBUG response_closed.complete
21:32:59,379 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:32:59,412 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTo the right of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:32:59,415 httpcore.connection DEBUG close.started
21:32:59,416 httpcore.connection DEBUG close.complete
21:32:59,416 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:32:59,418 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3cba10>
21:32:59,419 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e2690> server_hostname='api.openai.com' timeout=None
21:32:59,426 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3c9210>
21:32:59,426 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:32:59,428 httpcore.http11 DEBUG send_request_headers.complete
21:32:59,428 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:32:59,428 httpcore.http11 DEBUG send_request_body.complete
21:32:59,429 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:00,82 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'564'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'156af51638724f7dedcf10841137f8cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a51fb6d173031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:00,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:33:00,89 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:00,91 httpcore.http11 DEBUG receive_response_body.complete
21:33:00,92 httpcore.http11 DEBUG response_closed.started
21:33:00,93 httpcore.http11 DEBUG response_closed.complete
21:33:00,94 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:33:00,385 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:00,387 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:06,889 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:06,907 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:06,911 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:11,914 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:11,932 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:11,936 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:13,938 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:13,955 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:13,957 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:17,359 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:17,376 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:17,380 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:23,884 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:23,898 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:23,900 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:27,303 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:27,321 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:27,325 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:32,326 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:32,329 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:33:32,333 httpcore.connection DEBUG close.started
21:33:32,333 httpcore.connection DEBUG close.complete
21:33:32,333 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:33:32,336 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40b950>
21:33:32,337 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:33:32,345 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40bb90>
21:33:32,346 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:32,347 httpcore.http11 DEBUG send_request_headers.complete
21:33:32,348 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:32,349 httpcore.http11 DEBUG send_request_body.complete
21:33:32,349 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:33,51 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:33 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'576'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1f6668d7e5a96e0a944a54c39a914158'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a52c92c804d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:33,56 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:33:33,58 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:34,17 httpcore.http11 DEBUG receive_response_body.complete
21:33:34,18 httpcore.http11 DEBUG response_closed.started
21:33:34,19 httpcore.http11 DEBUG response_closed.complete
21:33:34,20 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:33:34,94 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:33:46,40 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:33:46,45 httpcore.connection DEBUG close.started
21:33:46,46 httpcore.connection DEBUG close.complete
21:33:46,46 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:33:47,75 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fe8d0>
21:33:47,76 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:33:47,84 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ff250>
21:33:47,84 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:47,86 httpcore.http11 DEBUG send_request_headers.complete
21:33:47,86 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:47,108 httpcore.http11 DEBUG send_request_body.complete
21:33:47,108 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:47,919 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:47 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'393'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd2c59e781a211f7ffd650b7a904739da'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a53254b754d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:47,922 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:33:47,922 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:47,923 httpcore.http11 DEBUG receive_response_body.complete
21:33:47,923 httpcore.http11 DEBUG response_closed.started
21:33:47,924 httpcore.http11 DEBUG response_closed.complete
21:33:47,924 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:33:47,925 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:33:47,959 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:33:47,962 httpcore.connection DEBUG close.started
21:33:47,963 httpcore.connection DEBUG close.complete
21:33:47,963 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:33:47,966 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40c690>
21:33:47,966 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:33:47,971 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40d950>
21:33:47,971 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:47,972 httpcore.http11 DEBUG send_request_headers.complete
21:33:47,973 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:47,973 httpcore.http11 DEBUG send_request_body.complete
21:33:47,973 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:48,174 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'111'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dccc9cd3a08a4335716411f516549b12'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a532adb9c4d0e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:48,179 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:33:48,180 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:48,181 httpcore.http11 DEBUG receive_response_body.complete
21:33:48,182 httpcore.http11 DEBUG response_closed.started
21:33:48,182 httpcore.http11 DEBUG response_closed.complete
21:33:48,183 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:33:48,216 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:33:48,219 httpcore.connection DEBUG close.started
21:33:48,220 httpcore.connection DEBUG close.complete
21:33:48,220 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:33:48,223 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3effd0>
21:33:48,223 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:33:48,230 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ed4d0>
21:33:48,230 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:48,231 httpcore.http11 DEBUG send_request_headers.complete
21:33:48,231 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:48,232 httpcore.http11 DEBUG send_request_body.complete
21:33:48,232 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:48,416 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'64'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7bf6edd219607fe8215436b9ff1452c8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a532c79674d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:48,422 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:33:48,423 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:48,424 httpcore.http11 DEBUG receive_response_body.complete
21:33:48,425 httpcore.http11 DEBUG response_closed.started
21:33:48,425 httpcore.http11 DEBUG response_closed.complete
21:33:48,425 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:33:48,442 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:33:48,445 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:33:51,853 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:33:51,860 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:33:51,867 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:33:51,868 httpcore.http11 DEBUG send_request_headers.complete
21:33:51,868 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:33:51,868 httpcore.http11 DEBUG send_request_body.complete
21:33:51,869 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:33:52,547 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:33:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'568'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'540b242be95bca3af6639193a9531e76'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a53432e3e4d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:33:52,552 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:33:52,553 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:33:53,612 httpcore.http11 DEBUG receive_response_body.complete
21:33:53,612 httpcore.http11 DEBUG response_closed.started
21:33:53,613 httpcore.http11 DEBUG response_closed.complete
21:33:53,614 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:33:53,677 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:34:06,249 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:34:06,253 httpcore.connection DEBUG close.started
21:34:06,253 httpcore.connection DEBUG close.complete
21:34:06,254 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:34:06,282 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40c350>
21:34:06,282 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:34:06,289 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40e750>
21:34:06,290 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:06,291 httpcore.http11 DEBUG send_request_headers.complete
21:34:06,292 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:06,308 httpcore.http11 DEBUG send_request_body.complete
21:34:06,308 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:07,317 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'408'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'aedd01f2feb1c7990e3b21e61a1e15d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a539d5e354cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:07,322 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:34:07,323 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:07,324 httpcore.http11 DEBUG receive_response_body.complete
21:34:07,325 httpcore.http11 DEBUG response_closed.started
21:34:07,326 httpcore.http11 DEBUG response_closed.complete
21:34:07,326 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:34:07,327 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:34:07,356 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\noff to the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:34:07,359 httpcore.connection DEBUG close.started
21:34:07,359 httpcore.connection DEBUG close.complete
21:34:07,360 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:34:07,362 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ff290>
21:34:07,362 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:34:07,367 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ff590>
21:34:07,368 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:07,369 httpcore.http11 DEBUG send_request_headers.complete
21:34:07,369 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:07,370 httpcore.http11 DEBUG send_request_body.complete
21:34:07,370 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:07,604 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'93aa6898e113ef52e2e4964c7bf2995b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a53a40e204cdc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:07,610 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:34:07,610 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:07,611 httpcore.http11 DEBUG receive_response_body.complete
21:34:07,611 httpcore.http11 DEBUG response_closed.started
21:34:07,612 httpcore.http11 DEBUG response_closed.complete
21:34:07,612 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:34:07,628 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:34:07,631 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:34:11,33 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:34:11,39 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:34:11,46 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:11,47 httpcore.http11 DEBUG send_request_headers.complete
21:34:11,48 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:11,48 httpcore.http11 DEBUG send_request_body.complete
21:34:11,49 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:11,541 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:11 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8ef990cbba80b93fd1e7b0e61cd7817d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a53bb0eee4cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:11,544 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:34:11,545 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:12,832 httpcore.http11 DEBUG receive_response_body.complete
21:34:12,833 httpcore.http11 DEBUG response_closed.started
21:34:12,834 httpcore.http11 DEBUG response_closed.complete
21:34:12,835 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:34:12,904 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:34:25,504 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:34:25,510 httpcore.connection DEBUG close.started
21:34:25,511 httpcore.connection DEBUG close.complete
21:34:25,512 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:34:25,515 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee408110>
21:34:25,515 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:34:25,521 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40a050>
21:34:25,521 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:25,523 httpcore.http11 DEBUG send_request_headers.complete
21:34:25,523 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:25,549 httpcore.http11 DEBUG send_request_body.complete
21:34:25,550 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:26,627 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:26 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'13'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'49e8da70b170eb6e034d6d09aefcdc3a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a54158be64ce9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:26,632 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:34:26,632 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:26,633 httpcore.http11 DEBUG receive_response_body.complete
21:34:26,634 httpcore.http11 DEBUG response_closed.started
21:34:26,634 httpcore.http11 DEBUG response_closed.complete
21:34:26,635 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:34:26,636 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:34:26,667 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nto the right\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:34:26,670 httpcore.connection DEBUG close.started
21:34:26,671 httpcore.connection DEBUG close.complete
21:34:26,671 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:34:26,674 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee41a6d0>
21:34:26,674 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:34:26,683 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee419450>
21:34:26,684 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:26,686 httpcore.http11 DEBUG send_request_headers.complete
21:34:26,686 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:26,686 httpcore.http11 DEBUG send_request_body.complete
21:34:26,687 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:26,924 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ccb10f64b49ebe419a5b3cada5b4358a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a541cc8d64cdb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:26,931 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:34:26,932 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:26,934 httpcore.http11 DEBUG receive_response_body.complete
21:34:26,934 httpcore.http11 DEBUG response_closed.started
21:34:26,934 httpcore.http11 DEBUG response_closed.complete
21:34:26,935 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:34:26,950 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:34:26,952 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:34:30,354 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:34:30,361 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:34:30,370 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:30,371 httpcore.http11 DEBUG send_request_headers.complete
21:34:30,371 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:30,372 httpcore.http11 DEBUG send_request_body.complete
21:34:30,372 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:30,890 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:30 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'442'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6362d0e0dcc82a1dc52654da560ba6e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5433db824ce9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:30,894 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:34:30,895 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:31,884 httpcore.http11 DEBUG receive_response_body.complete
21:34:31,885 httpcore.http11 DEBUG response_closed.started
21:34:31,885 httpcore.http11 DEBUG response_closed.complete
21:34:31,885 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:34:31,949 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:34:44,492 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:34:44,496 httpcore.connection DEBUG close.started
21:34:44,497 httpcore.connection DEBUG close.complete
21:34:44,497 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:34:44,500 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fc650>
21:34:44,500 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:34:44,507 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fe990>
21:34:44,508 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:44,509 httpcore.http11 DEBUG send_request_headers.complete
21:34:44,509 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:44,531 httpcore.http11 DEBUG send_request_body.complete
21:34:44,531 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:45,308 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'10'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'332'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9815f66d5b4d225f05ee89374d692c52'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a548c2a6f4d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:45,313 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:34:45,314 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:45,316 httpcore.http11 DEBUG receive_response_body.complete
21:34:45,316 httpcore.http11 DEBUG response_closed.started
21:34:45,317 httpcore.http11 DEBUG response_closed.complete
21:34:45,318 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:34:45,318 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:34:45,346 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nMove down\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:34:45,349 httpcore.connection DEBUG close.started
21:34:45,350 httpcore.connection DEBUG close.complete
21:34:45,350 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:34:45,352 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40e2d0>
21:34:45,352 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:34:45,359 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40dd50>
21:34:45,359 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:45,361 httpcore.http11 DEBUG send_request_headers.complete
21:34:45,361 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:45,361 httpcore.http11 DEBUG send_request_body.complete
21:34:45,362 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:45,573 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6a15a67c9fe9d68265b61654785d2d86'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a54918b503b7b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:45,578 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:34:45,578 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:45,579 httpcore.http11 DEBUG receive_response_body.complete
21:34:45,580 httpcore.http11 DEBUG response_closed.started
21:34:45,580 httpcore.http11 DEBUG response_closed.complete
21:34:45,580 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:34:45,597 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:34:45,601 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:34:49,3 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:34:49,12 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:34:49,17 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:34:49,18 httpcore.http11 DEBUG send_request_headers.complete
21:34:49,18 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:34:49,19 httpcore.http11 DEBUG send_request_body.complete
21:34:49,19 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:34:49,559 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:34:49 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'448'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'98c69fddd15f3fec2544b6cffa878638'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a54a859b34d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:34:49,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:34:49,565 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:34:50,756 httpcore.http11 DEBUG receive_response_body.complete
21:34:50,756 httpcore.http11 DEBUG response_closed.started
21:34:50,757 httpcore.http11 DEBUG response_closed.complete
21:34:50,758 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:34:50,821 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent9.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:35:03,305 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent9.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:35:03,310 httpcore.connection DEBUG close.started
21:35:03,310 httpcore.connection DEBUG close.complete
21:35:03,311 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:35:03,313 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ec610>
21:35:03,313 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:35:03,320 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee0d0>
21:35:03,320 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:03,322 httpcore.http11 DEBUG send_request_headers.complete
21:35:03,322 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:03,339 httpcore.http11 DEBUG send_request_body.complete
21:35:03,340 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:04,220 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:04 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8a2b2673fa04feb4a54c656af725fcf0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5501ca703061-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:04,222 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:35:04,223 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:04,223 httpcore.http11 DEBUG receive_response_body.complete
21:35:04,224 httpcore.http11 DEBUG response_closed.started
21:35:04,224 httpcore.http11 DEBUG response_closed.complete
21:35:04,224 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:35:04,225 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:35:04,251 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:35:04,255 httpcore.connection DEBUG close.started
21:35:04,255 httpcore.connection DEBUG close.complete
21:35:04,255 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:35:04,258 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee419890>
21:35:04,258 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:35:04,265 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee41ab10>
21:35:04,266 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:04,267 httpcore.http11 DEBUG send_request_headers.complete
21:35:04,267 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:04,267 httpcore.http11 DEBUG send_request_body.complete
21:35:04,268 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:04,499 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'00b46a41a3950624ce7f336b13a3fcb0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5507af3f4cc6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:04,506 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:35:04,507 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:04,509 httpcore.http11 DEBUG receive_response_body.complete
21:35:04,509 httpcore.http11 DEBUG response_closed.started
21:35:04,510 httpcore.http11 DEBUG response_closed.complete
21:35:04,510 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:35:04,525 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:04,528 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:07,929 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:07,934 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:35:07,939 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:07,941 httpcore.http11 DEBUG send_request_headers.complete
21:35:07,942 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:07,942 httpcore.http11 DEBUG send_request_body.complete
21:35:07,943 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:08,447 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:08 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'430'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b1044a78153689d781f70be414031dc3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a551eacac3061-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:08,451 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:35:08,452 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:09,635 httpcore.http11 DEBUG receive_response_body.complete
21:35:09,636 httpcore.http11 DEBUG response_closed.started
21:35:09,637 httpcore.http11 DEBUG response_closed.complete
21:35:09,639 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:35:09,711 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent10.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:35:22,282 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent10.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:35:22,289 httpcore.connection DEBUG close.started
21:35:22,290 httpcore.connection DEBUG close.complete
21:35:22,290 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:35:22,320 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40f510>
21:35:22,320 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:35:22,330 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40dad0>
21:35:22,331 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:22,333 httpcore.http11 DEBUG send_request_headers.complete
21:35:22,334 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:22,354 httpcore.http11 DEBUG send_request_body.complete
21:35:22,354 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:23,248 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:23 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b6c0cf91f03da1315c631d4f6a176b03'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5578992c4d07-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:23,253 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:35:23,254 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:23,256 httpcore.http11 DEBUG receive_response_body.complete
21:35:23,256 httpcore.http11 DEBUG response_closed.started
21:35:23,257 httpcore.http11 DEBUG response_closed.complete
21:35:23,258 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:35:23,259 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:35:23,288 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:35:23,291 httpcore.connection DEBUG close.started
21:35:23,291 httpcore.connection DEBUG close.complete
21:35:23,292 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:35:23,294 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fd210>
21:35:23,294 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:35:23,302 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fef10>
21:35:23,302 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:23,303 httpcore.http11 DEBUG send_request_headers.complete
21:35:23,304 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:23,304 httpcore.http11 DEBUG send_request_body.complete
21:35:23,304 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:23,600 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5f96571c49e06550c01c36898d7b6a53'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a557eab3a4d16-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:23,606 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:35:23,606 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:23,607 httpcore.http11 DEBUG receive_response_body.complete
21:35:23,607 httpcore.http11 DEBUG response_closed.started
21:35:23,608 httpcore.http11 DEBUG response_closed.complete
21:35:23,608 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:35:23,624 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:23,627 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:27,29 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:27,46 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:27,50 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:29,53 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:29,72 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:29,76 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:32,478 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:32,484 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:35:32,493 httpcore.connection DEBUG close.started
21:35:32,493 httpcore.connection DEBUG close.complete
21:35:32,494 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:35:32,497 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fca10>
21:35:32,497 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:35:32,502 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fd490>
21:35:32,503 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:32,504 httpcore.http11 DEBUG send_request_headers.complete
21:35:32,504 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:32,505 httpcore.http11 DEBUG send_request_body.complete
21:35:32,505 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:33,134 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:33 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'487'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2173c0dbf4b44bd0655f0cac65a97145'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a55b829b04d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:33,139 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:35:33,140 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:33,603 httpcore.http11 DEBUG receive_response_body.complete
21:35:33,603 httpcore.http11 DEBUG response_closed.started
21:35:33,604 httpcore.http11 DEBUG response_closed.complete
21:35:33,604 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:35:33,674 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent11.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:35:44,968 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent11.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:35:44,973 httpcore.connection DEBUG close.started
21:35:44,973 httpcore.connection DEBUG close.complete
21:35:44,974 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:35:44,976 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee409ed0>
21:35:44,977 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:35:44,984 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40b710>
21:35:44,985 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:44,986 httpcore.http11 DEBUG send_request_headers.complete
21:35:44,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:45,24 httpcore.http11 DEBUG send_request_body.complete
21:35:45,24 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:45,885 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:45 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'31'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'07d6caf40507f6c459c4aef1dafd0105'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a56062f604d12-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:45,889 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:35:45,890 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:45,890 httpcore.http11 DEBUG receive_response_body.complete
21:35:45,891 httpcore.http11 DEBUG response_closed.started
21:35:45,891 httpcore.http11 DEBUG response_closed.complete
21:35:45,892 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:35:45,892 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:35:45,923 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it below the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:35:45,928 httpcore.connection DEBUG close.started
21:35:45,929 httpcore.connection DEBUG close.complete
21:35:45,929 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:35:45,932 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40d950>
21:35:45,933 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:35:45,939 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40da90>
21:35:45,939 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:45,941 httpcore.http11 DEBUG send_request_headers.complete
21:35:45,941 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:45,942 httpcore.http11 DEBUG send_request_body.complete
21:35:45,943 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:46,178 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'124'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'53a2dbe0df4969f4d28805acc5f7b090'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a560c2bfb4cfc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:46,184 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:35:46,185 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:46,186 httpcore.http11 DEBUG receive_response_body.complete
21:35:46,187 httpcore.http11 DEBUG response_closed.started
21:35:46,187 httpcore.http11 DEBUG response_closed.complete
21:35:46,187 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:35:46,221 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it below the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:35:46,224 httpcore.connection DEBUG close.started
21:35:46,224 httpcore.connection DEBUG close.complete
21:35:46,225 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:35:46,227 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee41d8d0>
21:35:46,228 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e2690> server_hostname='api.openai.com' timeout=None
21:35:46,235 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee41f350>
21:35:46,235 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:35:46,237 httpcore.http11 DEBUG send_request_headers.complete
21:35:46,238 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:35:46,239 httpcore.http11 DEBUG send_request_body.complete
21:35:46,239 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:35:46,944 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:35:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'572'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1abf9c02ddab4e723e386f74273e16ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a560dfffc4cfc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:35:46,949 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:35:46,950 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:35:46,952 httpcore.http11 DEBUG receive_response_body.complete
21:35:46,953 httpcore.http11 DEBUG response_closed.started
21:35:46,953 httpcore.http11 DEBUG response_closed.complete
21:35:46,954 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:35:46,971 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:46,975 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:53,477 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:53,496 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:53,499 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:35:58,501 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:35:58,512 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:35:58,516 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:00,519 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:00,538 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:00,541 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:03,943 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:03,960 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:03,963 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:10,466 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:10,487 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:10,491 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:13,895 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:13,911 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:13,915 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:18,918 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:18,925 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:36:18,932 httpcore.connection DEBUG close.started
21:36:18,933 httpcore.connection DEBUG close.complete
21:36:18,934 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:36:18,937 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40b710>
21:36:18,937 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:36:18,943 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee40a890>
21:36:18,944 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:18,945 httpcore.http11 DEBUG send_request_headers.complete
21:36:18,945 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:18,946 httpcore.http11 DEBUG send_request_body.complete
21:36:18,946 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:19,457 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'430'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ec526e8875cfa33ec31a60f78ba28e59'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a56da6c733010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:19,463 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:36:19,464 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:20,698 httpcore.http11 DEBUG receive_response_body.complete
21:36:20,698 httpcore.http11 DEBUG response_closed.started
21:36:20,698 httpcore.http11 DEBUG response_closed.complete
21:36:20,699 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:36:20,767 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent12.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:36:33,322 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent12.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:36:33,329 httpcore.connection DEBUG close.started
21:36:33,329 httpcore.connection DEBUG close.complete
21:36:33,330 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:36:33,357 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ca450>
21:36:33,357 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1d00> server_hostname='api.openai.com' timeout=5.0
21:36:33,364 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3c99d0>
21:36:33,364 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:33,366 httpcore.http11 DEBUG send_request_headers.complete
21:36:33,366 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:33,384 httpcore.http11 DEBUG send_request_body.complete
21:36:33,384 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:34,236 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'edfb1a3be5f3d68cbdcf55978f8f7e90'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a573489073b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:34,241 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:36:34,242 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:34,243 httpcore.http11 DEBUG receive_response_body.complete
21:36:34,244 httpcore.http11 DEBUG response_closed.started
21:36:34,245 httpcore.http11 DEBUG response_closed.complete
21:36:34,245 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:36:34,246 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:36:34,273 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove down.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:36:34,276 httpcore.connection DEBUG close.started
21:36:34,276 httpcore.connection DEBUG close.complete
21:36:34,277 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:36:34,279 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ee610>
21:36:34,279 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1eb0> server_hostname='api.openai.com' timeout=None
21:36:34,286 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3efa10>
21:36:34,287 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:34,288 httpcore.http11 DEBUG send_request_headers.complete
21:36:34,288 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:34,288 httpcore.http11 DEBUG send_request_body.complete
21:36:34,289 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:34,524 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a5b010a32bca11cb7b6ed7fe93faff26'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a573a48c24cec-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:34,529 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:36:34,530 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:34,530 httpcore.http11 DEBUG receive_response_body.complete
21:36:34,531 httpcore.http11 DEBUG response_closed.started
21:36:34,531 httpcore.http11 DEBUG response_closed.complete
21:36:34,531 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:36:34,567 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nMove down.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:36:34,570 httpcore.connection DEBUG close.started
21:36:34,571 httpcore.connection DEBUG close.complete
21:36:34,571 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:36:34,574 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3fef10>
21:36:34,574 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2bee5e1e20> server_hostname='api.openai.com' timeout=None
21:36:34,585 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2bee3ff690>
21:36:34,585 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:34,587 httpcore.http11 DEBUG send_request_headers.complete
21:36:34,588 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:34,589 httpcore.http11 DEBUG send_request_body.complete
21:36:34,589 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:34,831 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5e4b007dd747f812d0540e9816795bdb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a573c2fd14cd6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:34,836 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:36:34,837 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:34,838 httpcore.http11 DEBUG receive_response_body.complete
21:36:34,839 httpcore.http11 DEBUG response_closed.started
21:36:34,839 httpcore.http11 DEBUG response_closed.complete
21:36:34,840 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:36:34,856 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:36:34,860 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:36:38,263 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:36:38,271 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:36:38,278 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:36:38,279 httpcore.http11 DEBUG send_request_headers.complete
21:36:38,279 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:36:38,280 httpcore.http11 DEBUG send_request_body.complete
21:36:38,280 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:36:38,992 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:36:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'590'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd809338ee505bfc38db87201268fa95d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a57533e163b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:36:38,998 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:36:38,998 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:36:40,96 httpcore.http11 DEBUG receive_response_body.complete
21:36:40,97 httpcore.http11 DEBUG response_closed.started
21:36:40,98 httpcore.http11 DEBUG response_closed.complete
21:36:40,99 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:36:40,167 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent13.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:38:51,197 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:51,201 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,22 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,23 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,64 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,65 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,113 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,114 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,155 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,156 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,202 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,204 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,244 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,245 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,293 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,294 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:52,335 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:38:52,336 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:38:53,247 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:38:53,267 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:38:53,299 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce6f10>
21:38:53,300 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61d00> server_hostname='api.openai.com' timeout=5.0
21:38:53,307 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce7450>
21:38:53,308 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:38:53,311 httpcore.http11 DEBUG send_request_headers.complete
21:38:53,312 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:38:53,313 httpcore.http11 DEBUG send_request_body.complete
21:38:53,313 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:38:53,966 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:38:53 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'538'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1dc972a2a98cd7409685f2b1ba540fa3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XuR6dHiFWDet6yM8pNetMsJGLr3EEqb327OWzeMeUGg-1702262333-1-AbxsMkwu+SPwSzDya0nzRU3B9r9E4KzjTDia/PPTArPD/xe+6rUgZlK8A1r4iLBuzjVerTuM2Dn+H8m2a8D+dSc=; path=/; expires=Mon, 11-Dec-23 03:08:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NejP2LMGGfd9B2K0X.9E5eyEVgvg6HTdxtSQK_ZhtZA-1702262333959-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5a9f3fbc4cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:38:53,974 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:38:53,974 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:38:54,719 httpcore.http11 DEBUG receive_response_body.complete
21:38:54,720 httpcore.http11 DEBUG response_closed.started
21:38:54,720 httpcore.http11 DEBUG response_closed.complete
21:38:54,721 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:38:54,799 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:39:08,83 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:39:08,93 httpcore.connection DEBUG close.started
21:39:08,93 httpcore.connection DEBUG close.complete
21:39:08,94 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:39:08,97 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce7590>
21:39:08,97 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61d00> server_hostname='api.openai.com' timeout=5.0
21:39:08,103 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce7710>
21:39:08,104 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:08,105 httpcore.http11 DEBUG send_request_headers.complete
21:39:08,105 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:08,137 httpcore.http11 DEBUG send_request_body.complete
21:39:08,137 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:09,0 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:08 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'199d392ac5ab3e89a9ace3b4cbe883fd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5afbab7f4cf4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:09,6 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:39:09,7 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:09,8 httpcore.http11 DEBUG receive_response_body.complete
21:39:09,9 httpcore.http11 DEBUG response_closed.started
21:39:09,10 httpcore.http11 DEBUG response_closed.complete
21:39:09,10 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:39:09,10 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:39:09,43 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:39:09,55 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:39:09,57 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb37010>
21:39:09,57 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61eb0> server_hostname='api.openai.com' timeout=None
21:39:09,64 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82e733010>
21:39:09,64 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:09,66 httpcore.http11 DEBUG send_request_headers.complete
21:39:09,66 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:09,66 httpcore.http11 DEBUG send_request_body.complete
21:39:09,67 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:09,280 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2318b9f608f30d4add1820b0a10ab99a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=90hcpys9mXXA0VCT7iOFmpeByDIL84iovesQrz2SsU8-1702262349-1-AeVAMRtc38Lk3piszm8aXrmiaoFrLJ4x9rDJKCROhbRKHPzSyEVIXZpa8NpCOVwLmD2puetcUajSjUt0QmuFJf0=; path=/; expires=Mon, 11-Dec-23 03:09:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=7GfasFhw.AYzIxLcYviyAOt7v1Z.PFho0p_6E6OGGQk-1702262349276-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5b01acc26ac6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:09,288 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:39:09,289 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:09,292 httpcore.http11 DEBUG receive_response_body.complete
21:39:09,292 httpcore.http11 DEBUG response_closed.started
21:39:09,293 httpcore.http11 DEBUG response_closed.complete
21:39:09,293 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:39:09,326 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:39:09,337 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:39:09,355 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb47c50>
21:39:09,356 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd62690> server_hostname='api.openai.com' timeout=None
21:39:09,363 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb44250>
21:39:09,364 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:09,366 httpcore.http11 DEBUG send_request_headers.complete
21:39:09,366 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:09,367 httpcore.http11 DEBUG send_request_body.complete
21:39:09,367 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:10,482 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'864'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cfafc262672a5e510f39022200743952'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mUyF_fkF0Jc0av20NXdVp63D4TULpdBXMUJA6xuI3J0-1702262350-1-AZui/GQWY5MegJ4dLdTjtF47IUXSL5EoLkWPKNFSoY/7H1pfXTpVAzk5TbngxN4qYIBN64gcTnKG3z9abqH/sUM=; path=/; expires=Mon, 11-Dec-23 03:09:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=4WX_MZXtmGXxW0XzONPsoglFzezneXtl.zsSDErPJos-1702262350477-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5b038d214ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:10,488 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:39:10,488 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:10,490 httpcore.http11 DEBUG receive_response_body.complete
21:39:10,490 httpcore.http11 DEBUG response_closed.started
21:39:10,490 httpcore.http11 DEBUG response_closed.complete
21:39:10,491 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:39:10,509 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:10,513 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:17,21 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:17,40 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:17,44 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:22,46 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:22,64 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:22,67 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:24,69 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:24,85 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:24,88 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:27,490 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:27,509 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:27,512 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:34,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:34,30 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:34,33 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:37,837 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:37,856 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:39:37,860 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:39:41,663 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:39:41,671 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:39:41,676 httpcore.connection DEBUG close.started
21:39:41,677 httpcore.connection DEBUG close.complete
21:39:41,677 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:39:41,680 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cce7710>
21:39:41,681 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61d00> server_hostname='api.openai.com' timeout=5.0
21:39:41,688 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb4c510>
21:39:41,688 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:41,690 httpcore.http11 DEBUG send_request_headers.complete
21:39:41,691 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:41,691 httpcore.http11 DEBUG send_request_body.complete
21:39:41,692 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:42,171 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'403'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6bfe35f6f56ccc230c806a4295e99005'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5bcd9a153068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:42,176 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:39:42,177 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:43,284 httpcore.http11 DEBUG receive_response_body.complete
21:39:43,285 httpcore.http11 DEBUG response_closed.started
21:39:43,285 httpcore.http11 DEBUG response_closed.complete
21:39:43,286 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:39:43,356 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:39:55,836 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:39:55,840 httpcore.connection DEBUG close.started
21:39:55,841 httpcore.connection DEBUG close.complete
21:39:55,841 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:39:55,870 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb72490>
21:39:55,871 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61d00> server_hostname='api.openai.com' timeout=5.0
21:39:55,879 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb72510>
21:39:55,879 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:55,881 httpcore.http11 DEBUG send_request_headers.complete
21:39:55,881 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:55,906 httpcore.http11 DEBUG send_request_body.complete
21:39:55,906 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:56,738 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:56 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'361'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'df08aec852f455457652db8b4eb8db4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5c264a9c4d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:56,744 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:39:56,745 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:56,746 httpcore.http11 DEBUG receive_response_body.complete
21:39:56,746 httpcore.http11 DEBUG response_closed.started
21:39:56,747 httpcore.http11 DEBUG response_closed.complete
21:39:56,747 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:39:56,748 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:39:56,778 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nUh, yes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:39:56,782 httpcore.connection DEBUG close.started
21:39:56,783 httpcore.connection DEBUG close.complete
21:39:56,783 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:39:56,786 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb36f10>
21:39:56,786 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd61eb0> server_hostname='api.openai.com' timeout=None
21:39:56,793 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb37010>
21:39:56,793 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:56,794 httpcore.http11 DEBUG send_request_headers.complete
21:39:56,795 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:56,795 httpcore.http11 DEBUG send_request_body.complete
21:39:56,796 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:57,0 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'af27e90c57b6a2211563d1edadc9a063'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5c2bf9304d02-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:57,5 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:39:57,6 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:57,7 httpcore.http11 DEBUG receive_response_body.complete
21:39:57,7 httpcore.http11 DEBUG response_closed.started
21:39:57,8 httpcore.http11 DEBUG response_closed.complete
21:39:57,8 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:39:57,43 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nUh, yes.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:39:57,55 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:39:57,58 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb73850>
21:39:57,58 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff82cd62210> server_hostname='api.openai.com' timeout=None
21:39:57,64 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff82cb73390>
21:39:57,65 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:57,66 httpcore.http11 DEBUG send_request_headers.complete
21:39:57,66 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:57,67 httpcore.http11 DEBUG send_request_body.complete
21:39:57,67 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:57,947 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'789'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b345d98b80cc1650f8595ffc4c3d510a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jFc99JuO9cuXY1jcUCbH8jCC.5.EwfGf9wEEbzpuudc-1702262397-1-AeyJ+Awzw+WqleAHwfuU5KtRhXWf4o4yl3kYhHc1Jj9O7EI4ssvZ8B6xXDnI6yGJk5t9ISLE7Pvf0irsG1PhVp4=; path=/; expires=Mon, 11-Dec-23 03:09:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Vo5gG_cpdJPHtRa07q4sBVSx9YpxrecfYFLB7DDItM0-1702262397942-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5c2daca94d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:57,955 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:39:57,955 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:57,956 httpcore.http11 DEBUG receive_response_body.complete
21:39:57,956 httpcore.http11 DEBUG response_closed.started
21:39:57,957 httpcore.http11 DEBUG response_closed.complete
21:39:57,957 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:39:57,965 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Great! Let's keep going. Can you please move the next candle to the left a bit? Once you have placed all the candles, we can light them up and enjoy the cake!", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:39:57,968 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:39:57,970 httpcore.http11 DEBUG send_request_headers.complete
21:39:57,970 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:39:57,971 httpcore.http11 DEBUG send_request_body.complete
21:39:57,971 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:39:58,506 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:39:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'464'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6328283f5ca6d66553d96fe27c0b0441'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a5c335a3e4d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:39:58,508 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:39:58,509 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:39:59,842 httpcore.http11 DEBUG receive_response_body.complete
21:39:59,843 httpcore.http11 DEBUG response_closed.started
21:39:59,843 httpcore.http11 DEBUG response_closed.complete
21:39:59,844 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:39:59,916 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:51:58,1 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,7 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:58,832 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,833 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:58,874 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,875 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:58,924 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,925 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:58,966 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:58,967 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:59,14 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:59,15 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:59,56 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:59,58 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:59,105 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:59,106 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:51:59,147 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:51:59,148 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:52:02,846 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:52:02,868 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:52:02,899 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f822535d0>
21:52:02,900 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:52:02,908 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82253ad0>
21:52:02,910 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:02,911 httpcore.http11 DEBUG send_request_headers.complete
21:52:02,912 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:02,912 httpcore.http11 DEBUG send_request_body.complete
21:52:02,913 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:03,371 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:03 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'82b4fb9c8fba4dd5fdbe104709699bb0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=P6KrdQzKvliYSRglOJr8gX6fxxW9tGLdkkz5edOY0YA-1702263123-1-AYx8U06QecceD/xcwaICNtoz4Q0UmRMF7QKCK4vZ10iB87En1bg/HWq88DEoQ9FK2sTgNf6K17QJvKoZYK+ovgc=; path=/; expires=Mon, 11-Dec-23 03:22:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=JHsJ792RKLrQjeQ9wwpCce66p7RUtapa15zzY3.wFv4-1702263123365-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6de638244cf6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:03,382 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:52:03,383 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:04,153 httpcore.http11 DEBUG receive_response_body.complete
21:52:04,154 httpcore.http11 DEBUG response_closed.started
21:52:04,154 httpcore.http11 DEBUG response_closed.complete
21:52:04,155 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:52:04,233 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:52:17,569 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:52:17,583 httpcore.connection DEBUG close.started
21:52:17,583 httpcore.connection DEBUG close.complete
21:52:17,584 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:52:17,586 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82253c50>
21:52:17,587 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:52:17,592 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82253dd0>
21:52:17,593 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:17,594 httpcore.http11 DEBUG send_request_headers.complete
21:52:17,594 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:17,645 httpcore.http11 DEBUG send_request_body.complete
21:52:17,645 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:18,623 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:18 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'454'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a42bed77301e1b3163a40b51236220ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6e41f9614ced-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:18,630 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:52:18,630 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:18,631 httpcore.http11 DEBUG receive_response_body.complete
21:52:18,632 httpcore.http11 DEBUG response_closed.started
21:52:18,632 httpcore.http11 DEBUG response_closed.complete
21:52:18,632 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:52:18,633 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:52:18,667 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:52:18,680 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:52:18,683 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b4110>
21:52:18,683 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9f40> server_hostname='api.openai.com' timeout=None
21:52:18,688 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b4050>
21:52:18,689 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:18,690 httpcore.http11 DEBUG send_request_headers.complete
21:52:18,690 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:18,691 httpcore.http11 DEBUG send_request_body.complete
21:52:18,691 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:18,912 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8b4bb834fc36ce0736c6003cd3d32245'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cO2zrtcI9AY7n4r_ddi6yBjlBxSBEw0WwOJlM.4B_kQ-1702263138-1-AY8B6FbYQcrUDsseRfPHxL0XAASiOFJQamejCcJ3OGcxyE6ozlZScIfgJK2AkiFDbnhyR4cFUdqloXBha63Akcs=; path=/; expires=Mon, 11-Dec-23 03:22:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rsB6OtRo2_8WCQFCh_8_VgXlYx9SbgY24KCOBqd6ZtY-1702263138909-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6e48d9f13b70-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:18,916 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:52:18,917 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:18,918 httpcore.http11 DEBUG receive_response_body.complete
21:52:18,918 httpcore.http11 DEBUG response_closed.started
21:52:18,918 httpcore.http11 DEBUG response_closed.complete
21:52:18,919 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:52:18,956 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:52:18,968 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:52:18,970 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f824ce950>
21:52:18,971 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822da720> server_hostname='api.openai.com' timeout=None
21:52:18,977 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b4710>
21:52:18,977 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:18,978 httpcore.http11 DEBUG send_request_headers.complete
21:52:18,979 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:18,979 httpcore.http11 DEBUG send_request_body.complete
21:52:18,979 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:19,898 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'824'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0e7af500c0107fb5de75d3d733bb4e6d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0DowzlPNPBv5cYaP49YTMy5VM6KuuzW7SFhMHNmiBD8-1702263139-1-Af0TaECuV53rU/pd7zDNTOmoW90Y0xlhGqqjoyXQXIwaJGLNgVzHL8ncYwkXurIX/EuyWxbjIATeef2syu9ubrs=; path=/; expires=Mon, 11-Dec-23 03:22:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LyRVuS8LgZV0vAklcHzFG0wT1K4_E4.pqR98RSmjR6c-1702263139892-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6e4a98304d1c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:19,904 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:52:19,904 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:19,905 httpcore.http11 DEBUG receive_response_body.complete
21:52:19,906 httpcore.http11 DEBUG response_closed.started
21:52:19,906 httpcore.http11 DEBUG response_closed.complete
21:52:19,907 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:52:19,926 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:19,930 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:26,439 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:26,454 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:26,457 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:31,459 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:31,476 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:31,480 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:33,482 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:33,500 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:33,504 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:36,906 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:36,924 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:36,927 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:43,429 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:43,446 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:43,449 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:47,652 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:47,670 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:52:47,674 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:52:51,878 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:52:51,885 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:52:51,889 httpcore.connection DEBUG close.started
21:52:51,889 httpcore.connection DEBUG close.complete
21:52:51,890 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:52:51,906 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82297890>
21:52:51,907 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:52:51,913 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f82252d10>
21:52:51,914 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:52:51,915 httpcore.http11 DEBUG send_request_headers.complete
21:52:51,916 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:52:51,916 httpcore.http11 DEBUG send_request_body.complete
21:52:51,917 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:52:52,501 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:52:52 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'479'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'17d4e9efd68fdae53bb45f8a85b30ca0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6f18797c3061-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:52:52,506 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:52:52,507 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:52:53,532 httpcore.http11 DEBUG receive_response_body.complete
21:52:53,533 httpcore.http11 DEBUG response_closed.started
21:52:53,534 httpcore.http11 DEBUG response_closed.complete
21:52:53,535 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:52:53,606 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:53:06,47 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:53:06,53 httpcore.connection DEBUG close.started
21:53:06,53 httpcore.connection DEBUG close.complete
21:53:06,54 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:53:06,83 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e69d0>
21:53:06,84 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:53:06,90 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e6a50>
21:53:06,90 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:06,91 httpcore.http11 DEBUG send_request_headers.complete
21:53:06,92 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:06,110 httpcore.http11 DEBUG send_request_body.complete
21:53:06,111 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:08,724 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:08 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'2105'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'10b7cceb9f9c067315bd990550767540'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6f711b044cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:08,730 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:53:08,731 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:08,733 httpcore.http11 DEBUG receive_response_body.complete
21:53:08,733 httpcore.http11 DEBUG response_closed.started
21:53:08,734 httpcore.http11 DEBUG response_closed.complete
21:53:08,735 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:53:08,736 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:53:08,769 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nyes\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:53:08,773 httpcore.connection DEBUG close.started
21:53:08,773 httpcore.connection DEBUG close.complete
21:53:08,774 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:53:08,776 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b42d0>
21:53:08,777 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9f40> server_hostname='api.openai.com' timeout=None
21:53:08,781 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820b5910>
21:53:08,782 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:08,783 httpcore.http11 DEBUG send_request_headers.complete
21:53:08,783 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:08,784 httpcore.http11 DEBUG send_request_body.complete
21:53:08,784 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:09,10 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ebc3eb7e95ba56324b5f195243f29a65'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6f81e93a4d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:09,16 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:53:09,17 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:09,19 httpcore.http11 DEBUG receive_response_body.complete
21:53:09,20 httpcore.http11 DEBUG response_closed.started
21:53:09,21 httpcore.http11 DEBUG response_closed.complete
21:53:09,22 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:53:09,53 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nyes\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:53:09,65 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:53:09,67 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e6390>
21:53:09,67 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9eb0> server_hostname='api.openai.com' timeout=None
21:53:09,74 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e63d0>
21:53:09,75 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:09,76 httpcore.http11 DEBUG send_request_headers.complete
21:53:09,76 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:09,77 httpcore.http11 DEBUG send_request_body.complete
21:53:09,77 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:09,307 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b9d57e9d6c94d2696fa486722a373659'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0.iPAX6uAQlEBKSbn63aJjw41zUUOkb7HTrizuACkCQ-1702263189-1-AQC88FwN+ZgEFqdqqQQs8nyxWBQOFUKeauZv+weUFlXPlnNZUIP3nfvvteB3W/rWHLSYF7ZdCCttYoYi2fE/lRA=; path=/; expires=Mon, 11-Dec-23 03:23:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3h_dZbbOVQ8yydSMvYWyix02QkHRK7Txfo8hUfXXKvM-1702263189302-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6f83b8ba4cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:09,315 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:53:09,317 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:09,318 httpcore.http11 DEBUG receive_response_body.complete
21:53:09,319 httpcore.http11 DEBUG response_closed.started
21:53:09,319 httpcore.http11 DEBUG response_closed.complete
21:53:09,319 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:53:09,335 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:09,337 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:12,739 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:12,759 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:12,763 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:14,765 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:14,780 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:14,783 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:18,185 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:18,188 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:53:18,192 httpcore.connection DEBUG close.started
21:53:18,192 httpcore.connection DEBUG close.complete
21:53:18,193 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:53:18,195 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e6910>
21:53:18,195 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:53:18,204 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820e72d0>
21:53:18,205 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:18,207 httpcore.http11 DEBUG send_request_headers.complete
21:53:18,208 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:18,209 httpcore.http11 DEBUG send_request_body.complete
21:53:18,209 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:18,632 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:18 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b226b0bc33058a34587563ddb626e1c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a6fbccd684d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:18,637 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:53:18,638 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:19,32 httpcore.http11 DEBUG receive_response_body.complete
21:53:19,32 httpcore.http11 DEBUG response_closed.started
21:53:19,33 httpcore.http11 DEBUG response_closed.complete
21:53:19,34 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:53:19,103 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:53:30,235 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:53:30,242 httpcore.connection DEBUG close.started
21:53:30,242 httpcore.connection DEBUG close.complete
21:53:30,243 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:53:30,245 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820f2b10>
21:53:30,246 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9d90> server_hostname='api.openai.com' timeout=5.0
21:53:30,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820f2b90>
21:53:30,251 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:30,252 httpcore.http11 DEBUG send_request_headers.complete
21:53:30,253 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:30,285 httpcore.http11 DEBUG send_request_body.complete
21:53:30,285 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:32,58 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:32 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'34'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1338'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd24ebbf86bcb391ff1785ae38f5de664'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a70081be54cfb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:32,66 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:53:32,68 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:32,69 httpcore.http11 DEBUG receive_response_body.complete
21:53:32,70 httpcore.http11 DEBUG response_closed.started
21:53:32,70 httpcore.http11 DEBUG response_closed.complete
21:53:32,70 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:53:32,71 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:53:32,101 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the right of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:53:32,105 httpcore.connection DEBUG close.started
21:53:32,105 httpcore.connection DEBUG close.complete
21:53:32,105 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:53:32,109 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820fdc90>
21:53:32,110 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822d9f40> server_hostname='api.openai.com' timeout=None
21:53:32,119 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820fdd10>
21:53:32,120 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:32,122 httpcore.http11 DEBUG send_request_headers.complete
21:53:32,123 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:32,124 httpcore.http11 DEBUG send_request_body.complete
21:53:32,125 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:32,341 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1aebb77a97d07092fd5c0da1ad952b7c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7013c92c4cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:32,348 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:53:32,349 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:32,351 httpcore.http11 DEBUG receive_response_body.complete
21:53:32,351 httpcore.http11 DEBUG response_closed.started
21:53:32,352 httpcore.http11 DEBUG response_closed.complete
21:53:32,352 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:53:32,389 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the right of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:53:32,393 httpcore.connection DEBUG close.started
21:53:32,393 httpcore.connection DEBUG close.complete
21:53:32,393 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:53:32,396 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820f3bd0>
21:53:32,397 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2f822da720> server_hostname='api.openai.com' timeout=None
21:53:32,404 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2f820f1050>
21:53:32,405 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:53:32,409 httpcore.http11 DEBUG send_request_headers.complete
21:53:32,410 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:53:32,411 httpcore.http11 DEBUG send_request_body.complete
21:53:32,412 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:53:32,859 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:53:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'340'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c9c1c43cc80f07c79421cb8d1c1f1763'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a70158eaa3ba6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:53:32,863 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:53:32,863 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:53:32,865 httpcore.http11 DEBUG receive_response_body.complete
21:53:32,865 httpcore.http11 DEBUG response_closed.started
21:53:32,866 httpcore.http11 DEBUG response_closed.complete
21:53:32,866 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:53:32,884 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:32,887 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:39,389 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:39,401 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:39,404 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:44,406 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:44,424 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:44,427 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:46,429 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:46,445 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:46,448 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:49,850 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:49,868 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:49,871 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:53:56,373 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:53:56,391 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:53:56,394 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:54:00,995 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:54:01,8 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:54:01,11 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:14,590 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:14,593 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,401 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,402 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,440 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,441 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,483 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,483 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,520 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,521 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,560 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,561 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,598 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,599 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,640 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,641 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,678 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
21:57:15,679 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
21:57:15,720 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:57:15,732 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:57:15,761 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a4035d0>
21:57:15,762 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:57:15,770 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a34ea50>
21:57:15,771 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:57:15,773 httpcore.http11 DEBUG send_request_headers.complete
21:57:15,773 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:57:15,774 httpcore.http11 DEBUG send_request_body.complete
21:57:15,774 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:57:16,411 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:57:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'519'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f1ce11860ba68de5e081704ecf82e6e4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ndg69kOB50ZxPUxn1BYt3n65nOP2iLt.lENh6u.j6Uk-1702263436-1-Abh5gGukCJQETusdToU53VKAD96n9NOgIYmnkMI+ojrJuvsG5QqHMjdgIMAAY6MpCkZjRNqTvDeO0pDEyDpaiao=; path=/; expires=Mon, 11-Dec-23 03:27:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IOA2LXrmMO7l6PkuAL7mjfKZ7sIjN5iMKaH1c7aUjDM-1702263436408-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a75899cbc3035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:57:16,414 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:57:16,415 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:57:17,202 httpcore.http11 DEBUG receive_response_body.complete
21:57:17,203 httpcore.http11 DEBUG response_closed.started
21:57:17,203 httpcore.http11 DEBUG response_closed.complete
21:57:17,204 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:57:17,272 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:57:30,499 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:57:30,507 httpcore.connection DEBUG close.started
21:57:30,507 httpcore.connection DEBUG close.complete
21:57:30,508 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:57:30,510 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a34eb10>
21:57:30,510 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:57:30,531 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a34dd10>
21:57:30,531 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:57:30,532 httpcore.http11 DEBUG send_request_headers.complete
21:57:30,532 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:57:30,563 httpcore.http11 DEBUG send_request_body.complete
21:57:30,564 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:57:31,464 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:57:31 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'15'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0a29848a462e427a5f688e77d157bafb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a75e5dd7f305d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:57:31,466 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:57:31,466 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:57:31,467 httpcore.http11 DEBUG receive_response_body.complete
21:57:31,467 httpcore.http11 DEBUG response_closed.started
21:57:31,468 httpcore.http11 DEBUG response_closed.complete
21:57:31,468 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:57:31,469 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:57:31,488 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:57:31,497 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:57:31,500 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36fb10>
21:57:31,500 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:57:31,508 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36f9d0>
21:57:31,508 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:57:31,509 httpcore.http11 DEBUG send_request_headers.complete
21:57:31,509 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:57:31,509 httpcore.http11 DEBUG send_request_body.complete
21:57:31,509 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:57:31,745 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:57:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'137'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'627844504904c4467b2cb31cd91f26db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2KjFBAZXqgKLOkL5Lk47kkT3KEjXNlRSlUvTIkNHy.E-1702263451-1-ARmxaGckDa8eFLPLn8D/PNKgR2GL8+4omCE6Xw8IwP+HWdknWBGOz6M4h8m+3/qwlC2PxjFEdXKXrPV85U89ww8=; path=/; expires=Mon, 11-Dec-23 03:27:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=wHEX6G8xNelus3za7Vp74BZ41lYiywrqnWcD_HfSjdY-1702263451741-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a75ebeb454cf0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:57:31,747 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:57:31,748 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:57:31,748 httpcore.http11 DEBUG receive_response_body.complete
21:57:31,748 httpcore.http11 DEBUG response_closed.started
21:57:31,749 httpcore.http11 DEBUG response_closed.complete
21:57:31,749 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:57:31,771 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:57:31,782 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:57:31,784 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36d310>
21:57:31,785 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d2720> server_hostname='api.openai.com' timeout=None
21:57:31,792 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1af7d0>
21:57:31,792 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:57:31,793 httpcore.http11 DEBUG send_request_headers.complete
21:57:31,793 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:57:31,794 httpcore.http11 DEBUG send_request_body.complete
21:57:31,794 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:57:32,539 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:57:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'646'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6ded54cc55c5f7fe0fad4512927143d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=a7InAs3iQ7otjv1GmzQ1GPPiryFb.WUNL.8cpvXtOQs-1702263452-1-Ae5YpjM47Weka/UT1HkHcZ/ldbHmGLXznlkfw2VCaYPfesnOdEoIuDFDTk3FxKlVVG9O36c+aGvHLuDsDmgHX+A=; path=/; expires=Mon, 11-Dec-23 03:27:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=rfIRbTn01r_yhnvGj7BcqYfZDLFfg0sT1beRxcSauWQ-1702263452535-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a75edb8704cc2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:57:32,543 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:57:32,543 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:57:32,545 httpcore.http11 DEBUG receive_response_body.complete
21:57:32,545 httpcore.http11 DEBUG response_closed.started
21:57:32,545 httpcore.http11 DEBUG response_closed.complete
21:57:32,546 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:57:32,558 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:32,615 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:39,122 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:39,134 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:39,137 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:44,138 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:44,150 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:44,153 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:46,154 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:46,164 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:46,167 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:49,568 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:49,582 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:49,586 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:57:56,88 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:57:56,100 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:57:56,105 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:00,306 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:00,317 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:00,321 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:04,522 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:04,526 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:58:04,532 httpcore.connection DEBUG close.started
21:58:04,532 httpcore.connection DEBUG close.complete
21:58:04,533 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:58:04,563 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a34dd10>
21:58:04,563 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:58:04,575 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1b0c50>
21:58:04,576 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:04,577 httpcore.http11 DEBUG send_request_headers.complete
21:58:04,577 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:04,578 httpcore.http11 DEBUG send_request_body.complete
21:58:04,578 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:05,103 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'456'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5ae27cc9f586b24a1da6293b5dc37b98'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a76ba98364ce3-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:05,105 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:58:05,106 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:06,265 httpcore.http11 DEBUG receive_response_body.complete
21:58:06,266 httpcore.http11 DEBUG response_closed.started
21:58:06,266 httpcore.http11 DEBUG response_closed.complete
21:58:06,267 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:58:06,332 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:58:18,523 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:58:18,527 httpcore.connection DEBUG close.started
21:58:18,527 httpcore.connection DEBUG close.complete
21:58:18,527 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:58:18,544 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2090>
21:58:18,544 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:58:18,552 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2110>
21:58:18,553 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:18,554 httpcore.http11 DEBUG send_request_headers.complete
21:58:18,554 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:18,575 httpcore.http11 DEBUG send_request_body.complete
21:58:18,575 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:19,398 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:19 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'342'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd2aa20c3c92d9e6ca5311679a45183fb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7711f8aa4ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:19,400 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:58:19,400 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:19,401 httpcore.http11 DEBUG receive_response_body.complete
21:58:19,401 httpcore.http11 DEBUG response_closed.started
21:58:19,402 httpcore.http11 DEBUG response_closed.complete
21:58:19,402 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:58:19,402 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:58:19,418 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:58:19,420 httpcore.connection DEBUG close.started
21:58:19,420 httpcore.connection DEBUG close.complete
21:58:19,420 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:58:19,422 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36f9d0>
21:58:19,423 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:58:19,428 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a36ff10>
21:58:19,429 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:19,429 httpcore.http11 DEBUG send_request_headers.complete
21:58:19,429 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:19,430 httpcore.http11 DEBUG send_request_body.complete
21:58:19,430 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:19,664 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'317396bb9f1094f115d2bd2da3089d52'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a77176b0a4cd8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:19,667 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:58:19,668 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:19,669 httpcore.http11 DEBUG receive_response_body.complete
21:58:19,669 httpcore.http11 DEBUG response_closed.started
21:58:19,670 httpcore.http11 DEBUG response_closed.complete
21:58:19,670 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:58:19,688 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:58:19,697 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:58:19,699 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c0b10>
21:58:19,699 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
21:58:19,706 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e3990>
21:58:19,706 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:19,707 httpcore.http11 DEBUG send_request_headers.complete
21:58:19,707 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:19,707 httpcore.http11 DEBUG send_request_body.complete
21:58:19,707 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:19,954 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'133'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'96a5881216ced1695c9c2aee4b2f4a00'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fG0b2xgR.ZvdstRZ906JhdQSVHxhMdqVGoWX6m5JC6c-1702263499-1-AebVGBxddOjME+V0rNzXhcmBNedNCM1EEq4ZJia68GvBgDDvW6lC1DfrednkYioLmr7wj6fcFEfuxdQIlQ8MXxk=; path=/; expires=Mon, 11-Dec-23 03:28:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=anZbBqxxIz2CNjCI1dgomFXJGgEKd3wdMQf2zGS8YyE-1702263499951-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a771929bc3b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:19,958 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:58:19,958 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:19,959 httpcore.http11 DEBUG receive_response_body.complete
21:58:19,959 httpcore.http11 DEBUG response_closed.started
21:58:19,960 httpcore.http11 DEBUG response_closed.complete
21:58:19,960 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:58:19,972 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:19,975 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:23,377 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:23,386 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:23,389 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:25,391 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:25,405 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:25,409 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:28,810 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:28,814 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:58:28,819 httpcore.connection DEBUG close.started
21:58:28,819 httpcore.connection DEBUG close.complete
21:58:28,820 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:58:28,822 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e1dd0>
21:58:28,822 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:58:28,829 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2210>
21:58:28,829 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:28,830 httpcore.http11 DEBUG send_request_headers.complete
21:58:28,830 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:28,830 httpcore.http11 DEBUG send_request_body.complete
21:58:28,830 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:29,288 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:29 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2dfe6be01f2dcda3d6b8c3411d703d11'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a77523d754cd4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:29,289 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:58:29,289 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:29,748 httpcore.http11 DEBUG receive_response_body.complete
21:58:29,749 httpcore.http11 DEBUG response_closed.started
21:58:29,749 httpcore.http11 DEBUG response_closed.complete
21:58:29,749 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:58:29,816 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:58:41,79 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:58:41,83 httpcore.connection DEBUG close.started
21:58:41,84 httpcore.connection DEBUG close.complete
21:58:41,84 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:58:41,86 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3d90>
21:58:41,86 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:58:41,91 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3e10>
21:58:41,92 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:41,92 httpcore.http11 DEBUG send_request_headers.complete
21:58:41,93 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:41,125 httpcore.http11 DEBUG send_request_body.complete
21:58:41,125 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:42,275 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:42 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'34'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'582'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3ac5a2cd023ca75edd046eaf23dc1419'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a779edf8d3b8e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:42,276 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:58:42,276 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:42,277 httpcore.http11 DEBUG receive_response_body.complete
21:58:42,277 httpcore.http11 DEBUG response_closed.started
21:58:42,277 httpcore.http11 DEBUG response_closed.complete
21:58:42,277 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:58:42,278 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:58:42,291 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the right of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:58:42,294 httpcore.connection DEBUG close.started
21:58:42,294 httpcore.connection DEBUG close.complete
21:58:42,295 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:58:42,297 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f6f90>
21:58:42,297 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:58:42,302 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f7090>
21:58:42,302 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:42,303 httpcore.http11 DEBUG send_request_headers.complete
21:58:42,303 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:42,303 httpcore.http11 DEBUG send_request_body.complete
21:58:42,303 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:42,507 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'90e9d702d9cb2c3911c399b8323c29b1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a77a66a073b70-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:42,510 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:58:42,511 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:42,513 httpcore.http11 DEBUG receive_response_body.complete
21:58:42,513 httpcore.http11 DEBUG response_closed.started
21:58:42,514 httpcore.http11 DEBUG response_closed.complete
21:58:42,514 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:58:42,531 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nto the right of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:58:42,533 httpcore.connection DEBUG close.started
21:58:42,533 httpcore.connection DEBUG close.complete
21:58:42,533 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:58:42,535 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c2850>
21:58:42,535 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d2720> server_hostname='api.openai.com' timeout=None
21:58:42,541 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c12d0>
21:58:42,541 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:58:42,542 httpcore.http11 DEBUG send_request_headers.complete
21:58:42,542 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:58:42,542 httpcore.http11 DEBUG send_request_body.complete
21:58:42,542 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:58:43,59 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:58:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'db455a1c801b9beaf4bb94dacbee96c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a77a7ed243035-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:58:43,62 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:58:43,62 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:58:43,64 httpcore.http11 DEBUG receive_response_body.complete
21:58:43,64 httpcore.http11 DEBUG response_closed.started
21:58:43,65 httpcore.http11 DEBUG response_closed.complete
21:58:43,65 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:58:43,76 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:43,80 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:49,582 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:49,595 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:49,598 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:54,599 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:54,610 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:54,614 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:58:56,615 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:58:56,628 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:58:56,630 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:00,32 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:00,38 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:00,41 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:06,542 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:06,554 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:06,558 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:11,160 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:11,171 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:11,174 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:15,377 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:15,381 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:59:15,386 httpcore.connection DEBUG close.started
21:59:15,387 httpcore.connection DEBUG close.complete
21:59:15,387 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:59:15,390 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3e10>
21:59:15,391 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:59:15,398 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3450>
21:59:15,399 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:15,400 httpcore.http11 DEBUG send_request_headers.complete
21:59:15,400 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:15,401 httpcore.http11 DEBUG send_request_body.complete
21:59:15,401 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:15,922 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'437'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8192910a1f2c550be1d0809d2ddd2afb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a78754c814ccc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:15,924 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:59:15,924 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:17,1 httpcore.http11 DEBUG receive_response_body.complete
21:59:17,1 httpcore.http11 DEBUG response_closed.started
21:59:17,1 httpcore.http11 DEBUG response_closed.complete
21:59:17,2 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:59:17,68 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:59:29,540 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:59:29,543 httpcore.connection DEBUG close.started
21:59:29,543 httpcore.connection DEBUG close.complete
21:59:29,544 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:59:29,574 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2350>
21:59:29,575 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:59:29,584 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e2210>
21:59:29,585 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:29,586 httpcore.http11 DEBUG send_request_headers.complete
21:59:29,586 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:29,608 httpcore.http11 DEBUG send_request_body.complete
21:59:29,609 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:30,360 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'344'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'675dcc6f05db73d80c38be1e6bb1940e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a78cded834cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:30,363 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:59:30,364 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:30,364 httpcore.http11 DEBUG receive_response_body.complete
21:59:30,365 httpcore.http11 DEBUG response_closed.started
21:59:30,365 httpcore.http11 DEBUG response_closed.complete
21:59:30,366 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:59:30,367 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:59:30,382 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:59:30,384 httpcore.connection DEBUG close.started
21:59:30,384 httpcore.connection DEBUG close.complete
21:59:30,385 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:59:30,387 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f8dd0>
21:59:30,387 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:59:30,393 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f89d0>
21:59:30,393 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:30,394 httpcore.http11 DEBUG send_request_headers.complete
21:59:30,394 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:30,394 httpcore.http11 DEBUG send_request_body.complete
21:59:30,394 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:30,839 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'338'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e24dcbefd9699c05e9ceaab9d3fa945d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a78d2faf23b99-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:30,841 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:59:30,841 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:30,842 httpcore.http11 DEBUG receive_response_body.complete
21:59:30,842 httpcore.http11 DEBUG response_closed.started
21:59:30,843 httpcore.http11 DEBUG response_closed.complete
21:59:30,843 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:59:30,862 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:59:30,864 httpcore.connection DEBUG close.started
21:59:30,864 httpcore.connection DEBUG close.complete
21:59:30,864 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:59:30,867 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1fadd0>
21:59:30,867 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
21:59:30,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1fb510>
21:59:30,877 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:30,878 httpcore.http11 DEBUG send_request_headers.complete
21:59:30,878 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:30,878 httpcore.http11 DEBUG send_request_body.complete
21:59:30,878 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:31,111 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4414274a8f15797b3537b147d8d8103f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a78d5f9c94d07-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:31,114 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:59:31,115 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:31,116 httpcore.http11 DEBUG receive_response_body.complete
21:59:31,116 httpcore.http11 DEBUG response_closed.started
21:59:31,117 httpcore.http11 DEBUG response_closed.complete
21:59:31,117 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:59:31,127 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:31,130 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:34,531 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:34,544 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:34,550 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:36,552 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:36,562 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:36,566 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
21:59:39,968 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
21:59:39,972 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
21:59:39,975 httpcore.connection DEBUG close.started
21:59:39,975 httpcore.connection DEBUG close.complete
21:59:39,976 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:59:39,978 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1b2a50>
21:59:39,978 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:59:39,983 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1b0790>
21:59:39,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:39,984 httpcore.http11 DEBUG send_request_headers.complete
21:59:39,984 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:39,985 httpcore.http11 DEBUG send_request_body.complete
21:59:39,985 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:40,603 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'483'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c0219dafaf6238245cab860559ce3502'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a790eecb06ac7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:40,605 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
21:59:40,606 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:41,17 httpcore.http11 DEBUG receive_response_body.complete
21:59:41,17 httpcore.http11 DEBUG response_closed.started
21:59:41,17 httpcore.http11 DEBUG response_closed.complete
21:59:41,17 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
21:59:41,81 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
21:59:52,202 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
21:59:52,205 httpcore.connection DEBUG close.started
21:59:52,205 httpcore.connection DEBUG close.complete
21:59:52,205 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
21:59:52,208 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c1a90>
21:59:52,208 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
21:59:52,214 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3790>
21:59:52,214 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:52,215 httpcore.http11 DEBUG send_request_headers.complete
21:59:52,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:52,247 httpcore.http11 DEBUG send_request_body.complete
21:59:52,247 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:53,145 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:53 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a9ce07d4173d5825efb080f7aad5426d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a795b5d344cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:53,147 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
21:59:53,148 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:53,149 httpcore.http11 DEBUG receive_response_body.complete
21:59:53,149 httpcore.http11 DEBUG response_closed.started
21:59:53,149 httpcore.http11 DEBUG response_closed.complete
21:59:53,150 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
21:59:53,150 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
21:59:53,166 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nbelow the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:59:53,168 httpcore.connection DEBUG close.started
21:59:53,168 httpcore.connection DEBUG close.complete
21:59:53,168 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:59:53,171 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f8f10>
21:59:53,171 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
21:59:53,178 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1fa790>
21:59:53,179 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:53,180 httpcore.http11 DEBUG send_request_headers.complete
21:59:53,180 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:53,180 httpcore.http11 DEBUG send_request_body.complete
21:59:53,180 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:53,404 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'98'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'13b6273cefe5cfd96f100a264903fd5c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a79616fdb4d14-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:53,407 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:59:53,407 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:53,409 httpcore.http11 DEBUG receive_response_body.complete
21:59:53,409 httpcore.http11 DEBUG response_closed.started
21:59:53,409 httpcore.http11 DEBUG response_closed.complete
21:59:53,410 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:59:53,426 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2 + 1\nlambda x1, surface_width: x1 > surface_width // 2 + 1\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nbelow the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
21:59:53,428 httpcore.connection DEBUG close.started
21:59:53,429 httpcore.connection DEBUG close.complete
21:59:53,429 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
21:59:53,431 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c3f90>
21:59:53,431 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d2720> server_hostname='api.openai.com' timeout=None
21:59:53,437 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c0950>
21:59:53,437 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
21:59:53,437 httpcore.http11 DEBUG send_request_headers.complete
21:59:53,438 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
21:59:53,438 httpcore.http11 DEBUG send_request_body.complete
21:59:53,438 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
21:59:53,802 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 02:59:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'262'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f9ab5f5b319a21cda24cb2f380f3d6e1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7962fbe14d13-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
21:59:53,806 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
21:59:53,807 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
21:59:53,809 httpcore.http11 DEBUG receive_response_body.complete
21:59:53,809 httpcore.http11 DEBUG response_closed.started
21:59:53,810 httpcore.http11 DEBUG response_closed.complete
21:59:53,810 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
21:59:53,820 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
21:59:53,823 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:00,324 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:00,339 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:00,342 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:05,343 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:05,352 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:05,356 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:07,358 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:07,371 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:07,374 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:10,776 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:10,787 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:10,791 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:17,293 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:17,304 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:17,308 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:20,309 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:20,321 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:20,324 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:23,725 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:23,729 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
22:00:23,734 httpcore.connection DEBUG close.started
22:00:23,734 httpcore.connection DEBUG close.complete
22:00:23,734 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:00:23,737 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a2041d0>
22:00:23,737 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:00:23,744 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a204d10>
22:00:23,745 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:23,745 httpcore.http11 DEBUG send_request_headers.complete
22:00:23,745 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:23,746 httpcore.http11 DEBUG send_request_body.complete
22:00:23,746 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:24,265 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:24 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'edd0fef1be48529d7e5ae3fde87c913c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a206bf14cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:24,267 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
22:00:24,268 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:25,300 httpcore.http11 DEBUG receive_response_body.complete
22:00:25,300 httpcore.http11 DEBUG response_closed.started
22:00:25,300 httpcore.http11 DEBUG response_closed.complete
22:00:25,301 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
22:00:25,367 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
22:00:37,614 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
22:00:37,617 httpcore.connection DEBUG close.started
22:00:37,617 httpcore.connection DEBUG close.complete
22:00:37,617 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:00:37,648 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a207790>
22:00:37,649 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:00:37,659 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a207810>
22:00:37,660 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:37,661 httpcore.http11 DEBUG send_request_headers.complete
22:00:37,662 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:37,682 httpcore.http11 DEBUG send_request_body.complete
22:00:37,683 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:38,580 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:38 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'369'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e5b456bdb14db0d2c31328c7777a512b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a77680a4d07-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:38,583 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
22:00:38,583 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:38,586 httpcore.http11 DEBUG receive_response_body.complete
22:00:38,586 httpcore.http11 DEBUG response_closed.started
22:00:38,586 httpcore.http11 DEBUG response_closed.complete
22:00:38,586 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
22:00:38,587 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
22:00:38,602 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nto the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:00:38,604 httpcore.connection DEBUG close.started
22:00:38,604 httpcore.connection DEBUG close.complete
22:00:38,605 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:00:38,607 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c2910>
22:00:38,607 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1f40> server_hostname='api.openai.com' timeout=None
22:00:38,612 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1c05d0>
22:00:38,613 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:38,614 httpcore.http11 DEBUG send_request_headers.complete
22:00:38,614 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:38,615 httpcore.http11 DEBUG send_request_body.complete
22:00:38,615 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:38,891 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1230792f14dbd2fd7a17e941ae0258d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a7d5d4c305d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:38,894 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:00:38,895 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:38,896 httpcore.http11 DEBUG receive_response_body.complete
22:00:38,897 httpcore.http11 DEBUG response_closed.started
22:00:38,897 httpcore.http11 DEBUG response_closed.complete
22:00:38,898 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:00:38,914 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? (You can say either yes, no, or move to the left, to the right, move up or move down)\n'''\nAnd the human answered\n'''\nto the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:00:38,916 httpcore.connection DEBUG close.started
22:00:38,916 httpcore.connection DEBUG close.complete
22:00:38,916 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:00:38,918 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1fa9d0>
22:00:38,918 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
22:00:38,926 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f8550>
22:00:38,926 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:38,927 httpcore.http11 DEBUG send_request_headers.complete
22:00:38,927 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:38,927 httpcore.http11 DEBUG send_request_body.complete
22:00:38,927 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:39,164 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ae414569c8140a3b51cbeb007d80a761'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a7f4ea13031-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:39,166 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:00:39,166 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:39,167 httpcore.http11 DEBUG receive_response_body.complete
22:00:39,167 httpcore.http11 DEBUG response_closed.started
22:00:39,167 httpcore.http11 DEBUG response_closed.complete
22:00:39,167 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:00:39,178 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:39,181 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:00:42,583 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:00:42,587 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
22:00:42,591 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:42,592 httpcore.http11 DEBUG send_request_headers.complete
22:00:42,592 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:42,592 httpcore.http11 DEBUG send_request_body.complete
22:00:42,592 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:43,89 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:43 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'426'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6044a2f16c2b6bf36681cb2bd9ccec18'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7a963a584d07-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:43,91 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
22:00:43,92 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:44,221 httpcore.http11 DEBUG receive_response_body.complete
22:00:44,222 httpcore.http11 DEBUG response_closed.started
22:00:44,222 httpcore.http11 DEBUG response_closed.complete
22:00:44,222 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
22:00:44,285 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
22:00:56,875 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
22:00:56,878 httpcore.connection DEBUG close.started
22:00:56,878 httpcore.connection DEBUG close.complete
22:00:56,879 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:00:56,881 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f5450>
22:00:56,881 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:00:56,887 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f61d0>
22:00:56,888 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:56,888 httpcore.http11 DEBUG send_request_headers.complete
22:00:56,888 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:56,909 httpcore.http11 DEBUG send_request_body.complete
22:00:56,909 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:57,691 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'344'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ddd2b51dfbd72575837eb7a3f014163f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7aef8ea94cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:57,693 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
22:00:57,693 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:57,694 httpcore.http11 DEBUG receive_response_body.complete
22:00:57,695 httpcore.http11 DEBUG response_closed.started
22:00:57,695 httpcore.http11 DEBUG response_closed.complete
22:00:57,695 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
22:00:57,696 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
22:00:57,709 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nTo the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:00:57,711 httpcore.connection DEBUG close.started
22:00:57,711 httpcore.connection DEBUG close.complete
22:00:57,711 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:00:57,714 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1b8410>
22:00:57,714 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
22:00:57,719 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1e1390>
22:00:57,719 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:00:57,720 httpcore.http11 DEBUG send_request_headers.complete
22:00:57,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:00:57,720 httpcore.http11 DEBUG send_request_body.complete
22:00:57,720 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:00:58,23 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:00:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e60f46db2103230c8f837d68d0b972ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7af4c91b4d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:00:58,25 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:00:58,25 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:00:58,25 httpcore.http11 DEBUG receive_response_body.complete
22:00:58,26 httpcore.http11 DEBUG response_closed.started
22:00:58,26 httpcore.http11 DEBUG response_closed.complete
22:00:58,26 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:00:58,36 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:00:58,40 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:01,441 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:01:01,445 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
22:01:01,449 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:01,450 httpcore.http11 DEBUG send_request_headers.complete
22:01:01,451 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:01,451 httpcore.http11 DEBUG send_request_body.complete
22:01:01,451 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:01,980 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'443'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd8b3f8093c397f15ff9cb143ccced627'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7b0c1a0a4cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:01,982 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
22:01:01,983 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:03,200 httpcore.http11 DEBUG receive_response_body.complete
22:01:03,201 httpcore.http11 DEBUG response_closed.started
22:01:03,201 httpcore.http11 DEBUG response_closed.complete
22:01:03,202 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
22:01:03,264 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
22:01:15,634 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
22:01:15,638 httpcore.connection DEBUG close.started
22:01:15,639 httpcore.connection DEBUG close.complete
22:01:15,639 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:01:15,642 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f6b10>
22:01:15,642 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:01:15,649 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1f4690>
22:01:15,650 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:15,650 httpcore.http11 DEBUG send_request_headers.complete
22:01:15,650 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:15,672 httpcore.http11 DEBUG send_request_body.complete
22:01:15,672 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:16,561 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:16 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a4028f338109d8ffdcb82053f51db6a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7b64de734d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:16,564 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
22:01:16,565 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:16,566 httpcore.http11 DEBUG receive_response_body.complete
22:01:16,566 httpcore.http11 DEBUG response_closed.started
22:01:16,567 httpcore.http11 DEBUG response_closed.complete
22:01:16,567 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
22:01:16,568 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
22:01:16,583 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nto the right.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:01:16,585 httpcore.connection DEBUG close.started
22:01:16,585 httpcore.connection DEBUG close.complete
22:01:16,585 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:01:16,587 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a206250>
22:01:16,588 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
22:01:16,593 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a205490>
22:01:16,594 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:16,594 httpcore.http11 DEBUG send_request_headers.complete
22:01:16,594 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:16,595 httpcore.http11 DEBUG send_request_body.complete
22:01:16,595 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:16,793 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e95469566d051818ccd8ad811375d7be'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7b6ab94d6ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:16,796 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:01:16,797 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:16,798 httpcore.http11 DEBUG receive_response_body.complete
22:01:16,799 httpcore.http11 DEBUG response_closed.started
22:01:16,799 httpcore.http11 DEBUG response_closed.complete
22:01:16,800 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:01:16,809 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:01:16,811 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:20,213 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:01:20,216 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
22:01:20,220 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:20,221 httpcore.http11 DEBUG send_request_headers.complete
22:01:20,221 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:20,222 httpcore.http11 DEBUG send_request_body.complete
22:01:20,222 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:20,792 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'482'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'65d55f779992c368bccec72354ecf507'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7b816c9b4d0a-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:20,794 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
22:01:20,795 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:21,756 httpcore.http11 DEBUG receive_response_body.complete
22:01:21,756 httpcore.http11 DEBUG response_closed.started
22:01:21,756 httpcore.http11 DEBUG response_closed.complete
22:01:21,757 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
22:01:21,823 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent8.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
22:01:33,542 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent8.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
22:01:33,545 httpcore.connection DEBUG close.started
22:01:33,545 httpcore.connection DEBUG close.complete
22:01:33,546 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
22:01:33,548 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1af490>
22:01:33,548 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1e20> server_hostname='api.openai.com' timeout=5.0
22:01:33,553 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a1af290>
22:01:33,553 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:33,554 httpcore.http11 DEBUG send_request_headers.complete
22:01:33,554 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:33,578 httpcore.http11 DEBUG send_request_body.complete
22:01:33,578 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:34,345 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b948e6590841875bd74618abf8661ac6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7bd4bbcd4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:34,347 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
22:01:34,348 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:34,348 httpcore.http11 DEBUG receive_response_body.complete
22:01:34,349 httpcore.http11 DEBUG response_closed.started
22:01:34,349 httpcore.http11 DEBUG response_closed.complete
22:01:34,349 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
22:01:34,350 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
22:01:34,365 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location (You can say either yes, no, or move to the left, to the right, move up or move down)?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location, did not accept your location but did not specify which way to move, or whether the human wanted you to move either left, right, up or down. Answer with either 'accept', 'no accept', 'left', 'right', 'up', or 'down' only. \nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
22:01:34,367 httpcore.connection DEBUG close.started
22:01:34,367 httpcore.connection DEBUG close.complete
22:01:34,367 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
22:01:34,369 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a208750>
22:01:34,370 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc27a3d1eb0> server_hostname='api.openai.com' timeout=None
22:01:34,379 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc27a208050>
22:01:34,379 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
22:01:34,380 httpcore.http11 DEBUG send_request_headers.complete
22:01:34,380 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
22:01:34,380 httpcore.http11 DEBUG send_request_body.complete
22:01:34,381 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
22:01:34,585 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 11 Dec 2023 03:01:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cc1b179c51f2ba70dd7738729755c5fd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'833a7bd9e9864cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
22:01:34,587 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
22:01:34,587 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
22:01:34,588 httpcore.http11 DEBUG receive_response_body.complete
22:01:34,589 httpcore.http11 DEBUG response_closed.started
22:01:34,589 httpcore.http11 DEBUG response_closed.complete
22:01:34,590 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
22:01:34,599 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:01:34,603 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:38,4 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:01:38,17 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:01:38,20 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:40,21 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
22:01:40,35 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
22:01:40,39 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
22:01:43,440 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
