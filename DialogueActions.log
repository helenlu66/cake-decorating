18:04:21,622 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:21,623 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,389 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,390 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,427 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,427 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,463 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,463 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,496 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,496 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,529 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,530 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,562 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,562 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,595 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,596 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,629 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:04:22,629 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:04:22,660 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:04:22,669 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:04:22,702 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f35ba84c810>
18:04:22,702 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f35ba61c170> server_hostname='api.openai.com' timeout=5.0
18:04:22,708 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f35ba82a050>
18:04:22,709 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:04:22,709 httpcore.http11 DEBUG send_request_headers.complete
18:04:22,709 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:04:22,710 httpcore.http11 DEBUG send_request_body.complete
18:04:22,710 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:04:23,243 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:04:23 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'362'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8a1b342bd8f027ad464bf3499661f716'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_vwJq7f_YtnDfo7kT3LQIpt8PoYRZ42x8IjNJ.tINvU-1701903863-0-Aas5pB/11cVRQt3Cxrc1MGAavRRZILVLQQM2yTrM6F7cUcfsBbudyQBtPUzh3QXYG7S1N3sDO65Yj92PGArdkfU=; path=/; expires=Wed, 06-Dec-23 23:34:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=36Qo1ZYu6gQdOCDfqnA4zeNaIqH3vP3YtsEoftUbH2g-1701903863241-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182ae5eceb6ac8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:04:23,245 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:04:23,245 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:04:23,767 httpcore.http11 DEBUG receive_response_body.complete
18:04:23,767 httpcore.http11 DEBUG response_closed.started
18:04:23,767 httpcore.http11 DEBUG response_closed.complete
18:04:23,768 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:10,562 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:10,563 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,328 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,329 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,368 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,369 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,403 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,403 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,436 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,436 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,469 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,469 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,501 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,501 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,534 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,535 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,565 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:06:11,566 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:06:11,596 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:06:11,605 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:06:11,633 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c92add0>
18:06:11,633 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986cb33c80> server_hostname='api.openai.com' timeout=5.0
18:06:11,640 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c935750>
18:06:11,641 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:11,641 httpcore.http11 DEBUG send_request_headers.complete
18:06:11,641 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:11,642 httpcore.http11 DEBUG send_request_body.complete
18:06:11,642 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:12,87 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:12 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'359'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'86b27ebb4df5bb027061a47a4a23a408'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7OBsIGWLKw429wzNfubpBG1w1xPo9p_pn0f6xrLiTKI-1701903972-0-AVz57idx+VRHj3//Be5Xro1KpS6xo5GySIXgt2QxBI0pxs3Yd76f6BKTVjgjrPPIl1JxN1dYCyI003RVuZbX+ZA=; path=/; expires=Wed, 06-Dec-23 23:36:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=51BY5i2lwp6sgvCs2Vq.kLOMPs.7fiKtpCi1Sm45j2Y-1701903972084-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182d8ecc8b4cef-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:12,88 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:06:12,89 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:12,439 httpcore.http11 DEBUG receive_response_body.complete
18:06:12,439 httpcore.http11 DEBUG response_closed.started
18:06:12,439 httpcore.http11 DEBUG response_closed.complete
18:06:12,440 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:12,514 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:06:26,287 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:06:26,289 httpcore.connection DEBUG close.started
18:06:26,289 httpcore.connection DEBUG close.complete
18:06:26,289 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:06:26,292 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c934e10>
18:06:26,292 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986cb33c80> server_hostname='api.openai.com' timeout=5.0
18:06:26,298 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986cc14c10>
18:06:26,298 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:26,299 httpcore.http11 DEBUG send_request_headers.complete
18:06:26,299 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:26,334 httpcore.http11 DEBUG send_request_body.complete
18:06:26,334 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:28,964 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:28 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'1'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1893'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5bec98e9862a580d6efccd0d023504a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182dea5eef3ba6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:28,965 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:06:28,965 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:28,965 httpcore.http11 DEBUG receive_response_body.complete
18:06:28,965 httpcore.http11 DEBUG response_closed.started
18:06:28,965 httpcore.http11 DEBUG response_closed.complete
18:06:28,966 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:06:28,966 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 2 column 1 (char 1)
18:06:28,975 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\n\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:06:28,983 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:06:28,985 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c755090>
18:06:28,985 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986cb33bf0> server_hostname='api.openai.com' timeout=None
18:06:28,993 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c7550d0>
18:06:28,993 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:28,994 httpcore.http11 DEBUG send_request_headers.complete
18:06:28,994 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:28,994 httpcore.http11 DEBUG send_request_body.complete
18:06:28,994 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:29,388 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'242'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f2f42517cf15248f3ff1bb96beab6a74'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uc5orlaxhb0ZcteprbJs2Xa4CDOyG13cBf8Me1.Rq_0-1701903989-0-AWNKkThf4sgC84DSHjlRsOPq/618IxHhsyu0HQWfFxqcBP2Gjj1N9Lotkd4HyBNAwscdrSR2yBEz+eLB98OJudg=; path=/; expires=Wed, 06-Dec-23 23:36:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=duNqR8Wjcid7Omebc9tIirrXdOjFRpKA2suM7guSmc8-1701903989386-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182dfb3c264d14-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:29,390 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:06:29,390 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:29,390 httpcore.http11 DEBUG receive_response_body.complete
18:06:29,390 httpcore.http11 DEBUG response_closed.started
18:06:29,391 httpcore.http11 DEBUG response_closed.complete
18:06:29,391 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:06:29,400 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\n\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:06:29,408 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:06:29,410 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c778610>
18:06:29,410 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f986ca00290> server_hostname='api.openai.com' timeout=None
18:06:29,416 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f986c76e290>
18:06:29,416 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:29,417 httpcore.http11 DEBUG send_request_headers.complete
18:06:29,417 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:29,417 httpcore.http11 DEBUG send_request_body.complete
18:06:29,417 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:30,585 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1065'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9207908209e01a3602f1fea617be88b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aG4uNt6aPcJ8f5jiDGhP3NjLfnUgCYLh7t7Qnrg2jlI-1701903990-0-AbT4R5pGqX91gzP+zpmAUPxOunDK2SZ2J7NOgnRgNQmEq5d2xDvzBnf8xxA1S4Z6WDztsLrTv6B7CC8FR6VhlzE=; path=/; expires=Wed, 06-Dec-23 23:36:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=HGBGp4DM4fSOnAr6j9OrbTutJmgN.vDcFD7qj2NM0yM-1701903990583-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182dfddb863b69-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:30,587 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:06:30,587 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:30,587 httpcore.http11 DEBUG receive_response_body.complete
18:06:30,588 httpcore.http11 DEBUG response_closed.started
18:06:30,588 httpcore.http11 DEBUG response_closed.complete
18:06:30,588 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:06:30,591 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "Ok, let's start with the first candle. Can you tell me where you would like me to place it? Please be as specific as possible so I can help you accurately place the candles.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:06:30,593 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:06:30,593 httpcore.http11 DEBUG send_request_headers.complete
18:06:30,593 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:06:30,593 httpcore.http11 DEBUG send_request_body.complete
18:06:30,594 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:06:31,300 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:06:31 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'591'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e475a4697f85a0c0194679c8836f47a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83182e053d1c3ba6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:06:31,301 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:06:31,301 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:06:32,910 httpcore.http11 DEBUG receive_response_body.complete
18:06:32,911 httpcore.http11 DEBUG response_closed.started
18:06:32,911 httpcore.http11 DEBUG response_closed.complete
18:06:32,911 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:06:32,978 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:14:23,343 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:23,345 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,108 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,109 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,143 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,144 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,177 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,178 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,209 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,209 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,241 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,241 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,270 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,271 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,301 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,301 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,331 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:14:24,332 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:14:24,361 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:14:24,370 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:14:24,400 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603364c50>
18:14:24,400 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa603563c80> server_hostname='api.openai.com' timeout=5.0
18:14:24,405 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603395f50>
18:14:24,405 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:24,405 httpcore.http11 DEBUG send_request_headers.complete
18:14:24,406 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:24,406 httpcore.http11 DEBUG send_request_body.complete
18:14:24,406 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:24,885 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:24 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'26605efdef44faeb5fa397dab600436d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.5_fPErG5K9yT9CzSLuLk4xxrEUHDSPB8HlHAJbSn3s-1701904464-0-AUwZLBAqvU8hvqGFBloYcA/QvYrRDYCiuK9HELpp1xr8kyM+NnOgu27PcE9hjH2sF2XpwPfJiHKanB5K9FsgnVQ=; path=/; expires=Wed, 06-Dec-23 23:44:24 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RrcE_r3qRBeJA9XO3QDWwJXkPumpU5oUi8W0SM8uHak-1701904464882-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8318399688244d05-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:24,887 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:14:24,887 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:25,387 httpcore.http11 DEBUG receive_response_body.complete
18:14:25,387 httpcore.http11 DEBUG response_closed.started
18:14:25,387 httpcore.http11 DEBUG response_closed.complete
18:14:25,387 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:14:25,453 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:14:39,676 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:14:39,679 httpcore.connection DEBUG close.started
18:14:39,679 httpcore.connection DEBUG close.complete
18:14:39,679 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:14:39,682 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603364d90>
18:14:39,682 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa603563c80> server_hostname='api.openai.com' timeout=5.0
18:14:39,691 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603364bd0>
18:14:39,691 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:39,691 httpcore.http11 DEBUG send_request_headers.complete
18:14:39,691 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:39,712 httpcore.http11 DEBUG send_request_body.complete
18:14:39,712 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:40,830 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:40 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'24'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'463'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f119909bbf016b463e69a8b85f8f7499'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'831839f61ffa4cfc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:40,831 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:14:40,831 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:40,831 httpcore.http11 DEBUG receive_response_body.complete
18:14:40,832 httpcore.http11 DEBUG response_closed.started
18:14:40,832 httpcore.http11 DEBUG response_closed.complete
18:14:40,832 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:14:40,832 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:14:40,842 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nHi, put it to the left.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:14:40,849 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:14:40,852 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa6031876d0>
18:14:40,852 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa603563bf0> server_hostname='api.openai.com' timeout=None
18:14:40,856 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa603185350>
18:14:40,856 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:40,857 httpcore.http11 DEBUG send_request_headers.complete
18:14:40,857 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:40,857 httpcore.http11 DEBUG send_request_body.complete
18:14:40,857 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:41,203 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'248'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9f8f58dd013b12c3fb666bc2ce803985'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.puo5hr42Xfy6VXBM2_hu.ajlEasEBr.VZAeHhhdlfk-1701904481-0-AZ5atlemN9efs9P73MdzgjDVfL4fiDIr+iuYSc6oSycd2iIevVRCTmWaougAT7VH3SCIiFSBwdJfg1kQo8HPgok=; path=/; expires=Wed, 06-Dec-23 23:44:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=fzLBxL33cqWWyrCo5LxWD3e5yXHVNlNdPtYWLHZWdKg-1701904481201-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'831839fd5a643b87-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:41,204 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:14:41,205 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:41,205 httpcore.http11 DEBUG receive_response_body.complete
18:14:41,205 httpcore.http11 DEBUG response_closed.started
18:14:41,205 httpcore.http11 DEBUG response_closed.complete
18:14:41,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:14:41,217 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 20 in the x direction and 20 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (20, 20). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 20 in the x direction and 20 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (20, 20). You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nHi, put it to the left.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:14:41,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:14:41,226 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa6031a8ad0>
18:14:41,226 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fa60342c680> server_hostname='api.openai.com' timeout=None
18:14:41,233 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fa60319e650>
18:14:41,233 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:41,233 httpcore.http11 DEBUG send_request_headers.complete
18:14:41,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:41,233 httpcore.http11 DEBUG send_request_body.complete
18:14:41,233 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:41,841 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'511'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'bfef72e3ebef5a20041562e23339b414'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.gLcC.aGbDun4o4tCJNM1Nw9_M9d2J3Lr6ohlWLIWNY-1701904481-0-AfSLW8aiQLGs033TGofP75MYjpOKsDiAAb25q2mvxbJU7t1Mh3QfTKR1AIY0SNeoQNk6jSaIZ7Xw8jb8onC02pE=; path=/; expires=Wed, 06-Dec-23 23:44:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=N0n1QIYAmak4GdVuITmDa9uCgDJuv.oVsCGfsEqwf0Q-1701904481838-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'831839ffbcdb3bab-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:41,842 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:14:41,842 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:41,842 httpcore.http11 DEBUG receive_response_body.complete
18:14:41,843 httpcore.http11 DEBUG response_closed.started
18:14:41,843 httpcore.http11 DEBUG response_closed.complete
18:14:41,843 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:14:41,846 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:14:41,848 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:14:41,848 httpcore.http11 DEBUG send_request_headers.complete
18:14:41,848 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:14:41,849 httpcore.http11 DEBUG send_request_body.complete
18:14:41,849 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:14:42,282 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:14:42 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a01e73ae8692ff7669545c8f6d6d2ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83183a038aee4cfc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:14:42,283 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:14:42,284 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:14:42,546 httpcore.http11 DEBUG receive_response_body.complete
18:14:42,546 httpcore.http11 DEBUG response_closed.started
18:14:42,546 httpcore.http11 DEBUG response_closed.complete
18:14:42,547 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:14:42,614 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:37:39,803 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:39,805 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,587 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,587 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,627 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,628 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,663 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,664 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,696 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,697 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,730 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,731 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,763 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,764 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,796 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,796 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,827 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:37:40,828 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:37:40,858 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:37:40,867 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:40,898 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980ea1910>
18:37:40,898 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980dbfc80> server_hostname='api.openai.com' timeout=5.0
18:37:40,904 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980bc1650>
18:37:40,905 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:40,905 httpcore.http11 DEBUG send_request_headers.complete
18:37:40,905 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:40,906 httpcore.http11 DEBUG send_request_body.complete
18:37:40,906 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:41,340 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:41 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'604426a3dd0bf52bfb7bf8720d30b357'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=de6QToKOzo_TOprGGzP4kqrM4aDhqYNAQShJBa2ekGY-1701905861-0-AW7P/Y78OT1+BpbixU52xxnQl2904QjHRIvGvM8Do11SnvDHIk01CLz6ckixBiLJcC74Q7ShbyWcwhE9SA8dAlo=; path=/; expires=Thu, 07-Dec-23 00:07:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=atZXLIi7KvMZ4QIH45s2rsC_OD3On6OmUfS1z8lUQsU-1701905861338-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185baea9da4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:41,342 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:37:41,342 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:41,804 httpcore.http11 DEBUG receive_response_body.complete
18:37:41,804 httpcore.http11 DEBUG response_closed.started
18:37:41,804 httpcore.http11 DEBUG response_closed.complete
18:37:41,804 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:37:41,872 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:37:56,194 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:37:56,196 httpcore.connection DEBUG close.started
18:37:56,196 httpcore.connection DEBUG close.complete
18:37:56,196 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:37:56,199 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980bc0dd0>
18:37:56,199 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980dbfc80> server_hostname='api.openai.com' timeout=5.0
18:37:56,204 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980bc1650>
18:37:56,204 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:56,204 httpcore.http11 DEBUG send_request_headers.complete
18:37:56,205 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:56,238 httpcore.http11 DEBUG send_request_body.complete
18:37:56,238 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:57,347 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'304b683735aad1698e99e070bc91657e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c0e4c4c3b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:57,348 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:37:57,348 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:57,348 httpcore.http11 DEBUG receive_response_body.complete
18:37:57,348 httpcore.http11 DEBUG response_closed.started
18:37:57,349 httpcore.http11 DEBUG response_closed.complete
18:37:57,349 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:37:57,349 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:37:57,359 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nWhat? What the hell?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:57,366 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:57,373 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f29809e1310>
18:37:57,373 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980dbfbf0> server_hostname='api.openai.com' timeout=None
18:37:57,383 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f29809e36d0>
18:37:57,383 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:57,383 httpcore.http11 DEBUG send_request_headers.complete
18:37:57,383 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:57,383 httpcore.http11 DEBUG send_request_body.complete
18:37:57,384 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:57,750 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'283'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0fe0f87f58127da520805ba11a341f02'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=tkIpVU8zlHVgog7ySbANVP48LRNh1ZluWPznK0zxESM-1701905877-0-ASNPR2sFTnIrf9qf2ByHDdZgl5ibgtRO/DVScrwmhYpeK6rZSZTfkbK2fpTcZvVrePEKQconE6kPD/zU1MC8thY=; path=/; expires=Thu, 07-Dec-23 00:07:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=LgIa1EKKFXm04ANCyoYfIri1oGws56qPbS76CvFRCN0-1701905877747-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c15afe54cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:57,751 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:57,751 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:57,752 httpcore.http11 DEBUG receive_response_body.complete
18:37:57,752 httpcore.http11 DEBUG response_closed.started
18:37:57,752 httpcore.http11 DEBUG response_closed.complete
18:37:57,752 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:57,762 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nWhat? What the hell?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:37:57,769 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:37:57,771 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2980a04590>
18:37:57,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2980c88290> server_hostname='api.openai.com' timeout=None
18:37:57,781 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f29809fa050>
18:37:57,781 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:57,782 httpcore.http11 DEBUG send_request_headers.complete
18:37:57,782 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:57,783 httpcore.http11 DEBUG send_request_body.complete
18:37:57,783 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:58,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'923'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'dbdb68d56db24ee3169a697f331e243f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ofgQFnumf_P1RqpMbtybZU5_e7FY1Ccj8nWibhFtJkc-1701905878-0-Afy/8PaqwnU4rzj0KppX0Rdp7dW0nza7hqQrPmPsWCGIGKvNdPqZR8Z6qzvJafd3p5y3ZIF6dMaT6M9FYxn+MOw=; path=/; expires=Thu, 07-Dec-23 00:07:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=tZb85p34uxKEet0sTPLGoGvUvbtL.enYL.LCK.gSax4-1701905878853-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c1829004ce4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:58,857 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:37:58,857 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:37:58,858 httpcore.http11 DEBUG receive_response_body.complete
18:37:58,858 httpcore.http11 DEBUG response_closed.started
18:37:58,858 httpcore.http11 DEBUG response_closed.complete
18:37:58,858 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:37:58,861 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "I apologize for the confusion. I'm an assistant robot here to help you place the candles on the cake. Could you please tell me where you would like me to place the first candle?", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:37:58,863 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:37:58,863 httpcore.http11 DEBUG send_request_headers.complete
18:37:58,863 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:37:58,864 httpcore.http11 DEBUG send_request_body.complete
18:37:58,864 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:37:59,558 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 06 Dec 2023 23:37:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'563'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd32feb71cc070df82be98a9b0fcb6c5c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83185c1eeb4b3b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:37:59,558 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:37:59,559 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:38:00,919 httpcore.http11 DEBUG receive_response_body.complete
18:38:00,919 httpcore.http11 DEBUG response_closed.started
18:38:00,919 httpcore.http11 DEBUG response_closed.complete
18:38:00,920 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:38:00,990 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
16:55:11,373 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:11,374 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,151 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,152 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,192 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,193 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,228 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,229 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,262 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,263 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,298 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,298 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,332 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,332 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,367 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,367 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,401 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:55:12,401 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:55:12,436 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
16:55:12,445 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:55:12,476 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ade90>
16:55:12,476 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb2afd10> server_hostname='api.openai.com' timeout=5.0
16:55:12,481 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ae990>
16:55:12,482 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:12,482 httpcore.http11 DEBUG send_request_headers.complete
16:55:12,482 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:12,482 httpcore.http11 DEBUG send_request_body.complete
16:55:12,482 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:13,319 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:13 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'686'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1c8ff1093f8090a98d62e8cd557fc279'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4zYLpK4yTUQ0n0kaSrsah29EYn2ZRZrBnMB0lQok4BQ-1702072513-1-AbE5Lw1tjGBcR1wV449SOIelknkIgqMtqV73ZGs6HLfh8hYsiYbC/7kwhuWde/p+OFDOJJygNGFym6qLP/1s0ms=; path=/; expires=Fri, 08-Dec-23 22:25:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=MlOgY.svFauQZRJUJFtVu1FA6nZ3.aLWSFNdT1VM8x0-1702072513316-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840530e9f3031-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:13,321 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
16:55:13,321 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:13,714 httpcore.http11 DEBUG receive_response_body.complete
16:55:13,714 httpcore.http11 DEBUG response_closed.started
16:55:13,714 httpcore.http11 DEBUG response_closed.complete
16:55:13,715 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
16:55:13,785 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
16:55:29,394 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
16:55:29,398 httpcore.connection DEBUG close.started
16:55:29,398 httpcore.connection DEBUG close.complete
16:55:29,399 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:55:29,401 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ae990>
16:55:29,401 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb2afd10> server_hostname='api.openai.com' timeout=5.0
16:55:29,407 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0ade90>
16:55:29,407 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:29,408 httpcore.http11 DEBUG send_request_headers.complete
16:55:29,408 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:29,437 httpcore.http11 DEBUG send_request_body.complete
16:55:29,437 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:30,392 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:30 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'437'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e5629beaede2321395038eb80c11384b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840bccbf03010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:30,393 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
16:55:30,393 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:30,393 httpcore.http11 DEBUG receive_response_body.complete
16:55:30,393 httpcore.http11 DEBUG response_closed.started
16:55:30,393 httpcore.http11 DEBUG response_closed.complete
16:55:30,394 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
16:55:30,394 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
16:55:30,402 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:55:30,409 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:55:30,412 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0d1e50>
16:55:30,412 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb2afc80> server_hostname='api.openai.com' timeout=None
16:55:30,420 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0d1e90>
16:55:30,420 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:30,421 httpcore.http11 DEBUG send_request_headers.complete
16:55:30,421 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:30,421 httpcore.http11 DEBUG send_request_body.complete
16:55:30,421 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:30,770 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'186'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5269eee3b54f3a98592582eef1560f4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=v3.Kb7jblhUJRA1BN_uhHrQvvXW6dluGTmtW8K_b..o-1702072530-1-ASArlEnPeikY1DISWext0GMx4JILrJz5p7bk/tVYcXDaZGjVTOJihU/eoUAJ3/3vG+N6o/XiZWMB0a/oR83SbMs=; path=/; expires=Fri, 08-Dec-23 22:25:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=VOhwumN2dYGtyYK4S5LP05AfgKDyemM5C6pZiEt7BqM-1702072530768-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840c32fce3b94-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:30,772 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:55:30,772 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:30,772 httpcore.http11 DEBUG receive_response_body.complete
16:55:30,773 httpcore.http11 DEBUG response_closed.started
16:55:30,773 httpcore.http11 DEBUG response_closed.complete
16:55:30,773 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:55:30,783 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:55:30,790 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:55:30,792 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdb0e52d0>
16:55:30,792 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f4bdb378710> server_hostname='api.openai.com' timeout=None
16:55:30,800 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f4bdc468510>
16:55:30,800 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:55:30,800 httpcore.http11 DEBUG send_request_headers.complete
16:55:30,801 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:55:30,801 httpcore.http11 DEBUG send_request_body.complete
16:55:30,801 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:55:31,450 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:55:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'531'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7efefc471661137d4f864c61148267ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ew5pdzQq0nfh8fpyLkNAOpjDgXXrFCyFZr1oTrzxCrQ-1702072531-1-AUXExlmI8OdCM2BViZUCm7t6Y6Y7xUYMcY66dk2zo6aMyBEuOpTXbn7hNfI6GVWD6tZ+Un/PjkQAA4cj5DNm+WQ=; path=/; expires=Fri, 08-Dec-23 22:25:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=XhS5ZcvpMGOkKOM.GPRroqOZwEZhwvIYBJqHUJ13m7w-1702072531447-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832840c58b114cd0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:55:31,451 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:55:31,451 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:55:31,452 httpcore.http11 DEBUG receive_response_body.complete
16:55:31,452 httpcore.http11 DEBUG response_closed.started
16:55:31,452 httpcore.http11 DEBUG response_closed.complete
16:55:31,452 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:55:31,458 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:31,461 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:35,164 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:35,167 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:35,169 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:38,870 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:38,873 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:38,875 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:42,576 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:42,579 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:42,581 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:55:46,282 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:55:46,285 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:55:46,288 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:58:16,994 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:16,995 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,777 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,779 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,819 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,820 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,855 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,856 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,889 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,890 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,925 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,925 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,958 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,959 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:17,994 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:17,994 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:18,29 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:58:18,29 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:58:18,65 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
16:58:18,75 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:58:18,105 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345828c10>
16:58:18,105 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0345a2bd10> server_hostname='api.openai.com' timeout=5.0
16:58:18,113 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345b18910>
16:58:18,113 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:18,114 httpcore.http11 DEBUG send_request_headers.complete
16:58:18,114 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:18,115 httpcore.http11 DEBUG send_request_body.complete
16:58:18,115 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:18,591 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:18 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'393'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b399c5855eee82464de261ac5ab6d325'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=oLEvUg0.bIurRQ7aq8DlLv77vlvw0flsXM4OVlp7yuU-1702072698-1-ASpUvYKeIJ3XIpgej0NYiDs0VlcE6ymfC2I05gaJ4RcaxnMQtrrxXjmwOjUqNrvJv2/en2ApcY0kA7IoW9Q9lTA=; path=/; expires=Fri, 08-Dec-23 22:28:18 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=nqwjw0Zf2JL21eKZD9M5gjdel.0bPqjDQ64r0idKm1Y-1702072698588-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832844db3a4f4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:18,593 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
16:58:18,594 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:19,280 httpcore.http11 DEBUG receive_response_body.complete
16:58:19,280 httpcore.http11 DEBUG response_closed.started
16:58:19,280 httpcore.http11 DEBUG response_closed.complete
16:58:19,281 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
16:58:19,351 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
16:58:35,45 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
16:58:35,48 httpcore.connection DEBUG close.started
16:58:35,48 httpcore.connection DEBUG close.complete
16:58:35,48 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:58:35,50 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345af5a50>
16:58:35,50 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0345a2bd10> server_hostname='api.openai.com' timeout=5.0
16:58:35,55 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f034582a210>
16:58:35,55 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:35,56 httpcore.http11 DEBUG send_request_headers.complete
16:58:35,56 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:35,90 httpcore.http11 DEBUG send_request_body.complete
16:58:35,90 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:36,101 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:36 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'438'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'26e6de7c22dd2b79bd55d37543beba4e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832845451d004cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:36,102 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
16:58:36,102 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:36,103 httpcore.http11 DEBUG receive_response_body.complete
16:58:36,103 httpcore.http11 DEBUG response_closed.started
16:58:36,103 httpcore.http11 DEBUG response_closed.complete
16:58:36,103 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
16:58:36,103 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
16:58:36,112 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:58:36,117 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:58:36,119 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345650d90>
16:58:36,120 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0345a2bc80> server_hostname='api.openai.com' timeout=None
16:58:36,125 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f03456511d0>
16:58:36,125 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:36,125 httpcore.http11 DEBUG send_request_headers.complete
16:58:36,125 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:36,126 httpcore.http11 DEBUG send_request_body.complete
16:58:36,126 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:36,338 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a7d3c852bea74ac1142eff1fee56aab3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5ky0R..GYuMBz6_cK0.cFzL.cxh1GQ55GSPfLD9XnFQ-1702072716-1-ATE6JAyZyD0415ecWJbHiPocs0tCnmW4De6MCqZB8WMoybShM2RSqVjdxPZueb4kNoWrbLQxYNcWB8SpXB8IA5Y=; path=/; expires=Fri, 08-Dec-23 22:28:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=AS6y5vKL0QVgfEWrVmApqgusuR4EaZs2_Un_DUMKscM-1702072716335-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328454bc8274cfa-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:36,339 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:58:36,339 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:36,340 httpcore.http11 DEBUG receive_response_body.complete
16:58:36,340 httpcore.http11 DEBUG response_closed.started
16:58:36,340 httpcore.http11 DEBUG response_closed.complete
16:58:36,340 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:58:36,351 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
16:58:36,358 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
16:58:36,361 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f034565fd50>
16:58:36,361 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f03458f8710> server_hostname='api.openai.com' timeout=None
16:58:36,366 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0345666250>
16:58:36,366 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:58:36,367 httpcore.http11 DEBUG send_request_headers.complete
16:58:36,367 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:58:36,367 httpcore.http11 DEBUG send_request_body.complete
16:58:36,367 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:58:36,854 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:58:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b77a3bf21164697821d25da9fc1d331e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xoo35dNVIb4Yi4KzEVHWIddfcPLnpSkwfVIrdXtp2Wc-1702072716-1-Ab/te3M34njoDiKAhJb78KhjQ8NdVVFZV2v1D0heYRj78mW8w2ZwoZkdEXzASekxYWAAEZOMElubohd3/3cMuF0=; path=/; expires=Fri, 08-Dec-23 22:28:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=u_OW2rULnHVUHx5C6jTo.3Ghj5DJsl0LgmlKhQwjkjg-1702072716850-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328454d4ae23068-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:58:36,855 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
16:58:36,855 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:58:36,855 httpcore.http11 DEBUG receive_response_body.complete
16:58:36,856 httpcore.http11 DEBUG response_closed.started
16:58:36,856 httpcore.http11 DEBUG response_closed.complete
16:58:36,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
16:58:36,860 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:58:36,863 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:58:40,566 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:58:40,568 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:58:40,571 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:58:44,272 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
16:58:44,274 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
16:58:44,276 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
16:59:44,209 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:44,211 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:44,994 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:44,996 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,32 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,32 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,67 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,67 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,100 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,100 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,133 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,134 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,165 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,166 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,198 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,198 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,230 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
16:59:45,231 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
16:59:45,263 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
16:59:45,272 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
16:59:45,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e28606d0>
16:59:45,301 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
16:59:45,308 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571e90>
16:59:45,308 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
16:59:45,308 httpcore.http11 DEBUG send_request_headers.complete
16:59:45,309 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
16:59:45,309 httpcore.http11 DEBUG send_request_body.complete
16:59:45,309 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
16:59:45,761 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 21:59:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'378'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'62871b462068aeb8478f769924f1ef08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=l9pnjJ10wrk6VJdpc0EQmWAdUckzhr7AF74lC7T705g-1702072785-1-AbPqxEcXVeqY39XHmJh4tgzmb4yU2TYDKpBgNG2bU9QczKn84f2qy8dGMG6CSiNo2jwGTRetv6lgn5WBxOjUG50=; path=/; expires=Fri, 08-Dec-23 22:29:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=YyGTkFLiueEaI15vagqpOObSiZlgSLA5smuzvNluYyw-1702072785758-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832846fc2b654cd6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
16:59:45,763 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
16:59:45,763 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
16:59:46,546 httpcore.http11 DEBUG receive_response_body.complete
16:59:46,547 httpcore.http11 DEBUG response_closed.started
16:59:46,547 httpcore.http11 DEBUG response_closed.complete
16:59:46,547 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
16:59:46,619 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:00:02,343 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:00:02,346 httpcore.connection DEBUG close.started
17:00:02,346 httpcore.connection DEBUG close.complete
17:00:02,346 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:00:02,348 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571e90>
17:00:02,348 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:00:02,353 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571710>
17:00:02,353 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:02,354 httpcore.http11 DEBUG send_request_headers.complete
17:00:02,354 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:02,364 httpcore.http11 DEBUG send_request_body.complete
17:00:02,364 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:03,258 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:03 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'483'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8ea4d98b2ed1727b9dbd6d7c177be133'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284766bd2a304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:03,259 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:00:03,259 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:03,260 httpcore.http11 DEBUG receive_response_body.complete
17:00:03,260 httpcore.http11 DEBUG response_closed.started
17:00:03,260 httpcore.http11 DEBUG response_closed.complete
17:00:03,260 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:00:03,261 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:00:03,270 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:03,277 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:03,279 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595650>
17:00:03,279 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:00:03,288 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595d10>
17:00:03,289 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:03,289 httpcore.http11 DEBUG send_request_headers.complete
17:00:03,289 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:03,289 httpcore.http11 DEBUG send_request_body.complete
17:00:03,290 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:03,514 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'a8de8edd4a2574d8937a8f009b32b191'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2dz_LzaTTVdrO2zXC.prMPCK6viwTrMNUMj2ADy9UTo-1702072803-1-AaQw5kOM9KFasftiwjul3Tz4HGu62YK13LUlFNTsSiI40J6TPdXtnIiNuF6BiblW/ByglPyIfCOGdCcb/IBSSqM=; path=/; expires=Fri, 08-Dec-23 22:30:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Mkh7vJhMOqAMnnvy68CFViiMYWDHn3oFx0EdiEpBIJs-1702072803511-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328476c8a184ce9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:03,515 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:03,515 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:03,516 httpcore.http11 DEBUG receive_response_body.complete
17:00:03,516 httpcore.http11 DEBUG response_closed.started
17:00:03,516 httpcore.http11 DEBUG response_closed.complete
17:00:03,517 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:03,527 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:03,534 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:03,536 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25a8cd0>
17:00:03,536 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2838710> server_hostname='api.openai.com' timeout=None
17:00:03,547 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25a8d10>
17:00:03,547 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:03,548 httpcore.http11 DEBUG send_request_headers.complete
17:00:03,548 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:03,548 httpcore.http11 DEBUG send_request_body.complete
17:00:03,548 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:04,42 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'391'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9b8825da9b8ffc65e55f2e2b2f24f507'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PjJpiPCfUI7cP3H3Q8HpHAYxX2Cnk_orHSSUnXG5oZA-1702072804-1-AUkjFLCFY0WsM0vrgsBXl0M3sx/zBEL1UABda9FWN8VBBEKAr9+PLBMW0x/zbfQBcn7cdZs2iAtcg4FDOajeIMg=; path=/; expires=Fri, 08-Dec-23 22:30:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=pAJ0Xfv.a6DaPyD6qYyEKb4EMXstPa9CxtrXnuwja3U-1702072804039-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328476e2b4e4ccc-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:04,44 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:04,44 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:04,45 httpcore.http11 DEBUG receive_response_body.complete
17:00:04,45 httpcore.http11 DEBUG response_closed.started
17:00:04,45 httpcore.http11 DEBUG response_closed.complete
17:00:04,45 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:04,51 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:04,54 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:07,757 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:07,761 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:07,763 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:11,465 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:11,467 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:11,470 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:15,171 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:15,174 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:15,177 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:18,878 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:18,881 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:18,884 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:22,585 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:22,587 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:22,590 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:26,291 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:26,294 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:26,297 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:29,998 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:30,2 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:30,5 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:33,706 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:33,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:00:33,709 httpcore.connection DEBUG close.started
17:00:33,709 httpcore.connection DEBUG close.complete
17:00:33,709 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:00:33,738 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2571710>
17:00:33,738 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:00:33,747 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2594c90>
17:00:33,747 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:33,747 httpcore.http11 DEBUG send_request_headers.complete
17:00:33,747 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:33,747 httpcore.http11 DEBUG send_request_body.complete
17:00:33,747 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:34,434 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:34 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'576'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9d0b9798f5ad1e8260f041a86e9c7e18'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328482ae9c84d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:34,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:00:34,435 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:34,705 httpcore.http11 DEBUG receive_response_body.complete
17:00:34,705 httpcore.http11 DEBUG response_closed.started
17:00:34,705 httpcore.http11 DEBUG response_closed.complete
17:00:34,706 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:00:34,775 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:00:47,498 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:00:47,499 httpcore.connection DEBUG close.started
17:00:47,499 httpcore.connection DEBUG close.complete
17:00:47,499 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:00:47,515 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b1090>
17:00:47,515 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:00:47,521 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b0510>
17:00:47,521 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:47,522 httpcore.http11 DEBUG send_request_headers.complete
17:00:47,522 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:47,553 httpcore.http11 DEBUG send_request_body.complete
17:00:47,554 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:48,439 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'382'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1fc2b7602aad4ca93c849b17173ffb50'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832848810e0e3074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:48,440 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:00:48,440 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:48,441 httpcore.http11 DEBUG receive_response_body.complete
17:00:48,441 httpcore.http11 DEBUG response_closed.started
17:00:48,441 httpcore.http11 DEBUG response_closed.complete
17:00:48,441 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:00:48,441 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:00:48,449 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:48,451 httpcore.connection DEBUG close.started
17:00:48,452 httpcore.connection DEBUG close.complete
17:00:48,452 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:48,454 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595d10>
17:00:48,454 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:00:48,459 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2595710>
17:00:48,459 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:48,459 httpcore.http11 DEBUG send_request_headers.complete
17:00:48,459 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:48,460 httpcore.http11 DEBUG send_request_body.complete
17:00:48,460 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:48,672 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'98'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'51384e70329e3d88c964aaeabb875f68'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284886dbb74cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:48,673 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:48,673 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:48,674 httpcore.http11 DEBUG receive_response_body.complete
17:00:48,674 httpcore.http11 DEBUG response_closed.started
17:00:48,674 httpcore.http11 DEBUG response_closed.complete
17:00:48,674 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:48,684 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:00:48,691 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:00:48,693 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c6610>
17:00:48,693 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773e30> server_hostname='api.openai.com' timeout=None
17:00:48,699 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c6410>
17:00:48,699 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:00:48,699 httpcore.http11 DEBUG send_request_headers.complete
17:00:48,699 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:00:48,700 httpcore.http11 DEBUG send_request_body.complete
17:00:48,700 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:00:48,945 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:00:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'133'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3e3859be5d4ec909f33068e030fd479c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=agydFVpaIi0uRPHsRxUQRk3raHVyGUDWdK93ce33IuA-1702072848-1-ATKSAAUV1EmL/QbEPiz6oBVOSwToRCc6eCtDYDrSQZc0nQCPNd6Z84h2jApl8PFyr9X3pvhrZcA1SHVL9VozSvc=; path=/; expires=Fri, 08-Dec-23 22:30:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=D64X7tNyLEpH1ev9iA1XxE2rblqGvtTZ9Vfsy1DwtHk-1702072848942-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832848885d374d06-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:00:48,946 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:00:48,947 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:00:48,947 httpcore.http11 DEBUG receive_response_body.complete
17:00:48,947 httpcore.http11 DEBUG response_closed.started
17:00:48,947 httpcore.http11 DEBUG response_closed.complete
17:00:48,948 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:00:48,951 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:48,954 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:52,655 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:52,657 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:52,660 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:00:56,361 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:00:56,364 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:00:56,366 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:00,67 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:00,68 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:01:00,70 httpcore.connection DEBUG close.started
17:01:00,70 httpcore.connection DEBUG close.complete
17:01:00,70 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:01:00,73 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cc650>
17:01:00,73 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:01:00,81 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cccd0>
17:01:00,81 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:00,82 httpcore.http11 DEBUG send_request_headers.complete
17:01:00,82 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:00,82 httpcore.http11 DEBUG send_request_body.complete
17:01:00,82 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:00,820 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'500'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1c7254255dbe193e67d5efa3a15e55cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832848cf8fb94cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:00,820 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:01:00,821 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:01,161 httpcore.http11 DEBUG receive_response_body.complete
17:01:01,162 httpcore.http11 DEBUG response_closed.started
17:01:01,162 httpcore.http11 DEBUG response_closed.complete
17:01:01,162 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:01:01,230 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:01:14,521 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:01:14,524 httpcore.connection DEBUG close.started
17:01:14,524 httpcore.connection DEBUG close.complete
17:01:14,524 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:01:14,527 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c6f90>
17:01:14,527 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:01:14,534 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c7090>
17:01:14,534 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:14,534 httpcore.http11 DEBUG send_request_headers.complete
17:01:14,535 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:14,564 httpcore.http11 DEBUG send_request_body.complete
17:01:14,564 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:15,448 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:15 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'434'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'46476bc6e3794aa8f299099c8f91b153'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284929d8cf3b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:15,449 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:01:15,450 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:15,450 httpcore.http11 DEBUG receive_response_body.complete
17:01:15,450 httpcore.http11 DEBUG response_closed.started
17:01:15,450 httpcore.http11 DEBUG response_closed.complete
17:01:15,450 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:01:15,451 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:01:15,457 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:01:15,458 httpcore.connection DEBUG close.started
17:01:15,458 httpcore.connection DEBUG close.complete
17:01:15,459 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:01:15,461 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b3950>
17:01:15,461 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:01:15,468 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b1e90>
17:01:15,468 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:15,468 httpcore.http11 DEBUG send_request_headers.complete
17:01:15,469 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:15,469 httpcore.http11 DEBUG send_request_body.complete
17:01:15,469 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:15,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'300'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd53d3064a6086635bb2238a7ab6f8e84'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328492fad654d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:15,856 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:01:15,856 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:15,857 httpcore.http11 DEBUG receive_response_body.complete
17:01:15,857 httpcore.http11 DEBUG response_closed.started
17:01:15,857 httpcore.http11 DEBUG response_closed.complete
17:01:15,857 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:01:15,867 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nput it on the right side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:01:15,868 httpcore.connection DEBUG close.started
17:01:15,869 httpcore.connection DEBUG close.complete
17:01:15,869 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:01:15,872 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2573950>
17:01:15,872 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2838710> server_hostname='api.openai.com' timeout=None
17:01:15,878 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e2573f90>
17:01:15,878 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:01:15,878 httpcore.http11 DEBUG send_request_headers.complete
17:01:15,878 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:01:15,878 httpcore.http11 DEBUG send_request_body.complete
17:01:15,878 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:01:16,406 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:01:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'413'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'048dfa6c6cf4bd8bf777de3725d7b011'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284932398a4d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:01:16,406 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:01:16,407 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:01:16,407 httpcore.http11 DEBUG receive_response_body.complete
17:01:16,407 httpcore.http11 DEBUG response_closed.started
17:01:16,407 httpcore.http11 DEBUG response_closed.complete
17:01:16,407 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:01:16,412 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:16,414 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:20,115 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:20,118 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:20,120 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:23,821 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:23,823 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:23,826 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:27,527 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:27,530 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:27,537 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:31,238 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:31,241 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:31,243 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:34,944 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:34,946 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:34,949 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:38,650 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:38,652 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:38,673 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:42,373 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:42,376 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:42,379 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:46,80 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:46,83 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:46,85 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:49,786 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:49,789 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:49,791 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:53,492 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:53,495 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:53,497 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:01:57,198 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:01:57,200 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:01:57,202 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:00,903 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:00,904 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:02:00,906 httpcore.connection DEBUG close.started
17:02:00,906 httpcore.connection DEBUG close.complete
17:02:00,906 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:02:00,935 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c60d0>
17:02:00,936 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:02:00,946 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25c5d10>
17:02:00,946 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:00,946 httpcore.http11 DEBUG send_request_headers.complete
17:02:00,947 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:00,947 httpcore.http11 DEBUG send_request_body.complete
17:02:00,947 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:01,364 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:01 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f4569221506058a12bcd2392a8d12130'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284a4be8c43071-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:01,365 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:02:01,365 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:01,645 httpcore.http11 DEBUG receive_response_body.complete
17:02:01,646 httpcore.http11 DEBUG response_closed.started
17:02:01,646 httpcore.http11 DEBUG response_closed.complete
17:02:01,646 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:02:01,714 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:02:14,403 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:02:14,404 httpcore.connection DEBUG close.started
17:02:14,405 httpcore.connection DEBUG close.complete
17:02:14,405 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:02:14,407 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cc810>
17:02:14,407 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:02:14,412 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25cc610>
17:02:14,413 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:14,413 httpcore.http11 DEBUG send_request_headers.complete
17:02:14,413 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:14,443 httpcore.http11 DEBUG send_request_body.complete
17:02:14,443 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:15,702 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:15 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'386'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f6658bb19dc7371d1798ca045351f907'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284aa01b9c3008-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:15,702 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:02:15,702 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:15,703 httpcore.http11 DEBUG receive_response_body.complete
17:02:15,703 httpcore.http11 DEBUG response_closed.started
17:02:15,703 httpcore.http11 DEBUG response_closed.complete
17:02:15,703 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:02:15,703 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:02:15,707 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:02:15,708 httpcore.connection DEBUG close.started
17:02:15,708 httpcore.connection DEBUG close.complete
17:02:15,708 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:02:15,711 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25d5690>
17:02:15,711 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773c80> server_hostname='api.openai.com' timeout=None
17:02:15,719 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25d4f90>
17:02:15,720 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:15,720 httpcore.http11 DEBUG send_request_headers.complete
17:02:15,720 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:15,721 httpcore.http11 DEBUG send_request_body.complete
17:02:15,721 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:15,912 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'101'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ecd4c53851c8e5f03a906e43943af6a1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284aa84df63b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:15,912 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:02:15,913 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:15,913 httpcore.http11 DEBUG receive_response_body.complete
17:02:15,913 httpcore.http11 DEBUG response_closed.started
17:02:15,913 httpcore.http11 DEBUG response_closed.complete
17:02:15,913 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:02:15,920 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:02:15,921 httpcore.connection DEBUG close.started
17:02:15,921 httpcore.connection DEBUG close.complete
17:02:15,921 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:02:15,923 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b39d0>
17:02:15,923 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773e30> server_hostname='api.openai.com' timeout=None
17:02:15,929 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b2510>
17:02:15,929 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:15,929 httpcore.http11 DEBUG send_request_headers.complete
17:02:15,929 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:15,930 httpcore.http11 DEBUG send_request_body.complete
17:02:15,930 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:16,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'cbb47112dc4dd6256e4e950421e1d60f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284aa98af23b8e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:16,127 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:02:16,127 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:16,127 httpcore.http11 DEBUG receive_response_body.complete
17:02:16,127 httpcore.http11 DEBUG response_closed.started
17:02:16,127 httpcore.http11 DEBUG response_closed.complete
17:02:16,128 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:02:16,131 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:02:16,133 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:19,834 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:19,838 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:02:19,840 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:23,541 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:23,544 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:02:23,547 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:02:27,247 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:02:27,248 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:02:27,249 httpcore.connection DEBUG close.started
17:02:27,249 httpcore.connection DEBUG close.complete
17:02:27,249 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:02:27,251 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b2050>
17:02:27,252 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fc8e2773d10> server_hostname='api.openai.com' timeout=5.0
17:02:27,257 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fc8e25b2110>
17:02:27,257 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:02:27,257 httpcore.http11 DEBUG send_request_headers.complete
17:02:27,258 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:02:27,258 httpcore.http11 DEBUG send_request_body.complete
17:02:27,258 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:02:27,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:02:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'449'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8020f093ad53e6afde755c8df2d0ce49'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83284af059c54ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:02:27,821 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:02:27,821 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:02:28,244 httpcore.http11 DEBUG receive_response_body.complete
17:02:28,244 httpcore.http11 DEBUG response_closed.started
17:02:28,245 httpcore.http11 DEBUG response_closed.complete
17:02:28,245 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:02:28,312 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:42:51,316 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:51,319 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,138 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,140 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,182 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,183 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,231 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,232 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,273 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,274 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,322 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,323 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,363 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,364 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,412 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,413 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:52,454 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:42:52,455 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:42:55,612 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:42:55,636 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:42:55,654 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa2599a90>
17:42:55,655 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:42:55,662 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f771d0>
17:42:55,663 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:42:55,665 httpcore.http11 DEBUG send_request_headers.complete
17:42:55,666 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:42:55,667 httpcore.http11 DEBUG send_request_body.complete
17:42:55,667 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:42:56,304 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:42:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'503'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c4d9faf20af794464e44451784fb0114'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=hcwEV4YeN53KbWYeynAhXHuSFyXCbSQVuPontRzJ_NM-1702075376-1-AfOFqF6fo0n7K3qqZ38C6NfpT53ZKfAeDydv33JWcmMuT1ClxobG/9COVLHrOMoKCFuKrPYRK+Ks8wr7y5a7w8M=; path=/; expires=Fri, 08-Dec-23 23:12:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=T9HzWSHYRM2Zw_iE1fw6u9y3OCaj4C24TmT2_4HvyTY-1702075376299-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288639edc74cda-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:42:56,314 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:42:56,315 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:42:57,137 httpcore.http11 DEBUG receive_response_body.complete
17:42:57,138 httpcore.http11 DEBUG response_closed.started
17:42:57,139 httpcore.http11 DEBUG response_closed.complete
17:42:57,140 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:42:57,211 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:43:13,3 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:43:13,13 httpcore.connection DEBUG close.started
17:43:13,14 httpcore.connection DEBUG close.complete
17:43:13,14 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:43:13,16 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f771d0>
17:43:13,16 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:43:13,22 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f77410>
17:43:13,22 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:13,23 httpcore.http11 DEBUG send_request_headers.complete
17:43:13,24 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:13,55 httpcore.http11 DEBUG send_request_body.complete
17:43:13,55 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:14,45 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:43:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'36'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'457'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ad0c7cf71d3797488592eb246f7aaa1a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832886a66d653035-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:14,49 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:43:14,50 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:14,51 httpcore.http11 DEBUG receive_response_body.complete
17:43:14,51 httpcore.http11 DEBUG response_closed.started
17:43:14,52 httpcore.http11 DEBUG response_closed.complete
17:43:14,52 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:43:14,53 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:43:14,88 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:43:14,100 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:43:14,103 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcb150>
17:43:14,103 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9eb0> server_hostname='api.openai.com' timeout=None
17:43:14,117 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcb010>
17:43:14,118 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:14,119 httpcore.http11 DEBUG send_request_headers.complete
17:43:14,120 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:14,121 httpcore.http11 DEBUG send_request_body.complete
17:43:14,121 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:14,364 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:43:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9f2bdf70efce46b39ba7be1dc470a5f2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3Kt38mmV2MuKJo21sBRk1W31dKpT3u2kJ2RsGCr9UuI-1702075394-1-AUGGDfbt80RYKPv3zeGi6k4JnRTSKI+2rOo83x0ml+Rt2uJHtWSmVRPTsmuZBgiyz/sow+g2jBGHZyzGGdhfKjM=; path=/; expires=Fri, 08-Dec-23 23:13:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BC8AiFYMeFeCmUhVHL85Yr01uzaVA_5S5L5chC56I70-1702075394360-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832886ad49394d12-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:14,373 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:43:14,374 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:14,374 httpcore.http11 DEBUG receive_response_body.complete
17:43:14,375 httpcore.http11 DEBUG response_closed.started
17:43:14,375 httpcore.http11 DEBUG response_closed.complete
17:43:14,375 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:43:14,408 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it on the left side of the cake\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:43:14,419 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:43:14,422 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0ddf990>
17:43:14,422 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ffa7b0> server_hostname='api.openai.com' timeout=None
17:43:14,428 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0ddf790>
17:43:14,429 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:43:14,430 httpcore.http11 DEBUG send_request_headers.complete
17:43:14,430 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:43:14,431 httpcore.http11 DEBUG send_request_body.complete
17:43:14,431 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:43:14,993 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:43:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'478'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fc6c609dd563d1d9609c7a78c6adcb59'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4NITqCPlM1B4VMqRzNquqEdORArm1rtIbj09Pe6YaHQ-1702075394-1-AcSTYurJ0y9qrTkyb//2jYffZszQ4sN4ovdh6m638bbPcXxYQ1g6CpI1vpgHeBXFvkRFrH5wcDhLBiL9DFPC1oA=; path=/; expires=Fri, 08-Dec-23 23:13:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IYdOLrWclqHvzdZQmjiBCY9RCmnq9Ox6r5sdOMG.M64-1702075394989-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832886af39923045-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:43:15,0 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:43:15,1 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:43:15,3 httpcore.http11 DEBUG receive_response_body.complete
17:43:15,4 httpcore.http11 DEBUG response_closed.started
17:43:15,5 httpcore.http11 DEBUG response_closed.complete
17:43:15,5 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:43:15,22 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:15,27 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:22,234 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:22,245 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:22,248 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:27,450 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:27,468 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:27,472 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:32,675 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:32,693 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:32,698 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:37,901 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:37,921 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:37,926 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:45,129 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:45,151 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:45,155 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:50,358 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:50,377 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:50,380 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:43:55,582 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:43:55,602 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:43:55,606 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:00,809 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:00,829 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:44:00,833 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:06,36 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:06,44 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:06,48 httpcore.connection DEBUG close.started
17:44:06,49 httpcore.connection DEBUG close.complete
17:44:06,49 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:06,79 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f77410>
17:44:06,80 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:06,87 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0ddbed0>
17:44:06,88 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:06,89 httpcore.http11 DEBUG send_request_headers.complete
17:44:06,90 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:06,91 httpcore.http11 DEBUG send_request_body.complete
17:44:06,91 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:07,173 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'956'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'57c361ac2d2baaf42a3e80df39159ba6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832887f21cc04d01-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:07,178 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:07,179 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:07,482 httpcore.http11 DEBUG receive_response_body.complete
17:44:07,483 httpcore.http11 DEBUG response_closed.started
17:44:07,484 httpcore.http11 DEBUG response_closed.complete
17:44:07,485 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:07,552 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:44:20,292 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:44:20,298 httpcore.connection DEBUG close.started
17:44:20,298 httpcore.connection DEBUG close.complete
17:44:20,299 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:20,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09a50>
17:44:20,302 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:20,309 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09ad0>
17:44:20,309 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:20,310 httpcore.http11 DEBUG send_request_headers.complete
17:44:20,310 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:20,347 httpcore.http11 DEBUG send_request_body.complete
17:44:20,348 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:21,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'18'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'389'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c96069710dbb00f5fb7f88bb03cb2b77'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328884afe934cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:21,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:44:21,460 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:21,461 httpcore.http11 DEBUG receive_response_body.complete
17:44:21,461 httpcore.http11 DEBUG response_closed.started
17:44:21,462 httpcore.http11 DEBUG response_closed.complete
17:44:21,462 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:44:21,463 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:44:21,496 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:21,500 httpcore.connection DEBUG close.started
17:44:21,501 httpcore.connection DEBUG close.complete
17:44:21,501 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:21,504 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dca1d0>
17:44:21,504 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9eb0> server_hostname='api.openai.com' timeout=None
17:44:21,509 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcb110>
17:44:21,510 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:21,511 httpcore.http11 DEBUG send_request_headers.complete
17:44:21,511 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:21,512 httpcore.http11 DEBUG send_request_body.complete
17:44:21,512 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:21,705 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'106'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fb643bb5c44ed7c6e942a67ba414a70f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888527f5f4cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:21,712 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:21,713 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:21,715 httpcore.http11 DEBUG receive_response_body.complete
17:44:21,716 httpcore.http11 DEBUG response_closed.started
17:44:21,716 httpcore.http11 DEBUG response_closed.complete
17:44:21,717 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:21,752 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nmove to the right\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:21,767 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:21,770 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09e50>
17:44:21,771 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:44:21,777 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09050>
17:44:21,777 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:21,778 httpcore.http11 DEBUG send_request_headers.complete
17:44:21,778 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:21,779 httpcore.http11 DEBUG send_request_body.complete
17:44:21,779 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:21,994 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8af60fac07d0d6e94e9ca8bdb3e58fdc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Wp_iVMatOZMSFDkPdpMQt_hy17v_wIK.dyzDzdNXN4c-1702075461-1-AcwPH6cdh/ZGIQcavKJgJm3Pm6bqYSh4dv13grlgXpT8LSHGU1ZyKlE3qOF0dfpuCxP4ZT/aWThSAxkPvQvYPg4=; path=/; expires=Fri, 08-Dec-23 23:14:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=QltwJ6RX5me7d1gAx1ZEmXTSD2j.p5H7bXtMBKbGViM-1702075461989-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888541ff94ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:22,4 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:22,5 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:22,6 httpcore.http11 DEBUG receive_response_body.complete
17:44:22,6 httpcore.http11 DEBUG response_closed.started
17:44:22,7 httpcore.http11 DEBUG response_closed.complete
17:44:22,7 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:22,22 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:44:22,27 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:27,231 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:27,236 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:27,241 httpcore.connection DEBUG close.started
17:44:27,241 httpcore.connection DEBUG close.complete
17:44:27,242 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:27,244 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e08cd0>
17:44:27,245 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:27,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0b490>
17:44:27,251 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:27,253 httpcore.http11 DEBUG send_request_headers.complete
17:44:27,253 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:27,254 httpcore.http11 DEBUG send_request_body.complete
17:44:27,254 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:27,664 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'339'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'557c902f8ceba2f99e4df00384ff57c4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888765d374d17-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:27,670 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:27,671 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:27,853 httpcore.http11 DEBUG receive_response_body.complete
17:44:27,854 httpcore.http11 DEBUG response_closed.started
17:44:27,855 httpcore.http11 DEBUG response_closed.complete
17:44:27,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:27,928 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:44:40,661 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:44:40,669 httpcore.connection DEBUG close.started
17:44:40,670 httpcore.connection DEBUG close.complete
17:44:40,671 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:40,674 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e11850>
17:44:40,674 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:40,682 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e118d0>
17:44:40,683 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:40,685 httpcore.http11 DEBUG send_request_headers.complete
17:44:40,686 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:40,718 httpcore.http11 DEBUG send_request_body.complete
17:44:40,718 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:41,628 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:41 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'72d1af114600a180239e224359e9e870'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888ca4b5a4ccf-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:41,633 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:44:41,634 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:41,635 httpcore.http11 DEBUG receive_response_body.complete
17:44:41,635 httpcore.http11 DEBUG response_closed.started
17:44:41,635 httpcore.http11 DEBUG response_closed.complete
17:44:41,636 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:44:41,636 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:44:41,666 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:44:41,669 httpcore.connection DEBUG close.started
17:44:41,670 httpcore.connection DEBUG close.complete
17:44:41,670 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:44:41,672 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ca10>
17:44:41,673 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:44:41,680 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ca90>
17:44:41,681 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:41,682 httpcore.http11 DEBUG send_request_headers.complete
17:44:41,682 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:41,683 httpcore.http11 DEBUG send_request_body.complete
17:44:41,683 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:41,884 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'109'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'174f7159ade3952c06b9f4739ffac3f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888d08b2c4cdb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:41,890 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:44:41,891 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:41,892 httpcore.http11 DEBUG receive_response_body.complete
17:44:41,892 httpcore.http11 DEBUG response_closed.started
17:44:41,893 httpcore.http11 DEBUG response_closed.complete
17:44:41,893 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:44:41,910 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:44:41,915 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:44:47,117 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:44:47,123 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:44:47,128 httpcore.connection DEBUG close.started
17:44:47,129 httpcore.connection DEBUG close.complete
17:44:47,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:44:47,131 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e117d0>
17:44:47,131 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:44:47,141 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e126d0>
17:44:47,142 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:44:47,144 httpcore.http11 DEBUG send_request_headers.complete
17:44:47,144 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:44:47,145 httpcore.http11 DEBUG send_request_body.complete
17:44:47,146 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:44:47,586 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:44:47 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'371'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0b52604eb0551e7ecffc578365b1f9dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832888f2a8596ac9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:44:47,590 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:44:47,591 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:44:47,780 httpcore.http11 DEBUG receive_response_body.complete
17:44:47,781 httpcore.http11 DEBUG response_closed.started
17:44:47,782 httpcore.http11 DEBUG response_closed.complete
17:44:47,783 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:44:47,849 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:00,393 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:00,397 httpcore.connection DEBUG close.started
17:45:00,397 httpcore.connection DEBUG close.complete
17:45:00,397 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:00,400 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0a650>
17:45:00,400 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:00,407 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0a4d0>
17:45:00,408 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:00,409 httpcore.http11 DEBUG send_request_headers.complete
17:45:00,409 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:00,447 httpcore.http11 DEBUG send_request_body.complete
17:45:00,447 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:01,430 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:01 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'd5ddffa97fde7c58351c4f71a7377efb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889458a984d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:01,435 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:01,435 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:01,436 httpcore.http11 DEBUG receive_response_body.complete
17:45:01,437 httpcore.http11 DEBUG response_closed.started
17:45:01,437 httpcore.http11 DEBUG response_closed.complete
17:45:01,438 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:01,439 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:01,469 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\ndown\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:01,472 httpcore.connection DEBUG close.started
17:45:01,472 httpcore.connection DEBUG close.complete
17:45:01,473 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:01,475 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0b050>
17:45:01,475 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:45:01,481 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09b50>
17:45:01,481 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:01,482 httpcore.http11 DEBUG send_request_headers.complete
17:45:01,483 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:01,483 httpcore.http11 DEBUG send_request_body.complete
17:45:01,484 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:01,762 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'134'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b9c73caec8e0e791549baa62c9b5280b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328894c4ff43010-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:01,768 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:01,769 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:01,770 httpcore.http11 DEBUG receive_response_body.complete
17:45:01,771 httpcore.http11 DEBUG response_closed.started
17:45:01,771 httpcore.http11 DEBUG response_closed.complete
17:45:01,772 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:01,790 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:01,794 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:06,995 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:07,2 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:07,10 httpcore.connection DEBUG close.started
17:45:07,10 httpcore.connection DEBUG close.complete
17:45:07,11 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:07,42 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0ba50>
17:45:07,43 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:07,50 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0a950>
17:45:07,51 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:07,52 httpcore.http11 DEBUG send_request_headers.complete
17:45:07,53 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:07,54 httpcore.http11 DEBUG send_request_body.complete
17:45:07,54 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:07,484 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'351'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'db9c5552fc7aee2bca1847df98796cd1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328896f1ad74cdc-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:07,489 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:07,490 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:07,752 httpcore.http11 DEBUG receive_response_body.complete
17:45:07,753 httpcore.http11 DEBUG response_closed.started
17:45:07,754 httpcore.http11 DEBUG response_closed.complete
17:45:07,755 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:07,820 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:20,463 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:20,468 httpcore.connection DEBUG close.started
17:45:20,469 httpcore.connection DEBUG close.complete
17:45:20,469 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:20,472 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1e9d0>
17:45:20,472 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:20,478 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ea90>
17:45:20,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:20,479 httpcore.http11 DEBUG send_request_headers.complete
17:45:20,480 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:20,516 httpcore.http11 DEBUG send_request_body.complete
17:45:20,517 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:21,728 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'644'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'acfafac8b0c92ef392f24a50f5faeb55'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889c30bc24cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:21,732 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:21,733 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:21,734 httpcore.http11 DEBUG receive_response_body.complete
17:45:21,735 httpcore.http11 DEBUG response_closed.started
17:45:21,735 httpcore.http11 DEBUG response_closed.complete
17:45:21,736 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:21,737 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:21,765 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nforward.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:21,769 httpcore.connection DEBUG close.started
17:45:21,769 httpcore.connection DEBUG close.complete
17:45:21,769 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:21,772 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e19b90>
17:45:21,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:45:21,779 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e19c10>
17:45:21,780 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:21,781 httpcore.http11 DEBUG send_request_headers.complete
17:45:21,781 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:21,782 httpcore.http11 DEBUG send_request_body.complete
17:45:21,782 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:21,979 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'112'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'051529ebf99663b80ec99b5432bd273f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889cb2c714cd6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:21,983 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:21,984 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:21,986 httpcore.http11 DEBUG receive_response_body.complete
17:45:21,986 httpcore.http11 DEBUG response_closed.started
17:45:21,987 httpcore.http11 DEBUG response_closed.complete
17:45:21,987 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:22,5 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:22,9 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:27,212 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:27,218 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:27,224 httpcore.connection DEBUG close.started
17:45:27,224 httpcore.connection DEBUG close.complete
17:45:27,224 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:27,227 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ebd0>
17:45:27,227 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:27,233 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1f850>
17:45:27,234 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:27,235 httpcore.http11 DEBUG send_request_headers.complete
17:45:27,235 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:27,236 httpcore.http11 DEBUG send_request_body.complete
17:45:27,236 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:27,855 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'478'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'de3cead6a00db61ee829722dce0d9382'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832889ed3ff04d08-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:27,859 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:27,861 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:28,140 httpcore.http11 DEBUG receive_response_body.complete
17:45:28,141 httpcore.http11 DEBUG response_closed.started
17:45:28,142 httpcore.http11 DEBUG response_closed.complete
17:45:28,143 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:28,209 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:45:40,894 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:45:40,898 httpcore.connection DEBUG close.started
17:45:40,899 httpcore.connection DEBUG close.complete
17:45:40,899 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:40,901 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f68910>
17:45:40,902 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:40,908 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0f68710>
17:45:40,909 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:40,911 httpcore.http11 DEBUG send_request_headers.complete
17:45:40,912 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:40,950 httpcore.http11 DEBUG send_request_body.complete
17:45:40,951 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:41,846 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:41 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'387'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8f93cdb2836f72aa5d1e79a0adcdc8f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288a42bef74cde-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:41,851 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:45:41,852 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:41,854 httpcore.http11 DEBUG receive_response_body.complete
17:45:41,855 httpcore.http11 DEBUG response_closed.started
17:45:41,855 httpcore.http11 DEBUG response_closed.complete
17:45:41,856 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:45:41,857 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:45:41,884 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:45:41,887 httpcore.connection DEBUG close.started
17:45:41,888 httpcore.connection DEBUG close.complete
17:45:41,888 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:45:41,890 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09750>
17:45:41,891 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9f40> server_hostname='api.openai.com' timeout=None
17:45:41,895 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0ba50>
17:45:41,896 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:41,897 httpcore.http11 DEBUG send_request_headers.complete
17:45:41,897 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:41,897 httpcore.http11 DEBUG send_request_body.complete
17:45:41,898 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:42,103 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'741106a7e8fefa1071eba29ce1648572'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288a48df5c3b93-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:42,110 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:45:42,110 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:42,111 httpcore.http11 DEBUG receive_response_body.complete
17:45:42,112 httpcore.http11 DEBUG response_closed.started
17:45:42,112 httpcore.http11 DEBUG response_closed.complete
17:45:42,112 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:45:42,128 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:42,131 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:47,333 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:47,348 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:47,351 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:52,554 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:52,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:45:52,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:45:57,781 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:45:57,789 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:45:57,794 httpcore.connection DEBUG close.started
17:45:57,794 httpcore.connection DEBUG close.complete
17:45:57,795 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:45:57,797 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e0bb90>
17:45:57,798 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:45:57,806 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e09810>
17:45:57,807 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:45:57,809 httpcore.http11 DEBUG send_request_headers.complete
17:45:57,810 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:45:57,811 httpcore.http11 DEBUG send_request_body.complete
17:45:57,811 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:45:58,255 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:45:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1c6496de4c649c1c16fbc9adaae4a679'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288aac5f794cec-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:45:58,260 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:45:58,261 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:45:58,632 httpcore.http11 DEBUG receive_response_body.complete
17:45:58,633 httpcore.http11 DEBUG response_closed.started
17:45:58,634 httpcore.http11 DEBUG response_closed.complete
17:45:58,635 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:45:58,703 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:46:12,270 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:46:12,275 httpcore.connection DEBUG close.started
17:46:12,275 httpcore.connection DEBUG close.complete
17:46:12,275 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:46:12,305 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e19d50>
17:46:12,306 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9e20> server_hostname='api.openai.com' timeout=5.0
17:46:12,312 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1a310>
17:46:12,313 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:12,315 httpcore.http11 DEBUG send_request_headers.complete
17:46:12,315 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:12,347 httpcore.http11 DEBUG send_request_body.complete
17:46:12,348 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:13,483 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:13 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'39'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'416'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c2b570e392ed39fe920ab4a4212f31c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b06fcea3010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:13,487 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:46:13,488 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:13,489 httpcore.http11 DEBUG receive_response_body.complete
17:46:13,490 httpcore.http11 DEBUG response_closed.started
17:46:13,490 httpcore.http11 DEBUG response_closed.complete
17:46:13,491 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:46:13,491 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:46:13,522 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nI don't know, do you have suggestions?\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:13,527 httpcore.connection DEBUG close.started
17:46:13,528 httpcore.connection DEBUG close.complete
17:46:13,529 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:13,533 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dcaf50>
17:46:13,534 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ff9eb0> server_hostname='api.openai.com' timeout=None
17:46:13,539 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0dca1d0>
17:46:13,539 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:13,540 httpcore.http11 DEBUG send_request_headers.complete
17:46:13,541 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:13,541 httpcore.http11 DEBUG send_request_body.complete
17:46:13,541 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:14,360 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'723'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd153d7a4faee8abf407ec6dbb4bf9807'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b0eaa1f4d04-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:14,369 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:14,370 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:14,370 httpcore.http11 DEBUG receive_response_body.complete
17:46:14,371 httpcore.http11 DEBUG response_closed.started
17:46:14,371 httpcore.http11 DEBUG response_closed.complete
17:46:14,371 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:14,405 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nI don't know, do you have suggestions?\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:46:14,419 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:46:14,422 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1b2d0>
17:46:14,423 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f2fa0ffa330> server_hostname='api.openai.com' timeout=None
17:46:14,430 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f2fa0e1ab50>
17:46:14,430 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:14,431 httpcore.http11 DEBUG send_request_headers.complete
17:46:14,432 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:14,432 httpcore.http11 DEBUG send_request_body.complete
17:46:14,433 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:15,564 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1037'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1811757b03dbea470d826b8dbc8c7ff2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YMuLF_lv.L3t46b8rx2n6_f4ad4eUvKoklDoBLCWiTo-1702075575-1-ASK49isOOMTWcfj7tzqPFtQ7qTjRWu1qXRUiR3oqX77Q/o9D/ZAjkDRKEu0cUQ1bgpLoYTfK8pdat63J5Gv+7Uc=; path=/; expires=Fri, 08-Dec-23 23:16:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=FrWjeQm.9SpF2yEIu0hyHl.sP3scNoo2LGq0Gm5498k-1702075575559-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b143c3a3ba0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:15,571 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:46:15,572 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:15,573 httpcore.http11 DEBUG receive_response_body.complete
17:46:15,574 httpcore.http11 DEBUG response_closed.started
17:46:15,574 httpcore.http11 DEBUG response_closed.complete
17:46:15,575 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:46:15,582 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'I suggest placing the second candle directly across from the first candle. That way, the candles will be evenly spaced around the cake. Shall I go ahead and place the second candle there?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:46:15,586 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:46:15,587 httpcore.http11 DEBUG send_request_headers.complete
17:46:15,588 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:46:15,588 httpcore.http11 DEBUG send_request_body.complete
17:46:15,589 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:46:16,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:46:16 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'465'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9a07111c011108c35350f35374f20433'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83288b1b6a653010-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:46:16,131 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:46:16,132 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:46:17,896 httpcore.http11 DEBUG receive_response_body.complete
17:46:17,897 httpcore.http11 DEBUG response_closed.started
17:46:17,898 httpcore.http11 DEBUG response_closed.complete
17:46:17,898 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:46:17,971 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:58:04,276 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:04,280 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,118 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,119 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,163 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,164 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,212 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,213 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,254 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,255 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,302 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,303 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,343 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,344 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,392 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,393 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:05,433 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:05,434 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:45,731 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:45,734 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,569 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,570 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,612 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,613 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,660 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,661 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,703 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,704 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,751 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,752 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,793 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,794 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,841 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,842 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:46,882 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
17:58:46,883 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
17:58:48,190 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Helen. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
17:58:48,210 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:58:48,241 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d3190>
17:58:48,241 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
17:58:48,251 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d3690>
17:58:48,253 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:58:48,256 httpcore.http11 DEBUG send_request_headers.complete
17:58:48,256 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:58:48,257 httpcore.http11 DEBUG send_request_body.complete
17:58:48,258 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:58:48,722 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:58:48 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ac569a87614adb6fb1f6f2ecb763610b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6CntS1cxn46BYQ6TxeHy2uH5.71dbNbSBXuwlyT3TnQ-1702076328-1-Ace9EsaQUzXzYwiA/qt428W+V29XaW4XcdsnxyeTAnW2zGGe701zYZcaUxRSy1IWEhDHwQJXPaxmsGhxXzWKVbY=; path=/; expires=Fri, 08-Dec-23 23:28:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=FUK2NY5e7HqqJ.RiJF5e8K2PXnDF8BMZzpTXKPHcGjE-1702076328717-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289d7b9a3a4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:58:48,732 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
17:58:48,733 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:58:49,549 httpcore.http11 DEBUG receive_response_body.complete
17:58:49,550 httpcore.http11 DEBUG response_closed.started
17:58:49,551 httpcore.http11 DEBUG response_closed.complete
17:58:49,552 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
17:58:49,639 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
17:59:03,208 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
17:59:03,222 httpcore.connection DEBUG close.started
17:59:03,223 httpcore.connection DEBUG close.complete
17:59:03,223 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
17:59:03,225 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d3690>
17:59:03,226 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
17:59:03,231 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf27d38d0>
17:59:03,232 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:59:03,233 httpcore.http11 DEBUG send_request_headers.complete
17:59:03,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:59:03,271 httpcore.http11 DEBUG send_request_body.complete
17:59:03,272 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:59:04,160 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:59:04 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'37'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'10be7de730dbeef26d67bd4316620be7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289dd939664d14-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:59:04,163 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
17:59:04,164 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:59:04,166 httpcore.http11 DEBUG receive_response_body.complete
17:59:04,167 httpcore.http11 DEBUG response_closed.started
17:59:04,168 httpcore.http11 DEBUG response_closed.complete
17:59:04,168 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
17:59:04,170 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
17:59:04,206 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:59:04,219 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:59:04,222 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf28287d0>
17:59:04,222 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859fd0> server_hostname='api.openai.com' timeout=None
17:59:04,230 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2828750>
17:59:04,231 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:59:04,232 httpcore.http11 DEBUG send_request_headers.complete
17:59:04,232 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:59:04,233 httpcore.http11 DEBUG send_request_body.complete
17:59:04,233 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:59:04,470 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:59:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'123'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b2528ca6c8ce5584683f9f6166ee64d8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mZ8gxZBR2DcChR4F.pLZ1CtzRM5smSRnIZBxtQBoMSQ-1702076344-1-ASFLYminXObAdcconYf2zyKHdtigVIsKNcKkNkLAzvE8/UYftJvxkb2VblsiU29MIsE4vkbYbTQ3YcrN9RLk2gY=; path=/; expires=Fri, 08-Dec-23 23:29:04 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=62HD2qCHMXW7UH8_9wEEgmueG8SJ2l_MYcPvkgEygWI-1702076344466-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289ddf78084ce6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:59:04,476 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:59:04,477 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:59:04,478 httpcore.http11 DEBUG receive_response_body.complete
17:59:04,478 httpcore.http11 DEBUG response_closed.started
17:59:04,479 httpcore.http11 DEBUG response_closed.complete
17:59:04,479 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:59:04,513 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Helen. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it on the left side of the cake.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
17:59:04,524 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
17:59:04,527 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2837710>
17:59:04,527 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf285a7b0> server_hostname='api.openai.com' timeout=None
17:59:04,536 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2834350>
17:59:04,536 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
17:59:04,537 httpcore.http11 DEBUG send_request_headers.complete
17:59:04,537 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
17:59:04,538 httpcore.http11 DEBUG send_request_body.complete
17:59:04,539 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
17:59:05,75 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 22:59:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'414'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0c7c552e9bc3c9ba3ac42d62b9062e32'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=JsNp_.Nm6azw8J.iO0xmqu7B9L4GWs3v5Q8aNuRg5uo-1702076345-1-AUW1pz97OwBIrOot5YEgKQNpMO5IF7lEPhvQ27Mm7fwF4ZyzeOkmuWqnVkkCmFTQdfR2clV3UBKM/DKAUXe/B9U=; path=/; expires=Fri, 08-Dec-23 23:29:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=CYbqbW3mFK3XsRGj4QdsECRGC2RLVk0nPrwHDuRes3Y-1702076345070-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289de15c0a3b8e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
17:59:05,82 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
17:59:05,83 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
17:59:05,83 httpcore.http11 DEBUG receive_response_body.complete
17:59:05,84 httpcore.http11 DEBUG response_closed.started
17:59:05,84 httpcore.http11 DEBUG response_closed.complete
17:59:05,84 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
17:59:05,101 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:05,106 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:12,314 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:12,330 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:12,333 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:17,538 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:17,558 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:17,562 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:22,764 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:22,783 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:22,786 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:27,988 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:28,4 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:28,8 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:35,210 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:35,228 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:35,232 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:40,435 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:40,452 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:40,456 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:45,659 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:45,683 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:45,687 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:50,889 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:50,907 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:50,911 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
17:59:56,114 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
17:59:56,132 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
17:59:56,135 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:01,338 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:01,344 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:00:01,351 httpcore.connection DEBUG close.started
18:00:01,351 httpcore.connection DEBUG close.complete
18:00:01,351 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:01,383 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2894e50>
18:00:01,383 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:01,390 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2648090>
18:00:01,391 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:01,393 httpcore.http11 DEBUG send_request_headers.complete
18:00:01,394 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:01,395 httpcore.http11 DEBUG send_request_body.complete
18:00:01,395 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:02,3 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:02 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'492'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3344db0081bb6388243b45fef530d60'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f44bc654d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:02,8 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:00:02,9 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:02,203 httpcore.http11 DEBUG receive_response_body.complete
18:00:02,204 httpcore.http11 DEBUG response_closed.started
18:00:02,205 httpcore.http11 DEBUG response_closed.complete
18:00:02,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:00:02,271 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:00:09,815 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:00:09,819 httpcore.connection DEBUG close.started
18:00:09,820 httpcore.connection DEBUG close.complete
18:00:09,820 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:09,823 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265dd50>
18:00:09,823 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:09,831 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265ddd0>
18:00:09,831 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:09,833 httpcore.http11 DEBUG send_request_headers.complete
18:00:09,833 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:09,902 httpcore.http11 DEBUG send_request_body.complete
18:00:09,903 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:10,960 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:10 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'67f5c93b689dc1a082cc488ededc6538'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f797eb43bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:10,965 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:00:10,966 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:10,968 httpcore.http11 DEBUG receive_response_body.complete
18:00:10,968 httpcore.http11 DEBUG response_closed.started
18:00:10,969 httpcore.http11 DEBUG response_closed.complete
18:00:10,969 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:00:10,970 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:00:11,3 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMove forward.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:11,6 httpcore.connection DEBUG close.started
18:00:11,6 httpcore.connection DEBUG close.complete
18:00:11,7 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:00:11,9 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2822fd0>
18:00:11,10 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859fd0> server_hostname='api.openai.com' timeout=None
18:00:11,16 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf2823f10>
18:00:11,16 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:11,17 httpcore.http11 DEBUG send_request_headers.complete
18:00:11,18 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:11,18 httpcore.http11 DEBUG send_request_body.complete
18:00:11,19 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:11,269 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'676b94a77ac4d2a5f09ce57e1eef6445'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f80daa44d0d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:11,275 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:11,277 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:11,279 httpcore.http11 DEBUG receive_response_body.complete
18:00:11,279 httpcore.http11 DEBUG response_closed.started
18:00:11,280 httpcore.http11 DEBUG response_closed.complete
18:00:11,280 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:11,288 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or to the left, right, up or down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:00:11,292 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:11,293 httpcore.http11 DEBUG send_request_headers.complete
18:00:11,294 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:11,294 httpcore.http11 DEBUG send_request_body.complete
18:00:11,294 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:12,58 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:12 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'691'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1531eaf516916d0a32f192ab023c7db4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289f829dcb3bac-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:12,62 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:00:12,63 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:12,989 httpcore.http11 DEBUG receive_response_body.complete
18:00:12,990 httpcore.http11 DEBUG response_closed.started
18:00:12,990 httpcore.http11 DEBUG response_closed.complete
18:00:12,991 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:00:13,58 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:00:27,289 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:00:27,294 httpcore.connection DEBUG close.started
18:00:27,295 httpcore.connection DEBUG close.complete
18:00:27,296 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:27,298 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265f250>
18:00:27,298 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:27,303 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265e850>
18:00:27,304 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:27,305 httpcore.http11 DEBUG send_request_headers.complete
18:00:27,305 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:27,337 httpcore.http11 DEBUG send_request_body.complete
18:00:27,337 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:28,153 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:28 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'70ca47bce3b16a6bb9ceaacbc27f2b5b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289fe6a8604d06-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:28,158 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:00:28,159 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:28,159 httpcore.http11 DEBUG receive_response_body.complete
18:00:28,160 httpcore.http11 DEBUG response_closed.started
18:00:28,160 httpcore.http11 DEBUG response_closed.complete
18:00:28,160 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:00:28,161 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:00:28,191 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or to the left, right, up or down.\n'''\nAnd the human answered\n'''\nUp.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:28,203 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:00:28,206 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266cd90>
18:00:28,206 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859f40> server_hostname='api.openai.com' timeout=None
18:00:28,213 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266cd10>
18:00:28,214 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:28,215 httpcore.http11 DEBUG send_request_headers.complete
18:00:28,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:28,216 httpcore.http11 DEBUG send_request_body.complete
18:00:28,216 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:28,431 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'119'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2b9c6447414e16771bc74604d53d763c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YF2IZaCcr2QQl28Zz1ASq2Ihf_fADTIzydIdR16uf54-1702076428-1-AfYQ8aYu/AUFClEp6kxbourjvTKtmTp0Cct44dYritFKtUkMcbAUkVx9trjhjYi/HLe/WVzdNQ9a+SxydACjUt4=; path=/; expires=Fri, 08-Dec-23 23:30:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=bWMThyFXdmzDK4JwGf7c9IjZi.b9v6WDGhEVBsVJLNI-1702076428427-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289fec5b734cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:28,437 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:28,438 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:28,440 httpcore.http11 DEBUG receive_response_body.complete
18:00:28,440 httpcore.http11 DEBUG response_closed.started
18:00:28,441 httpcore.http11 DEBUG response_closed.complete
18:00:28,441 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:28,474 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or to the left, right, up or down.\n'''\nAnd the human answered\n'''\nUp.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:28,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:28,479 httpcore.http11 DEBUG send_request_headers.complete
18:00:28,479 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:28,479 httpcore.http11 DEBUG send_request_body.complete
18:00:28,480 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:28,724 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'143'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b41d9669c62d5187f2af96d444f9e364'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'83289fee0ef44cc0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:28,731 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:28,732 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:28,734 httpcore.http11 DEBUG receive_response_body.complete
18:00:28,735 httpcore.http11 DEBUG response_closed.started
18:00:28,735 httpcore.http11 DEBUG response_closed.complete
18:00:28,736 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:28,752 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:28,757 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:33,960 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:33,967 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:00:33,973 httpcore.connection DEBUG close.started
18:00:33,973 httpcore.connection DEBUG close.complete
18:00:33,974 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:33,976 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266d7d0>
18:00:33,976 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:33,984 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf266d710>
18:00:33,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:33,985 httpcore.http11 DEBUG send_request_headers.complete
18:00:33,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:33,986 httpcore.http11 DEBUG send_request_body.complete
18:00:33,987 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:34,604 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:34 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'490'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'db6497489e3b0910acdaec4a2ad54c50'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a0106c403b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:34,610 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:00:34,611 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:34,818 httpcore.http11 DEBUG receive_response_body.complete
18:00:34,819 httpcore.http11 DEBUG response_closed.started
18:00:34,820 httpcore.http11 DEBUG response_closed.complete
18:00:34,820 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:00:34,891 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Helen3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:00:45,527 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Helen3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:00:45,532 httpcore.connection DEBUG close.started
18:00:45,532 httpcore.connection DEBUG close.complete
18:00:45,533 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:00:45,535 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265e750>
18:00:45,535 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:00:45,541 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265e890>
18:00:45,541 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:45,542 httpcore.http11 DEBUG send_request_headers.complete
18:00:45,542 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:45,573 httpcore.http11 DEBUG send_request_body.complete
18:00:45,574 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:46,419 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:46 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'7'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'df8d6a12c5b7dce1fa5e62032bc3f6cc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a058ae7a4ce4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:46,425 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:00:46,426 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:46,426 httpcore.http11 DEBUG receive_response_body.complete
18:00:46,427 httpcore.http11 DEBUG response_closed.started
18:00:46,427 httpcore.http11 DEBUG response_closed.complete
18:00:46,427 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:00:46,428 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:00:46,457 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nRight.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:00:46,461 httpcore.connection DEBUG close.started
18:00:46,461 httpcore.connection DEBUG close.complete
18:00:46,461 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:00:46,464 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265d890>
18:00:46,464 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859f40> server_hostname='api.openai.com' timeout=None
18:00:46,470 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265ff50>
18:00:46,470 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:00:46,471 httpcore.http11 DEBUG send_request_headers.complete
18:00:46,471 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:00:46,472 httpcore.http11 DEBUG send_request_body.complete
18:00:46,472 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:00:46,731 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:00:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'144'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'052a40cd9df75181705f4e77786a7580'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a05e7864300c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:00:46,737 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:00:46,738 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:00:46,740 httpcore.http11 DEBUG receive_response_body.complete
18:00:46,741 httpcore.http11 DEBUG response_closed.started
18:00:46,741 httpcore.http11 DEBUG response_closed.complete
18:00:46,742 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:00:46,759 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:46,763 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:51,966 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:51,984 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:51,988 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:00:57,190 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:00:57,207 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:00:57,211 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:01:02,413 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:01:02,420 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:01:02,427 httpcore.connection DEBUG close.started
18:01:02,427 httpcore.connection DEBUG close.complete
18:01:02,428 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:01:02,594 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265d610>
18:01:02,595 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f9bf2859e20> server_hostname='api.openai.com' timeout=5.0
18:01:02,603 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f9bf265d350>
18:01:02,603 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:01:02,605 httpcore.http11 DEBUG send_request_headers.complete
18:01:02,605 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:01:02,606 httpcore.http11 DEBUG send_request_body.complete
18:01:02,606 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:01:03,211 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:01:03 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'467'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'dfb6c72e49cdd8069ce88f480b96391f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328a0c34fdc4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:01:03,216 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:01:03,217 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:15,28 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,32 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:15,880 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,882 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:15,929 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,930 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:15,986 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:15,987 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,30 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,31 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,82 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,83 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,126 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,127 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,178 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,179 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:16,220 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:23:16,221 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:23:17,467 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vicent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:23:17,489 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:17,520 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee34d0>
18:23:17,521 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:23:17,531 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee3990>
18:23:17,532 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:17,535 httpcore.http11 DEBUG send_request_headers.complete
18:23:17,535 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:17,536 httpcore.http11 DEBUG send_request_body.complete
18:23:17,536 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:18,2 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:17 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e9ca4e281ca6f77f64b908e3f4ba0baf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xUWW4x9NzaNcAa5uVx_gIunLCU5YwGTWv8GSc3X1C_A-1702077797-1-AZdrdYV8eV2OLH0lMBPqoFzfs91CB06uhzFjy97uKWoPurccld0M5lejQa1P+yoML9uPgY9FAHq3l7nOqoTc62M=; path=/; expires=Fri, 08-Dec-23 23:53:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Q_1_OgfTeEUutufDcIQaDF2njOyVvdkVaJCOgTXxRB8-1702077797997-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c15a9e4d4cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:18,11 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:23:18,12 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:18,713 httpcore.http11 DEBUG receive_response_body.complete
18:23:18,714 httpcore.http11 DEBUG response_closed.started
18:23:18,715 httpcore.http11 DEBUG response_closed.complete
18:23:18,715 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:23:18,799 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:23:32,430 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:23:32,443 httpcore.connection DEBUG close.started
18:23:32,443 httpcore.connection DEBUG close.complete
18:23:32,444 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:32,446 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee3990>
18:23:32,446 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:23:32,451 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8ee3a90>
18:23:32,452 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:32,453 httpcore.http11 DEBUG send_request_headers.complete
18:23:32,453 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:32,481 httpcore.http11 DEBUG send_request_body.complete
18:23:32,482 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:33,466 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:33 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'431'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'552ce54d1a09d6a2d281322c6b96f1c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1b7da5c3049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:33,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:23:33,472 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:33,473 httpcore.http11 DEBUG receive_response_body.complete
18:23:33,473 httpcore.http11 DEBUG response_closed.started
18:23:33,473 httpcore.http11 DEBUG response_closed.complete
18:23:33,474 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:23:33,474 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:23:33,515 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vicent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nTell it.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:33,530 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:33,533 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38150>
18:23:33,533 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65f40> server_hostname='api.openai.com' timeout=None
18:23:33,542 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38110>
18:23:33,542 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:33,544 httpcore.http11 DEBUG send_request_headers.complete
18:23:33,544 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:33,545 httpcore.http11 DEBUG send_request_body.complete
18:23:33,545 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:33,789 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7574a139f9405dd5724740f59e183259'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=OK4QdgFhZe1YNKHqYgNSpHQChB5xRl.PIpZEAh26u88-1702077813-1-AfgS4NdTF3Rn2Ib/AStVPCfOgjpepWx4sYKE4YsLcue4tPgR+hAkJokllr2XzAhTDD0bCNH1gE+JtMdTdw8CVxw=; path=/; expires=Fri, 08-Dec-23 23:53:33 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=tgHR3w5fbYt2g2Prv1iOPDprn5VMdlJTarIXteunFFE-1702077813783-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1beafc14cc2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:33,798 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:33,799 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:33,801 httpcore.http11 DEBUG receive_response_body.complete
18:23:33,802 httpcore.http11 DEBUG response_closed.started
18:23:33,802 httpcore.http11 DEBUG response_closed.complete
18:23:33,802 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:33,838 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vicent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nTell it.\n\n'''\nRespond and redirect the human back to the candle placement task. Limit your response to three sentences.\nYour response:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:33,849 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:33,851 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d39890>
18:23:33,852 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f662a0> server_hostname='api.openai.com' timeout=None
18:23:33,858 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d39d10>
18:23:33,858 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:33,859 httpcore.http11 DEBUG send_request_headers.complete
18:23:33,860 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:33,860 httpcore.http11 DEBUG send_request_body.complete
18:23:33,860 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:34,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'856'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b77e020a7d006c2a9a145018a4a45663'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3HRjSjzp3RWjGVCXNn4ZIPLtk39gs76yTZVri09Lzps-1702077814-1-AV3/GfUWQdHxRHFvlfs0a+TfuOFejekuWcEDusdyRQoI8nX8HVyACadYn0aW530JxlH1v7XIwV1334Wul0g+jmg=; path=/; expires=Fri, 08-Dec-23 23:53:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=4JX4gMGR7KJIDVG95hLkEfOwUECbp3OBKhK.ypi3LMg-1702077814816-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1c0981c4d1c-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:34,828 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:34,829 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:34,830 httpcore.http11 DEBUG receive_response_body.complete
18:23:34,830 httpcore.http11 DEBUG response_closed.started
18:23:34,831 httpcore.http11 DEBUG response_closed.complete
18:23:34,831 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:34,841 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': "\nGreat, let's start with the first candle. Where would you like me to place it? Please give me a specific location on the cake so I can help you place the candle.", 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:23:34,845 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:34,846 httpcore.http11 DEBUG send_request_headers.complete
18:23:34,847 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:34,847 httpcore.http11 DEBUG send_request_body.complete
18:23:34,847 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:35,373 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'460'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ea20feffce2c47fc4dc62084b42d1963'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c1c6ceb83049-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:35,378 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:23:35,378 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:37,27 httpcore.http11 DEBUG receive_response_body.complete
18:23:37,28 httpcore.http11 DEBUG response_closed.started
18:23:37,29 httpcore.http11 DEBUG response_closed.complete
18:23:37,30 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:23:37,103 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:23:56,124 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:23:56,128 httpcore.connection DEBUG close.started
18:23:56,128 httpcore.connection DEBUG close.complete
18:23:56,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:23:56,131 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55cd0>
18:23:56,131 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:23:56,137 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55d50>
18:23:56,137 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:56,138 httpcore.http11 DEBUG send_request_headers.complete
18:23:56,138 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:56,172 httpcore.http11 DEBUG send_request_body.complete
18:23:56,172 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:57,188 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:57 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'532'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'982913517078f6bf97aa09c9ba5d4d67'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c24bd9ae4cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:57,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:23:57,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:57,196 httpcore.http11 DEBUG receive_response_body.complete
18:23:57,196 httpcore.http11 DEBUG response_closed.started
18:23:57,197 httpcore.http11 DEBUG response_closed.complete
18:23:57,198 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:23:57,198 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:23:57,227 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\n\nGreat, let's start with the first candle. Where would you like me to place it? Please give me a specific location on the cake so I can help you place the candle.\n'''\nAnd the human answered\n'''\nput it in the center\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:57,231 httpcore.connection DEBUG close.started
18:23:57,231 httpcore.connection DEBUG close.complete
18:23:57,232 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:57,234 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38110>
18:23:57,235 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65f40> server_hostname='api.openai.com' timeout=None
18:23:57,241 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38bd0>
18:23:57,242 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:57,243 httpcore.http11 DEBUG send_request_headers.complete
18:23:57,243 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:57,244 httpcore.http11 DEBUG send_request_body.complete
18:23:57,244 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:57,454 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9a7077a8c2e00d80ecd5637c3df36dab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c252cbcc3061-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:57,459 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:57,459 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:57,461 httpcore.http11 DEBUG receive_response_body.complete
18:23:57,461 httpcore.http11 DEBUG response_closed.started
18:23:57,461 httpcore.http11 DEBUG response_closed.complete
18:23:57,462 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:57,495 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\n\nGreat, let's start with the first candle. Where would you like me to place it? Please give me a specific location on the cake so I can help you place the candle.\n'''\nAnd the human answered\n'''\nput it in the center\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:23:57,506 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:23:57,509 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d61350>
18:23:57,509 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f66720> server_hostname='api.openai.com' timeout=None
18:23:57,516 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d63610>
18:23:57,516 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:23:57,517 httpcore.http11 DEBUG send_request_headers.complete
18:23:57,517 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:23:57,518 httpcore.http11 DEBUG send_request_body.complete
18:23:57,518 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:23:58,376 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:23:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'770'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5b1a86b0e9bf6900638848b618d2fa14'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=X1jKHHb4hvhU3kk0UkI3emNxF7qmSfUGNULWagG7FXk-1702077838-1-AQAUxjk5QIYmXKUcO2wuk9KCR9JQ1V4gmqDewbj3BXw1bXv/oQR+u8PNMR8ekGW9jiEwf3JCHASUQnGtUWat8m8=; path=/; expires=Fri, 08-Dec-23 23:53:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=0o_wmImkxugk3a9YvyFgUlQ3qNApN1kbwSEktx7guE0-1702077838371-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c2547ddd3059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:23:58,383 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:23:58,383 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:23:58,385 httpcore.http11 DEBUG receive_response_body.complete
18:23:58,385 httpcore.http11 DEBUG response_closed.started
18:23:58,386 httpcore.http11 DEBUG response_closed.complete
18:23:58,386 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:23:58,801 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:23:58,805 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:06,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:06,28 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:06,31 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:11,233 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:11,257 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:11,260 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:16,462 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:16,478 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:16,482 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:21,684 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:21,703 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:21,707 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:28,909 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:28,928 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:28,937 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:34,140 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:34,159 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:34,163 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:39,364 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:39,382 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:39,385 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:44,587 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:44,602 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:44,605 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:49,807 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:49,824 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:49,828 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:24:55,30 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:24:55,47 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:24:55,50 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:25:00,252 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:25:00,260 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:25:00,270 httpcore.connection DEBUG close.started
18:25:00,271 httpcore.connection DEBUG close.complete
18:25:00,272 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:00,301 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55c10>
18:25:00,302 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:00,309 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d55e50>
18:25:00,309 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:00,311 httpcore.http11 DEBUG send_request_headers.complete
18:25:00,312 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:00,313 httpcore.http11 DEBUG send_request_body.complete
18:25:00,313 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:00,781 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:00 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'355'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bed552900bdaf75d0f9d78e25c298f21'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c3dcfff24ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:00,787 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:25:00,788 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:00,979 httpcore.http11 DEBUG receive_response_body.complete
18:25:00,981 httpcore.http11 DEBUG response_closed.started
18:25:00,981 httpcore.http11 DEBUG response_closed.complete
18:25:00,983 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:25:01,54 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:25:08,662 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:25:08,667 httpcore.connection DEBUG close.started
18:25:08,667 httpcore.connection DEBUG close.complete
18:25:08,668 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:08,670 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80a50>
18:25:08,670 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:08,677 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80ad0>
18:25:08,678 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:08,679 httpcore.http11 DEBUG send_request_headers.complete
18:25:08,679 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:08,714 httpcore.http11 DEBUG send_request_body.complete
18:25:08,714 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:09,479 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:09 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'322'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'84de94c52755d4f33c2b3458de718116'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4113c8b4ce8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:09,485 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:25:09,486 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:09,488 httpcore.http11 DEBUG receive_response_body.complete
18:25:09,489 httpcore.http11 DEBUG response_closed.started
18:25:09,489 httpcore.http11 DEBUG response_closed.complete
18:25:09,490 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:25:09,490 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:25:09,524 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:09,527 httpcore.connection DEBUG close.started
18:25:09,528 httpcore.connection DEBUG close.complete
18:25:09,528 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:09,530 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38bd0>
18:25:09,531 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65f40> server_hostname='api.openai.com' timeout=None
18:25:09,539 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d38cd0>
18:25:09,539 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:09,541 httpcore.http11 DEBUG send_request_headers.complete
18:25:09,542 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:09,543 httpcore.http11 DEBUG send_request_body.complete
18:25:09,543 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:09,763 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9f21fed6e24c1380fc32e3547dd920e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c416aa3d4d07-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:09,769 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:09,771 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:09,772 httpcore.http11 DEBUG receive_response_body.complete
18:25:09,772 httpcore.http11 DEBUG response_closed.started
18:25:09,772 httpcore.http11 DEBUG response_closed.complete
18:25:09,773 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:09,805 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:09,817 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:09,819 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d810d0>
18:25:09,819 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65eb0> server_hostname='api.openai.com' timeout=None
18:25:09,824 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d81250>
18:25:09,825 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:09,826 httpcore.http11 DEBUG send_request_headers.complete
18:25:09,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:09,827 httpcore.http11 DEBUG send_request_body.complete
18:25:09,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:10,33 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1d8ee58fbeef267175cd7c2559ad57ef'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fBY4YD7lLKLqufnDVhuWLyIEHNN0OjByFqt4o6sVDIg-1702077910-1-AYLmfmdXUh0cKd42QuWOk4vmSOOjhgGdFA48Qd1n/qeWzI5FlaOo/HYBdNZ+c/y253hnCl05bg3ODkx+h8b5g3A=; path=/; expires=Fri, 08-Dec-23 23:55:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=s8gVlfggjFVWmPbiqNL.Zn9gx1Qw5la5M_EdQStQAHE-1702077910029-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4186875305d-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:10,42 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:10,43 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:10,43 httpcore.http11 DEBUG receive_response_body.complete
18:25:10,44 httpcore.http11 DEBUG response_closed.started
18:25:10,44 httpcore.http11 DEBUG response_closed.complete
18:25:10,44 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:10,59 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:25:10,63 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:25:15,265 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:25:15,272 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:25:15,279 httpcore.connection DEBUG close.started
18:25:15,279 httpcore.connection DEBUG close.complete
18:25:15,279 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:15,282 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80990>
18:25:15,282 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:15,288 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80810>
18:25:15,289 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:15,290 httpcore.http11 DEBUG send_request_headers.complete
18:25:15,290 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:15,291 httpcore.http11 DEBUG send_request_body.complete
18:25:15,291 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:15,733 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:15 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb95a15999b3418cdd3b4b93e4850bab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c43a9cd74cde-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:15,738 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:25:15,739 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:16,36 httpcore.http11 DEBUG receive_response_body.complete
18:25:16,37 httpcore.http11 DEBUG response_closed.started
18:25:16,38 httpcore.http11 DEBUG response_closed.complete
18:25:16,39 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:25:16,110 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:25:23,813 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:25:23,817 httpcore.connection DEBUG close.started
18:25:23,818 httpcore.connection DEBUG close.complete
18:25:23,818 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:23,821 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d86790>
18:25:23,822 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:23,827 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d86810>
18:25:23,828 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:23,829 httpcore.http11 DEBUG send_request_headers.complete
18:25:23,829 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:23,852 httpcore.http11 DEBUG send_request_body.complete
18:25:23,853 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:24,551 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:24 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'309'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b11b02134efdddac2b04a4256ec8e73d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c46fe8ff4d19-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:24,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:25:24,557 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:24,559 httpcore.http11 DEBUG receive_response_body.complete
18:25:24,559 httpcore.http11 DEBUG response_closed.started
18:25:24,560 httpcore.http11 DEBUG response_closed.complete
18:25:24,561 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:25:24,562 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:25:24,590 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:24,593 httpcore.connection DEBUG close.started
18:25:24,594 httpcore.connection DEBUG close.complete
18:25:24,594 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:24,597 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d8d8d0>
18:25:24,597 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65eb0> server_hostname='api.openai.com' timeout=None
18:25:24,604 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d8d950>
18:25:24,604 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:24,605 httpcore.http11 DEBUG send_request_headers.complete
18:25:24,606 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:24,606 httpcore.http11 DEBUG send_request_body.complete
18:25:24,606 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:24,820 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3b50e9c7e76b05af90d0138a9f909801'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c474c8bf4d08-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:24,825 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:24,826 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:24,828 httpcore.http11 DEBUG receive_response_body.complete
18:25:24,828 httpcore.http11 DEBUG response_closed.started
18:25:24,829 httpcore.http11 DEBUG response_closed.complete
18:25:24,829 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:24,849 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:25:24,853 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:25:30,55 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:25:30,63 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:25:30,68 httpcore.connection DEBUG close.started
18:25:30,68 httpcore.connection DEBUG close.complete
18:25:30,69 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:30,71 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d86550>
18:25:30,71 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:30,78 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d879d0>
18:25:30,78 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:30,79 httpcore.http11 DEBUG send_request_headers.complete
18:25:30,79 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:30,80 httpcore.http11 DEBUG send_request_body.complete
18:25:30,80 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:30,530 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:30 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'365'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'3ca591c8b673a82faccfe25779b920b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c496f9003ba0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:30,534 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:25:30,534 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:30,801 httpcore.http11 DEBUG receive_response_body.complete
18:25:30,802 httpcore.http11 DEBUG response_closed.started
18:25:30,802 httpcore.http11 DEBUG response_closed.complete
18:25:30,803 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:25:30,868 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vicent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:25:38,532 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vicent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:25:38,536 httpcore.connection DEBUG close.started
18:25:38,537 httpcore.connection DEBUG close.complete
18:25:38,537 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:25:38,540 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d87bd0>
18:25:38,540 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65d90> server_hostname='api.openai.com' timeout=5.0
18:25:38,547 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d84e50>
18:25:38,548 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:38,549 httpcore.http11 DEBUG send_request_headers.complete
18:25:38,549 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:38,562 httpcore.http11 DEBUG send_request_body.complete
18:25:38,563 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:39,691 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:39 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'637'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'98e0711b71b0ae6e5fbd74c71d4cad7e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4cbec0e300c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:39,695 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:25:39,696 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:39,697 httpcore.http11 DEBUG receive_response_body.complete
18:25:39,698 httpcore.http11 DEBUG response_closed.started
18:25:39,698 httpcore.http11 DEBUG response_closed.complete
18:25:39,699 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:25:39,699 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:25:39,730 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:25:39,733 httpcore.connection DEBUG close.started
18:25:39,734 httpcore.connection DEBUG close.complete
18:25:39,734 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:25:39,736 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d80050>
18:25:39,737 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f33c8f65eb0> server_hostname='api.openai.com' timeout=None
18:25:39,741 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f33c8d81010>
18:25:39,742 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:25:39,743 httpcore.http11 DEBUG send_request_headers.complete
18:25:39,743 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:25:39,744 httpcore.http11 DEBUG send_request_body.complete
18:25:39,744 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:25:39,965 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:25:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c46a0462a3848e50c802561ddd0a0f36'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328c4d3682d6ac6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:25:39,972 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:25:39,973 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:25:39,974 httpcore.http11 DEBUG receive_response_body.complete
18:25:39,974 httpcore.http11 DEBUG response_closed.started
18:25:39,975 httpcore.http11 DEBUG response_closed.complete
18:25:39,975 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:25:39,990 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:25:39,993 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:29:54,154 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:54,158 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:54,987 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:54,988 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,32 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,33 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,82 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,83 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,125 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,126 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,174 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,175 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,216 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,217 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,266 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,267 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:55,309 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:29:55,310 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:29:58,168 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:29:58,186 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:29:58,218 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8934537910>
18:29:58,218 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fdd90> server_hostname='api.openai.com' timeout=5.0
18:29:58,226 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f893447f890>
18:29:58,226 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:29:58,228 httpcore.http11 DEBUG send_request_headers.complete
18:29:58,228 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:29:58,228 httpcore.http11 DEBUG send_request_body.complete
18:29:58,229 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:29:58,686 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:29:58 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'017bd1ee9bc6e1438c7c05807e0198a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0Is7Y8KR.l9FcBdTCYag6iwuL.YEOQ7bUfhNQqV4iTk-1702078198-1-AcPGqEbMcyFUlXX+syLVmDwI7ieaHi7J+7TO76683ogrZnHCYqPGsiYR7nY3yPGB9uOU6OE0ycTz5vxtvVh/euA=; path=/; expires=Fri, 08-Dec-23 23:59:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=MDogYZKkc0nDuRGyl2pUP7P2jg79vEHDrtw_an_d7vQ-1702078198681-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb22ef42300c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:29:58,694 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:29:58,694 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:29:59,607 httpcore.http11 DEBUG receive_response_body.complete
18:29:59,608 httpcore.http11 DEBUG response_closed.started
18:29:59,609 httpcore.http11 DEBUG response_closed.complete
18:29:59,610 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:29:59,695 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:30:13,610 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:30:13,620 httpcore.connection DEBUG close.started
18:30:13,621 httpcore.connection DEBUG close.complete
18:30:13,622 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:30:13,624 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f893449f390>
18:30:13,625 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fdd90> server_hostname='api.openai.com' timeout=5.0
18:30:13,631 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f893447ea90>
18:30:13,632 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:13,633 httpcore.http11 DEBUG send_request_headers.complete
18:30:13,633 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:13,661 httpcore.http11 DEBUG send_request_body.complete
18:30:13,662 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:14,940 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:30:14 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'620'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fc001f635c0c71ef5e6ad9d95a029e36'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb8338bd4d16-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:14,944 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:30:14,944 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:14,945 httpcore.http11 DEBUG receive_response_body.complete
18:30:14,945 httpcore.http11 DEBUG response_closed.started
18:30:14,946 httpcore.http11 DEBUG response_closed.complete
18:30:14,946 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:30:14,947 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:30:14,985 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:14,997 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:15,34 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344d0050>
18:30:15,35 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fdf40> server_hostname='api.openai.com' timeout=None
18:30:15,44 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344d09d0>
18:30:15,45 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:15,47 httpcore.http11 DEBUG send_request_headers.complete
18:30:15,48 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:15,49 httpcore.http11 DEBUG send_request_body.complete
18:30:15,50 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:15,270 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:30:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'126'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f3c3625e971ea3fb70da5adfcf286b4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dbargJkkEaFHQlRLZ27GrWHvuEM9ku.1CXn.O33WS3k-1702078215-1-AWDr0h2WHGkOftqneN1AjW7w73OWa1JmVT+FlGutLRYMN89juH+VAODdDOZWfm1rNkITDFmoDNR6vapkyerxBpc=; path=/; expires=Sat, 09-Dec-23 00:00:15 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=b5_Kgpbm9qWypxiqBy4M0qNdlv3lRcqoHaF8N6Km9hI-1702078215265-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb8c0eaf3074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:15,281 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:15,282 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:15,283 httpcore.http11 DEBUG receive_response_body.complete
18:30:15,283 httpcore.http11 DEBUG response_closed.started
18:30:15,283 httpcore.http11 DEBUG response_closed.complete
18:30:15,284 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:15,318 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:30:15,330 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:30:15,333 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344d34d0>
18:30:15,334 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f89344fe720> server_hostname='api.openai.com' timeout=None
18:30:15,341 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f89344c3390>
18:30:15,342 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:30:15,343 httpcore.http11 DEBUG send_request_headers.complete
18:30:15,343 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:30:15,344 httpcore.http11 DEBUG send_request_body.complete
18:30:15,344 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:30:16,33 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:30:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'582'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3ccf74c03bfa36b94aa9ccaa35fa818e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ygw5NT9AtjcNhF8ntOgI2jR7guV_pQD9Oq.y84PJujQ-1702078216-1-AbV1bJE/bLvHlSNhlet46qQwCI7PgaxFt2Akprl01QP3hS9hSFKANB2FuJwdPackoE2vWb4XNKNkjE468H4uiZU=; path=/; expires=Sat, 09-Dec-23 00:00:16 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ZwmI4wipG.EaPhIYQxoZRWsPiUnvL4cgTTDUs2zRV5I-1702078216029-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cb8dede14cce-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:30:16,40 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:30:16,42 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:30:16,44 httpcore.http11 DEBUG receive_response_body.complete
18:30:16,45 httpcore.http11 DEBUG response_closed.started
18:30:16,45 httpcore.http11 DEBUG response_closed.complete
18:30:16,46 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:30:16,478 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:16,483 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:30:23,692 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:30:23,709 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:23,713 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:30:28,915 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:30:28,930 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:30:28,933 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:03,833 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:03,836 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,642 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,643 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,685 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,686 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,735 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,736 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,777 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,778 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,825 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,826 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,867 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,868 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,916 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,917 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:04,957 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:32:04,958 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:32:05,769 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:32:05,789 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:05,819 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5957190>
18:32:05,820 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:32:05,828 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5957690>
18:32:05,829 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:05,831 httpcore.http11 DEBUG send_request_headers.complete
18:32:05,831 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:05,831 httpcore.http11 DEBUG send_request_body.complete
18:32:05,832 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:06,290 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:06 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'377'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'32613f16b25f4de3d8e5dcd331fbeafd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9HmoBvScVOe.Z.OztyDEvfeNTWsn_yP.MqJ4wSRWs5s-1702078326-1-AQtG60gO3oyV9HIGAEVz8m0h0yRbGJnImquaur/klkYWi4i0ciWutJWjalSgYnGSbhfwQX5eLB1HhSMWnsttuhs=; path=/; expires=Sat, 09-Dec-23 00:02:06 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BlUebMc3WvduuuIx_5GL781YUhfCu.N1O6lLu65Jm_g-1702078326284-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ce407fb04cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:06,298 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:32:06,299 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:07,60 httpcore.http11 DEBUG receive_response_body.complete
18:32:07,61 httpcore.http11 DEBUG response_closed.started
18:32:07,62 httpcore.http11 DEBUG response_closed.complete
18:32:07,62 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:32:07,141 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:32:20,759 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:32:20,768 httpcore.connection DEBUG close.started
18:32:20,769 httpcore.connection DEBUG close.complete
18:32:20,769 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:32:20,772 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5957a50>
18:32:20,772 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:32:20,779 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59578d0>
18:32:20,780 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:20,781 httpcore.http11 DEBUG send_request_headers.complete
18:32:20,781 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:20,813 httpcore.http11 DEBUG send_request_body.complete
18:32:20,813 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:21,995 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'15'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'365'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bf0e59de5342c6686a9ed873c6cb964f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ce9de94d4d0e-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:21,998 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:32:21,998 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:21,999 httpcore.http11 DEBUG receive_response_body.complete
18:32:21,999 httpcore.http11 DEBUG response_closed.started
18:32:22,0 httpcore.http11 DEBUG response_closed.complete
18:32:22,0 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:32:22,1 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:32:22,34 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nat the center.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:32:22,45 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:32:22,48 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ac050>
18:32:22,48 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1f40> server_hostname='api.openai.com' timeout=None
18:32:22,55 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ac9d0>
18:32:22,55 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:22,56 httpcore.http11 DEBUG send_request_headers.complete
18:32:22,57 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:22,57 httpcore.http11 DEBUG send_request_body.complete
18:32:22,58 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:22,276 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'108'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2293db4494c04809be682fdf7514c255'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=m1zrGgYQjxfwCcem2nnhb5LCrREj0b0xvPFTu60.zD8-1702078342-1-AcBQ5zOi+fmc/SI7ebIixQZATlaXbY+fUIlfhVC5v7OxnFmw2SHl/Nj0kKNuTKXxAVgBc9BZmBMJ82gV8Bid7jE=; path=/; expires=Sat, 09-Dec-23 00:02:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=cvD7tntWNsq.6jpjHkXGxgb_fz.pb.N1RBc_y6XSJ9U-1702078342271-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cea5d9b26ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:22,285 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:32:22,286 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:22,287 httpcore.http11 DEBUG receive_response_body.complete
18:32:22,287 httpcore.http11 DEBUG response_closed.started
18:32:22,287 httpcore.http11 DEBUG response_closed.complete
18:32:22,288 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:32:22,322 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nat the center.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:32:22,332 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:32:22,335 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5df0510>
18:32:22,335 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be2720> server_hostname='api.openai.com' timeout=None
18:32:22,341 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ad810>
18:32:22,341 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:32:22,342 httpcore.http11 DEBUG send_request_headers.complete
18:32:22,342 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:32:22,343 httpcore.http11 DEBUG send_request_body.complete
18:32:22,343 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:32:23,72 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:32:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'633'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5e67480df490c2521f325e712ab21bcd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=z0ghITu4MfFJldyk04tPCJw5hPK_t7CCKynH1_NGIiM-1702078343-1-AbvYghKjT0JhRWSQMT3FyCY2GYtGzoeXOdC+jt8wBCVOCGZ7uLqI2CKOUKW+sYEhWgSRaVqL5VBjfYliu6pNSfI=; path=/; expires=Sat, 09-Dec-23 00:02:23 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kRO4TA0a.aG68ZSpVgsgT.oghKyYLs11qI_aYEythu8-1702078343067-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328cea7a9253025-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:32:23,78 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:32:23,79 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:32:23,80 httpcore.http11 DEBUG receive_response_body.complete
18:32:23,81 httpcore.http11 DEBUG response_closed.started
18:32:23,82 httpcore.http11 DEBUG response_closed.complete
18:32:23,82 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:32:23,492 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:23,496 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:30,704 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:30,720 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:30,724 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:35,926 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:35,944 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:35,949 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:41,152 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:41,169 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:41,173 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:46,376 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:46,393 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:46,397 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:53,600 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:53,620 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:53,623 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:32:58,824 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:32:58,841 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:32:58,845 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:04,47 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:04,66 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:04,69 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:09,271 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:09,289 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:09,292 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:14,494 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:14,512 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:14,515 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:19,718 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:19,726 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:33:19,732 httpcore.connection DEBUG close.started
18:33:19,732 httpcore.connection DEBUG close.complete
18:33:19,733 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:19,760 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e5a17650>
18:33:19,760 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:19,767 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59cbc50>
18:33:19,768 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:19,770 httpcore.http11 DEBUG send_request_headers.complete
18:33:19,771 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:19,772 httpcore.http11 DEBUG send_request_body.complete
18:33:19,772 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:20,491 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:20 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'566'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f46fb0a20ea44e0cc7741973439b41ea'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d00e9ebf4d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:20,495 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:33:20,496 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:21,418 httpcore.http11 DEBUG receive_response_body.complete
18:33:21,418 httpcore.http11 DEBUG response_closed.started
18:33:21,419 httpcore.http11 DEBUG response_closed.complete
18:33:21,419 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:33:21,483 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:33:33,469 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:33:33,476 httpcore.connection DEBUG close.started
18:33:33,476 httpcore.connection DEBUG close.complete
18:33:33,476 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:33,479 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de950>
18:33:33,479 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:33,486 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de9d0>
18:33:33,486 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:33,487 httpcore.http11 DEBUG send_request_headers.complete
18:33:33,488 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:33,514 httpcore.http11 DEBUG send_request_body.complete
18:33:33,514 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:34,322 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:34 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'19'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'354'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6ea4f4f06d0b6bd01a3fca57ec1e0b7b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0644c634ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:34,324 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:33:34,324 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:34,325 httpcore.http11 DEBUG receive_response_body.complete
18:33:34,325 httpcore.http11 DEBUG response_closed.started
18:33:34,325 httpcore.http11 DEBUG response_closed.complete
18:33:34,326 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:33:34,326 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:33:34,355 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nUh, most of the...\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:33:34,358 httpcore.connection DEBUG close.started
18:33:34,359 httpcore.connection DEBUG close.complete
18:33:34,359 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:33:34,361 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ac9d0>
18:33:34,361 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1f40> server_hostname='api.openai.com' timeout=None
18:33:34,368 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59aca50>
18:33:34,368 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:34,369 httpcore.http11 DEBUG send_request_headers.complete
18:33:34,370 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:34,370 httpcore.http11 DEBUG send_request_body.complete
18:33:34,370 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:34,588 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'120'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e160c6b4cd9e533a737dc8610c926234'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d069ca7a4cf2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:34,595 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:33:34,597 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:34,599 httpcore.http11 DEBUG receive_response_body.complete
18:33:34,600 httpcore.http11 DEBUG response_closed.started
18:33:34,601 httpcore.http11 DEBUG response_closed.complete
18:33:34,601 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:33:34,608 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:33:34,612 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:34,613 httpcore.http11 DEBUG send_request_headers.complete
18:33:34,613 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:34,613 httpcore.http11 DEBUG send_request_body.complete
18:33:34,614 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:35,285 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'555'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9e1403a25c2f0f9162f184678aaffec9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d06b5f114ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:35,290 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:33:35,291 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:36,358 httpcore.http11 DEBUG receive_response_body.complete
18:33:36,358 httpcore.http11 DEBUG response_closed.started
18:33:36,359 httpcore.http11 DEBUG response_closed.complete
18:33:36,360 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:33:36,434 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:33:49,118 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:33:49,125 httpcore.connection DEBUG close.started
18:33:49,126 httpcore.connection DEBUG close.complete
18:33:49,126 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:49,129 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59dcb10>
18:33:49,129 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:49,136 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59dd410>
18:33:49,136 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:49,138 httpcore.http11 DEBUG send_request_headers.complete
18:33:49,138 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:49,163 httpcore.http11 DEBUG send_request_body.complete
18:33:49,164 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:50,31 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:50 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'9'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'371'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'be53eab8116e395b4c0f9f7211a466da'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0c61c5c4cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:50,35 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:33:50,36 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:50,37 httpcore.http11 DEBUG receive_response_body.complete
18:33:50,37 httpcore.http11 DEBUG response_closed.started
18:33:50,38 httpcore.http11 DEBUG response_closed.complete
18:33:50,38 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:33:50,39 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:33:50,69 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:33:50,78 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:33:50,81 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59edf10>
18:33:50,81 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:33:50,89 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59eded0>
18:33:50,89 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:50,91 httpcore.http11 DEBUG send_request_headers.complete
18:33:50,91 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:50,92 httpcore.http11 DEBUG send_request_body.complete
18:33:50,92 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:50,326 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1ec717c35c2eecaf712d20dc9bd377b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=qjIMCtEoaSLJp_MQ2EXqxL30whdS1mIOSN8H3LdfQbM-1702078430-1-AdCwUQ+ZThDSIRTbD3WV0cOeGpDZIzsv0OI9V7PKWjoPN1jxxVhke5+102Sj2kM6zVXOa9bB1e9hF2qOPtSgSqA=; path=/; expires=Sat, 09-Dec-23 00:03:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=BihLozpwzEEi8EODi.w2D2yyOgL8lrSw_QiYkSdosDc-1702078430320-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0cc1bb44d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:50,334 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:33:50,335 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:50,336 httpcore.http11 DEBUG receive_response_body.complete
18:33:50,336 httpcore.http11 DEBUG response_closed.started
18:33:50,336 httpcore.http11 DEBUG response_closed.complete
18:33:50,337 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:33:50,370 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nMove up.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:33:50,374 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:50,375 httpcore.http11 DEBUG send_request_headers.complete
18:33:50,375 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:50,376 httpcore.http11 DEBUG send_request_body.complete
18:33:50,376 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:50,592 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'1fffccca370d09b92f5eb46b9f6cba81'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0cddf104d0a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:50,597 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:33:50,598 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:50,600 httpcore.http11 DEBUG receive_response_body.complete
18:33:50,601 httpcore.http11 DEBUG response_closed.started
18:33:50,602 httpcore.http11 DEBUG response_closed.complete
18:33:50,602 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:33:50,618 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:33:50,621 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:33:55,823 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:33:55,829 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:33:55,835 httpcore.connection DEBUG close.started
18:33:55,835 httpcore.connection DEBUG close.complete
18:33:55,836 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:33:55,838 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ee5d0>
18:33:55,839 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:33:55,844 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ef790>
18:33:55,845 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:33:55,847 httpcore.http11 DEBUG send_request_headers.complete
18:33:55,847 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:33:55,848 httpcore.http11 DEBUG send_request_body.complete
18:33:55,848 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:33:56,428 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:33:56 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'469'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'74fb29e2d51344f09da55043bc76f8bf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d0f00c4e4cd4-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:33:56,433 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:33:56,434 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:33:56,722 httpcore.http11 DEBUG receive_response_body.complete
18:33:56,722 httpcore.http11 DEBUG response_closed.started
18:33:56,723 httpcore.http11 DEBUG response_closed.complete
18:33:56,723 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:33:56,788 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:34:04,548 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:34:04,555 httpcore.connection DEBUG close.started
18:34:04,555 httpcore.connection DEBUG close.complete
18:34:04,556 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:04,558 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59df110>
18:34:04,559 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:04,567 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de350>
18:34:04,568 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:04,569 httpcore.http11 DEBUG send_request_headers.complete
18:34:04,569 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:04,646 httpcore.http11 DEBUG send_request_body.complete
18:34:04,647 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:05,520 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:05 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'11'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'c028e0b52c8bf36837d083fa2ef74384'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d12688e14ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:05,524 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:34:05,525 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:05,526 httpcore.http11 DEBUG receive_response_body.complete
18:34:05,527 httpcore.http11 DEBUG response_closed.started
18:34:05,527 httpcore.http11 DEBUG response_closed.complete
18:34:05,528 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:34:05,529 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:34:05,560 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nMoved out.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:34:05,563 httpcore.connection DEBUG close.started
18:34:05,563 httpcore.connection DEBUG close.complete
18:34:05,564 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:34:05,566 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59df550>
18:34:05,567 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:34:05,575 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59de650>
18:34:05,575 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:05,576 httpcore.http11 DEBUG send_request_headers.complete
18:34:05,577 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:05,578 httpcore.http11 DEBUG send_request_body.complete
18:34:05,578 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:05,815 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2229ce4935f11453a5eeb597cad3ab9a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d12cde264ce9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:05,820 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:34:05,821 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:05,822 httpcore.http11 DEBUG receive_response_body.complete
18:34:05,822 httpcore.http11 DEBUG response_closed.started
18:34:05,822 httpcore.http11 DEBUG response_closed.complete
18:34:05,823 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:34:05,839 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:34:05,843 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:34:11,45 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:34:11,51 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:34:11,58 httpcore.connection DEBUG close.started
18:34:11,59 httpcore.connection DEBUG close.complete
18:34:11,59 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:11,62 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59df090>
18:34:11,62 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:11,70 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59deed0>
18:34:11,70 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:11,71 httpcore.http11 DEBUG send_request_headers.complete
18:34:11,72 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:11,72 httpcore.http11 DEBUG send_request_body.complete
18:34:11,73 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:11,499 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:11 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'352'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6a5cc310aaebe4c5c4ff55b87fe8f352'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d14f39464cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:11,505 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:34:11,506 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:11,777 httpcore.http11 DEBUG receive_response_body.complete
18:34:11,778 httpcore.http11 DEBUG response_closed.started
18:34:11,779 httpcore.http11 DEBUG response_closed.complete
18:34:11,779 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:34:11,845 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:34:19,670 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:34:19,674 httpcore.connection DEBUG close.started
18:34:19,674 httpcore.connection DEBUG close.complete
18:34:19,674 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:19,677 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f7b50>
18:34:19,677 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:19,683 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f7bd0>
18:34:19,683 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:19,685 httpcore.http11 DEBUG send_request_headers.complete
18:34:19,685 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:19,706 httpcore.http11 DEBUG send_request_body.complete
18:34:19,706 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:20,539 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:20 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'498'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cb87ba7bf2d4506f73dbd82e4e5e332b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1850f373b7b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:20,544 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:34:20,546 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:20,547 httpcore.http11 DEBUG receive_response_body.complete
18:34:20,548 httpcore.http11 DEBUG response_closed.started
18:34:20,548 httpcore.http11 DEBUG response_closed.complete
18:34:20,549 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:34:20,550 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:34:20,579 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:34:20,582 httpcore.connection DEBUG close.started
18:34:20,583 httpcore.connection DEBUG close.complete
18:34:20,583 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:34:20,614 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59fedd0>
18:34:20,614 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:34:20,623 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59fee50>
18:34:20,624 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:20,627 httpcore.http11 DEBUG send_request_headers.complete
18:34:20,627 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:20,628 httpcore.http11 DEBUG send_request_body.complete
18:34:20,629 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:20,841 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ad4fe815c833158de85947bd8dc9f37a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d18ae91e4cd2-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:20,848 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:34:20,849 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:20,852 httpcore.http11 DEBUG receive_response_body.complete
18:34:20,853 httpcore.http11 DEBUG response_closed.started
18:34:20,853 httpcore.http11 DEBUG response_closed.complete
18:34:20,854 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:34:20,872 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:34:20,875 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:34:26,77 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:34:26,86 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:34:26,90 httpcore.connection DEBUG close.started
18:34:26,91 httpcore.connection DEBUG close.complete
18:34:26,91 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:26,94 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f5750>
18:34:26,94 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:26,100 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59f5ad0>
18:34:26,101 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:26,102 httpcore.http11 DEBUG send_request_headers.complete
18:34:26,102 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:26,102 httpcore.http11 DEBUG send_request_body.complete
18:34:26,103 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:26,535 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:26 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bb950392a890502ad403a97cf3c9a648'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1ad2c93304d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:26,540 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:34:26,541 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:26,811 httpcore.http11 DEBUG receive_response_body.complete
18:34:26,812 httpcore.http11 DEBUG response_closed.started
18:34:26,813 httpcore.http11 DEBUG response_closed.complete
18:34:26,814 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:34:26,883 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:34:34,593 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:34:34,597 httpcore.connection DEBUG close.started
18:34:34,597 httpcore.connection DEBUG close.complete
18:34:34,598 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:34:34,600 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e599dcd0>
18:34:34,600 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1d90> server_hostname='api.openai.com' timeout=5.0
18:34:34,605 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e599c390>
18:34:34,606 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:34,607 httpcore.http11 DEBUG send_request_headers.complete
18:34:34,607 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:34,630 httpcore.http11 DEBUG send_request_body.complete
18:34:34,630 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:35,426 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:35 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'336'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'58c6fad6d2b59197e5ebf3181c628e6e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1e24fdf4cf0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:35,430 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:34:35,431 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:35,432 httpcore.http11 DEBUG receive_response_body.complete
18:34:35,432 httpcore.http11 DEBUG response_closed.started
18:34:35,432 httpcore.http11 DEBUG response_closed.complete
18:34:35,433 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:34:35,433 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:34:35,463 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:34:35,466 httpcore.connection DEBUG close.started
18:34:35,467 httpcore.connection DEBUG close.complete
18:34:35,467 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:34:35,469 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ef010>
18:34:35,470 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f45e5be1eb0> server_hostname='api.openai.com' timeout=None
18:34:35,475 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f45e59ee450>
18:34:35,476 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:34:35,477 httpcore.http11 DEBUG send_request_headers.complete
18:34:35,477 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:34:35,478 httpcore.http11 DEBUG send_request_body.complete
18:34:35,478 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:34:35,684 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:34:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'38b68a276c8269fbb7b84f4750a6a859'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328d1e7b8884d1e-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:34:35,690 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:34:35,692 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:34:35,693 httpcore.http11 DEBUG receive_response_body.complete
18:34:35,693 httpcore.http11 DEBUG response_closed.started
18:34:35,694 httpcore.http11 DEBUG response_closed.complete
18:34:35,694 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:34:35,710 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:34:35,713 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:41:41,494 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:41,498 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,337 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,338 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,381 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,382 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,429 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,430 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,470 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,471 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,518 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,519 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,559 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,560 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,608 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,609 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:41:42,649 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:41:42,650 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:42:45,929 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:42:45,948 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:42:45,980 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064f850>
18:42:45,981 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:42:45,989 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064fd50>
18:42:45,991 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:42:45,994 httpcore.http11 DEBUG send_request_headers.complete
18:42:45,995 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:42:45,996 httpcore.http11 DEBUG send_request_body.complete
18:42:45,997 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:42:46,464 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:42:46 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'99b41040259ebd3bc782f6f4f2ac88bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=wi_FXDO2QKu2OL8vQus_m1LE9jBhW0NTBOGuxR4CuD4-1702078966-1-AYnT8afk/4CRrar/B4GsZuuHFJv7l0Jj8n2lQ7pSb33yvhl9r3vc7PIxIdvgegevkzEL3LU/53SLXaRDq/DHxX8=; path=/; expires=Sat, 09-Dec-23 00:12:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=08XvDRGHVrTqXpcytxXI9BeyktXmRV1qNTQelLTZ4Y8-1702078966460-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328dde17c603074-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:42:46,471 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:42:46,473 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:42:47,206 httpcore.http11 DEBUG receive_response_body.complete
18:42:47,207 httpcore.http11 DEBUG response_closed.started
18:42:47,208 httpcore.http11 DEBUG response_closed.complete
18:42:47,209 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:42:47,293 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:43:01,20 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:43:01,34 httpcore.connection DEBUG close.started
18:43:01,34 httpcore.connection DEBUG close.complete
18:43:01,35 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:43:01,38 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064fc10>
18:43:01,39 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:43:01,47 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25064e3d0>
18:43:01,48 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:01,50 httpcore.http11 DEBUG send_request_headers.complete
18:43:01,50 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:01,82 httpcore.http11 DEBUG send_request_body.complete
18:43:01,83 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:02,4 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:43:02 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'2117486d1cb246e760553bc28c2dae1c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328de3f8eb04d0b-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:02,8 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:43:02,9 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:02,9 httpcore.http11 DEBUG receive_response_body.complete
18:43:02,10 httpcore.http11 DEBUG response_closed.started
18:43:02,10 httpcore.http11 DEBUG response_closed.complete
18:43:02,11 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:43:02,12 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:43:02,49 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:43:02,60 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:43:02,62 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc590>
18:43:02,63 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9f40> server_hostname='api.openai.com' timeout=None
18:43:02,70 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc510>
18:43:02,71 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:02,72 httpcore.http11 DEBUG send_request_headers.complete
18:43:02,73 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:02,73 httpcore.http11 DEBUG send_request_body.complete
18:43:02,74 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:02,294 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:43:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd380830568c83b1629eeb170ca5cdc52'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IotWwaSYls2XBWPILfuL.kRIqZN1FfcmaIgKE8d03bM-1702078982-1-AWisfyM23/Nej7pH2wfyLfput/fQKw5Dt1bedUVw+eywK/Vt4vNnc8254ospV1LTxcUItdIqhqpjHaW2XDTI1Iw=; path=/; expires=Sat, 09-Dec-23 00:13:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OSSESw2HPKvvyx4qOyoYOoixayRS28jmxa.0nlKrXlk-1702078982289-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328de45fc5a3b9a-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:02,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:43:02,304 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:02,306 httpcore.http11 DEBUG receive_response_body.complete
18:43:02,306 httpcore.http11 DEBUG response_closed.started
18:43:02,306 httpcore.http11 DEBUG response_closed.complete
18:43:02,307 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:43:02,342 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:43:02,357 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:43:02,360 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504c2d90>
18:43:02,360 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506da720> server_hostname='api.openai.com' timeout=None
18:43:02,367 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504c2d10>
18:43:02,367 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:43:02,368 httpcore.http11 DEBUG send_request_headers.complete
18:43:02,369 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:43:02,370 httpcore.http11 DEBUG send_request_body.complete
18:43:02,370 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:43:03,262 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:43:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'764'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e49cccdeb5a77ff05f9bfe87928556e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ghm66SyyP6DHtF9PC6dGI1JUUnObmysNUC5niSlcnAg-1702078983-1-AfdTfmkzpvpY0gvJUpS4H3zE4VKlF5xbuxlZv6hvrulwhZ16PdzrLZLREzvE4YCWz8g1YFMdItglEXJ5OXrFSQM=; path=/; expires=Sat, 09-Dec-23 00:13:03 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=NMlCLq77tPJASCAw_TcAwUEkFhBL3QAgF39QkRJbHeQ-1702078983256-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328de47cd5e4cfb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:43:03,269 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:43:03,270 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:43:03,271 httpcore.http11 DEBUG receive_response_body.complete
18:43:03,272 httpcore.http11 DEBUG response_closed.started
18:43:03,272 httpcore.http11 DEBUG response_closed.complete
18:43:03,273 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:43:03,557 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:03,561 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:10,769 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:10,783 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:10,787 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:15,990 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:16,12 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:16,16 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:21,218 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:21,236 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:21,239 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:26,441 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:26,459 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:26,463 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:33,665 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:33,681 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:33,685 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:38,887 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:38,908 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:38,912 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:44,114 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:44,131 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:44,134 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:49,336 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:49,351 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:49,355 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:54,557 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:54,572 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:54,580 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:43:59,782 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:43:59,802 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:43:59,805 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:05,7 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:05,13 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:44:05,19 httpcore.connection DEBUG close.started
18:44:05,19 httpcore.connection DEBUG close.complete
18:44:05,19 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:05,48 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd25081d890>
18:44:05,49 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:05,56 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504cd350>
18:44:05,57 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:05,59 httpcore.http11 DEBUG send_request_headers.complete
18:44:05,59 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:05,61 httpcore.http11 DEBUG send_request_body.complete
18:44:05,61 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:05,623 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:05 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'457'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a72d868546398846336e6cb9186059f0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328dfcf9ee63021-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:05,628 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:44:05,630 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:06,754 httpcore.http11 DEBUG receive_response_body.complete
18:44:06,755 httpcore.http11 DEBUG response_closed.started
18:44:06,755 httpcore.http11 DEBUG response_closed.complete
18:44:06,756 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:44:06,817 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:44:19,638 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:44:19,642 httpcore.connection DEBUG close.started
18:44:19,642 httpcore.connection DEBUG close.complete
18:44:19,643 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:19,647 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e2450>
18:44:19,647 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:19,652 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e24d0>
18:44:19,653 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:19,654 httpcore.http11 DEBUG send_request_headers.complete
18:44:19,654 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:19,677 httpcore.http11 DEBUG send_request_body.complete
18:44:19,678 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:21,279 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:21 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'891'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'111fa734b29acb5b37bf3cd91c7ade74'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e02adb0f4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:21,282 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:44:21,282 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:21,283 httpcore.http11 DEBUG receive_response_body.complete
18:44:21,284 httpcore.http11 DEBUG response_closed.started
18:44:21,284 httpcore.http11 DEBUG response_closed.complete
18:44:21,285 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:44:21,285 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:44:21,315 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:21,318 httpcore.connection DEBUG close.started
18:44:21,318 httpcore.connection DEBUG close.complete
18:44:21,319 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:21,321 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc510>
18:44:21,321 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9f40> server_hostname='api.openai.com' timeout=None
18:44:21,327 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504bc5d0>
18:44:21,327 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:21,328 httpcore.http11 DEBUG send_request_headers.complete
18:44:21,329 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:21,329 httpcore.http11 DEBUG send_request_body.complete
18:44:21,329 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:21,565 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'121'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'3aa1c78749a7b4393dcbb99e0fef59df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e035484a6ac7-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:21,572 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:21,573 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:21,575 httpcore.http11 DEBUG receive_response_body.complete
18:44:21,575 httpcore.http11 DEBUG response_closed.started
18:44:21,575 httpcore.http11 DEBUG response_closed.complete
18:44:21,576 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:21,611 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:21,623 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:21,625 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e0a50>
18:44:21,625 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9eb0> server_hostname='api.openai.com' timeout=None
18:44:21,635 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e1710>
18:44:21,635 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:21,636 httpcore.http11 DEBUG send_request_headers.complete
18:44:21,637 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:21,638 httpcore.http11 DEBUG send_request_body.complete
18:44:21,638 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:21,850 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'115'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'bc576522874978d0af920b82881d9940'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=lRxa3Yn3qd31UYZEaVnA6qjrTbCfOVzR4Pa5qsVDB2o-1702079061-1-AV9728OAGIXxecbahCvnWFbyT3oUQhO59+ZlJdh1YyfT4n4zC6+HwSHkahCjJi1lpTngOFx92mPv0WtXTKBAJeA=; path=/; expires=Sat, 09-Dec-23 00:14:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=gMYtQlB4yxjNIAvFzMuIVIgXXAmBq6pjavXnKoIEPR8-1702079061846-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0373a7a3b7b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:21,856 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:21,857 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:21,858 httpcore.http11 DEBUG receive_response_body.complete
18:44:21,859 httpcore.http11 DEBUG response_closed.started
18:44:21,859 httpcore.http11 DEBUG response_closed.complete
18:44:21,859 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:21,875 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:21,878 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:27,80 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:27,98 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:27,102 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:32,304 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:32,322 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:32,325 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:37,527 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:37,530 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:44:37,535 httpcore.connection DEBUG close.started
18:44:37,535 httpcore.connection DEBUG close.complete
18:44:37,536 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:37,538 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e0ed0>
18:44:37,539 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:37,544 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e0fd0>
18:44:37,544 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:37,545 httpcore.http11 DEBUG send_request_headers.complete
18:44:37,546 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:37,546 httpcore.http11 DEBUG send_request_body.complete
18:44:37,546 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:38,146 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:38 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'a167828c9e8827a7be1fc8b095348094'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e09aa9ca4cd0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:38,149 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:44:38,150 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:38,517 httpcore.http11 DEBUG receive_response_body.complete
18:44:38,518 httpcore.http11 DEBUG response_closed.started
18:44:38,519 httpcore.http11 DEBUG response_closed.complete
18:44:38,519 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:44:38,587 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:44:49,934 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:44:49,939 httpcore.connection DEBUG close.started
18:44:49,939 httpcore.connection DEBUG close.complete
18:44:49,940 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:44:49,942 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e6590>
18:44:49,943 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:44:49,950 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e6610>
18:44:49,950 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:49,952 httpcore.http11 DEBUG send_request_headers.complete
18:44:49,952 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:49,983 httpcore.http11 DEBUG send_request_body.complete
18:44:49,983 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:51,80 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:51 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'17'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'359'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'8eb63832b3b7fb39ad18c876cab499d4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0e83da14cef-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:51,85 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:44:51,86 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:51,87 httpcore.http11 DEBUG receive_response_body.complete
18:44:51,88 httpcore.http11 DEBUG response_closed.started
18:44:51,88 httpcore.http11 DEBUG response_closed.complete
18:44:51,89 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:44:51,90 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:44:51,124 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTop left corner.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:51,128 httpcore.connection DEBUG close.started
18:44:51,129 httpcore.connection DEBUG close.complete
18:44:51,129 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:51,132 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504fd810>
18:44:51,132 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9f40> server_hostname='api.openai.com' timeout=None
18:44:51,137 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504fd890>
18:44:51,138 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:51,138 httpcore.http11 DEBUG send_request_headers.complete
18:44:51,139 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:51,139 httpcore.http11 DEBUG send_request_body.complete
18:44:51,140 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:51,335 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'103'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'29d8292cba0aed70deebd23b81b3c015'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0ef9a414d18-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:51,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:51,345 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:51,346 httpcore.http11 DEBUG receive_response_body.complete
18:44:51,347 httpcore.http11 DEBUG response_closed.started
18:44:51,347 httpcore.http11 DEBUG response_closed.complete
18:44:51,348 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:51,381 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nTop left corner.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:44:51,384 httpcore.connection DEBUG close.started
18:44:51,385 httpcore.connection DEBUG close.complete
18:44:51,385 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:44:51,387 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e6c50>
18:44:51,388 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506da720> server_hostname='api.openai.com' timeout=None
18:44:51,401 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e4310>
18:44:51,401 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:44:51,402 httpcore.http11 DEBUG send_request_headers.complete
18:44:51,403 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:44:51,403 httpcore.http11 DEBUG send_request_body.complete
18:44:51,404 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:44:52,104 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:44:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'606'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'8c3b945b27b48f9080f1644271379082'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e0f14fa64cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:44:52,107 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:44:52,107 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:44:52,108 httpcore.http11 DEBUG receive_response_body.complete
18:44:52,108 httpcore.http11 DEBUG response_closed.started
18:44:52,109 httpcore.http11 DEBUG response_closed.complete
18:44:52,109 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:44:52,448 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:52,450 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:44:59,652 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:44:59,675 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:44:59,678 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:04,879 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:04,900 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:04,904 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:10,107 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:10,127 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:10,131 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:15,333 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:15,351 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:15,354 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:22,556 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:22,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:22,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:27,780 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:27,796 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:27,799 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:33,1 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:33,20 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:33,23 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:38,225 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:38,243 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:38,246 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:43,448 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:43,466 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:43,470 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:48,674 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:48,692 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:48,695 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:53,898 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:53,915 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:45:53,919 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:45:59,121 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:45:59,126 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:45:59,131 httpcore.connection DEBUG close.started
18:45:59,131 httpcore.connection DEBUG close.complete
18:45:59,132 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:45:59,163 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e64d0>
18:45:59,164 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fd2506d9d90> server_hostname='api.openai.com' timeout=5.0
18:45:59,171 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fd2504e4a90>
18:45:59,171 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:45:59,172 httpcore.http11 DEBUG send_request_headers.complete
18:45:59,173 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:45:59,173 httpcore.http11 DEBUG send_request_body.complete
18:45:59,173 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:45:59,670 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:45:59 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'86b424eb81b7831c353cf4d5979932f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e298d81b3b9f-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:45:59,673 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:45:59,673 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:46:00,700 httpcore.http11 DEBUG receive_response_body.complete
18:46:00,701 httpcore.http11 DEBUG response_closed.started
18:46:00,702 httpcore.http11 DEBUG response_closed.complete
18:46:00,703 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:46:00,770 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:47:56,52 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:56,56 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:56,904 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:56,905 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:56,950 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:56,951 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,1 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,2 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,48 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,49 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,101 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,102 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,147 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,149 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,201 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,202 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:47:57,249 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:47:57,250 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:48:09,925 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:48:09,944 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:48:09,976 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc5689a90>
18:48:09,976 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5645d90> server_hostname='api.openai.com' timeout=5.0
18:48:09,983 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc55bfd10>
18:48:09,984 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:09,986 httpcore.http11 DEBUG send_request_headers.complete
18:48:09,986 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:09,987 httpcore.http11 DEBUG send_request_body.complete
18:48:09,988 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:10,456 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:10 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'449a95a7f51aab3ec967c1af2e7d7467'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=e9v_Yq1LjGMEUFZmhDQhdX2BRWr1F4pqoarj3JpJNTE-1702079290-1-ARwwPrWU+5K2XmjUt8yncnIwPTlPZTK+TIrHTNEufnuB+3Mj2QBXVZu0gKsbl/COp3usz96LrMZI1Mo3yMMYcZE=; path=/; expires=Sat, 09-Dec-23 00:18:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ADNQZqI8wiHniLCbIPKsSjE4Czw1gMYxw9uvawUzKEw-1702079290449-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e5ca6d904cf8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:10,463 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:48:10,464 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:11,114 httpcore.http11 DEBUG receive_response_body.complete
18:48:11,115 httpcore.http11 DEBUG response_closed.started
18:48:11,116 httpcore.http11 DEBUG response_closed.complete
18:48:11,117 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:48:11,197 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:48:24,724 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:48:24,735 httpcore.connection DEBUG close.started
18:48:24,735 httpcore.connection DEBUG close.complete
18:48:24,735 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:48:24,738 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc540d290>
18:48:24,738 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5645d90> server_hostname='api.openai.com' timeout=5.0
18:48:24,746 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc540d310>
18:48:24,747 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:24,748 httpcore.http11 DEBUG send_request_headers.complete
18:48:24,748 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:24,783 httpcore.http11 DEBUG send_request_body.complete
18:48:24,784 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:25,762 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:25 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'21'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'afec12eeba1bf50ad7035d4d1a3f18dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e626a92b4ce1-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:25,767 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:48:25,768 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:25,769 httpcore.http11 DEBUG receive_response_body.complete
18:48:25,770 httpcore.http11 DEBUG response_closed.started
18:48:25,771 httpcore.http11 DEBUG response_closed.complete
18:48:25,772 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:48:25,773 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:48:25,806 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:48:25,816 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:48:25,818 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc541f990>
18:48:25,819 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5645f40> server_hostname='api.openai.com' timeout=None
18:48:25,824 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc541f950>
18:48:25,825 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:25,826 httpcore.http11 DEBUG send_request_headers.complete
18:48:25,826 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:25,827 httpcore.http11 DEBUG send_request_body.complete
18:48:25,827 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:26,39 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7f620ed3632d59c441a29472144e2cf8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WHjNpa9IOIxC1uAayIgMQVuIe3sR4gQsdvz4vpCW3WI-1702079306-1-AVX8P8w3Ms7A353KWBIEYSweKNzXgz3QRBNkwrDnGjEInY5xyVLxE8joKyuhDadUjuHfNFeKPy79x8JOoupdKhQ=; path=/; expires=Sat, 09-Dec-23 00:18:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=zs2F1hwN2b6znnmh3UVH5c25Uut56iobzVMew6Ldrx8-1702079306035-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e62d6f404ce4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:26,46 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:48:26,46 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:26,47 httpcore.http11 DEBUG receive_response_body.complete
18:48:26,47 httpcore.http11 DEBUG response_closed.started
18:48:26,48 httpcore.http11 DEBUG response_closed.complete
18:48:26,48 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:48:26,82 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nput it in the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:48:26,93 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:48:26,96 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc55ec410>
18:48:26,96 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f6bc5646720> server_hostname='api.openai.com' timeout=None
18:48:26,103 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f6bc5431610>
18:48:26,104 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:48:26,105 httpcore.http11 DEBUG send_request_headers.complete
18:48:26,105 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:48:26,106 httpcore.http11 DEBUG send_request_body.complete
18:48:26,106 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:48:26,935 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:48:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'736'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'c114ec412e02adfc286bbe8020fbe22d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ewj2m4UQcMA6xJ7gxuZNhZvJpIVitnQvrncsKI4jhr8-1702079306-1-AdkzviaW+F1u6+IDaIAFY+WQvKoYYVabsiqV/001/ApCwCn3Ksa9jisEYJKMQnCUZ3tEvkgTryeG6rDu52MbJQU=; path=/; expires=Sat, 09-Dec-23 00:18:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1IXrh_2oGeGP1CmVdRLwHh_n9mIhlvN17KTPNVwxyW8-1702079306930-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328e62f2dd84cf4-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:48:26,942 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:48:26,942 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:48:26,943 httpcore.http11 DEBUG receive_response_body.complete
18:48:26,944 httpcore.http11 DEBUG response_closed.started
18:48:26,944 httpcore.http11 DEBUG response_closed.complete
18:48:26,944 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:49:46,538 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:46,543 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,364 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,366 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,413 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,414 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,467 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,468 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,512 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,513 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,568 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,569 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,613 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,614 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,665 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,667 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:49:47,710 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:49:47,711 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:51:27,217 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:51:27,235 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:27,265 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6f0c590>
18:51:27,266 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f99d90> server_hostname='api.openai.com' timeout=5.0
18:51:27,273 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6f0a5d0>
18:51:27,274 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:27,276 httpcore.http11 DEBUG send_request_headers.complete
18:51:27,277 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:27,278 httpcore.http11 DEBUG send_request_body.complete
18:51:27,278 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:27,739 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:27 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'382'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'89ec8f8157188fbdedbedc2939cc4ced'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cv5BcEheV2lQH63JB07Zn4QnxjPzqyFbIcOYJiHIkls-1702079487-1-AXtwi+zeEiCI05U8dZCNhwfnnybf/ryTwM3d+scARDTsC8cWu9PAdPIIiAplRDp7ypQVv2D1Dc46NQ8hrsh+vRA=; path=/; expires=Sat, 09-Dec-23 00:21:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=S.CKZe5di2.CNojoRRbkSiVLweo2LJ3cMTHHG3AYh1E-1702079487732-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ea9b7db14cdb-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:27,746 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:51:27,747 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:28,435 httpcore.http11 DEBUG receive_response_body.complete
18:51:28,436 httpcore.http11 DEBUG response_closed.started
18:51:28,437 httpcore.http11 DEBUG response_closed.complete
18:51:28,438 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:51:28,516 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:51:42,186 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:51:42,195 httpcore.connection DEBUG close.started
18:51:42,196 httpcore.connection DEBUG close.complete
18:51:42,196 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:51:42,199 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d621d0>
18:51:42,199 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f99d90> server_hostname='api.openai.com' timeout=5.0
18:51:42,204 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d62250>
18:51:42,204 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:42,205 httpcore.http11 DEBUG send_request_headers.complete
18:51:42,206 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:42,233 httpcore.http11 DEBUG send_request_body.complete
18:51:42,234 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:43,7 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:43 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'12'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'6e4c48ae0fc4da7f997a08c106ea4897'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eaf8c8426ac7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:43,13 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:51:43,14 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:43,14 httpcore.http11 DEBUG receive_response_body.complete
18:51:43,15 httpcore.http11 DEBUG response_closed.started
18:51:43,15 httpcore.http11 DEBUG response_closed.complete
18:51:43,16 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:51:43,16 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:51:43,51 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nthe middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:43,64 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:43,66 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d80610>
18:51:43,67 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f99f40> server_hostname='api.openai.com' timeout=None
18:51:43,74 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d80590>
18:51:43,74 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:43,76 httpcore.http11 DEBUG send_request_headers.complete
18:51:43,76 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:43,77 httpcore.http11 DEBUG send_request_body.complete
18:51:43,77 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:43,271 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'107'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ebb291b2736136fe297c2bc490e8b5d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6IzzDXaNhw6A_oHbLwOXHXIglQGTipgr3.U5WJ7u5kU-1702079503-1-AaLQyDjPIK0dXWyBw0s/OgOeOWeEzqpNixXjT1NkLSCBmX2bMi2mZCMDS9/Qjpe1lo6xQjjaYe8QjdWvTpEG7BI=; path=/; expires=Sat, 09-Dec-23 00:21:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=3SJBydyFukFYWn70QWR3ehIh43L2vCm4RjL.0wXZ.lY-1702079503266-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eafe3e243b69-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:43,278 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:43,279 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:43,280 httpcore.http11 DEBUG receive_response_body.complete
18:51:43,280 httpcore.http11 DEBUG response_closed.started
18:51:43,280 httpcore.http11 DEBUG response_closed.complete
18:51:43,281 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:51:43,315 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1 surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nthe middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:51:43,325 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:51:43,328 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d85dd0>
18:51:43,328 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f88f6f9a720> server_hostname='api.openai.com' timeout=None
18:51:43,334 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f88f6d85e90>
18:51:43,334 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:51:43,335 httpcore.http11 DEBUG send_request_headers.complete
18:51:43,336 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:51:43,336 httpcore.http11 DEBUG send_request_body.complete
18:51:43,337 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:51:44,154 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:51:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'727'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd275a54142d87d510b333b933f105403'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=BzcslWb8HcNPpblypowyx4qD82JTHxtYnd64sgVYzOs-1702079504-1-Aa3HhS1CV2iMPSyCXF5hdZImb/5ha8DUyJL/KVcdUPubwXu4zwEftYfixP3TabQ7ivpTB2smnnfyiNkfhQQz/SU=; path=/; expires=Sat, 09-Dec-23 00:21:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=Qthr1NCaH.k4eZDNxC7pfvx36kSbYfWLO3JCYmvUBls-1702079504149-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eaffde723074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:51:44,162 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:51:44,162 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:51:44,163 httpcore.http11 DEBUG receive_response_body.complete
18:51:44,164 httpcore.http11 DEBUG response_closed.started
18:51:44,164 httpcore.http11 DEBUG response_closed.complete
18:51:44,164 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:34,922 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:34,925 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,711 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,712 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,750 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,751 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,791 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,792 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,829 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,830 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,869 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,870 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,907 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,908 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,957 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,958 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:35,997 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:52:35,998 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:52:36,41 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:52:36,53 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:52:36,85 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd6dd0>
18:52:36,86 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a061d90> server_hostname='api.openai.com' timeout=5.0
18:52:36,95 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd7310>
18:52:36,96 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:36,98 httpcore.http11 DEBUG send_request_headers.complete
18:52:36,98 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:36,98 httpcore.http11 DEBUG send_request_body.complete
18:52:36,98 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:36,603 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'392'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'775c16faba4146365bd8c0ae07f32222'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Mfmw4EPT_jTakmvNpKDO6jMRDzRtP8VTdGi1AiaFQYA-1702079556-1-AeVKSYgiD1t9lGNvPVmasvUWXlcX6Rz4rrx5I6dTFeSsy5ioeMaL5YwcpnBNu9f99R7nzn0wBUvt4LNYSTm9gCk=; path=/; expires=Sat, 09-Dec-23 00:22:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=RFzAmMtwMLoviWsElxfjF0gQuC_Tz0MDfPvOO44BvmU-1702079556598-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ec4998264cd9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:36,608 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:52:36,608 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:37,410 httpcore.http11 DEBUG receive_response_body.complete
18:52:37,411 httpcore.http11 DEBUG response_closed.started
18:52:37,411 httpcore.http11 DEBUG response_closed.complete
18:52:37,412 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:52:37,483 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:52:51,326 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:52:51,332 httpcore.connection DEBUG close.started
18:52:51,332 httpcore.connection DEBUG close.complete
18:52:51,333 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:52:51,335 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd7250>
18:52:51,335 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a061d90> server_hostname='api.openai.com' timeout=5.0
18:52:51,342 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff839fd7610>
18:52:51,342 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:51,343 httpcore.http11 DEBUG send_request_headers.complete
18:52:51,343 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:51,373 httpcore.http11 DEBUG send_request_body.complete
18:52:51,373 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:52,191 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:52 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'350'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1190784aedabb98b9b1816cd1c691718'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328eca8ef044ce7-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:52,193 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:52:52,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:52,195 httpcore.http11 DEBUG receive_response_body.complete
18:52:52,195 httpcore.http11 DEBUG response_closed.started
18:52:52,195 httpcore.http11 DEBUG response_closed.complete
18:52:52,196 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:52:52,196 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:52:52,215 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:52,226 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:52,228 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a0340d0>
18:52:52,228 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a061f40> server_hostname='api.openai.com' timeout=None
18:52:52,237 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a034090>
18:52:52,237 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:52,238 httpcore.http11 DEBUG send_request_headers.complete
18:52:52,238 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:52,239 httpcore.http11 DEBUG send_request_body.complete
18:52:52,239 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:52,462 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'126'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'b5cfd52460b8f786f856cdff10f18595'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WNBnanKjT2zx1FCeLCTfspPIndN7Wzf0zHrr3s3pW4s-1702079572-1-AacBzi4gHxRe5M7gC5kdlUYh+mTmJqTo3cWJqwTrpoF8do9o9w/pJ+JkmX817611AnFus6vHXbWMJkMTI8be+ds=; path=/; expires=Sat, 09-Dec-23 00:22:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=qEkBcI7szGPGOXBWdPORCtFUeo0KJFd0gsnViCrBldA-1702079572458-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ecae7bc83008-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:52,466 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:52,467 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:52,468 httpcore.http11 DEBUG receive_response_body.complete
18:52:52,468 httpcore.http11 DEBUG response_closed.started
18:52:52,469 httpcore.http11 DEBUG response_closed.complete
18:52:52,469 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:52,486 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1, surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:52:52,495 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:52:52,497 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a023290>
18:52:52,497 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7ff83a062720> server_hostname='api.openai.com' timeout=None
18:52:52,503 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7ff83a020ed0>
18:52:52,504 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:52:52,504 httpcore.http11 DEBUG send_request_headers.complete
18:52:52,504 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:52:52,505 httpcore.http11 DEBUG send_request_body.complete
18:52:52,505 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:52:53,353 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:52:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'759'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'6fea5a5d84504d3c70e1b0723cbfdc4c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=3uo9fb4A5hlcwwhbM4DHbLKQqAnx.pVFQvURi67oK.E-1702079573-1-AXvDqDkGfe8ylgrvbpOJmH1sVrwvvAizG6DEoUaQk36tZBu1jg/XDiK2Rqy/kywhGmWaISH2t3NSHprmRZUerYo=; path=/; expires=Sat, 09-Dec-23 00:22:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=C3caYzHytfZdkIme09_IYeUnnEIBFzQl33oZuxI5710-1702079573350-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ecb02e5b3b9f-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:52:53,356 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:52:53,357 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:52:53,358 httpcore.http11 DEBUG receive_response_body.complete
18:52:53,358 httpcore.http11 DEBUG response_closed.started
18:52:53,358 httpcore.http11 DEBUG response_closed.complete
18:52:53,359 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:52:53,554 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:52:53,557 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:53:00,762 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:53:00,770 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:53:00,772 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:53:05,973 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:53:05,986 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:53:05,987 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:53:41,707 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:41,710 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,528 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,530 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,579 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,581 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,631 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,632 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,676 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,677 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,728 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,729 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,774 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,775 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,832 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,834 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:42,880 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:53:42,882 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:53:51,122 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:53:51,142 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:53:51,174 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f6058610>
18:53:51,175 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e5d90> server_hostname='api.openai.com' timeout=5.0
18:53:51,181 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f6061090>
18:53:51,182 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:53:51,183 httpcore.http11 DEBUG send_request_headers.complete
18:53:51,184 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:53:51,184 httpcore.http11 DEBUG send_request_body.complete
18:53:51,184 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:53:51,655 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:53:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'390'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ee28c9c26f6477a1f7fbd742e2976d2f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=thxRTcHv4WcPdJuqTdGu.rE6CSxx7Be5tJOUUwFMXnE-1702079631-1-ARJSeC8V96/xLNaEzjJqrqn/Q0xoAgJMrcELjPPbkU0CI10puUWupQotIlvAKil6zi4jA1KAQ6ewh6JBZpZv3is=; path=/; expires=Sat, 09-Dec-23 00:23:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=a9cRWtm88Di0eqdaHTp4y4BS66EudSZZZzOlssMsAMY-1702079631648-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee1eeeaa4d18-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:53:51,667 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:53:51,668 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:53:52,427 httpcore.http11 DEBUG receive_response_body.complete
18:53:52,428 httpcore.http11 DEBUG response_closed.started
18:53:52,429 httpcore.http11 DEBUG response_closed.complete
18:53:52,430 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:53:52,512 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:54:06,458 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:54:06,468 httpcore.connection DEBUG close.started
18:54:06,469 httpcore.connection DEBUG close.complete
18:54:06,469 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:54:06,472 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5eade10>
18:54:06,472 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e5d90> server_hostname='api.openai.com' timeout=5.0
18:54:06,478 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5eade90>
18:54:06,478 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:54:06,479 httpcore.http11 DEBUG send_request_headers.complete
18:54:06,480 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:54:06,508 httpcore.http11 DEBUG send_request_body.complete
18:54:06,509 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:54:07,298 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:54:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'15'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'79eea58607ea2273c9cbc7676dc585dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee7e79ad3ba5-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:54:07,303 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:54:07,304 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:54:07,306 httpcore.http11 DEBUG receive_response_body.complete
18:54:07,307 httpcore.http11 DEBUG response_closed.started
18:54:07,308 httpcore.http11 DEBUG response_closed.complete
18:54:07,309 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:54:07,310 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:54:07,345 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:54:07,360 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:54:07,364 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ecc610>
18:54:07,364 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e5f40> server_hostname='api.openai.com' timeout=None
18:54:07,370 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ecc590>
18:54:07,371 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:54:07,372 httpcore.http11 DEBUG send_request_headers.complete
18:54:07,372 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:54:07,373 httpcore.http11 DEBUG send_request_body.complete
18:54:07,373 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:54:07,597 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:54:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'412c66d70872091d1f00b7ff86f2589d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yLoFHGZAWxMqZiD0Ku9AIawNZn.sjxp9.uC6buXy_NQ-1702079647-1-AW8zA0kLS/F3M+ByUObm3+6cXLn8lf9xsSuYlHXBS5NGtjbU/3g3bn6nBroqZBsIyC+LPV4cy3qiOSwn8pYXfkc=; path=/; expires=Sat, 09-Dec-23 00:24:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=ASop8s9C.97.346TCxsFoC4M2dvULj3I_6brHiRML3g-1702079647592-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee841f484cd5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:54:07,605 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:54:07,607 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:54:07,609 httpcore.http11 DEBUG receive_response_body.complete
18:54:07,610 httpcore.http11 DEBUG response_closed.started
18:54:07,610 httpcore.http11 DEBUG response_closed.complete
18:54:07,611 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:54:07,646 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height / 2\nlambda x1, surface_width: x1 > surface_width / 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height / 2\nlambda x1 surface_width: x1 == surface_width / 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nIn the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:54:07,659 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:54:07,662 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ed1a90>
18:54:07,663 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f97f60e6720> server_hostname='api.openai.com' timeout=None
18:54:07,668 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f97f5ed2810>
18:54:07,668 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:54:07,669 httpcore.http11 DEBUG send_request_headers.complete
18:54:07,670 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:54:07,670 httpcore.http11 DEBUG send_request_body.complete
18:54:07,670 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:54:08,569 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:54:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'802'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'73a59ff0790f3ac4a47084f33242f1de'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=ovigVkpz1HTHiuqtL9srzDmoTvhTO2BII3yc2rReqxM-1702079648-1-Ae2/H9JZSgVzHGyMa0sI6VRD4uuGamLZ2LpfXlDBZRpLIj3PNRGu3LamzXx0phYheG+n3/klrQpC9SFZUeqYR8s=; path=/; expires=Sat, 09-Dec-23 00:24:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=kbnLYr3Z6nPOYndHky9SpbvjWe2poxL8kbUfxBqKX0A-1702079648564-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328ee85ebe44cc9-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:54:08,577 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:54:08,578 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:54:08,578 httpcore.http11 DEBUG receive_response_body.complete
18:54:08,579 httpcore.http11 DEBUG response_closed.started
18:54:08,579 httpcore.http11 DEBUG response_closed.complete
18:54:08,579 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:57:45,844 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:45,850 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,683 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,684 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,733 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,734 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,785 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,786 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,829 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,830 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,879 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,880 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,922 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,923 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:46,971 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:46,972 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:47,12 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
18:57:47,13 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
18:57:50,834 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:57:50,853 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:57:50,898 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6850>
18:57:50,898 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631d90> server_hostname='api.openai.com' timeout=5.0
18:57:50,906 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6d50>
18:57:50,906 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:57:50,908 httpcore.http11 DEBUG send_request_headers.complete
18:57:50,909 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:57:50,909 httpcore.http11 DEBUG send_request_body.complete
18:57:50,910 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:57:51,549 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:57:51 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'520'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'b3b96eca2e0f0adc5e3fdb377eb81365'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=IvRsw4EWyqP75u9_k8UmWBJe8fgpbv2iaRXRvbRhEDA-1702079871-1-Aa9w8lAwGGkmDaFqWrWqmE0eFzSzF+F5uiEn7yXyRftMbU5JAta9XtSvOpGFdFFcbsEsk9CNvfMcCKK78X3KYro=; path=/; expires=Sat, 09-Dec-23 00:27:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=n804DXmYhBUICp43ibOi_zeYTzFrfGiPs1PQZf8OHwM-1702079871541-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f3f92f4a4cd8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:57:51,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:57:51,557 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:57:52,336 httpcore.http11 DEBUG receive_response_body.complete
18:57:52,337 httpcore.http11 DEBUG response_closed.started
18:57:52,338 httpcore.http11 DEBUG response_closed.complete
18:57:52,339 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:57:52,417 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
18:58:06,160 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
18:58:06,170 httpcore.connection DEBUG close.started
18:58:06,170 httpcore.connection DEBUG close.complete
18:58:06,171 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:58:06,173 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6d50>
18:58:06,173 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631d90> server_hostname='api.openai.com' timeout=5.0
18:58:06,180 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b6e90>
18:58:06,181 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:06,182 httpcore.http11 DEBUG send_request_headers.complete
18:58:06,182 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:06,215 httpcore.http11 DEBUG send_request_body.complete
18:58:06,215 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:07,24 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:58:07 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'349'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'ff25fa70e96caff7bde9b19b211527c7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f458acb23018-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:07,29 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
18:58:07,29 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:07,30 httpcore.http11 DEBUG receive_response_body.complete
18:58:07,30 httpcore.http11 DEBUG response_closed.started
18:58:07,31 httpcore.http11 DEBUG response_closed.complete
18:58:07,31 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
18:58:07,32 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
18:58:07,65 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:07,77 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:07,79 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715fdc50>
18:58:07,80 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631f40> server_hostname='api.openai.com' timeout=None
18:58:07,86 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715fd350>
18:58:07,87 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:07,88 httpcore.http11 DEBUG send_request_headers.complete
18:58:07,88 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:07,88 httpcore.http11 DEBUG send_request_body.complete
18:58:07,89 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:07,313 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:58:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'5ed6a9f9d2d30e4543be80a86ff586c3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=G3E8TL4a8hKafqYK81ZWneet7UwuE5ZLoHvnEkF.lZ8-1702079887-1-ARR87A7TjBQy0OAwREz2bL/L0wL1zHCTO+tqJVrG9NjbGT3jzGPYxwq/k/8wqXy6ba6+nNse1egX2lXT95f4G8g=; path=/; expires=Sat, 09-Dec-23 00:28:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=EbKlL5x6HOTuU2zpmvGpktFeB23WTYBRy2pi.o66bKs-1702079887310-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f45e4c384cc3-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:07,317 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:07,318 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:07,319 httpcore.http11 DEBUG receive_response_body.complete
18:58:07,319 httpcore.http11 DEBUG response_closed.started
18:58:07,320 httpcore.http11 DEBUG response_closed.complete
18:58:07,320 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:07,359 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2\nlambda x1 surface_width: x1 == surface_width // 2                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nin the middle\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
18:58:07,372 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
18:58:07,375 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8171420190>
18:58:07,375 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172632720> server_hostname='api.openai.com' timeout=None
18:58:07,381 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f8171420110>
18:58:07,381 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:58:07,382 httpcore.http11 DEBUG send_request_headers.complete
18:58:07,382 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:58:07,383 httpcore.http11 DEBUG send_request_body.complete
18:58:07,383 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:58:08,332 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:58:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'839'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'e001f844add94d9f1ba790550ea41a31'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=PRgqPKtcRrmPT5tMYG_bDk3mIJV9E3gZbq2sAnWZ1bc-1702079888-1-AQZaM1buRl1/7SwgVQuU/VaiWgk0F82DBVpwQRP0Zrs3thRYXvc34+dtF3kX3Y/0A1fe35TB0iRgfSbQjVQl6Ug=; path=/; expires=Sat, 09-Dec-23 00:28:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=lQ3QATF2tG1CdKrR0FKlVaOIroZqEoE.x5h20qnM.ss-1702079888327-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f4602cde4ce1-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:58:08,340 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
18:58:08,341 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:58:08,342 httpcore.http11 DEBUG receive_response_body.complete
18:58:08,342 httpcore.http11 DEBUG response_closed.started
18:58:08,343 httpcore.http11 DEBUG response_closed.complete
18:58:08,343 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
18:58:48,906 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:58:48,910 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:58:56,120 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:58:56,134 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:58:56,141 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:01,344 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:01,362 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:01,365 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:06,567 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:06,586 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:06,590 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:11,791 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:11,810 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:11,813 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:19,16 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:19,34 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:19,37 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:24,239 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:24,255 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:24,257 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:29,459 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:29,479 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:29,482 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:34,684 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:34,700 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
18:59:34,705 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
18:59:39,907 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
18:59:39,914 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
18:59:39,920 httpcore.connection DEBUG close.started
18:59:39,920 httpcore.connection DEBUG close.complete
18:59:39,921 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
18:59:39,953 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715b7010>
18:59:39,953 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7f8172631d90> server_hostname='api.openai.com' timeout=5.0
18:59:39,961 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f81715a0e50>
18:59:39,961 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
18:59:39,963 httpcore.http11 DEBUG send_request_headers.complete
18:59:39,963 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
18:59:39,964 httpcore.http11 DEBUG send_request_body.complete
18:59:39,965 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
18:59:40,477 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 08 Dec 2023 23:59:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'421'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f4e8abc5cdee16d649b4e143ecda98a2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f6a2cc7b4d1c-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
18:59:40,482 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
18:59:40,484 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
18:59:41,426 httpcore.http11 DEBUG receive_response_body.complete
18:59:41,427 httpcore.http11 DEBUG response_closed.started
18:59:41,427 httpcore.http11 DEBUG response_closed.complete
18:59:41,428 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
18:59:41,495 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:01:42,181 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:42,184 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,24 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,25 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,67 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,68 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,115 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,116 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,156 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,157 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,204 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,205 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,246 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,247 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,295 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,296 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:43,336 httpx DEBUG load_ssl_context verify=True cert=None trust_env=True http2=False
19:01:43,337 httpx DEBUG load_verify_locations cafile='/home/hrilab/miniconda3/envs/candlePlacementPilot/lib/python3.11/site-packages/certifi/cacert.pem'
19:01:44,672 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Hi, Vincent. Let us decorate a cake. Where should I place the first candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:01:44,687 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:01:44,717 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f13f90>
19:01:44,718 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:01:44,724 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f13ed0>
19:01:44,725 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:01:44,728 httpcore.http11 DEBUG send_request_headers.complete
19:01:44,729 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:01:44,730 httpcore.http11 DEBUG send_request_body.complete
19:01:44,730 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:01:45,369 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:01:45 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'522'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'cd6e9133806440c15d35f02475c3a83d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WVaETcnGkhLhF8PNV19cPKqYMbAZPi5EZyhK5CALbKU-1702080105-1-AfejuIfypisadAKse/Dd3U1Gmq6BtqKTHTR7KzV5/XZ5UWmJWzMVRZKfc9XYBsqrowhZ5vyxQGzZQuogmD1g2Dg=; path=/; expires=Sat, 09-Dec-23 00:31:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OM7OSsBXbfwjVGM4vaibR0NEi1C1qeM3fY99iiT1ZZ0-1702080105364-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328f9ae880f3068-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:01:45,379 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:01:45,380 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:01:46,158 httpcore.http11 DEBUG receive_response_body.complete
19:01:46,159 httpcore.http11 DEBUG response_closed.started
19:01:46,160 httpcore.http11 DEBUG response_closed.complete
19:01:46,161 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:01:46,247 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent0.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:02:00,82 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent0.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:02:00,94 httpcore.connection DEBUG close.started
19:02:00,95 httpcore.connection DEBUG close.complete
19:02:00,95 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:02:00,98 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f13ed0>
19:02:00,98 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:02:00,104 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243fcf350>
19:02:00,105 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:02:00,106 httpcore.http11 DEBUG send_request_headers.complete
19:02:00,106 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:02:00,160 httpcore.http11 DEBUG send_request_body.complete
19:02:00,161 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:02:01,39 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:02:01 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'22'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'371'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'23cec489945949461f1848e19aa2034f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fa0ead4c4cc6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:02:01,45 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:02:01,46 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:02:01,47 httpcore.http11 DEBUG receive_response_body.complete
19:02:01,47 httpcore.http11 DEBUG response_closed.started
19:02:01,47 httpcore.http11 DEBUG response_closed.complete
19:02:01,48 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:02:01,49 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:02:01,91 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:02:01,103 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:02:01,105 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d80410>
19:02:01,106 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:02:01,116 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d803d0>
19:02:01,117 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:02:01,118 httpcore.http11 DEBUG send_request_headers.complete
19:02:01,119 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:02:01,119 httpcore.http11 DEBUG send_request_body.complete
19:02:01,120 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:02:01,377 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:02:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'fcc9183ac8a21c416d5d0f88fed1b093'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=x8m7i0IsrJIAVIPzhK.sQ9fzVqXJehZ4B4t2LZR5n94-1702080121-1-AaUg6xnIruC9j8M+VcSyHVxfYmRFfWMmBilgKBfe0lv8iUH8G9y7tyumpbHEI8AmhqUgJPxjGkp9t9Vu2new3a8=; path=/; expires=Sat, 09-Dec-23 00:32:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=A65AmvKHgPjBv8Urd0GxGvpA9RWRs2pJn.7iZ1TGXA8-1702080121372-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fa14fe644d0b-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:02:01,385 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:02:01,386 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:02:01,387 httpcore.http11 DEBUG receive_response_body.complete
19:02:01,387 httpcore.http11 DEBUG response_closed.started
19:02:01,388 httpcore.http11 DEBUG response_closed.complete
19:02:01,388 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:02:01,423 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nHi, Vincent. Let us decorate a cake. Where should I place the first candle?\n'''\nAnd the human answered\n'''\nPut it in the middle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:02:01,434 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:02:01,437 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d5fed0>
19:02:01,437 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9e720> server_hostname='api.openai.com' timeout=None
19:02:01,442 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d5fcd0>
19:02:01,443 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:02:01,444 httpcore.http11 DEBUG send_request_headers.complete
19:02:01,444 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:02:01,445 httpcore.http11 DEBUG send_request_body.complete
19:02:01,445 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:02:02,550 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:02:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'1014'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'ba22ca9eefe7237d9cb5cf93067b8211'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=yz8JsX975OWbJv1CWRyPS9VSe494XdcZlsJnK5memO8-1702080122-1-ARYWIvVH7ENMThNzpSWuYg2CAo4g8FuYzSBeqZ6PYhXAvXKz53SqL5mgfeMW8q/vu6YtV8aaU0D8UMhCA5GM4U0=; path=/; expires=Sat, 09-Dec-23 00:32:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=DjpjU9E5MDJWZLYXdzoNAiQoVnXTeO74E3gt7UvXpsQ-1702080122545-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fa170b6d3025-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:02:02,556 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:02:02,557 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:02:02,558 httpcore.http11 DEBUG receive_response_body.complete
19:02:02,559 httpcore.http11 DEBUG response_closed.started
19:02:02,559 httpcore.http11 DEBUG response_closed.complete
19:02:02,559 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:02:02,582 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:02,586 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:09,794 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:09,808 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:09,812 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:15,14 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:15,33 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:15,36 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:20,239 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:20,257 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:20,260 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:25,463 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:25,480 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:25,484 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:32,686 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:32,705 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:32,708 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:37,909 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:37,927 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:37,931 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:43,133 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:43,151 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:43,155 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:48,359 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:48,376 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:48,379 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:53,581 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:53,598 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:53,601 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:02:58,803 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:02:58,822 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:02:58,825 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:04,27 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:04,34 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:03:04,40 httpcore.connection DEBUG close.started
19:03:04,40 httpcore.connection DEBUG close.complete
19:03:04,40 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:04,69 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe2440e1950>
19:03:04,70 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:04,77 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d8fdd0>
19:03:04,78 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:04,80 httpcore.http11 DEBUG send_request_headers.complete
19:03:04,80 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:04,81 httpcore.http11 DEBUG send_request_body.complete
19:03:04,82 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:04,765 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:04 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'552'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'47945773f414b2f53227d942fb597e27'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fb9e8b694cfe-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:04,769 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:03:04,770 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:05,646 httpcore.http11 DEBUG receive_response_body.complete
19:03:05,647 httpcore.http11 DEBUG response_closed.started
19:03:05,648 httpcore.http11 DEBUG response_closed.complete
19:03:05,649 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:03:05,716 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent1.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:03:18,400 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent1.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:03:18,406 httpcore.connection DEBUG close.started
19:03:18,407 httpcore.connection DEBUG close.complete
19:03:18,407 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:18,409 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daae10>
19:03:18,410 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:18,416 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daae90>
19:03:18,417 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:18,418 httpcore.http11 DEBUG send_request_headers.complete
19:03:18,418 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:18,442 httpcore.http11 DEBUG send_request_body.complete
19:03:18,443 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:19,161 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:19 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'5a66179a0c4fc8470c94e186a4cdaac5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fbf81cd74d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:19,166 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:03:19,167 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:19,169 httpcore.http11 DEBUG receive_response_body.complete
19:03:19,169 httpcore.http11 DEBUG response_closed.started
19:03:19,170 httpcore.http11 DEBUG response_closed.complete
19:03:19,171 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:03:19,172 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:03:19,200 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:19,204 httpcore.connection DEBUG close.started
19:03:19,204 httpcore.connection DEBUG close.complete
19:03:19,204 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:19,207 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243da9bd0>
19:03:19,207 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:03:19,214 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daa990>
19:03:19,214 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:19,215 httpcore.http11 DEBUG send_request_headers.complete
19:03:19,215 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:19,216 httpcore.http11 DEBUG send_request_body.complete
19:03:19,216 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:19,441 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'132'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'4d850911e3ab92dc8e2131898e4fd3cd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fbfd1ac44d05-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:19,447 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:19,447 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:19,448 httpcore.http11 DEBUG receive_response_body.complete
19:03:19,449 httpcore.http11 DEBUG response_closed.started
19:03:19,449 httpcore.http11 DEBUG response_closed.complete
19:03:19,450 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:19,482 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:19,493 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:19,496 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fd50>
19:03:19,496 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:03:19,501 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fe10>
19:03:19,501 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:19,503 httpcore.http11 DEBUG send_request_headers.complete
19:03:19,503 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:19,503 httpcore.http11 DEBUG send_request_body.complete
19:03:19,504 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:19,733 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'138'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'7af4f9f0af9180030c819aa00c2c97c4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=YFaREg4nOIA.DoUyA6p0fLht9BLGrpMUsf.bX1tFE5U-1702080199-1-AdZnRyw64l0yHTxiBzC5sLkrk8ZBoBY5wYaBG0TNQWeBj2pppOUxaZQjWUvbpLcb7zQCRFkfq380c58hWF1BHDo=; path=/; expires=Sat, 09-Dec-23 00:33:19 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=mlhRjw1nqy4Op7tWJvXGRo01vSJo6cVXOcVD.rYMTac-1702080199729-0-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fbfeec334cf8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:19,738 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:19,739 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:19,741 httpcore.http11 DEBUG receive_response_body.complete
19:03:19,741 httpcore.http11 DEBUG response_closed.started
19:03:19,742 httpcore.http11 DEBUG response_closed.complete
19:03:19,742 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:19,756 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:19,759 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:24,960 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:24,978 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:24,981 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:30,183 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:30,200 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:30,203 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:35,405 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:35,413 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the second candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:03:35,420 httpcore.connection DEBUG close.started
19:03:35,420 httpcore.connection DEBUG close.complete
19:03:35,420 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:35,423 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243da9410>
19:03:35,424 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:35,431 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daaf90>
19:03:35,432 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:35,433 httpcore.http11 DEBUG send_request_headers.complete
19:03:35,434 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:35,434 httpcore.http11 DEBUG send_request_body.complete
19:03:35,435 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:35,879 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:35 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'1171da99a282cf7ce62b08886bc57a78'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fc6279ae3059-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:35,885 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:03:35,885 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:36,337 httpcore.http11 DEBUG receive_response_body.complete
19:03:36,338 httpcore.http11 DEBUG response_closed.started
19:03:36,338 httpcore.http11 DEBUG response_closed.complete
19:03:36,340 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:03:36,413 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent2.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:03:47,981 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent2.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:03:47,986 httpcore.connection DEBUG close.started
19:03:47,986 httpcore.connection DEBUG close.complete
19:03:47,986 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:03:47,989 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2f90>
19:03:47,989 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:03:47,995 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db3010>
19:03:47,995 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:47,996 httpcore.http11 DEBUG send_request_headers.complete
19:03:47,997 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:48,30 httpcore.http11 DEBUG send_request_body.complete
19:03:48,31 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:48,902 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'40'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'68ec42b20cc7ab24e5f95cabbc8e2f06'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fcb0fb504cf2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:48,909 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:03:48,910 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:48,911 httpcore.http11 DEBUG receive_response_body.complete
19:03:48,912 httpcore.http11 DEBUG response_closed.started
19:03:48,913 httpcore.http11 DEBUG response_closed.complete
19:03:48,914 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:03:48,914 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:03:48,943 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:48,946 httpcore.connection DEBUG close.started
19:03:48,947 httpcore.connection DEBUG close.complete
19:03:48,947 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:48,949 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2110>
19:03:48,950 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:03:48,957 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2190>
19:03:48,958 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:48,959 httpcore.http11 DEBUG send_request_headers.complete
19:03:48,959 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:48,959 httpcore.http11 DEBUG send_request_body.complete
19:03:48,960 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:49,171 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'122'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'd147926c3c075eb20118aeae2ce65ca4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fcb6fb7c3051-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:49,176 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:49,177 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:49,179 httpcore.http11 DEBUG receive_response_body.complete
19:03:49,180 httpcore.http11 DEBUG response_closed.started
19:03:49,181 httpcore.http11 DEBUG response_closed.complete
19:03:49,182 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:49,218 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it to the left of the first candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:03:49,221 httpcore.connection DEBUG close.started
19:03:49,221 httpcore.connection DEBUG close.complete
19:03:49,222 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:03:49,224 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d8c710>
19:03:49,225 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9e720> server_hostname='api.openai.com' timeout=None
19:03:49,231 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7da50>
19:03:49,232 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:03:49,233 httpcore.http11 DEBUG send_request_headers.complete
19:03:49,233 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:03:49,234 httpcore.http11 DEBUG send_request_body.complete
19:03:49,234 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:03:49,770 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:03:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'394'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2ef90031b681f7b24d8722b25668f953'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fcb8bd8f4cf8-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:03:49,777 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:03:49,778 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:03:49,780 httpcore.http11 DEBUG receive_response_body.complete
19:03:49,781 httpcore.http11 DEBUG response_closed.started
19:03:49,781 httpcore.http11 DEBUG response_closed.complete
19:03:49,782 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:03:49,798 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:49,801 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:03:57,3 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:03:57,21 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:03:57,28 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:02,230 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:02,248 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:02,251 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:07,453 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:07,471 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:07,475 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:12,677 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:12,693 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:12,697 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:19,898 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:19,915 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:19,918 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:25,120 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:25,137 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:25,142 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:30,344 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:30,362 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:30,366 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:35,568 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:35,574 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:04:35,579 httpcore.connection DEBUG close.started
19:04:35,579 httpcore.connection DEBUG close.complete
19:04:35,580 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:04:35,609 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2f10>
19:04:35,609 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:04:35,617 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2490>
19:04:35,618 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:35,620 httpcore.http11 DEBUG send_request_headers.complete
19:04:35,621 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:35,622 httpcore.http11 DEBUG send_request_body.complete
19:04:35,623 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:36,126 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:36 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'bc13ad7bf9a0d19998e061321b92e1dc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fddaaca64cff-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:36,131 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:04:36,132 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:37,157 httpcore.http11 DEBUG receive_response_body.complete
19:04:37,158 httpcore.http11 DEBUG response_closed.started
19:04:37,159 httpcore.http11 DEBUG response_closed.complete
19:04:37,161 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:04:37,228 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent3.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:04:49,833 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent3.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:04:49,837 httpcore.connection DEBUG close.started
19:04:49,838 httpcore.connection DEBUG close.complete
19:04:49,838 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:04:49,867 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dabe10>
19:04:49,868 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:04:49,876 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243da9c50>
19:04:49,876 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:49,878 httpcore.http11 DEBUG send_request_headers.complete
19:04:49,878 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:49,903 httpcore.http11 DEBUG send_request_body.complete
19:04:49,904 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:50,643 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:50 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'343'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'fa17006c87aeb734210acccb7315c945'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe33b8df4cf9-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:50,646 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:04:50,646 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:50,647 httpcore.http11 DEBUG receive_response_body.complete
19:04:50,647 httpcore.http11 DEBUG response_closed.started
19:04:50,648 httpcore.http11 DEBUG response_closed.complete
19:04:50,648 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:04:50,649 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:04:50,678 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:04:50,681 httpcore.connection DEBUG close.started
19:04:50,681 httpcore.connection DEBUG close.complete
19:04:50,682 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:04:50,684 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2990>
19:04:50,685 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:04:50,690 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc06d0>
19:04:50,691 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:50,691 httpcore.http11 DEBUG send_request_headers.complete
19:04:50,692 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:50,692 httpcore.http11 DEBUG send_request_body.complete
19:04:50,692 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:50,903 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'118'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'70b7b71bd7c0cc2625ed9785264198e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe38dd264cef-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:50,909 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:04:50,910 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:50,911 httpcore.http11 DEBUG receive_response_body.complete
19:04:50,912 httpcore.http11 DEBUG response_closed.started
19:04:50,912 httpcore.http11 DEBUG response_closed.complete
19:04:50,913 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:04:50,946 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:04:50,949 httpcore.connection DEBUG close.started
19:04:50,949 httpcore.connection DEBUG close.complete
19:04:50,950 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:04:50,952 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fe10>
19:04:50,953 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:04:50,957 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fd10>
19:04:50,958 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:04:50,959 httpcore.http11 DEBUG send_request_headers.complete
19:04:50,959 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:04:50,959 httpcore.http11 DEBUG send_request_body.complete
19:04:50,960 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:04:51,189 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:04:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'137'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'eadafd5d547cf97835c778ad942fc690'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe3a7cd24cd6-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:04:51,194 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:04:51,194 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:04:51,196 httpcore.http11 DEBUG receive_response_body.complete
19:04:51,196 httpcore.http11 DEBUG response_closed.started
19:04:51,197 httpcore.http11 DEBUG response_closed.complete
19:04:51,197 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:04:51,214 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:51,217 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:04:56,419 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:04:56,435 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:04:56,439 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:01,641 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:01,661 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:01,664 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:06,867 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:06,874 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Where should I place the third candle?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:05:06,879 httpcore.connection DEBUG close.started
19:05:06,880 httpcore.connection DEBUG close.complete
19:05:06,880 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:06,883 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daac10>
19:05:06,883 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:05:06,892 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dab5d0>
19:05:06,892 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:06,894 httpcore.http11 DEBUG send_request_headers.complete
19:05:06,894 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:06,894 httpcore.http11 DEBUG send_request_body.complete
19:05:06,895 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:07,526 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:07 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'484'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'e4cb57ceb0b846f02c4076695ac13f9f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fe9e1d834cc0-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:07,532 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:05:07,532 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:07,894 httpcore.http11 DEBUG receive_response_body.complete
19:05:07,895 httpcore.http11 DEBUG response_closed.started
19:05:07,895 httpcore.http11 DEBUG response_closed.complete
19:05:07,896 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:05:07,962 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent4.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:05:19,401 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent4.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:05:19,405 httpcore.connection DEBUG close.started
19:05:19,406 httpcore.connection DEBUG close.complete
19:05:19,406 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:05:19,409 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7f4d0>
19:05:19,409 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:05:19,417 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243f0e510>
19:05:19,418 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:19,419 httpcore.http11 DEBUG send_request_headers.complete
19:05:19,419 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:19,451 httpcore.http11 DEBUG send_request_body.complete
19:05:19,452 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:20,337 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:20 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'434'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'4f98f20d22b2d1683bedf6b5b69f56f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328feec5de83059-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:20,343 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:05:20,344 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:20,346 httpcore.http11 DEBUG receive_response_body.complete
19:05:20,346 httpcore.http11 DEBUG response_closed.started
19:05:20,347 httpcore.http11 DEBUG response_closed.complete
19:05:20,347 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:05:20,348 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:05:20,376 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it between the first candle and second candle.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:20,380 httpcore.connection DEBUG close.started
19:05:20,380 httpcore.connection DEBUG close.complete
19:05:20,381 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:20,384 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc06d0>
19:05:20,384 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:05:20,389 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc2750>
19:05:20,390 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:20,391 httpcore.http11 DEBUG send_request_headers.complete
19:05:20,391 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:20,391 httpcore.http11 DEBUG send_request_body.complete
19:05:20,392 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:20,618 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'130'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'2a9b177b774968eda5a755ad3b1f1625'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fef27e484cdb-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:20,623 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:20,624 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:20,625 httpcore.http11 DEBUG receive_response_body.complete
19:05:20,626 httpcore.http11 DEBUG response_closed.started
19:05:20,626 httpcore.http11 DEBUG response_closed.complete
19:05:20,627 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:20,662 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nIt should be on the top right side of the cake and on the same horizontal line with the first candle.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 > surface_height // 2\nlambda x1, surface_width: x1 > surface_width // 2\nlambda y0, y1: y1==y0\n                                               \nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the second candle?\n'''\nAnd the human answered\n'''\nPut it in the center.\n'''\nExpress the human's preference for candle placement as a list of lambda functions with logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\nlambda y1, surface_height: y1 == surface_height // 2 + 1\nlambda x1 surface_width: x1 == surface_width // 2 + 1                                               \n\nYou are an assistant robot helping a human place candles on a cake. The task is to place 3 candles on the 2D top surface of the cake. The cake is 5 in the x direction and 5 in the y direction. The bottom left corner of the cake is (0,0). The top right corner of the cake (5, 5). You asked \n'''\nWhere should I place the third candle?\n'''\nAnd the human answered\n'''\nPut it between the first candle and second candle.\n\n'''\nExpress the human's preference as a list of logic constraints on the following variables: first candle x0, y0, second candle x1, y1, third candle x2, y2, surface_width indicating the width of the 2D surface, surface_height indicating the height of the 2D surface.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:05:20,666 httpcore.connection DEBUG close.started
19:05:20,666 httpcore.connection DEBUG close.complete
19:05:20,666 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:05:20,669 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d5fcd0>
19:05:20,669 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9e720> server_hostname='api.openai.com' timeout=None
19:05:20,675 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db3c90>
19:05:20,675 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:05:20,676 httpcore.http11 DEBUG send_request_headers.complete
19:05:20,676 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:05:20,677 httpcore.http11 DEBUG send_request_body.complete
19:05:20,677 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:05:21,712 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:05:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'952'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'9a5d8bc83c80f762753f90ca58062994'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8328fef439413068-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:05:21,719 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:05:21,720 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:05:21,722 httpcore.http11 DEBUG receive_response_body.complete
19:05:21,722 httpcore.http11 DEBUG response_closed.started
19:05:21,723 httpcore.http11 DEBUG response_closed.complete
19:05:21,723 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:05:22,326 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:22,329 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:29,531 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:29,551 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:29,554 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:34,755 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:34,773 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:34,776 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:39,978 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:39,996 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:40,0 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:45,204 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:45,221 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:45,224 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:52,426 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:52,443 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:52,447 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:05:57,650 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:05:57,668 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:05:57,672 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:02,875 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:02,893 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:02,896 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:08,98 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:08,119 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:08,122 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:13,324 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:13,340 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:13,344 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:18,546 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:18,554 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location? You can say either yes, or move to the left, to the right, move up or move down.', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:18,559 httpcore.connection DEBUG close.started
19:06:18,559 httpcore.connection DEBUG close.complete
19:06:18,560 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:18,590 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd0c10>
19:06:18,590 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:18,598 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd0210>
19:06:18,599 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:18,601 httpcore.http11 DEBUG send_request_headers.complete
19:06:18,601 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:18,602 httpcore.http11 DEBUG send_request_body.complete
19:06:18,602 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:19,186 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:19 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'507'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'9986ac1178e3429391ead91f39c3c691'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329005e48ec4ce6-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:19,192 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:19,193 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:20,200 httpcore.http11 DEBUG receive_response_body.complete
19:06:20,201 httpcore.http11 DEBUG response_closed.started
19:06:20,202 httpcore.http11 DEBUG response_closed.complete
19:06:20,203 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:20,276 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent5.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:32,866 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent5.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:32,872 httpcore.connection DEBUG close.started
19:06:32,872 httpcore.connection DEBUG close.complete
19:06:32,872 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:32,875 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd2dd0>
19:06:32,875 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:32,883 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd2e50>
19:06:32,884 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:32,885 httpcore.http11 DEBUG send_request_headers.complete
19:06:32,885 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:32,911 httpcore.http11 DEBUG send_request_body.complete
19:06:32,911 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:33,708 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:33 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'14'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'352'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0c56ab70c1a50f4276d3aa4ef9ad6048'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900b78e6c4cc8-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:33,710 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:33,710 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:33,711 httpcore.http11 DEBUG receive_response_body.complete
19:06:33,711 httpcore.http11 DEBUG response_closed.started
19:06:33,712 httpcore.http11 DEBUG response_closed.complete
19:06:33,712 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:33,713 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:33,741 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nTo the right.\n\n'''\nDetermine whether the human's answer is related to your question. Answer with 'yes' or 'no' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:33,745 httpcore.connection DEBUG close.started
19:06:33,745 httpcore.connection DEBUG close.complete
19:06:33,746 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:33,748 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc6d10>
19:06:33,749 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9df40> server_hostname='api.openai.com' timeout=None
19:06:33,755 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc5410>
19:06:33,755 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:33,756 httpcore.http11 DEBUG send_request_headers.complete
19:06:33,756 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:33,757 httpcore.http11 DEBUG send_request_body.complete
19:06:33,757 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:33,976 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'114'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'f24d6a64c7bb4aeeb758034f6d20aa68'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900bcfd1b4cf0-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:33,982 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:33,983 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:33,984 httpcore.http11 DEBUG receive_response_body.complete
19:06:33,985 httpcore.http11 DEBUG response_closed.started
19:06:33,985 httpcore.http11 DEBUG response_closed.complete
19:06:33,986 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:34,20 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location? You can say either yes, or move to the left, to the right, move up or move down.\n'''\nAnd the human answered\n'''\nTo the right.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:34,23 httpcore.connection DEBUG close.started
19:06:34,23 httpcore.connection DEBUG close.complete
19:06:34,24 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:34,26 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7fc90>
19:06:34,26 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:06:34,31 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243d7ead0>
19:06:34,32 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:34,33 httpcore.http11 DEBUG send_request_headers.complete
19:06:34,33 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:34,34 httpcore.http11 DEBUG send_request_body.complete
19:06:34,34 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:34,300 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'149'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'0ddfa16731c4ae7b4d27222bc48afb81'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900bebf0c6ac5-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:34,307 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:34,308 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:34,310 httpcore.http11 DEBUG receive_response_body.complete
19:06:34,310 httpcore.http11 DEBUG response_closed.started
19:06:34,311 httpcore.http11 DEBUG response_closed.complete
19:06:34,312 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:34,328 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:34,333 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:39,536 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:39,541 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:39,547 httpcore.connection DEBUG close.started
19:06:39,547 httpcore.connection DEBUG close.complete
19:06:39,548 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:39,550 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc7750>
19:06:39,551 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:39,558 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc6f50>
19:06:39,559 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:39,560 httpcore.http11 DEBUG send_request_headers.complete
19:06:39,560 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:39,561 httpcore.http11 DEBUG send_request_body.complete
19:06:39,561 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:40,15 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:40 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'384'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0aeb6b288e56d919359f1689fff77ed2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832900e14a354d0d-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:40,20 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:40,21 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:40,224 httpcore.http11 DEBUG receive_response_body.complete
19:06:40,225 httpcore.http11 DEBUG response_closed.started
19:06:40,226 httpcore.http11 DEBUG response_closed.complete
19:06:40,227 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:40,296 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent6.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:06:48,11 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent6.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:06:48,17 httpcore.connection DEBUG close.started
19:06:48,17 httpcore.connection DEBUG close.complete
19:06:48,17 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:48,20 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc1490>
19:06:48,20 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:48,26 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc1850>
19:06:48,26 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:48,27 httpcore.http11 DEBUG send_request_headers.complete
19:06:48,27 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:48,47 httpcore.http11 DEBUG send_request_body.complete
19:06:48,48 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:48,924 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:48 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'4'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'f18a096a7e1711fdce19e6c6c6222b0b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832901162afe4cc2-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:48,928 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:06:48,929 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:48,931 httpcore.http11 DEBUG receive_response_body.complete
19:06:48,931 httpcore.http11 DEBUG response_closed.started
19:06:48,932 httpcore.http11 DEBUG response_closed.complete
19:06:48,933 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:06:48,934 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:06:48,964 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nNo.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:06:48,967 httpcore.connection DEBUG close.started
19:06:48,967 httpcore.connection DEBUG close.complete
19:06:48,967 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:06:48,970 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd0950>
19:06:48,970 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:06:48,975 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dd1e50>
19:06:48,976 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:48,977 httpcore.http11 DEBUG send_request_headers.complete
19:06:48,977 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:48,978 httpcore.http11 DEBUG send_request_body.complete
19:06:48,978 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:49,196 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'682b7add316cb684eca57e0761a74c7f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329011c1c143074-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:49,202 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:06:49,203 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:49,204 httpcore.http11 DEBUG receive_response_body.complete
19:06:49,205 httpcore.http11 DEBUG response_closed.started
19:06:49,205 httpcore.http11 DEBUG response_closed.complete
19:06:49,206 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:06:49,222 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:06:49,225 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:06:54,427 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:06:54,434 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/speech', 'files': None, 'json_data': {'input': 'Is this a good location?', 'model': 'tts-1', 'voice': 'alloy', 'response_format': 'mp3'}}
19:06:54,438 httpcore.connection DEBUG close.started
19:06:54,438 httpcore.connection DEBUG close.complete
19:06:54,439 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:06:54,441 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc3a10>
19:06:54,442 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:06:54,447 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dc38d0>
19:06:54,447 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:06:54,448 httpcore.http11 DEBUG send_request_headers.complete
19:06:54,449 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:06:54,449 httpcore.http11 DEBUG send_request_body.complete
19:06:54,450 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:06:54,894 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:06:54 GMT'), (b'Content-Type', b'audio/mpeg'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'361'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'7f9da588ced1feb5a11bfc8e0b8aec1e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329013e4f763b81-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:06:54,898 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/speech "HTTP/1.1 200 OK"
19:06:54,899 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:06:55,183 httpcore.http11 DEBUG receive_response_body.complete
19:06:55,184 httpcore.http11 DEBUG response_closed.started
19:06:55,184 httpcore.http11 DEBUG response_closed.complete
19:06:55,185 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/speech "200 OK"
19:06:55,255 pydub.converter DEBUG subprocess.call(['ffmpeg', '-y', '-i', '/home/hrilab/helen/cake-decorating-preference/text2speech/Vincent7.wav', '-acodec', 'pcm_s16le', '-vn', '-f', 'wav', '-'])
19:07:02,917 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/audio/transcriptions', 'headers': {'Content-Type': 'multipart/form-data'}, 'files': [('file', SerializationIterator(index=0, iterator=<_io.BufferedReader name='speech2text/Vincent7.wav'>))], 'json_data': {'model': 'whisper-1', 'language': 'en', 'response_format': 'text'}}
19:07:02,923 httpcore.connection DEBUG close.started
19:07:02,923 httpcore.connection DEBUG close.complete
19:07:02,924 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
19:07:02,926 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2cd0>
19:07:02,926 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9dd90> server_hostname='api.openai.com' timeout=5.0
19:07:02,933 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243db2450>
19:07:02,934 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:02,936 httpcore.http11 DEBUG send_request_headers.complete
19:07:02,937 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:02,961 httpcore.http11 DEBUG send_request_body.complete
19:07:02,962 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:03,821 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:07:03 GMT'), (b'Content-Type', b'text/plain; charset=utf-8'), (b'Content-Length', b'5'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'336'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'50'), (b'x-ratelimit-remaining-requests', b'49'), (b'x-ratelimit-reset-requests', b'1.2s'), (b'x-request-id', b'0abb778d97b7ab6f4b7a6690c7fc2d9b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'832901735e784d17-BOS'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:03,826 httpx INFO HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "HTTP/1.1 200 OK"
19:07:03,826 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:03,827 httpcore.http11 DEBUG receive_response_body.complete
19:07:03,828 httpcore.http11 DEBUG response_closed.started
19:07:03,828 httpcore.http11 DEBUG response_closed.complete
19:07:03,829 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/audio/transcriptions "200 OK"
19:07:03,829 openai._response DEBUG Could not read JSON from response data due to <class 'json.decoder.JSONDecodeError'> - Expecting value: line 1 column 1 (char 0)
19:07:03,860 openai._base_client DEBUG Request options: {'method': 'post', 'url': '/completions', 'files': None, 'json_data': {'model': 'text-davinci-003', 'prompt': ["You are an assistant robot helping a human place candles on a cake. You asked \n'''\nIs this a good location?\n'''\nAnd the human answered\n'''\nYes.\n\n'''\nDetermine whether the human accepted your proposed location or whether the human wants you to move either left, right, up or down. Answer with either 'accept', 'left', 'right', 'up', or 'down' only.\nAnswer:\n"], 'frequency_penalty': 0, 'logit_bias': {}, 'max_tokens': 256, 'n': 1, 'presence_penalty': 0, 'temperature': 0.0, 'top_p': 1}}
19:07:03,863 httpcore.connection DEBUG close.started
19:07:03,864 httpcore.connection DEBUG close.complete
19:07:03,864 httpcore.connection DEBUG connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
19:07:03,867 httpcore.connection DEBUG connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243daaa90>
19:07:03,867 httpcore.connection DEBUG start_tls.started ssl_context=<ssl.SSLContext object at 0x7fe243f9deb0> server_hostname='api.openai.com' timeout=None
19:07:03,871 httpcore.connection DEBUG start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7fe243dab110>
19:07:03,872 httpcore.http11 DEBUG send_request_headers.started request=<Request [b'POST']>
19:07:03,873 httpcore.http11 DEBUG send_request_headers.complete
19:07:03,873 httpcore.http11 DEBUG send_request_body.started request=<Request [b'POST']>
19:07:03,873 httpcore.http11 DEBUG send_request_body.complete
19:07:03,874 httpcore.http11 DEBUG receive_response_headers.started request=<Request [b'POST']>
19:07:04,98 httpcore.http11 DEBUG receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 09 Dec 2023 00:07:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'text-davinci-003'), (b'openai-organization', b'user-tzqqoz8yhdcf4k0qioopmqhy'), (b'openai-processing-ms', b'127'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'250000'), (b'x-ratelimit-limit-tokens_usage_based', b'250000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'249744'), (b'x-ratelimit-remaining-tokens_usage_based', b'249744'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'61ms'), (b'x-ratelimit-reset-tokens_usage_based', b'61ms'), (b'x-request-id', b'560151d52e6f22bc122fc976618478f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8329017939f93021-BOS'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
19:07:04,102 httpx INFO HTTP Request: POST https://api.openai.com/v1/completions "HTTP/1.1 200 OK"
19:07:04,103 httpcore.http11 DEBUG receive_response_body.started request=<Request [b'POST']>
19:07:04,104 httpcore.http11 DEBUG receive_response_body.complete
19:07:04,105 httpcore.http11 DEBUG response_closed.started
19:07:04,106 httpcore.http11 DEBUG response_closed.complete
19:07:04,107 openai._base_client DEBUG HTTP Request: POST https://api.openai.com/v1/completions "200 OK"
19:07:04,124 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:07:04,128 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:09,330 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:07:09,349 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:07:09,353 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:14,556 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
19:07:14,575 urllib3.connectionpool DEBUG Starting new HTTP connection (1): localhost:8080
19:07:14,578 urllib3.connectionpool DEBUG http://localhost:8080 "POST / HTTP/1.1" 200 35
19:07:19,783 charset_normalizer DEBUG Encoding detection: ascii is most likely the one.
